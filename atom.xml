<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>白菜君の技术库</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.crazylaw.cn/"/>
  <updated>2023-08-28T09:26:57.958Z</updated>
  <id>http://blog.crazylaw.cn/</id>
  
  <author>
    <name>白菜(whiteCcinn)</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ssp-adx-localcache优化</title>
    <link href="http://blog.crazylaw.cn/2023/08/27/%E5%85%AC%E5%8F%B8/localcache/"/>
    <id>http://blog.crazylaw.cn/2023/08/27/%E5%85%AC%E5%8F%B8/localcache/</id>
    <published>2023-08-27T01:53:00.000Z</published>
    <updated>2023-08-28T09:26:57.958Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近在处理<code>ssp-adx-rtb</code>的服务的性能优化，做了好多方面的优化，其中一个就是我们的本地的<code>localcache</code>的问题。</p><p>经过<code>pprof</code>的性能分析，发现<code>cache2go</code>，在 <code>CPU Flame Graph</code> 中，占比十分严重，基本大于<code>1/3</code>，既然是<code>localcache</code>，那么，我们的目的本意就是为了提速，所以占比那么大，是十分不合理的。</p><p>所以需要找到原因，并且解决它。降低cpu使用率，从而提高服务的QPS，减少服务器成本。</p><a id="more"></a><h2 id="cache2go旧版"><a href="#cache2go旧版" class="headerlink" title="cache2go旧版"></a>cache2go旧版</h2><ul><li><a href="https://github.com/muesli/cache2go" target="_blank" rel="noopener">cache2go</a></li><li><a href="https://github.com/muesli/cache2go" target="_blank" rel="noopener">https://github.com/muesli/cache2go</a></li></ul><p>项目的描述为：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Concurrency-safe Go caching library with expiration capabilities and access counters</span><br></pre></td></tr></table></figure><p>并发安全，并且带有效期的和访问计数器的一个类库组件</p><p>我们需要用他来解决我们的3大核心问题</p><ul><li>本地缓存</li><li>并发安全</li><li>带ttl功能</li></ul><p>对于开源版本第一版本，我们已经做为处理了。</p><p>就是他的淘汰策略，是<code>ttl+lru</code>，当一个缓存在一定时间内被连续访问，或者在一个key，准备过期的时候，如果被访问，那么他的过期时间将继续延长到下一个周期。</p><p>这一特点，并不是我们需求，所以我们需要对这一点进行了调整，过期时间，只需要判断为 <code>ttl</code> 过期即可，不需要加上 <code>lru</code> 的方式。</p><p>这里就不展开细说。</p><h2 id="cache2go新版"><a href="#cache2go新版" class="headerlink" title="cache2go新版"></a>cache2go新版</h2><ul><li><a href="https://github.com/whiteCcinn/cache2go" target="_blank" rel="noopener">cache2go-new</a></li><li><a href="https://github.com/whiteCcinn/cache2go" target="_blank" rel="noopener">https://github.com/whiteCcinn/cache2go</a></li></ul><p><img src="/images/%E5%85%AC%E5%8F%B8/localcache.jpg" alt="localcache"></p><p>在这一个版本，基本把整个库都按需重构了。主要是以下几个方面。</p><ul><li>加入<code>hash分片</code>机制，把key打散到不同的<code>bucket</code>中，让<code>bucket-lock</code>的争抢降低</li><li>同一个<code>cache-table</code>，有且仅有一个<code>goroutine</code>，来处理 <code>ttl</code> 数据，并不会因为分片的个数调整带来更多的无效<code>goroutine</code></li><li>没有采用渐进式的方式来删除key, 在 <code>add</code>, <code>get</code> 的阶段，尽量保持服务的高效性能，方式由于锁带来的性能衰减</li><li>采用<code>双写机制</code>，实现<code>L1</code>和<code>L2</code>的二级包装级别，从而做到 <code>读写分离</code>, 尽可能的避免在必要的场景下由于<code>整个写锁</code>导致<code>读锁阻塞</code>的问题，让后台在处理 <code>ttl</code> 和 <code>重建map</code>的过程中，服务依然高效提供服务</li><li>定期重建底层<code>map</code>属性，来释放map申请的内存，让整个服务相对处于一个内存稳定的状态</li></ul><p>为了实现这几点：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> CacheTable <span class="keyword">struct</span> &#123;</span><br><span class="line">sync.RWMutex</span><br><span class="line"></span><br><span class="line">hash *fnv64a          <span class="comment">// 用于hash</span></span><br><span class="line">shardMask <span class="keyword">uint64</span>      <span class="comment">// 用于hash的mask，在做按位与操作的时候，实现求余一样的行为，由于是位运算，效率一般都偏高</span></span><br><span class="line"></span><br><span class="line">name <span class="keyword">string</span>           <span class="comment">// cache的命名</span></span><br><span class="line"></span><br><span class="line">L1Shards  shardItems  <span class="comment">// L1的分片组</span></span><br><span class="line">L2Shards  shardItems  <span class="comment">// L2的分片组</span></span><br><span class="line"></span><br><span class="line">cleanupInterval time.Duration  <span class="comment">// 定时处理ttl的数据</span></span><br><span class="line"></span><br><span class="line">l1BlockChan []*CacheItem <span class="comment">// 用于在L1分片组被后台处理过程中，暂时把数据缓存起来</span></span><br><span class="line">l2BlockChan []*CacheItem <span class="comment">// 用于在L2分片组被后台处理过程中，暂时把数据缓存起来</span></span><br><span class="line"></span><br><span class="line">l1Mask <span class="keyword">int32</span> <span class="comment">// L1原子计数器，用来代替lock，防止lock的堵塞现象，导致服务被影响</span></span><br><span class="line">l2Mask <span class="keyword">int32</span> <span class="comment">// L2原子计数器，用来代替lock，防止lock的堵塞现象，导致服务被影响</span></span><br><span class="line"></span><br><span class="line">switchMask <span class="keyword">uint8</span> <span class="comment">// 记录当前 cache-table是否在处理L1,L2分片组</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Add"><a href="#Add" class="headerlink" title="Add"></a>Add</h3><p>这是一个写入过程，实现起来也不算太复杂</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *CacheTable)</span> <span class="title">Add</span><span class="params">(key <span class="keyword">interface</span>&#123;&#125;, lifeSpan time.Duration, data <span class="keyword">interface</span>&#123;&#125;)</span> *<span class="title">CacheItem</span></span> &#123;</span><br><span class="line">item := NewCacheItem(key, lifeSpan, data)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断当前表是否在处理L1</span></span><br><span class="line"><span class="keyword">if</span> table.switchMask != <span class="number">1</span>&lt;&lt;<span class="number">1</span> &#123;</span><br><span class="line">        <span class="comment">// 记录L1正在处理写入行为，+1操作</span></span><br><span class="line">atomic.AddInt32(&amp;table.l1Mask, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">// 结束的时候L1写入的时候，-1操作</span></span><br><span class="line"><span class="keyword">defer</span> atomic.AddInt32(&amp;table.l1Mask, <span class="number">-1</span>)</span><br><span class="line">        <span class="comment">// L1内部分片片级写锁开发</span></span><br><span class="line">table.L1Shards[item.hashedKey&amp;table.shardMask].lock.Lock()</span><br><span class="line">        <span class="comment">// L1内部分片写入item</span></span><br><span class="line">table.L1Shards[item.hashedKey&amp;table.shardMask].m[item.key] = item</span><br><span class="line">        <span class="comment">// L1内部分片片级写锁结束</span></span><br><span class="line">table.L1Shards[item.hashedKey&amp;table.shardMask].lock.Unlock()</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 如果当前后台在处理L1的话，那么先缓存起来</span></span><br><span class="line">table.l1BlockChan = <span class="built_in">append</span>(table.l1BlockChan, item)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 判断当前表是否在处理L2</span></span><br><span class="line"><span class="keyword">if</span> table.switchMask != <span class="number">1</span>&lt;&lt;<span class="number">2</span> &#123;</span><br><span class="line">        <span class="comment">// 记录L2正在处理写入行为，+1操作</span></span><br><span class="line">atomic.AddInt32(&amp;table.l2Mask, <span class="number">1</span>)</span><br><span class="line">        <span class="comment">// 结束的时候L2写入的时候，-1操作</span></span><br><span class="line"><span class="keyword">defer</span> atomic.AddInt32(&amp;table.l2Mask, <span class="number">-1</span>)</span><br><span class="line">        <span class="comment">// L2内部分片片级写锁开发</span></span><br><span class="line">table.L2Shards[item.hashedKey&amp;table.shardMask].lock.Lock()</span><br><span class="line">        <span class="comment">// L2内部分片写入item</span></span><br><span class="line">table.L2Shards[item.hashedKey&amp;table.shardMask].m[item.key] = item</span><br><span class="line">        <span class="comment">// L2内部分片片级写锁结束</span></span><br><span class="line">table.L2Shards[item.hashedKey&amp;table.shardMask].lock.Unlock()</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// 如果当前后台在处理L2的话，那么先缓存起来</span></span><br><span class="line">table.l2BlockChan = <span class="built_in">append</span>(table.l2BlockChan, item)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> item</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>通过双写的方式，实现<code>L1</code>和<code>L2</code>的同时写入,以此达到空间换时间的做法。</p><p>其中 <code>(&amp; 2^(n-1))</code> 做到 <code>(%m)</code>的效果，并且由于是位运算，所以按理说效率会更高</p><h3 id="Value"><a href="#Value" class="headerlink" title="Value"></a>Value</h3><blockquote><p>Value 和 就是Get方法，获取key的item</p></blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(table *CacheTable)</span> <span class="title">Value</span><span class="params">(key <span class="keyword">interface</span>&#123;&#125;, args ...<span class="keyword">interface</span>&#123;&#125;)</span> <span class="params">(*CacheItem, error)</span></span> &#123;</span><br><span class="line">keyBytes, _ := json.Marshal(key)</span><br><span class="line">    <span class="comment">// 哈希的key</span></span><br><span class="line">hashedKey := table.hash.Sum64(<span class="keyword">string</span>(keyBytes))</span><br><span class="line"><span class="keyword">var</span> sm *shardItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> table.switchMask == <span class="number">1</span>&gt;&gt;<span class="number">1</span> &#123;</span><br><span class="line"><span class="comment">// 先查l1</span></span><br><span class="line">sm = table.L1Shards[hashedKey&amp;table.shardMask]</span><br><span class="line">sm.lock.RLock()</span><br><span class="line">r, ok := sm.m[key]</span><br><span class="line">sm.lock.RUnlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line"><span class="comment">// 正常返回结果</span></span><br><span class="line"><span class="keyword">return</span> r, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 再查l2</span></span><br><span class="line">sm = table.L2Shards[hashedKey&amp;table.shardMask]</span><br><span class="line">sm.lock.RLock()</span><br><span class="line">r, ok = sm.m[key]</span><br><span class="line">sm.lock.RUnlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line"><span class="comment">// 正常返回结果</span></span><br><span class="line"><span class="keyword">return</span> r, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 找不到key</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, ErrKeyNotFound</span><br><span class="line"></span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> table.switchMask == <span class="number">1</span>&lt;&lt;<span class="number">1</span> &#123;</span><br><span class="line"><span class="comment">// 正在处理l1，需要从l2读</span></span><br><span class="line">sm = table.L2Shards[hashedKey&amp;table.shardMask]</span><br><span class="line">sm.lock.RLock()</span><br><span class="line">r, ok := sm.m[key]</span><br><span class="line">sm.lock.RUnlock()</span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line"><span class="comment">// 正常返回结果</span></span><br><span class="line"><span class="keyword">return</span> r, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 找不到key</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, ErrKeyNotFound</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">// 正在处理l2，需要从l1读</span></span><br><span class="line">sm = table.L1Shards[hashedKey&amp;table.shardMask]</span><br><span class="line">sm.lock.RLock()</span><br><span class="line">r, ok := sm.m[key]</span><br><span class="line">sm.lock.RUnlock()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> ok &#123;</span><br><span class="line"><span class="comment">// 正常返回结果</span></span><br><span class="line"><span class="keyword">return</span> r, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 找不到key</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, ErrKeyNotFound</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>可以看到这里，如果后台没有在操作<code>L1</code>, <code>L2</code> 的话，那么先从<code>L1</code>拿数据，然后再从<code>L2</code>拿数据</li><li>如果后台在<code>操作L1</code>, 那么只能从 <code>L2</code> 读取</li><li>如果后台在<code>操作L2</code>, 那么只能从 <code>L1</code> 读取</li></ul><p>所以通过<code>L1</code>和<code>L2</code>，我们实现了一个读写分离的策略，并且在最大的程度上减少<code>分片锁</code>的读写锁冲突，从而提高服务的效率</p><h2 id="后台任务"><a href="#后台任务" class="headerlink" title="后台任务"></a>后台任务</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 定时清理过期缓存</span></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(t *CacheTable, ctx context.Context)</span></span> &#123;</span><br><span class="line">    <span class="comment">// 定时监测ttl数据</span></span><br><span class="line">    ticker := time.NewTicker(cleanInterval)</span><br><span class="line">    <span class="comment">// 定期重建map，以此来释放map申请的空间</span></span><br><span class="line">    reBuildTicker := time.NewTicker(<span class="number">30</span> * time.Minute)</span><br><span class="line">    <span class="keyword">for</span> &#123;</span><br><span class="line">        <span class="keyword">select</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> &lt;-ctx.Done():</span><br><span class="line">            ticker.Stop()</span><br><span class="line">            reBuildTicker.Stop()</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">case</span> &lt;-ticker.C:</span><br><span class="line">            <span class="comment">// 表锁</span></span><br><span class="line">            t.Lock()</span><br><span class="line">            <span class="comment">// 扫描需要删除的key</span></span><br><span class="line">            <span class="keyword">var</span> deleteList []*CacheItem</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 先处理l1，再处理l2</span></span><br><span class="line">            t.switchMask = <span class="number">1</span> &lt;&lt; <span class="number">1</span></span><br><span class="line">            now := time.Now()</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 处理l1</span></span><br><span class="line">            <span class="comment">// 不允许l1读写入，读写通过l2</span></span><br><span class="line">            <span class="keyword">for</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> atomic.LoadInt32(&amp;t.l1Mask) == <span class="number">0</span> &#123;</span><br><span class="line">                    <span class="comment">// 当L1已经操作完Add操作的时候继续往下走</span></span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">for</span> i, sad := <span class="keyword">range</span> t.L1Shards &#123;</span><br><span class="line">                <span class="comment">// 分片片级别读锁</span></span><br><span class="line">                sad.lock.RLock()</span><br><span class="line">                <span class="keyword">for</span> _, r := <span class="keyword">range</span> sad.m &#123;</span><br><span class="line">                    <span class="comment">// ttl数据校验处理</span></span><br><span class="line">                    <span class="keyword">if</span> now.Sub(r.createdOn).Seconds() &gt; r.lifeSpan.Seconds() &#123;</span><br><span class="line">                        deleteList = <span class="built_in">append</span>(deleteList, r)</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                sad.lock.RUnlock()</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 开始删除</span></span><br><span class="line">            <span class="keyword">for</span> _, item := <span class="keyword">range</span> deleteList &#123;</span><br><span class="line">                <span class="comment">// 分片片级别写锁，防止在 Value操作的时候，并行读写异常</span></span><br><span class="line">                t.L1Shards[item.hashedKey&amp;t.shardMask].lock.Lock()</span><br><span class="line">                <span class="built_in">delete</span>(t.L1Shards[item.hashedKey&amp;t.shardMask].m, item.key)</span><br><span class="line">                t.L1Shards[item.hashedKey&amp;t.shardMask].lock.Unlock()</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 重置deleteList</span></span><br><span class="line">            deleteList = <span class="built_in">make</span>([]*CacheItem, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 处理完l1,处理l2</span></span><br><span class="line">            t.switchMask = <span class="number">1</span> &lt;&lt; <span class="number">2</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 堵塞的item加回来到l1</span></span><br><span class="line">            l1Length := <span class="built_in">len</span>(t.l1BlockChan)</span><br><span class="line">            <span class="keyword">for</span> _, item := <span class="keyword">range</span> t.l1BlockChan &#123;</span><br><span class="line">                <span class="keyword">if</span> item != <span class="literal">nil</span> &#123;</span><br><span class="line">                    t.L1Shards[item.hashedKey&amp;t.shardMask].lock.Lock()</span><br><span class="line">                    t.L1Shards[item.hashedKey&amp;t.shardMask].m[item.key] = item</span><br><span class="line">                    t.L1Shards[item.hashedKey&amp;t.shardMask].lock.Unlock()</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 重置l1BlockChan, 预先申请大小为原来到一半</span></span><br><span class="line">            t.l1BlockChan = <span class="built_in">make</span>([]*CacheItem, <span class="number">0</span>, l1Length/<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 不允许l2读写入，读写通过l1</span></span><br><span class="line">            <span class="keyword">for</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> atomic.LoadInt32(&amp;t.l2Mask) == <span class="number">0</span> &#123;</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i, sad := <span class="keyword">range</span> t.L2Shards &#123;</span><br><span class="line">                sad.lock.RLock()</span><br><span class="line">                <span class="keyword">for</span> _, r := <span class="keyword">range</span> sad.m &#123;</span><br><span class="line">                    <span class="keyword">if</span> now.Sub(r.createdOn).Seconds() &gt; r.lifeSpan.Seconds() &#123;</span><br><span class="line">                        deleteList = <span class="built_in">append</span>(deleteList, r)</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                sad.lock.RUnlock()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 开始删除</span></span><br><span class="line">            <span class="keyword">for</span> _, item := <span class="keyword">range</span> deleteList &#123;</span><br><span class="line">                t.L2Shards[item.hashedKey&amp;t.shardMask].lock.Lock()</span><br><span class="line">                <span class="built_in">delete</span>(t.L2Shards[item.hashedKey&amp;t.shardMask].m, item.key)</span><br><span class="line">                t.L2Shards[item.hashedKey&amp;t.shardMask].lock.Unlock()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 恢复正常</span></span><br><span class="line">            t.switchMask = <span class="number">1</span> &gt;&gt; <span class="number">1</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> _, item := <span class="keyword">range</span> t.l2BlockChan &#123;</span><br><span class="line">                <span class="comment">//fmt.Println(t.name, t.L1Shards[item.hashedKey&amp;t.shardMask])</span></span><br><span class="line">                <span class="keyword">if</span> item != <span class="literal">nil</span> &#123;</span><br><span class="line">                    t.L2Shards[item.hashedKey&amp;t.shardMask].lock.Lock()</span><br><span class="line">                    t.L2Shards[item.hashedKey&amp;t.shardMask].m[item.key] = item</span><br><span class="line">                    t.L2Shards[item.hashedKey&amp;t.shardMask].lock.Unlock()</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 重置l2BlockChan</span></span><br><span class="line">            t.l2BlockChan = <span class="built_in">make</span>([]*CacheItem, <span class="number">0</span>, l2Length/<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">            t.Unlock()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">case</span> &lt;-reBuildTicker.C:</span><br><span class="line">            t.Lock()</span><br><span class="line">            <span class="comment">// 为了释放map内存</span></span><br><span class="line"></span><br><span class="line">            <span class="comment">// 先处理l1，再处理l2</span></span><br><span class="line">            t.switchMask = <span class="number">1</span> &lt;&lt; <span class="number">1</span></span><br><span class="line">            now := time.Now()</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 处理l1</span></span><br><span class="line">            <span class="comment">// 不允许l1读写入，读写通过l2</span></span><br><span class="line">            <span class="keyword">for</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> atomic.LoadInt32(&amp;t.l1Mask) == <span class="number">0</span> &#123;</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> _, sad := <span class="keyword">range</span> t.L1Shards &#123;</span><br><span class="line">                sad.lock.Lock()</span><br><span class="line">                nm := <span class="built_in">make</span>(shard, <span class="built_in">len</span>(sad.m))</span><br><span class="line">                <span class="keyword">for</span> key, r := <span class="keyword">range</span> sad.m &#123;</span><br><span class="line">                    <span class="keyword">if</span> now.Sub(r.createdOn).Seconds() &lt; r.lifeSpan.Seconds() &#123;</span><br><span class="line">                        nm[key] = r</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                sad.m = <span class="literal">nil</span></span><br><span class="line">                sad.m = nm</span><br><span class="line">                sad.lock.Unlock()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 先处理l1，再处理l2</span></span><br><span class="line">            t.switchMask = <span class="number">1</span> &lt;&lt; <span class="number">2</span></span><br><span class="line">            <span class="keyword">for</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> atomic.LoadInt32(&amp;t.l2Mask) == <span class="number">0</span> &#123;</span><br><span class="line">                    <span class="keyword">break</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> _, sad := <span class="keyword">range</span> t.L2Shards &#123;</span><br><span class="line">                sad.lock.Lock()</span><br><span class="line">                nm := <span class="built_in">make</span>(shard, <span class="built_in">len</span>(sad.m))</span><br><span class="line">                <span class="keyword">for</span> key, r := <span class="keyword">range</span> sad.m &#123;</span><br><span class="line">                    <span class="keyword">if</span> now.Sub(r.createdOn).Seconds() &lt; r.lifeSpan.Seconds() &#123;</span><br><span class="line">                        nm[key] = r</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                sad.m = <span class="literal">nil</span></span><br><span class="line">                sad.m = nm</span><br><span class="line">                sad.lock.Unlock()</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 恢复正常</span></span><br><span class="line">            t.switchMask = <span class="number">1</span> &gt;&gt; <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            runtime.GC()</span><br><span class="line">            debug.FreeOSMemory()</span><br><span class="line">            t.Unlock()</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;(t, ctx)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近在处理&lt;code&gt;ssp-adx-rtb&lt;/code&gt;的服务的性能优化，做了好多方面的优化，其中一个就是我们的本地的&lt;code&gt;localcache&lt;/code&gt;的问题。&lt;/p&gt;
&lt;p&gt;经过&lt;code&gt;pprof&lt;/code&gt;的性能分析，发现&lt;code&gt;cache2go&lt;/code&gt;，在 &lt;code&gt;CPU Flame Graph&lt;/code&gt; 中，占比十分严重，基本大于&lt;code&gt;1/3&lt;/code&gt;，既然是&lt;code&gt;localcache&lt;/code&gt;，那么，我们的目的本意就是为了提速，所以占比那么大，是十分不合理的。&lt;/p&gt;
&lt;p&gt;所以需要找到原因，并且解决它。降低cpu使用率，从而提高服务的QPS，减少服务器成本。&lt;/p&gt;
    
    </summary>
    
    
      <category term="组件优化" scheme="http://blog.crazylaw.cn/categories/%E7%BB%84%E4%BB%B6%E4%BC%98%E5%8C%96/"/>
    
    
      <category term="cache" scheme="http://blog.crazylaw.cn/tags/cache/"/>
    
  </entry>
  
  <entry>
    <title>Home Assistant （二）</title>
    <link href="http://blog.crazylaw.cn/2023/08/01/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/Home-Assistant2/"/>
    <id>http://blog.crazylaw.cn/2023/08/01/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/Home-Assistant2/</id>
    <published>2023-07-31T16:00:19.000Z</published>
    <updated>2023-08-02T16:45:58.961Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本次主要是讲解一下进阶版的<code>HA</code>，为什么说是进阶版本呢，因为我也是花了几天的时候，去了解各种知识才了解得到的内容。</p><p>内容包括：什么叫<code>hassio</code>，<code>hassos</code>，并且他们和<code>Home Assistant</code> 是什么关系。</p><p>并且我会重点讲解<code>docker版本</code>的<code>HA</code>都是需要怎么玩（<code>不借助hassio</code>），你问我为什么，我就告诉你因为过于繁琐，并且多了很多无用的容器占用系统资源。</p><p>为什么我偏执于<code>docker版本的ha</code>？因为我不想一台机器，只做一件事，这对高配置和高性能的机器是一种绝对的浪费。</p><p>在这个时候，<code>环境隔离</code>就成了<code>重要的因素</code>, 而<code>docker</code>就很好的做到了这一点，并且不像<code>hassio</code>的底层依赖。</p><a id="more"></a><h2 id="MQTT"><a href="#MQTT" class="headerlink" title="MQTT"></a>MQTT</h2><blockquote><p>什么是MQTT协议，这个得大家去了解了，这里我只和大家说，这是一个开源的发布订阅的简易协议<br>它可以做到服务发现的功能，也可以做到事件通知等等<br>它是传统的物联网大家都会选择的一个协议</p></blockquote><p>这里，我们需要安装一个<code>MQTT的服务器</code>，这个项目就是如下</p><ul><li><code>eclipse-mosquitto</code> (<a href="https://github.com/eclipse/mosquitto" target="_blank" rel="noopener">https://github.com/eclipse/mosquitto</a>) (<a href="https://hub.docker.com/r/amd64/eclipse-mosquitto" target="_blank" rel="noopener">https://hub.docker.com/r/amd64/eclipse-mosquitto</a>)</li></ul><p>这是一个一个由于C语言实现的MQTT协议的服务器，但是我们不直接用他。我们借助<code>docker</code>的特性，用docker来安装。</p><p>插一个题外话，其实<code>Home Assistant</code>的 <code>ADD-ON</code> 功能，也是创建一些服务的容器，所以我们手动操作，也是一样的。这个时候就是解答有一些小伙伴经常会纠结的一个问题，为什么我用docker安装的<code>HA</code>，它不存在 <code>Add-on</code> 这个加载项，我要怎么使用这个功能。答案就是：手动处理。当然如果你有编程能力的话，也可以做成一个自动化脚本，这也是我接下来准备做的。</p><p>好的，话不多说，我们继续我们的操作，基于 <code>docker</code> 安装 <code>eclipse-mosquitto</code> 服务。</p><p>找到一个目录，接着执行如下命令创建目录</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p ~/ha/mqtt/config</span><br><span class="line">mkdir -p ~/ha/mqtt/data</span><br><span class="line">mkdir -p ~/ha/mqtt/log</span><br></pre></td></tr></table></figure><p>在 <code>~/ha/mqtt/config</code> 目录下创建配置文件 <code>mosquitto.conf</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim mosquitto.conf</span><br></pre></td></tr></table></figure><p>内容如下，主要分别是需要持久化数据，存储的路径是容器内部的路径</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 是否允许未提供用户名的客户端进行连接</span></span><br><span class="line">allow_anonymous true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 0.0.0.0很重要，否则你的宿主机转发的端口，也无法被mqtt接收到</span></span><br><span class="line">listener 1883 0.0.0.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 是否持久化数据</span></span><br><span class="line">persistence true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 持久化数据的路径</span></span><br><span class="line">persistence_location /mosquitto/data</span><br><span class="line"><span class="meta">#</span><span class="bash"> 落盘日志</span></span><br><span class="line">log_dest file /mosquitto/log/mosquitto.log</span><br></pre></td></tr></table></figure><p>具体配置文档 <code>https://mosquitto.org/man/mosquitto-conf-5.html</code></p><p>最后执行如下命令即可启动 <code>mosquitto 容器</code>：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run -d --name=mosquitto --privileged</span><br><span class="line">-p 1883:1883 \</span><br><span class="line">-v $(PWD)/config/mosquitto.conf:/mosquitto/config/mosquitto.conf \</span><br><span class="line">-v $(PWD)/data:/mosquitto/data \</span><br><span class="line">-v $(PWD)/log:/mosquitto/log \</span><br><span class="line">eclipse-mosquitto</span><br></pre></td></tr></table></figure><blockquote><p>我的 <code>$(PWD)</code>代表当前目录，你可以改成上面的 <code>~/ha/mqtt/</code>目录</p></blockquote><p>查看容器是否启动：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CONTAINER ID   IMAGE                          COMMAND                  CREATED          STATUS          PORTS                                                                      NAMES</span><br><span class="line">b4a8f33dc8b2   eclipse-mosquitto              "/docker-entrypoint.…"   17 seconds ago   Up 17 seconds   0.0.0.0:1883-&gt;1883/tcp      mosquitto</span><br></pre></td></tr></table></figure><p>查看日志信息:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tail log/mosquitto.log</span><br><span class="line">1690908079: mosquitto version 2.0.15 starting</span><br><span class="line">1690908079: Config loaded from /mosquitto/config/mosquitto.conf.</span><br><span class="line">1690908079: Starting in local only mode. Connections will only be possible from clients running on this machine.</span><br><span class="line">1690908079: Create a configuration file which defines a listener to allow remote access.</span><br><span class="line">1690908079: For more details see https://mosquitto.org/documentation/authentication-methods/</span><br><span class="line">1690908079: Opening ipv4 listen socket on port 1883.</span><br><span class="line">1690908079: Opening ipv6 listen socket on port 1883.</span><br><span class="line">1690908079: Error: Address not available</span><br><span class="line">1690908079: mosquitto version 2.0.15 running</span><br></pre></td></tr></table></figure><p>OK，我们看到一切正常。</p><p>让我们来测试一下是不是真的ok了。</p><p>我们同样，用2个容器，分别创建<code>发布者</code>和<code>订阅者</code></p><blockquote><p>由于我的是macbook，所以我的容器可以通过<code>host.docker.internal</code>来访问宿主机，如果是linux环境下的，可以使用 <code>--net host</code> 模式</p></blockquote><p>订阅者（窗口1）:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it eclipse-mosquitto sh -c 'mosquitto_sub -h host.docker.internal -p 1883 -t "#" -v'</span><br></pre></td></tr></table></figure><blockquote><p>对应的参数就不一一解释了</p></blockquote><p>发布者（窗口2）:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it eclipse-mosquitto sh -c 'mosquitto_pub -h host.docker.internal -p 1883 -t "test/testdevice"  -m caiwenhui-hello'</span><br></pre></td></tr></table></figure><p>回到<code>窗口1</code>查看订阅者的情况</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm -it eclipse-mosquitto sh -c 'mosquitto_sub -h host.docker.internal -p 1883 -t "#" -v'                                                                         </span><br><span class="line">test/testdevice caiwenhui-hello</span><br></pre></td></tr></table></figure><p>可以看见，我们的消息和对应的topic都正常接受到了。非常好！</p><p>接下来，我们接入我们的<code>HA</code>！！</p><h2 id="让HA和MQTT连接"><a href="#让HA和MQTT连接" class="headerlink" title="让HA和MQTT连接"></a>让HA和MQTT连接</h2><p>我们打开回到我们的HA, <code>http://127.0.0.1:8123</code></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt1.jpg" alt="mqtt1"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt2.jpg" alt="mqtt2"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt3.jpg" alt="mqtt3"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt4.jpg" alt="mqtt4"></p><p>由于我这里没有账号密码，并且允许匿名发送，所以这里可以先忽视这些，正常的情况下，我们需要设置，<code>否则一旦mqtt被破解</code>，被发送<code>恶意指令</code>，可能会让你的设备<code>“发疯”</code></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt5.jpg" alt="mqtt5"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt6.jpg" alt="mqtt6"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt7.jpg" alt="mqtt7"></p><p>看到这里，我们配置完成了。接下里，就是在HA里面测试是否真的配置正确并且可通的了。</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt8.jpg" alt="mqtt8"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt9.jpg" alt="mqtt9"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt10.jpg" alt="mqtt10"></p><p>可以看到关键信息: <code>i am ha&#39;s caiwenhui</code> , 是因为我在我的电脑发送的消息<code>被HA接收到了</code></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/mqtt11.jpg" alt="mqtt11"></p><p>可以看到，这个图，代表，我接收到了从ha系统发出的消息。ok，我们ha和mqtt的连接在不借助 <code>hassio</code> 和 <code>add-on</code>的情况下已经打通了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;本次主要是讲解一下进阶版的&lt;code&gt;HA&lt;/code&gt;，为什么说是进阶版本呢，因为我也是花了几天的时候，去了解各种知识才了解得到的内容。&lt;/p&gt;
&lt;p&gt;内容包括：什么叫&lt;code&gt;hassio&lt;/code&gt;，&lt;code&gt;hassos&lt;/code&gt;，并且他们和&lt;code&gt;Home Assistant&lt;/code&gt; 是什么关系。&lt;/p&gt;
&lt;p&gt;并且我会重点讲解&lt;code&gt;docker版本&lt;/code&gt;的&lt;code&gt;HA&lt;/code&gt;都是需要怎么玩（&lt;code&gt;不借助hassio&lt;/code&gt;），你问我为什么，我就告诉你因为过于繁琐，并且多了很多无用的容器占用系统资源。&lt;/p&gt;
&lt;p&gt;为什么我偏执于&lt;code&gt;docker版本的ha&lt;/code&gt;？因为我不想一台机器，只做一件事，这对高配置和高性能的机器是一种绝对的浪费。&lt;/p&gt;
&lt;p&gt;在这个时候，&lt;code&gt;环境隔离&lt;/code&gt;就成了&lt;code&gt;重要的因素&lt;/code&gt;, 而&lt;code&gt;docker&lt;/code&gt;就很好的做到了这一点，并且不像&lt;code&gt;hassio&lt;/code&gt;的底层依赖。&lt;/p&gt;
    
    </summary>
    
    
      <category term="智能家居" scheme="http://blog.crazylaw.cn/categories/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/"/>
    
    
      <category term="智能家居" scheme="http://blog.crazylaw.cn/tags/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/"/>
    
      <category term="Home Assistant" scheme="http://blog.crazylaw.cn/tags/Home-Assistant/"/>
    
      <category term="HA" scheme="http://blog.crazylaw.cn/tags/HA/"/>
    
  </entry>
  
  <entry>
    <title>Home Assistant （一）</title>
    <link href="http://blog.crazylaw.cn/2023/07/30/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/Home-Assistant/"/>
    <id>http://blog.crazylaw.cn/2023/07/30/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/Home-Assistant/</id>
    <published>2023-07-29T16:00:19.000Z</published>
    <updated>2023-08-01T16:22:01.707Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>既然是技术博客，那么这一期，我会开始做一系列的关于智能家居的玩法。</p><p><code>Home Assistant</code> 也叫 <code>HA</code> + <code>Zigbee协议</code>(硬件之间的通信协议)</p><p><code>HACS</code> 是 <code>HA</code> 的一个第三方插件，这个插件包括了许多开发者所贡献的插件，如果你是一名开发人员，那么你一定了解什么叫<code>依赖库</code>。所以可以理解为 <code>HACS</code> 就是 <code>HA</code> 的第三方插件依赖库，你可以在连找到需要对你有用的插件，而你不必重新开发。</p><p>为什么选择 <code>Zigbee协议</code> ？ 在对比过<code>蓝牙mesh</code>,<code>wifi协议</code>之后，我最终选择了<code>zigbee协议</code>，在于硬件之间的控制信号量传输本身就少，所以它自身的稳定性和分布式的特点，可以很好的支持到家庭中的各个角落，不会出现由于信号差导致失灵的情况，并且<code>zigbee协议</code>的特点，电量的消耗也是十分的低。</p><a id="more"></a><h2 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h2><p>由于我现在没有<code>树莓派</code>或者<code>nas</code>等<code>本地服务器</code>，所以我以我的<code>macbook pro</code>来例。但是实际情况下的智能家居，我们需要有一台连接在本地局域网的服务，它需要要求的特点包括如下：</p><ul><li>低功耗</li><li>便携，不占用家庭空间</li><li>支持更多的其他功能，例如用于<code>nas</code>，<code>time machine</code>, <code>软路由(科学上学)</code> 等等（非必要，但是可以做在一起，所以机器的性能越出色越好）</li></ul><p>由于是测试用的，所以我只买了2个 <code>涂鸦</code> 品牌的 <code>e27</code> 的<code>智能灯泡</code> 和 <code>zigbee2mqtt</code> 的 <code>zigbee协议信号网关</code></p><p>** 需要去淘宝买 **</p><ul><li><code>zigbee信号网关</code></li><li><code>2个智能灯泡</code></li></ul><h3 id="zigbee信号网关"><a href="#zigbee信号网关" class="headerlink" title="zigbee信号网关"></a>zigbee信号网关</h3><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/y5.jpg" alt="y-5"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/y6.jpg" alt="y-6"></p><h3 id="支持zigbee协议的智能灯泡"><a href="#支持zigbee协议的智能灯泡" class="headerlink" title="支持zigbee协议的智能灯泡"></a>支持zigbee协议的智能灯泡</h3><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/y-1.jpg" alt="y-1"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/y2.jpg" alt="y-2"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/y3.jpg" alt="y-3"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/y4.jpg" alt="y-4"></p><h2 id="Home-Assistant-安装"><a href="#Home-Assistant-安装" class="headerlink" title="Home Assistant 安装"></a>Home Assistant 安装</h2><p>由于目前我在尝试阶段，并且是<code>macbook</code>，并且我更倾向于用<code>docker安装</code>各种服务，在容器化的时代，物理环境的隔离是十分重要的一个环节。</p><h3 id="docker-安装"><a href="#docker-安装" class="headerlink" title="docker 安装"></a>docker 安装</h3><blockquote><p>这里不介绍docker怎么安装了，如果是完全没编程的基础知识的话，折腾起来确实有点麻烦</p></blockquote><p>创建数据存储目录，<code>mkdir -p ~/ha;cd ~/ha</code>，然后执行如下 docker命令 进行安装</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run -d \</span><br><span class="line">  --name homeassistant \</span><br><span class="line">  --privileged \</span><br><span class="line">  -e TZ=Asia/Shanghai \</span><br><span class="line">  -v $(PWD):/config \</span><br><span class="line">  -p 8123:8123 \</span><br><span class="line">  homeassistant/home-assistant</span><br></pre></td></tr></table></figure><blockquote><p>网上很多都说要用–net=host模式，但是其实没必要的，指定端口暴露就好<br>ha的默认端口就是8123</p></blockquote><p><code>docker ps</code> 查看容器情况</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CONTAINER ID   IMAGE                          COMMAND                  CREATED         STATUS        PORTS                                                                      NAMES</span><br><span class="line">b2f9de1af25b   homeassistant/home-assistant   "/init"                  2 seconds ago   Up 1 second   0.0.0.0:8123-&gt;8123/tcp                                                     homeassistant</span><br></pre></td></tr></table></figure><p>可以看到我们的容器启动了。并且正常运行了。如果你还不放心，可以看一下日志也可以 <code>docker log homeassistant</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">s6-rc: info: service s6rc-oneshot-runner: starting</span><br><span class="line">s6-rc: info: service s6rc-oneshot-runner successfully started</span><br><span class="line">s6-rc: info: service fix-attrs: starting</span><br><span class="line">s6-rc: info: service fix-attrs successfully started</span><br><span class="line">s6-rc: info: service legacy-cont-init: starting</span><br><span class="line">s6-rc: info: service legacy-cont-init successfully started</span><br><span class="line">s6-rc: info: service legacy-services: starting</span><br><span class="line">services-up: info: copying legacy longrun home-assistant (no readiness notification)</span><br><span class="line">s6-rc: info: service legacy-services successfully started</span><br></pre></td></tr></table></figure><p>打开浏览器，在浏览器中输入 <code>127.0.0.1:8123</code>，就会看到如下界面</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/ha-1.jpg" alt="ha-1"></p><p>接下来，我们创建好账号密码，切勿忘记<code>密码</code>，好记性不如烂笔头，记得记录下来</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/ha-2.jpg" alt="ha-2"></p><p>这里我们，不怎么需要理会，正常填写即可。</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/ha-3.jpg" alt="ha-3"></p><p>这里默认的都是关闭的，也推荐关闭。然后点击下一步。</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/ha-4.jpg" alt="ha-4"></p><p>这里其实就可以选择你要连接的品牌了，但是这里我先跳过，后面再设置。直接点击 <code>完成</code> 即可</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/ha-5.jpg" alt="ha-5"></p><p>ok，现在我们可以看到了，完成之后，进到 <code>HA系统</code> 了，可以看到，内置了一个谷歌的<code>TTS</code>的功能，可以不用理会（这个是谷歌推出的一个文本转语音的机器学习的功能）。</p><h3 id="HACS-安装"><a href="#HACS-安装" class="headerlink" title="HACS 安装"></a>HACS 安装</h3><p><code>Home Assistant Community Store</code> 为社区建设的<code>HomeAssistant商店</code>，可以安装<code>第三方集成</code>、<code>主题</code>、<code>表盘</code>以及<code>自动化</code>等。</p><p>GitHub 地址如下:</p><ul><li><a href="https://github.com/hacs" target="_blank" rel="noopener">https://github.com/hacs</a></li><li><a href="https://github.com/hacs/integration" target="_blank" rel="noopener">https://github.com/hacs/integration</a></li></ul><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs1.jpg" alt="hacs1"></p><p>安装之前，让我们先把资源目录整理好.</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 存放等会要安装的 HACS文件</span></span><br><span class="line">mkdir -p ~/ha/custom_components/hacs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 存放未来 HACS 安装的各种首页磁贴啥的（官方叫Lovelace ）</span></span><br><span class="line">mkdir -p ~/ha/www</span><br></pre></td></tr></table></figure><p>打开浏览器，输入<code>github</code> 的地址 <code>https://github.com/hacs/integration/releases</code> ，在这里下载最新的hacs的releases包。</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs2.jpg" alt="hacs2"></p><p>这里看见，我当前看到的目前的版本是去到了 <code>1.32.1</code>，所以本篇文章将以 <code>1.32.1</code> 为例子.</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs3.jpg" alt="hacs3"></p><p>下载这个 <code>zip</code> 的压缩包，然后解压到 <code>~/ha/custom_components/hacs</code> 目录</p><p>终端命令如下： <code>unzip ~/Downloads/hacs.zip -d ~/ha/custom_components/hacs</code></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs4.jpg" alt="hacs4"></p><p>解压后的情况如上图。</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs5.jpg" alt="hacs5"></p><p>在这里点击<code>开发者工具页面</code>，然后点击<code>检测配置</code>。</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs6.jpg" alt="hacs6"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs7.jpg" alt="hacs7"></p><p>接下来就可以看到<code>检测通过</code>，然后我们在同一个页面中找到<code>重启按钮</code>, 就可以<code>重启我们的HA系统</code>，让<code>插件加载生效</code>.</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs8.jpg" alt="hacs8"></p><p>点击<code>重启按钮</code>之后，可以看到<code>系统正在重启，目前失去了连接</code>.</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs9.jpg" alt="hacs9"></p><p>接着，我们手动刷新一下页面，用户登陆失效了，代表重启成功了，所以我们需要重新登陆到我们的<code>HA系统</code>，这个时候，需要输入我们记下来的<code>账号密码</code></p><p>** 换另外一种 ** 方式去安装HACS也可以的，<code>直接在docker容器内部安装</code>，通过<code>hacs脚本</code>自动安装。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it homeassistant bash -c 'wget -q -O - https://install.hacs.xyz | bash -'</span><br></pre></td></tr></table></figure><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs10.jpg" alt="hacs10"></p><p>可以看到，现在安装完毕了，我需要重启然后让插件加载成功。</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs11.jpg" alt="hacs11"></p><p>接下来，我们点击 <code>配置</code> ，找到 <code>设备与服务</code> 项</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs12.jpg" alt="hacs12"></p><p>点击 <code>添加集成</code></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs13.jpg" alt="hacs13"></p><p>搜索一下hacs，然后我们就能识别到的刚才安装的hacs了。</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs14.jpg" alt="hacs14"></p><p>这里把<code>全部选中</code>，因为这个是第三方插件，所以<code>HA</code>需要确保你会排查问题。所以需要看你是否懂得这些，你只需要全选了即可.</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs15.jpg" alt="hacs15"></p><p>这是设备注册。需要先拥有Github账号，没有的话注册一个并在浏览器上登录,<code>github.com</code></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs16.jpg" alt="hacs16"></p><p>然后打开上面的提供的连接: <code>https://github.com/login/device</code>, 输入提供的 <code>设备码</code></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs17.jpg" alt="hacs17"></p><p>点击 账号授权给 <code>hacs</code> 服务，即可。</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs18.jpg" alt="hacs18"></p><p>回到 <code>HA系统</code>，会发现已经识别到了，所以完成安装了 <code>HACS</code> 。</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/hacs19.jpg" alt="hacs19"></p><h2 id="homeassistant-App"><a href="#homeassistant-App" class="headerlink" title="homeassistant App"></a>homeassistant App</h2><p>HA官方提供了APP，iOS和Android都有，可自行下载~</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ios: https://www.github.com/home-assistant/iOS</span><br><span class="line">android: https://github.com/home-assistant/android</span><br></pre></td></tr></table></figure><p>当然，也可以自行去各大应用商店下载，例如 <code>appstore</code></p><p>温馨提示： App需要填入自己的HA地址，所以如果服务跑在家里的话，需要内网穿透或者公网才能在外面使用噢~ </p><p>如果HA内网穿透，configuration.yaml需要加上下面内容，同时内网穿透服务器(如ngrok、frp等)的nginx需要开启websocket支持，否则会出现外网无法访问、能访问但是无法登录等问题。</p><p>HA配置文件<code>configuration.yaml</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">http:</span></span><br><span class="line">  <span class="attr">use_x_forwarded_for:</span> <span class="literal">True</span></span><br><span class="line">  <span class="attr">trusted_proxies:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span><span class="string">/24</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">::1/128</span></span><br></pre></td></tr></table></figure><p>nginx配置参考(用frp内网穿透)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">     listen  80;</span><br><span class="line">     server_name  *.frp.yourdomain.cn frp.yourdomain.cn;</span><br><span class="line">     location / &#123;</span><br><span class="line">             proxy_redirect off;</span><br><span class="line">             proxy_set_header Host $http_host;</span><br><span class="line">             proxy_set_header X-Real-IP $remote_addr;</span><br><span class="line">             proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;</span><br><span class="line">             # 下面两行提供websocket支持,homeassistant需要</span><br><span class="line">             proxy_set_header Upgrade $http_upgrade;</span><br><span class="line">             proxy_set_header Connection "upgrade";</span><br><span class="line">             proxy_pass http://127.0.0.1:8123;</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最后附上同一个局域网下的访问效果图</p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/haapp1.jpg" alt="haapp1"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/haapp2.jpg" alt="haapp2"></p><p><img src="/images/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/haapp3.jpg" alt="haapp3"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;既然是技术博客，那么这一期，我会开始做一系列的关于智能家居的玩法。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Home Assistant&lt;/code&gt; 也叫 &lt;code&gt;HA&lt;/code&gt; + &lt;code&gt;Zigbee协议&lt;/code&gt;(硬件之间的通信协议)&lt;/p&gt;
&lt;p&gt;&lt;code&gt;HACS&lt;/code&gt; 是 &lt;code&gt;HA&lt;/code&gt; 的一个第三方插件，这个插件包括了许多开发者所贡献的插件，如果你是一名开发人员，那么你一定了解什么叫&lt;code&gt;依赖库&lt;/code&gt;。所以可以理解为 &lt;code&gt;HACS&lt;/code&gt; 就是 &lt;code&gt;HA&lt;/code&gt; 的第三方插件依赖库，你可以在连找到需要对你有用的插件，而你不必重新开发。&lt;/p&gt;
&lt;p&gt;为什么选择 &lt;code&gt;Zigbee协议&lt;/code&gt; ？ 在对比过&lt;code&gt;蓝牙mesh&lt;/code&gt;,&lt;code&gt;wifi协议&lt;/code&gt;之后，我最终选择了&lt;code&gt;zigbee协议&lt;/code&gt;，在于硬件之间的控制信号量传输本身就少，所以它自身的稳定性和分布式的特点，可以很好的支持到家庭中的各个角落，不会出现由于信号差导致失灵的情况，并且&lt;code&gt;zigbee协议&lt;/code&gt;的特点，电量的消耗也是十分的低。&lt;/p&gt;
    
    </summary>
    
    
      <category term="智能家居" scheme="http://blog.crazylaw.cn/categories/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/"/>
    
    
      <category term="智能家居" scheme="http://blog.crazylaw.cn/tags/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/"/>
    
      <category term="Home Assistant" scheme="http://blog.crazylaw.cn/tags/Home-Assistant/"/>
    
      <category term="HA" scheme="http://blog.crazylaw.cn/tags/HA/"/>
    
  </entry>
  
  <entry>
    <title>【多媒体】- AAC音频</title>
    <link href="http://blog.crazylaw.cn/2022/08/20/%E5%A4%9A%E5%AA%92%E4%BD%93/aac/"/>
    <id>http://blog.crazylaw.cn/2022/08/20/%E5%A4%9A%E5%AA%92%E4%BD%93/aac/</id>
    <published>2022-08-20T03:10:40.000Z</published>
    <updated>2022-08-20T16:00:19.452Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>音频中的audio有很多格式，分别有<code>aac</code>,<code>mp3</code>等等</p><p>在海外市场中，<code>aac</code>格式比较普遍，所以最近对其进行了一些研究。</p><a id="more"></a><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><h2 id="格式协议"><a href="#格式协议" class="headerlink" title="格式协议"></a>格式协议</h2><h2 id="解码"><a href="#解码" class="headerlink" title="解码"></a>解码</h2><h3 id="id3v2"><a href="#id3v2" class="headerlink" title="id3v2"></a>id3v2</h3><h3 id="adts"><a href="#adts" class="headerlink" title="adts"></a>adts</h3>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;音频中的audio有很多格式，分别有&lt;code&gt;aac&lt;/code&gt;,&lt;code&gt;mp3&lt;/code&gt;等等&lt;/p&gt;
&lt;p&gt;在海外市场中，&lt;code&gt;aac&lt;/code&gt;格式比较普遍，所以最近对其进行了一些研究。&lt;/p&gt;
    
    </summary>
    
    
      <category term="多媒体" scheme="http://blog.crazylaw.cn/categories/%E5%A4%9A%E5%AA%92%E4%BD%93/"/>
    
    
      <category term="aac" scheme="http://blog.crazylaw.cn/tags/aac/"/>
    
  </entry>
  
  <entry>
    <title>大数据-spark解析数据入库</title>
    <link href="http://blog.crazylaw.cn/2022/06/08/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-spark%E8%A7%A3%E6%9E%90%E6%95%B0%E6%8D%AE%E5%85%A5%E5%BA%93/"/>
    <id>http://blog.crazylaw.cn/2022/06/08/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-spark%E8%A7%A3%E6%9E%90%E6%95%B0%E6%8D%AE%E5%85%A5%E5%BA%93/</id>
    <published>2022-06-08T10:52:40.000Z</published>
    <updated>2022-06-08T09:40:50.786Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近在处理原始日志入库的操作，由于这个不是一个常态化的需求，是一些日志的数据，所以和我们常规的日志存储不同，不经过<code>text</code>数据的存储，直接存储为<code>orc</code>的格式。</p><p>并且以往解析都是通过java的hadoop的map-reduce的api的去操作解析数据，这次采用<code>spark</code>来对数据进行解析，提高解析的速度。</p><a id="more"></a><h3 id="parse-s2s"><a href="#parse-s2s" class="headerlink" title="parse_s2s"></a>parse_s2s</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line"></span><br><span class="line">source ./config.sh</span><br><span class="line"></span><br><span class="line">yyyy=$(echo $&#123;yyyy_mm_dd_hh&#125; | awk -F- '&#123;print $1&#125;')</span><br><span class="line">mm=$(echo $&#123;yyyy_mm_dd_hh&#125; | awk -F- '&#123;print $2&#125;')</span><br><span class="line">dd=$(echo $&#123;yyyy_mm_dd_hh&#125; | awk -F- '&#123;print $3&#125;')</span><br><span class="line">hh=$(echo $&#123;yyyy_mm_dd_hh&#125; | awk -F- '&#123;print $4&#125;')</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 所有地区，例如singapore</span></span><br><span class="line">area='*'</span><br><span class="line">if [[ ! $&#123;is_day&#125; == "0" ]];then</span><br><span class="line">    hh='*'</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">input_path="$&#123;LOG_TRACKING_S2S_PATH&#125;/$&#123;yyyy&#125;/$&#123;mm&#125;/$&#123;dd&#125;/$&#123;hh&#125;/$&#123;area&#125;/"</span><br><span class="line">output_path="$&#123;HIVE_DB_PATH&#125;/$&#123;T_UPARPU_S2S&#125;/"</span><br><span class="line"></span><br><span class="line">dt=$&#123;yyyy_mm_dd_hh&#125;</span><br><span class="line">if [[ ! $&#123;is_day&#125; == "0" ]];then</span><br><span class="line">    dt=$&#123;yyyy_mm_dd&#125;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">spark-submit --class com.xx.spark.jobs.parse.S2sParsingJob \</span><br><span class="line">  --name "xx_S2sParsingJob_dt$&#123;dt&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory "$&#123;SPARK_EXECUTOR_MEMORY&#125;" \</span><br><span class="line">  --driver-memory "$&#123;SPARK_DRIVER_MEMORY&#125;" \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors "$&#123;SPARK_NUM_EXECUTORS&#125;" \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=8 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=32 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=3000 \</span><br><span class="line">  --files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="string">"<span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;dt&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;input_path&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;output_path&#125;</span>"</span></span></span><br><span class="line"></span><br><span class="line">hive -e "</span><br><span class="line">    use $&#123;DB_UPARPU&#125;;</span><br><span class="line">    MSCK REPAIR TABLE $&#123;T_UPARPU_S2S&#125;;</span><br><span class="line">"</span><br></pre></td></tr></table></figure><p>脚本很简单，只是一些参数的调整以及数据写入到<code>oss</code>后，对hive的数据进行可以重新修复分区的行为。</p><h3 id="S2sParsingJob"><a href="#S2sParsingJob" class="headerlink" title="S2sParsingJob"></a>S2sParsingJob</h3><p>我们主要看一下这个和spark相关的<code>scala</code>以及<code>java</code>的代码部分。</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.xx.spark.jobs.parse</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.xx.spark.beans.<span class="type">S2sBean</span></span><br><span class="line"><span class="keyword">import</span> com.xx.spark.json.<span class="type">S2sParsing</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.&#123;<span class="type">StringType</span>, <span class="type">StructType</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">Row</span>, <span class="type">SaveMode</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types.<span class="type">StructField</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">S2sParsingJob</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> tmpPath = args(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">val</span> dt = args(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">val</span> inputPath = args(<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">var</span> outputPath = args(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder</span><br><span class="line">      .master(<span class="string">"yarn"</span>) <span class="comment">// avoid hardcoding the deployment environment</span></span><br><span class="line">      .enableHiveSupport() <span class="comment">// self-explanatory, isn't it?</span></span><br><span class="line">      .config(<span class="string">"spark.sql.warehouse.dir"</span>, tmpPath)</span><br><span class="line">      .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> lineRDD = spark.sparkContext.textFile(inputPath)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> beans = lineRDD</span><br><span class="line">      .map(line =&gt; <span class="type">S2sParsing</span>.map(line))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> dts = dt.split(<span class="string">"-"</span>)</span><br><span class="line">    <span class="keyword">var</span> yyyy = <span class="string">"0000"</span></span><br><span class="line">    <span class="keyword">var</span> mm = <span class="string">"00"</span></span><br><span class="line">    <span class="keyword">var</span> dd = <span class="string">"00"</span></span><br><span class="line">    <span class="keyword">var</span> hh = <span class="string">"25"</span></span><br><span class="line">    yyyy = <span class="keyword">if</span> (dts.nonEmpty) &#123;</span><br><span class="line">      dts(<span class="number">0</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="string">"0000"</span></span><br><span class="line">    &#125;</span><br><span class="line">    mm = <span class="keyword">if</span> (dts.length &gt; <span class="number">1</span>) &#123;</span><br><span class="line">      dts(<span class="number">1</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="string">"00"</span></span><br><span class="line">    &#125;</span><br><span class="line">    dd = <span class="keyword">if</span> (dts.length &gt; <span class="number">2</span>) &#123;</span><br><span class="line">      dts(<span class="number">2</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="string">"00"</span></span><br><span class="line">    &#125;</span><br><span class="line">    hh = <span class="keyword">if</span> (dts.length &gt; <span class="number">3</span>) &#123;</span><br><span class="line">      dts(<span class="number">3</span>)</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="string">"25"</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    outputPath = dts.length <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span> =&gt; outputPath + <span class="string">"/yyyy="</span> + yyyy</span><br><span class="line">      <span class="keyword">case</span> <span class="number">2</span> =&gt; outputPath + <span class="string">"/yyyy="</span> + yyyy + <span class="string">"/mm="</span> + mm</span><br><span class="line">      <span class="keyword">case</span> <span class="number">3</span> =&gt; outputPath + <span class="string">"/yyyy="</span> + yyyy + <span class="string">"/mm="</span> + mm + <span class="string">"/dd="</span> + dd</span><br><span class="line">      <span class="keyword">case</span> <span class="number">4</span> =&gt; outputPath + <span class="string">"/yyyy="</span> + yyyy + <span class="string">"/mm="</span> + mm + <span class="string">"/dd="</span> + dd + <span class="string">"/hh="</span> + hh</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> values = beans.map(bean =&gt; <span class="type">S2sBean</span>.transfer(bean))</span><br><span class="line">      <span class="comment">// 不依赖time解析，重置分区属性</span></span><br><span class="line">      <span class="comment">// 如果传递的是2022-06-08，那么hh的分区由time解析获得</span></span><br><span class="line">      .map(bean =&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (dts.length &gt; <span class="number">3</span>) &#123;</span><br><span class="line">          bean.hh = hh</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (dts.length &gt; <span class="number">2</span>) &#123;</span><br><span class="line">          bean.dd = dd</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (dts.length &gt; <span class="number">1</span>) &#123;</span><br><span class="line">          bean.mm = mm</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (dts.nonEmpty) &#123;</span><br><span class="line">          bean.yyyy = yyyy</span><br><span class="line">        &#125;</span><br><span class="line">        bean</span><br><span class="line">      &#125;)</span><br><span class="line">      .map(bean =&gt; <span class="type">S2sParsing</span>.extractValueToArray(bean))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> fields = <span class="type">S2sParsing</span>.extractKeyToArray(beans.first())</span><br><span class="line">      .map(fieldName =&gt; <span class="type">StructField</span>(fieldName, <span class="type">StringType</span>, nullable = <span class="literal">true</span>))</span><br><span class="line">    <span class="keyword">val</span> schema = <span class="type">StructType</span>(fields)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> requiredNumberOfFields = schema.fieldNames.length</span><br><span class="line">    <span class="keyword">val</span> rowRDD = values.map(line =&gt; &#123;</span><br><span class="line">      <span class="type">Row</span>.fromSeq(appendDummyData(line, requiredNumberOfFields).toSeq)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> lineDF = spark.createDataFrame(rowRDD, schema)</span><br><span class="line">    <span class="comment">//        lineDF.show()</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> partition = <span class="type">S2sBean</span>.getPartitionBy(dts.length)</span><br><span class="line">    lineDF.write</span><br><span class="line">      .partitionBy(partition: _*)</span><br><span class="line">      .mode(<span class="type">SaveMode</span>.<span class="type">Overwrite</span>)</span><br><span class="line">      .option(<span class="string">"orc.compress"</span>, <span class="string">"zlib"</span>)</span><br><span class="line">      .orc(outputPath)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">appendDummyData</span></span>(row: <span class="type">Array</span>[<span class="type">String</span>], len: <span class="type">Int</span>): <span class="type">Array</span>[<span class="type">String</span>] = row.length == len <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="literal">true</span> =&gt; row</span><br><span class="line">    <span class="keyword">case</span> <span class="literal">false</span> =&gt; <span class="keyword">if</span> (len &gt; row.length) &#123;</span><br><span class="line">      <span class="keyword">val</span> add = (<span class="keyword">for</span> (loop &lt;- <span class="number">1</span> to len - row.length) <span class="keyword">yield</span> <span class="string">"unknow"</span>).toArray</span><br><span class="line">      row ++ add</span><br><span class="line">    &#125; <span class="keyword">else</span> row.take(len)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这一段的<code>scala</code>代码也比较简洁，主要涉及到几个参数</p><ul><li>临时目录路径</li><li>日期时间</li><li>数据源的路径</li><li>清洗后数据输出路径</li></ul><p>有意思的是，这里看到有一个<code>appendDummyData</code>的方法，该方法是用于对比<code>schema.fieldNames.length</code>用到，当从<code>javabean</code>中提取的<code>fields</code>个数和<code>values</code>个数不一致的时候，通过这个方法，可以给我们对齐数据量，防止程序报错，如果数据少了，则追加<code>unknow</code>值，如果数据多了，则追加最后一个元素的值。</p><p>其次，我们看到以下一段代码：</p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> partition = <span class="type">S2sBean</span>.getPartitionBy(dts.length)</span><br><span class="line">   lineDF.write</span><br><span class="line">     .partitionBy(partition: _*)</span><br></pre></td></tr></table></figure><p>这一部分的代码，是用于获取<code>partition分区</code>用的，通过dts的长度，我们调整了output的路径和分区的信息，做到了不管是跑一天的数据，还是跑每个小时的数据，都确保了无关的数据不会被删除掉。</p><p>并且通过<code>scala</code>的<code>可变参数语法</code> <code>:_*</code>，对 <code>String*</code> 这种参数进行动态传参，从而实现了代码的简洁性操作。</p><p>另外，接下里，最核心的其实还是我们的javabean</p><h3 id="S2sBean"><a href="#S2sBean" class="headerlink" title="S2sBean"></a>S2sBean</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">S2sBean</span> <span class="keyword">extends</span> <span class="title">AbstractExtract</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> String time;</span><br><span class="line">    <span class="keyword">public</span> CommonBean common;</span><br><span class="line">    <span class="keyword">public</span> DataBean data;</span><br><span class="line">    <span class="keyword">public</span> String callbackUrl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String yyyy;</span><br><span class="line">    <span class="keyword">public</span> String mm;</span><br><span class="line">    <span class="keyword">public</span> String dd;</span><br><span class="line">    <span class="keyword">public</span> String hh;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> S2sBean <span class="title">transfer</span><span class="params">(S2sBean s2sBean)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (s2sBean.time == <span class="keyword">null</span>) &#123;</span><br><span class="line">            s2sBean.time = <span class="string">"0"</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        SimpleDateFormat reformat = <span class="keyword">new</span> SimpleDateFormat(<span class="string">"yyyy MM dd HH"</span>);</span><br><span class="line">        reformat.setTimeZone(TimeZone.getTimeZone(<span class="string">"Asia/Shanghai"</span>));</span><br><span class="line"></span><br><span class="line">        String formatDate = reformat.format(<span class="keyword">new</span> Date(Integer.parseInt(s2sBean.time) * <span class="number">1000L</span>));</span><br><span class="line">        String[] DateArr = formatDate.split(<span class="string">" "</span>);</span><br><span class="line"></span><br><span class="line">        s2sBean.yyyy = DateArr[<span class="number">0</span>];</span><br><span class="line">        s2sBean.mm = DateArr[<span class="number">1</span>];</span><br><span class="line">        s2sBean.dd = DateArr[<span class="number">2</span>];</span><br><span class="line">        s2sBean.hh = DateArr[<span class="number">3</span>];</span><br><span class="line">        <span class="keyword">return</span> s2sBean;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String[] getPartitionBy() &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> String[]&#123;<span class="string">"yyyy"</span>, <span class="string">"mm"</span>, <span class="string">"dd"</span>, <span class="string">"hh"</span>&#125;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> String[] getPartitionBy(<span class="keyword">int</span> offset) &#123;</span><br><span class="line">        String[] partitions = <span class="keyword">new</span> String[]&#123;<span class="string">"yyyy"</span>, <span class="string">"mm"</span>, <span class="string">"dd"</span>, <span class="string">"hh"</span>&#125;;</span><br><span class="line">        ArrayList&lt;String&gt; partitionList = <span class="keyword">new</span> ArrayList&lt;&gt;(Arrays.asList(partitions));</span><br><span class="line">        <span class="keyword">while</span> (offset &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            partitionList.remove(<span class="number">0</span>);</span><br><span class="line">            offset--;</span><br><span class="line">        &#125;</span><br><span class="line">        String[] newPartition = <span class="keyword">new</span> String[partitionList.size()];</span><br><span class="line">        partitionList.toArray(newPartition);</span><br><span class="line">        <span class="keyword">return</span> newPartition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CommonBean</span> <span class="keyword">extends</span> <span class="title">AbstractExtract</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomBean</span> <span class="keyword">extends</span> <span class="title">AbstractExtract</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</span><br><span class="line">        <span class="keyword">public</span> String userCustomData;</span><br><span class="line">        <span class="keyword">public</span> String userId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> String appId;</span><br><span class="line">    <span class="keyword">public</span> String system;</span><br><span class="line">    <span class="keyword">public</span> String platform;</span><br><span class="line">    <span class="keyword">public</span> String osVn;</span><br><span class="line">    <span class="keyword">public</span> String osVc;</span><br><span class="line">    <span class="keyword">public</span> String packageName;</span><br><span class="line">    <span class="keyword">public</span> String appVn;</span><br><span class="line">    <span class="keyword">public</span> String appVc;</span><br><span class="line">    <span class="keyword">public</span> String brand;</span><br><span class="line">    <span class="keyword">public</span> String model;</span><br><span class="line">    <span class="keyword">public</span> String screen;</span><br><span class="line">    <span class="keyword">public</span> String networkType;</span><br><span class="line">    <span class="keyword">public</span> String mnc;</span><br><span class="line">    <span class="keyword">public</span> String mcc;</span><br><span class="line">    <span class="keyword">public</span> String language;</span><br><span class="line">    <span class="keyword">public</span> String timezone;</span><br><span class="line">    <span class="keyword">public</span> String sdkVer;</span><br><span class="line">    <span class="keyword">public</span> String gpVer;</span><br><span class="line">    <span class="keyword">public</span> String ua;</span><br><span class="line">    <span class="keyword">public</span> String orient;</span><br><span class="line">    <span class="keyword">public</span> String upid;</span><br><span class="line">    <span class="keyword">public</span> String androidId;</span><br><span class="line">    <span class="keyword">public</span> String gaid;</span><br><span class="line">    <span class="keyword">public</span> String gdprCs;</span><br><span class="line">    <span class="keyword">public</span> String isCnSdk;</span><br><span class="line">    <span class="keyword">public</span> String itSrc;</span><br><span class="line">    <span class="keyword">public</span> String abtestId;</span><br><span class="line">    <span class="keyword">public</span> String firstInitTime;</span><br><span class="line">    <span class="keyword">public</span> String daysFromFirstInit;</span><br><span class="line">    <span class="keyword">public</span> CustomBean custom;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DataBean</span> <span class="keyword">extends</span> <span class="title">AbstractExtract</span> <span class="keyword">implements</span> <span class="title">java</span>.<span class="title">io</span>.<span class="title">Serializable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> String plId;</span><br><span class="line">    <span class="keyword">public</span> String reqId;</span><br><span class="line">    <span class="keyword">public</span> String showId;</span><br><span class="line">    <span class="keyword">public</span> String unitId;</span><br><span class="line">    <span class="keyword">public</span> String nwFirmId;</span><br><span class="line">    <span class="keyword">public</span> String scenarioId;</span><br><span class="line">    <span class="keyword">public</span> String rvStartTs;</span><br><span class="line">    <span class="keyword">public</span> String rCallbackTs;</span><br><span class="line">    <span class="keyword">public</span> String rvPlayDur;</span><br><span class="line">    <span class="keyword">public</span> String currTs;</span><br><span class="line">    <span class="keyword">public</span> String ilrd;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractExtract</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">ArrayList&lt;String&gt; <span class="title">extractValue</span><span class="params">(T bean)</span> </span>&#123;</span><br><span class="line">        ArrayList&lt;String&gt; rs = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Class&lt;?&gt; c = bean.getClass();</span><br><span class="line">            Field[] fields = c.getDeclaredFields();</span><br><span class="line">            <span class="keyword">for</span> (Field f : fields) &#123;</span><br><span class="line">                f.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">                Object oo = f.get(bean);</span><br><span class="line">                <span class="keyword">if</span> (oo == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (f.getType().getName().contains(<span class="string">"xx"</span>)) &#123;</span><br><span class="line">                        Class&lt;?&gt; clazz = Class.forName(f.getType().getName());</span><br><span class="line">                        oo = clazz.getDeclaredConstructor().newInstance();</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        oo = <span class="string">""</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (oo.getClass().getSuperclass().getName().equals(Thread.currentThread().getStackTrace()[<span class="number">1</span>].getClassName())) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        Method method = oo.getClass().getSuperclass().getDeclaredMethod(Thread.currentThread().getStackTrace()[<span class="number">1</span>].getMethodName(), Object<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">                        rs.addAll((ArrayList&lt;String&gt;) method.invoke(oo, oo));</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (NoSuchMethodException | InvocationTargetException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    rs.add((String) oo);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IllegalAccessException | ClassNotFoundException | InstantiationException | NoSuchMethodException | InvocationTargetException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> rs;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> &lt;T&gt; <span class="function">ArrayList&lt;String&gt; <span class="title">extractKey</span><span class="params">(T bean)</span> </span>&#123;</span><br><span class="line">        ArrayList&lt;String&gt; rs = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Class&lt;?&gt; c = bean.getClass();</span><br><span class="line">            Field[] fields = c.getDeclaredFields();</span><br><span class="line">            <span class="keyword">for</span> (Field f : fields) &#123;</span><br><span class="line">                f.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">                Object o = f.get(bean);</span><br><span class="line">                <span class="keyword">if</span> (o == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (f.getType().getName().contains(<span class="string">"topon"</span>)) &#123;</span><br><span class="line">                        Class&lt;?&gt; clazz = Class.forName(f.getType().getName());</span><br><span class="line">                        o = clazz.getDeclaredConstructor().newInstance();</span><br><span class="line">                    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                        o = <span class="string">""</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">if</span> (o.getClass().getSuperclass().getName().equals(Thread.currentThread().getStackTrace()[<span class="number">1</span>].getClassName())) &#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        Method method = o.getClass().getSuperclass().getDeclaredMethod(Thread.currentThread().getStackTrace()[<span class="number">1</span>].getMethodName(), Object<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">                        rs.addAll((ArrayList&lt;String&gt;) method.invoke(o, o));</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (NoSuchMethodException | InvocationTargetException e) &#123;</span><br><span class="line">                        e.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    rs.add(StrUtil.camelToSnake(f.getName()));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IllegalAccessException | ClassNotFoundException | NoSuchMethodException | InstantiationException | InvocationTargetException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> rs;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> com.alibaba.fastjson.JSON.toJSONString(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们知道，在正常场景下，我们一个<code>bean对象</code>其实就是一个数据载体，他包含了必要的数据字段，并且我们的日志一般多为结构化的数据，所以这里的<code>javaBean</code> 通过实现对应的结构化，通过json 的转化，可以快速的实力化javabean，但是由于我们存储数据的时候，都是<code>一维</code>数据，所以，需要对数据进行扁平化处理，在这里，我们只需要简单的提取出来即可，不需要加任何的前缀，所以这里没有做过多的特殊处理。</p><p>我们主要观看<code>abstract class AbstractExtract</code>，通过这个类，我们通过 <code>extractValue()</code> , <code>extractKey()</code>，可以拿到javabean下的所有属性和所有属性值。该方法的原理是通过java的<code>反射</code>和<code>递归</code>实现的，和我以前实现的<code>kafka-swoole</code>的协议实现差不多思路。但是在这里更重要的一个原因是因为我不想写太多重复的字段，我觉得那些字段在代码层面上，都应该只写一次才合理，如果重复写了或者直接通过静态代码写死的方式，在后续想修改代码是很麻烦的一个事情，所以通过这种方式，后续不管是否需要加字段去解析，我都只需要找到对应的结构体下的类，添加或者删除一个字段即可，为后续的大大减少的工作量而考虑。</p><p>经过测试，通过spark解析数据再到写入orc和分区处理，整个过程处理<code>2k万条（每条数据大概在3.3kb）</code>的数据大概需要10分钟即可。所以处理数据的一个tps是在<code>33k/s</code>左右。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近在处理原始日志入库的操作，由于这个不是一个常态化的需求，是一些日志的数据，所以和我们常规的日志存储不同，不经过&lt;code&gt;text&lt;/code&gt;数据的存储，直接存储为&lt;code&gt;orc&lt;/code&gt;的格式。&lt;/p&gt;
&lt;p&gt;并且以往解析都是通过java的hadoop的map-reduce的api的去操作解析数据，这次采用&lt;code&gt;spark&lt;/code&gt;来对数据进行解析，提高解析的速度。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="公司" scheme="http://blog.crazylaw.cn/tags/%E5%85%AC%E5%8F%B8/"/>
    
  </entry>
  
  <entry>
    <title>大数据任务-dau-deu任务</title>
    <link href="http://blog.crazylaw.cn/2022/05/27/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-dau-deu%E4%BB%BB%E5%8A%A1/"/>
    <id>http://blog.crazylaw.cn/2022/05/27/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-dau-deu%E4%BB%BB%E5%8A%A1/</id>
    <published>2022-05-27T10:52:40.000Z</published>
    <updated>2022-06-08T09:16:06.844Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>总结一下公司大数据的任务ETL离线工作流 - dau-deu任务</p><a id="more"></a><p>公司的ETL服务，目前采用的是组件为：</p><ul><li>数仓 (hadoop)</li><li>任务调度器 (azkaban)</li><li>出仓 (gp)</li><li>数仓查询 (hue)(hive)(spark)</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;总结一下公司大数据的任务ETL离线工作流 - dau-deu任务&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="公司" scheme="http://blog.crazylaw.cn/tags/%E5%85%AC%E5%8F%B8/"/>
    
  </entry>
  
  <entry>
    <title>大数据任务-重分配任务</title>
    <link href="http://blog.crazylaw.cn/2022/05/27/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E9%87%8D%E5%88%86%E9%85%8D%E4%BB%BB%E5%8A%A1/"/>
    <id>http://blog.crazylaw.cn/2022/05/27/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E9%87%8D%E5%88%86%E9%85%8D%E4%BB%BB%E5%8A%A1/</id>
    <published>2022-05-27T10:52:40.000Z</published>
    <updated>2022-05-27T11:12:44.819Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>总结一下公司大数据的任务ETL离线工作流 - 重分配任务</p><a id="more"></a><p>公司的ETL服务，目前采用的是组件为：</p><ul><li>数仓 (hadoop)</li><li>任务调度器 (azkaban)</li><li>出仓 (gp)</li><li>数仓查询 (hue)(hive)(spark)</li></ul><h2 id="job-tk-reassign（重分配任务）"><a href="#job-tk-reassign（重分配任务）" class="headerlink" title="job_tk_reassign（重分配任务）"></a>job_tk_reassign（重分配任务）</h2><ul><li>schedule: <code>30 10 * * *</code></li></ul><blockquote><p>按 <code>天</code> 为一个周期</p></blockquote><p>天级指标：</p><ul><li><code>isready</code></li><li><code>isready_success</code></li><li><code>showfailed</code></li></ul><p>所以在查看报表数据的时候，这3个指标是<code>天级</code>的。</p><p>除了上面所说的，代码也包含了<code>source_type = 2</code>，即实时的数据。但是目前来说，已经没有<code>source_type=2</code>的数据了，主要是业务导向。</p><p><img src="/images/%E5%85%AC%E5%8F%B8/tk_reassign.png" alt="重分配任务"></p><h3 id="sync-mysql-unit-and-placement"><a href="#sync-mysql-unit-and-placement" class="headerlink" title="sync_mysql_unit_and_placement"></a>sync_mysql_unit_and_placement</h3><blockquote><p>拉取最新的广告位数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">stat_source='placement'</span><br><span class="line"></span><br><span class="line">tmpfilename="tmp/uparpu_mysql_placement.log"</span><br><span class="line"></span><br><span class="line">mkdir -p tmp</span><br><span class="line"></span><br><span class="line">if [ -f "$&#123;tmpfilename&#125;" ]; then</span><br><span class="line"></span><br><span class="line">  rm -f $&#123;tmpfilename&#125;</span><br><span class="line">  echo "delete $&#123;tmpfilename&#125;"</span><br><span class="line"></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">    select </span><br><span class="line">        id,</span><br><span class="line">        uuid,        </span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,      </span><br><span class="line">        name,        </span><br><span class="line">        format,      </span><br><span class="line">        remark,      </span><br><span class="line">        create_time, </span><br><span class="line">        update_time </span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_NAME&#125;.$&#123;stat_source&#125;</span><br><span class="line">    ;</span><br><span class="line">" --skip-column-names | sed 's/\t/|/g' &gt;$&#123;tmpfilename&#125;</span><br><span class="line"></span><br><span class="line">if [ -f "$&#123;tmpfilename&#125;" ]; then</span><br><span class="line"></span><br><span class="line">  target="$&#123;HIVE_DB_PATH&#125;/$&#123;T_UPARPU_PLACEMENT&#125;/yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;/"</span><br><span class="line"></span><br><span class="line">  hadoop fs -rm -r $&#123;target&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;FILE_COMMAND_CP&#125; <span class="variable">$&#123;tmpfilename&#125;</span> <span class="variable">$&#123;target&#125;</span></span></span><br><span class="line"></span><br><span class="line">  hive -e "</span><br><span class="line">        use $&#123;DB_UPARPU&#125;;</span><br><span class="line">        alter table $&#123;T_UPARPU_PLACEMENT&#125; drop partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;');</span><br><span class="line">        alter table $&#123;T_UPARPU_PLACEMENT&#125; add partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;') location 'yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;';</span><br><span class="line">    "</span><br><span class="line"></span><br><span class="line">  echo "sync $&#123;tmpfilename&#125; to $&#123;target&#125;"</span><br><span class="line"></span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>从mysql把出最新的广告位数据，然后同步到对应的hive表中</li></ol><h3 id="merge-isready"><a href="#merge-isready" class="headerlink" title="merge_isready"></a>merge_isready</h3><blockquote><p>统计isready的数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">清洗isready数据，写入report_tk,dt&amp;dimen=15</span></span><br><span class="line">hourGap=0</span><br><span class="line">date_time_timeStamp=$(date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s)</span><br><span class="line">next_date_time_timeStamp=$(expr $&#123;date_time_timeStamp&#125; + 86400)</span><br><span class="line">next_date_time=$(date -d @$&#123;next_date_time_timeStamp&#125; "+%Y-%m-%d")</span><br><span class="line"></span><br><span class="line">where_dt="dt='$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;'"</span><br><span class="line">if [[ $&#123;run_type&#125; = 'utc0' ]]; then</span><br><span class="line">  hourGap=8</span><br><span class="line">  where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">else</span><br><span class="line">  if [[ $&#123;run_type&#125; = 'utcw8' ]]; then</span><br><span class="line">    hourGap=16</span><br><span class="line">    where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">  else</span><br><span class="line">    hourGap=0</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">转换成utc8时间</span></span><br><span class="line">day_start_timeStamp=$(date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s)</span><br><span class="line">day_end_timeStamp=$(date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 23:00:00" +%s)</span><br><span class="line">while_run_stamp=$&#123;day_start_timeStamp&#125;</span><br><span class="line">where_hour='('</span><br><span class="line"></span><br><span class="line">while [ "$&#123;while_run_stamp&#125;" -le "$&#123;day_end_timeStamp&#125;" ]; do</span><br><span class="line">  tmp_run_stamp=$(expr $&#123;while_run_stamp&#125; + $&#123;hourGap&#125; \* 3600)</span><br><span class="line">  tmp_date_time=$(date -d @$&#123;tmp_run_stamp&#125; "+%Y-%m-%d-%H")</span><br><span class="line">  tmp_yyyy=$(echo $&#123;tmp_date_time&#125; | awk -F- '&#123;print $1&#125;')</span><br><span class="line">  tmp_mm=$(echo $&#123;tmp_date_time&#125; | awk -F- '&#123;print $2&#125;')</span><br><span class="line">  tmp_dd=$(echo $&#123;tmp_date_time&#125; | awk -F- '&#123;print $3&#125;')</span><br><span class="line">  tmp_hh=$(echo $&#123;tmp_date_time&#125; | awk -F- '&#123;print $4&#125;')</span><br><span class="line">  if [ "$&#123;while_run_stamp&#125;" == "$&#123;day_start_timeStamp&#125;" ]; then</span><br><span class="line">    where_hour="$&#123;where_hour&#125;dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">  else</span><br><span class="line">    where_hour="$&#123;where_hour&#125; or dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">  fi</span><br><span class="line">  while_run_stamp=$(expr $&#123;while_run_stamp&#125; + 3600)</span><br><span class="line">done</span><br><span class="line">where_hour="$&#123;where_hour&#125;)"</span><br><span class="line"></span><br><span class="line">hql="</span><br><span class="line">      select</span><br><span class="line">          '$&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;',</span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          1,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          1,</span><br><span class="line">          0,</span><br><span class="line">          '',</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          cast(sum(case  when (a.key_count is null or a.key_count='') then 0 else a.key_count end) as bigint),</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">          0</span><br><span class="line">      from </span><br><span class="line">          (</span><br><span class="line">            select </span><br><span class="line">                  nw_firm_id,</span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id,</span><br><span class="line">                  cast(sum(case  when (key_count is null or key_count='') then 0 else key_count end) as bigint) key_count</span><br><span class="line">            from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_EVENT_ANALYSIS_COUNT&#125;</span><br><span class="line">            where</span><br><span class="line">                 $&#123;where_dt&#125;</span><br><span class="line">                 and key='1004632'</span><br><span class="line">                 and $&#123;where_hour&#125;</span><br><span class="line">                 $&#123;whereInPublisherList&#125;</span><br><span class="line">            group by </span><br><span class="line">                  nw_firm_id,</span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id</span><br><span class="line">          ) as a</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,uuid,app_id,format</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_PLACEMENT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">                group by id,uuid,app_id,format</span><br><span class="line">          ) as b</span><br><span class="line">      on </span><br><span class="line">          a.placement_id=b.uuid and a.app_raw_id=b.app_id</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,network_id,nw_firm_id</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_UNIT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">          ) as c</span><br><span class="line">      on </span><br><span class="line">          a.unit_id=c.id</span><br><span class="line">      where</span><br><span class="line">         cast(a.group_id as bigint)&lt;=2147483647</span><br><span class="line">         and b.uuid is not null</span><br><span class="line">      group by </span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.topon.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">  --name "TopOn_CommonSparkDateTimeJob_report_isready_dt$&#123;yyyy_mm_dd&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory "$&#123;SPARK_EXECUTOR_MEMORY&#125;" \</span><br><span class="line">  --driver-memory "$&#123;SPARK_DRIVER_MEMORY&#125;" \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors "$&#123;SPARK_NUM_EXECUTORS&#125;" \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_UPARPU&#125;</span>.<span class="variable">$&#123;T_RUN_REASSIGN_REPORT_TK&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;ymd&#125;</span>', dimen='15'"</span> <span class="string">"overwrite"</span></span></span><br></pre></td></tr></table></figure><ol><li><code>key=&#39;1004632&#39;</code> 的数据为<code>isready</code>的数据</li><li>由于原始数据已经有统计，所以<code>sum(key_count)</code>的总和就是<code>isready</code>的<code>对应维度</code>的总数</li><li>数据写入到 <code>dimen = &#39;15&#39;</code> 的分区</li></ol><h3 id="merge-isready-success"><a href="#merge-isready-success" class="headerlink" title="merge_isready_success"></a>merge_isready_success</h3><blockquote><p>统计isready_success的数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">清洗isready_success数据，写入report_tk,dt&amp;dimen=16</span></span><br><span class="line">hourGap=0</span><br><span class="line">date_time_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s`</span><br><span class="line">next_date_time_timeStamp=`expr $&#123;date_time_timeStamp&#125; + 86400`</span><br><span class="line">next_date_time=`date -d @$&#123;next_date_time_timeStamp&#125; "+%Y-%m-%d"`</span><br><span class="line"></span><br><span class="line">where_dt="dt='$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;'"</span><br><span class="line">if [[ $&#123;run_type&#125; = 'utc0' ]]</span><br><span class="line">  then</span><br><span class="line">     hourGap=8</span><br><span class="line">     where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">  else</span><br><span class="line">      if [[ $&#123;run_type&#125; = 'utcw8' ]] </span><br><span class="line">      then</span><br><span class="line">          hourGap=16</span><br><span class="line">          where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">      else</span><br><span class="line">          hourGap=0</span><br><span class="line">      fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">转换成utc8时间</span></span><br><span class="line">day_start_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s`</span><br><span class="line">day_end_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 23:00:00" +%s`</span><br><span class="line">while_run_stamp=$&#123;day_start_timeStamp&#125;</span><br><span class="line">where_hour='('</span><br><span class="line"></span><br><span class="line">while [ "$&#123;while_run_stamp&#125;" -le "$&#123;day_end_timeStamp&#125;" ]</span><br><span class="line">do</span><br><span class="line">      tmp_run_stamp=`expr $&#123;while_run_stamp&#125; + $&#123;hourGap&#125; \* 3600`</span><br><span class="line">      tmp_date_time=`date -d @$&#123;tmp_run_stamp&#125; "+%Y-%m-%d-%H"`</span><br><span class="line">      tmp_yyyy=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $1&#125;'`</span><br><span class="line">      tmp_mm=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $2&#125;'`</span><br><span class="line">      tmp_dd=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $3&#125;'`</span><br><span class="line">      tmp_hh=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $4&#125;'`</span><br><span class="line">      if [ "$&#123;while_run_stamp&#125;" == "$&#123;day_start_timeStamp&#125;" ]</span><br><span class="line">        then</span><br><span class="line">           where_hour="$&#123;where_hour&#125;dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">        else</span><br><span class="line">           where_hour="$&#123;where_hour&#125; or dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">        fi</span><br><span class="line">        while_run_stamp=`expr $&#123;while_run_stamp&#125; + 3600`</span><br><span class="line">done</span><br><span class="line">where_hour="$&#123;where_hour&#125;)"</span><br><span class="line"></span><br><span class="line">hql="</span><br><span class="line">      select</span><br><span class="line">          '$&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;',</span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          1,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          1,</span><br><span class="line">          0,</span><br><span class="line">          '',</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          0,</span><br><span class="line">          cast(sum(case  when (a.key_count is null or a.key_count='') then 0 else a.key_count end) as bigint),</span><br><span class="line">          0,</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">          0</span><br><span class="line">      from </span><br><span class="line">          (</span><br><span class="line">            select </span><br><span class="line">                  nw_firm_id,</span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id,</span><br><span class="line">                  cast(sum(case  when (key_count is null or key_count='') then 0 else key_count end) as bigint) key_count</span><br><span class="line">            from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_EVENT_ANALYSIS_COUNT&#125;</span><br><span class="line">            where</span><br><span class="line">                 $&#123;where_dt&#125;</span><br><span class="line">                 and key='1004632'</span><br><span class="line">                 and extra3='1'</span><br><span class="line">                 and $&#123;where_hour&#125;</span><br><span class="line">                 $&#123;whereInPublisherList&#125;</span><br><span class="line">            group by </span><br><span class="line">                  nw_firm_id,</span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id</span><br><span class="line">          ) as a</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,uuid,app_id,format</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_PLACEMENT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">                group by id,uuid,app_id,format</span><br><span class="line">          ) as b</span><br><span class="line">      on </span><br><span class="line">          a.placement_id=b.uuid and a.app_raw_id=b.app_id</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,network_id,nw_firm_id</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_UNIT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">          ) as c</span><br><span class="line">      on </span><br><span class="line">          a.unit_id=c.id</span><br><span class="line">      where</span><br><span class="line">         cast(a.group_id as bigint)&lt;=2147483647</span><br><span class="line">         and b.uuid is not null</span><br><span class="line">      group by </span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.topon.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">  --name "TopOn_CommonSparkDateTimeJob_report_isready_success_dt$&#123;yyyy_mm_dd&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory "$&#123;SPARK_EXECUTOR_MEMORY&#125;" \</span><br><span class="line">  --driver-memory "$&#123;SPARK_DRIVER_MEMORY&#125;" \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors "$&#123;SPARK_NUM_EXECUTORS&#125;" \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_UPARPU&#125;</span>.<span class="variable">$&#123;T_RUN_REASSIGN_REPORT_TK&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;ymd&#125;</span>', dimen='16'"</span> <span class="string">"overwrite"</span></span></span><br></pre></td></tr></table></figure><ol><li><code>key=&#39;1004632&#39; and extra3=&#39;1&#39;</code> 代表 isready 下，并且相应成功的数据</li><li>由于原始数据已经有统计，所以<code>sum(key_count)</code>的总和就是<code>isready_success</code>的<code>对应维度</code>的总数</li><li>写入到 <code>dimen = &#39;16&#39;</code> 的分区</li></ol><h3 id="merge-showfailed"><a href="#merge-showfailed" class="headerlink" title="merge_showfailed"></a>merge_showfailed</h3><blockquote><p>统计广告展示失败</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">清洗isready数据，写入report_tk,dt&amp;dimen=15</span></span><br><span class="line">hourGap=0</span><br><span class="line">date_time_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s`</span><br><span class="line">next_date_time_timeStamp=`expr $&#123;date_time_timeStamp&#125; + 86400`</span><br><span class="line">next_date_time=`date -d @$&#123;next_date_time_timeStamp&#125; "+%Y-%m-%d"`</span><br><span class="line"></span><br><span class="line">where_dt="dt='$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;'"</span><br><span class="line">if [[ $&#123;run_type&#125; = 'utc0' ]]</span><br><span class="line">  then</span><br><span class="line">     hourGap=8</span><br><span class="line">     where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">  else</span><br><span class="line">      if [[ $&#123;run_type&#125; = 'utcw8' ]] </span><br><span class="line">      then</span><br><span class="line">          hourGap=16</span><br><span class="line">          where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">      else</span><br><span class="line">          hourGap=0</span><br><span class="line">      fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">转换成utc8时间</span></span><br><span class="line">day_start_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s`</span><br><span class="line">day_end_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 23:00:00" +%s`</span><br><span class="line">while_run_stamp=$&#123;day_start_timeStamp&#125;</span><br><span class="line">where_hour='('</span><br><span class="line"></span><br><span class="line">while [ "$&#123;while_run_stamp&#125;" -le "$&#123;day_end_timeStamp&#125;" ]</span><br><span class="line">do</span><br><span class="line">      tmp_run_stamp=`expr $&#123;while_run_stamp&#125; + $&#123;hourGap&#125; \* 3600`</span><br><span class="line">      tmp_date_time=`date -d @$&#123;tmp_run_stamp&#125; "+%Y-%m-%d-%H"`</span><br><span class="line">      tmp_yyyy=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $1&#125;'`</span><br><span class="line">      tmp_mm=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $2&#125;'`</span><br><span class="line">      tmp_dd=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $3&#125;'`</span><br><span class="line">      tmp_hh=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $4&#125;'`</span><br><span class="line">      if [ "$&#123;while_run_stamp&#125;" == "$&#123;day_start_timeStamp&#125;" ]</span><br><span class="line">        then</span><br><span class="line">           where_hour="$&#123;where_hour&#125;dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">        else</span><br><span class="line">           where_hour="$&#123;where_hour&#125; or dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">        fi</span><br><span class="line">        while_run_stamp=`expr $&#123;while_run_stamp&#125; + 3600`</span><br><span class="line">done</span><br><span class="line">where_hour="$&#123;where_hour&#125;)"</span><br><span class="line"></span><br><span class="line">hql="</span><br><span class="line">      select</span><br><span class="line">          '$&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;',</span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          1,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          1,</span><br><span class="line">          0,</span><br><span class="line">          '',</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          cast(sum(case  when (a.key_count is null or a.key_count='') then 0 else a.key_count end) as bigint),</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">          0</span><br><span class="line">      from </span><br><span class="line">          (</span><br><span class="line">            select </span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id,</span><br><span class="line">                  cast(sum(case  when (key_count is null or key_count='') then 0 else key_count end) as bigint) key_count</span><br><span class="line">            from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_EVENT_ANALYSIS_COUNT&#125;</span><br><span class="line">            where</span><br><span class="line">                 $&#123;where_dt&#125;</span><br><span class="line">                 and key='1004633'</span><br><span class="line">                 and $&#123;where_hour&#125;</span><br><span class="line">                 $&#123;whereInPublisherList&#125;</span><br><span class="line">            group by </span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id</span><br><span class="line">          ) as a</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,uuid,app_id,format</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_PLACEMENT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">                group by id,uuid,app_id,format</span><br><span class="line">          ) as b</span><br><span class="line">      on </span><br><span class="line">          a.placement_id=b.uuid and a.app_raw_id=b.app_id</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,network_id,nw_firm_id</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_UNIT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">          ) as c</span><br><span class="line">      on </span><br><span class="line">          a.unit_id=c.id</span><br><span class="line">      where</span><br><span class="line">         cast(a.group_id as bigint)&lt;=2147483647</span><br><span class="line">         and b.uuid is not null</span><br><span class="line">      group by </span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.topon.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">  --name "TopOn_CommonSparkDateTimeJob_report_showfailed_dt$&#123;yyyy_mm_dd&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory "$&#123;SPARK_EXECUTOR_MEMORY&#125;" \</span><br><span class="line">  --driver-memory "$&#123;SPARK_DRIVER_MEMORY&#125;" \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors "$&#123;SPARK_NUM_EXECUTORS&#125;" \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_UPARPU&#125;</span>.<span class="variable">$&#123;T_RUN_REASSIGN_REPORT_TK&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;ymd&#125;</span>', dimen='17'"</span> <span class="string">"overwrite"</span></span></span><br></pre></td></tr></table></figure><ol><li><code>key=&#39;1004633&#39;</code> 代表 <code>showfailed</code> 的数据</li><li>由于原始数据已经有统计，所以<code>sum(key_count)</code>的总和就是<code>showfailed</code>的<code>对应维度</code>的总数</li><li>写入到 <code>dimen = &#39;17&#39;</code> 的分区</li></ol><h3 id="merge-revenue"><a href="#merge-revenue" class="headerlink" title="merge_revenue"></a>merge_revenue</h3><blockquote><p>统计收益数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">hql="</span><br><span class="line">        select</span><br><span class="line">            '$&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;',</span><br><span class="line">            case  when (a.nw_firm_id is null or a.nw_firm_id='' or a.nw_firm_id not rlike '^\\\\\\d+$') then '0' else a.nw_firm_id end,</span><br><span class="line">            case  when (a.group_id is null or a.group_id='' or a.group_id not rlike '^\\\\\\d+$') then '0' else a.group_id end,</span><br><span class="line">            case  when (a.unit_id is null or a.unit_id='' or a.unit_id not rlike '^\\\\\\d+$') then '0' else a.unit_id end,</span><br><span class="line">            a.system_type,</span><br><span class="line">            a.sdk_version,</span><br><span class="line">            case a.app_vn when 'null' then '0' else regexp_replace(a.app_vn,'\\\\\\\\0000','') end,</span><br><span class="line">            a.os_platform,</span><br><span class="line">            a.geo_short,</span><br><span class="line">            a.publisher_id,</span><br><span class="line">            a.app_id,</span><br><span class="line">            a.placement_id,</span><br><span class="line">            a.format,</span><br><span class="line">            a.sc_type,</span><br><span class="line">            cast(sum(a.request) as bigint),</span><br><span class="line">            cast(sum(a.filled_request) as bigint),</span><br><span class="line">            cast(sum(a.impression) as bigint),</span><br><span class="line">            cast(sum(a.click) as bigint),</span><br><span class="line">            cast(sum(a.load) as bigint),</span><br><span class="line">            cast(sum(a.filled_load) as bigint),</span><br><span class="line">            cast(sum(a.rv_play_start) as bigint),</span><br><span class="line">            cast(sum(a.rv_play_complete) as bigint),</span><br><span class="line">            a.channel,</span><br><span class="line">            a.sub_channel,</span><br><span class="line">            cast(sum(a.app_request) as bigint),</span><br><span class="line">            cast(sum(a.placement_request) as bigint),</span><br><span class="line">            cast(sum(a.show) as bigint),</span><br><span class="line">            cast(sum(a.impression_optimize) as bigint),</span><br><span class="line">            a.network_id,</span><br><span class="line">            case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">            case  when (a.bidtype is null or a.bidtype='') then '0' else a.bidtype end,</span><br><span class="line">            cast(sum(case  when (a.bid_request is null or a.bid_request='') then '0' else a.bid_request end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.bid_response is null or a.bid_response='') then '0' else a.bid_response end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.estimated_revenue is null or a.estimated_revenue='') then '0' else a.estimated_revenue end) as float),</span><br><span class="line">            case </span><br><span class="line">                when (sum(case when a.fake_impression_optimize is not null then a.fake_impression_optimize else a.impression_optimize end)* sum(b.total_revenue) / sum(b.total_impression)) is null then '0' </span><br><span class="line">                else cast((sum(case when a.fake_impression_optimize is not null then a.fake_impression_optimize else a.impression_optimize end) * sum(b.total_revenue) / sum(b.total_impression)) as float) </span><br><span class="line">            end,</span><br><span class="line">            case </span><br><span class="line">                when (sum(case when a.fake_impression_optimize is not null then a.fake_impression_optimize else a.impression_optimize end)* sum(b.total_currency_revenue) / sum(b.total_impression)) is null then '0' </span><br><span class="line">                else cast((sum(case when a.fake_impression_optimize is not null then a.fake_impression_optimize else a.impression_optimize end) * sum(b.total_currency_revenue) / sum(b.total_impression)) as float) </span><br><span class="line">            end,</span><br><span class="line">            case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">            case when (error_type is null or error_type='') then '0' else error_type end,</span><br><span class="line">            case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">            cast(sum(case  when (a.fake_impression_optimize is null or a.fake_impression_optimize='') then a.impression_optimize else a.fake_impression_optimize end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.fake_filled_load is null or a.fake_filled_load='') then a.filled_load else a.fake_filled_load end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.fake_filled_request is null or a.fake_filled_request='') then a.filled_request else a.fake_filled_request end) as bigint),</span><br><span class="line">            case when (a.is_cn_sdk is null or a.is_cn_sdk not rlike '^\\\\\\d+$') then '0' else a.is_cn_sdk end,</span><br><span class="line">            cast(sum(case  when (a.ready_request is null or a.ready_request='' or a.ready_request='(null)') then 0 else a.ready_request end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.ready_success is null or a.ready_success='' or a.ready_success='(null)') then 0 else a.ready_success end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.show_failed is null or a.show_failed='' or a.show_failed='(null)') then 0 else a.show_failed end) as bigint),</span><br><span class="line">            case when device_type is null then 1 else device_type end,</span><br><span class="line">            cast(sum(case when load_cost_time is null or load_cost_time&lt;0 then 0 else load_cost_time end) as bigint),</span><br><span class="line">            cast(sum(case when request_cost_time is null or request_cost_time&lt;0 then 0 else request_cost_time end) as bigint),</span><br><span class="line">            case when idfa_exist_tag is null then 0 else idfa_exist_tag end,</span><br><span class="line">            case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end,</span><br><span class="line">            cast(coalesce(sum(scenario_entry),0) as bigint),</span><br><span class="line">            cast(coalesce(sum(scenario_entry_ready),0) as bigint),</span><br><span class="line">            case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">            case when ofl is null then 0 else ofl end</span><br><span class="line">        from </span><br><span class="line">            (select *</span><br><span class="line">            from $&#123;DB_UPARPU&#125;.$&#123;T_RUN_REPORT_TK&#125;</span><br><span class="line">            where</span><br><span class="line">                dt = '$&#123;ymd&#125;'</span><br><span class="line">                and dimen in ('0','15','16','17','18')</span><br><span class="line">                and os_platform is not null</span><br><span class="line">                and length(sdk_version) &lt; 15</span><br><span class="line">                and bidtype&lt;=20</span><br><span class="line">                and bidtype&gt;=0</span><br><span class="line">                and format&gt;=0</span><br><span class="line">                $&#123;whereInPublisherList&#125;</span><br><span class="line">            ) as a</span><br><span class="line">        left join</span><br><span class="line">            (</span><br><span class="line">           select </span><br><span class="line">              app_id,</span><br><span class="line">              placement_id,</span><br><span class="line">              geo_short,</span><br><span class="line">              unit_id,</span><br><span class="line">              tk_impression as total_impression,</span><br><span class="line">              revenue as total_revenue,</span><br><span class="line">              currency_revenue as total_currency_revenue,</span><br><span class="line">              dt</span><br><span class="line">            from</span><br><span class="line">              $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_TK_UNIT_ECPM&#125;</span><br><span class="line">            where</span><br><span class="line">              dt = '$&#123;ymd&#125;'</span><br><span class="line">              $&#123;whereInPublisherList&#125;</span><br><span class="line">            ) as b</span><br><span class="line">        on </span><br><span class="line">            a.app_id = b.app_id and</span><br><span class="line">            a.placement_id=b.placement_id and</span><br><span class="line">            a.geo_short = b.geo_short and</span><br><span class="line">            a.unit_id = b.unit_id</span><br><span class="line">            and a.dt = '$&#123;ymd&#125;'</span><br><span class="line">            and b.dt = '$&#123;ymd&#125;'</span><br><span class="line">            and a.dimen in ('0','15','16','17','18')</span><br><span class="line">        where </span><br><span class="line">            a.dt = '$&#123;ymd&#125;'</span><br><span class="line">            and a.dimen in ('0','15','16','17','18')</span><br><span class="line">        group by </span><br><span class="line">            case  when (a.nw_firm_id is null or a.nw_firm_id='' or a.nw_firm_id not rlike '^\\\\\\d+$') then '0' else a.nw_firm_id end,</span><br><span class="line">            case  when (a.group_id is null or a.group_id='' or a.group_id not rlike '^\\\\\\d+$') then '0' else a.group_id end,</span><br><span class="line">            case  when (a.unit_id is null or a.unit_id='' or a.unit_id not rlike '^\\\\\\d+$') then '0' else a.unit_id end,</span><br><span class="line">            a.system_type,</span><br><span class="line">            a.sdk_version,</span><br><span class="line">            case a.app_vn when 'null' then '0' else regexp_replace(a.app_vn,'\\\\\\\\0000','') end,</span><br><span class="line">            a.os_platform,</span><br><span class="line">            a.geo_short,</span><br><span class="line">            a.publisher_id,</span><br><span class="line">            a.app_id,</span><br><span class="line">            a.placement_id,</span><br><span class="line">            a.format,</span><br><span class="line">            a.sc_type,</span><br><span class="line">            a.channel,</span><br><span class="line">            a.sub_channel,</span><br><span class="line">            a.network_id,</span><br><span class="line">            case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">            case  when (a.bidtype is null or a.bidtype='') then '0' else a.bidtype end,</span><br><span class="line">            case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">            case when (error_type is null or error_type='') then '0' else error_type end,</span><br><span class="line">            case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">            case when (a.is_cn_sdk is null or a.is_cn_sdk not rlike '^\\\\\\d+$') then '0' else a.is_cn_sdk end,</span><br><span class="line">            case when device_type is null then 1 else device_type end,</span><br><span class="line">            case when idfa_exist_tag is null then 0 else idfa_exist_tag end,</span><br><span class="line">            case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">            case when ofl is null then 0 else ofl end</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.topon.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">  --name "TopOn_CommonSparkDateTimeJob_ltv_tk_reassign_revenue_dt$&#123;yyyy_mm_dd&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory "$&#123;SPARK_EXECUTOR_MEMORY&#125;" \</span><br><span class="line">  --driver-memory "$&#123;SPARK_DRIVER_MEMORY&#125;" \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors "$&#123;SPARK_NUM_EXECUTORS&#125;" \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;ymd&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_UPARPU&#125;</span>.<span class="variable">$&#123;T_RUN_REASSIGN_REPORT_TK&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;ymd&#125;</span>', dimen='00'"</span> <span class="string">"overwrite"</span></span></span><br></pre></td></tr></table></figure><ol><li><code>dimen in (&#39;0&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;18&#39;)</code>，分别是<code>0=原来的小时任务统计出来的数据，15=isready数据, 16=isready_success数据,17=showfailed数据, 18=source_type=2的实时数据</code>，拿到所有的数据，然后进行重新写入</li><li>重新写入到 <code>dimen = &#39;00&#39;</code> 的分区中</li></ol><h3 id="to-db"><a href="#to-db" class="headerlink" title="to_db"></a>to_db</h3><blockquote><p>数据出仓到gp</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source ./export_tk_util.sh</span><br><span class="line">export_tk_func "$&#123;DB_UPARPU&#125;.$&#123;T_RUN_REASSIGN_REPORT_TK&#125;" "$&#123;T_RUN_REPORT_TK_SOURCE&#125;" "dt='$&#123;ymd&#125;' AND dimen='00'" " date_time =$&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;  $&#123;whereInPublisherList&#125; "</span><br></pre></td></tr></table></figure><ol><li>把当天的数据delete掉</li><li>把所有数据重新写入到gp</li></ol><p>重分配到任务做的事情处理完毕。注意这里涉及到了<code>收益</code>数据，由于业务导向是聚合平台，所以会收益是从多个平台拉取回来的数据，可能存在拉取收益数据失败的情况，所以需要有重试机制，所以这里的的任务有分为<code>跑前1天</code>，<code>跑前2天</code>，<code>跑前3天</code>的数据，如果超过3天，都拉取失败，那么这部分数据我们需要手动重跑。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;总结一下公司大数据的任务ETL离线工作流 - 重分配任务&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="公司" scheme="http://blog.crazylaw.cn/tags/%E5%85%AC%E5%8F%B8/"/>
    
  </entry>
  
  <entry>
    <title>大数据任务-小时任务</title>
    <link href="http://blog.crazylaw.cn/2022/05/26/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E5%B0%8F%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    <id>http://blog.crazylaw.cn/2022/05/26/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E5%B0%8F%E6%97%B6%E4%BB%BB%E5%8A%A1/</id>
    <published>2022-05-26T03:52:40.000Z</published>
    <updated>2022-05-27T10:44:13.097Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>总结一下公司大数据的任务ETL离线工作流 - 小时任务</p><a id="more"></a><p>公司的ETL服务，目前采用的是组件为：</p><ul><li>数仓 (hadoop)</li><li>任务调度器 (azkaban)</li><li>出仓 (gp)</li><li>数仓查询 (hue)(hive)(spark)</li></ul><h2 id="job-hour（小时任务）"><a href="#job-hour（小时任务）" class="headerlink" title="job_hour（小时任务）"></a>job_hour（小时任务）</h2><ul><li>schedule: <code>30 * * * *</code></li></ul><blockquote><p>每小时30分的时候进行启动任务</p></blockquote><p><img src="/images/%E5%85%AC%E5%8F%B8/bigdata-hour.png" alt="小时任务"></p><h3 id="check-tk-batch-log-success"><a href="#check-tk-batch-log-success" class="headerlink" title="check_tk_batch_log_success"></a>check_tk_batch_log_success</h3><blockquote><p>检测tk服务是否把原始日志已经上传到oss服务中</p></blockquote><p>核心流程如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">path=$&#123;LOG_TRACKING_BATCH_PATH&#125;</span><br><span class="line"></span><br><span class="line">path=$&#123;path&#125;/$&#123;yyyy&#125;/$&#123;mm&#125;/$&#123;dd&#125;/$&#123;hh&#125;/_SUCCESS</span><br><span class="line"></span><br><span class="line">hadoop fs -test -e $&#123;path&#125;</span><br></pre></td></tr></table></figure><p>数据是根据每个小时为一个基本单位，通过<code>_SUCCESS</code>文件来标志当前小时的数据是否已经同步到OSS完毕。</p><h3 id="sync-mysql-config"><a href="#sync-mysql-config" class="headerlink" title="sync_mysql_config"></a>sync_mysql_config</h3><blockquote><p>同步mysql的当前配置信息</p></blockquote><h4 id="同步广告位数据"><a href="#同步广告位数据" class="headerlink" title="同步广告位数据"></a>同步广告位数据</h4><p>核心流程如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">stat_source='placement'</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">select id,uuid,format from $&#123;DB_NAME&#125;.$&#123;stat_source&#125;</span><br><span class="line">" &gt; tmp/bigdata_mysql_placement_list.log</span><br><span class="line"></span><br><span class="line">if [ -f "tmp/bigdata_mysql_placement_list.log" ]; then</span><br><span class="line">    # hadoop fs -rm -r $&#123;CLIENT_TMP_LOG_META_PATH&#125;/tmp/placement/</span><br><span class="line">    $&#123;FILE_COMMAND_RM&#125; $&#123;CLIENT_TMP_LOG_META_PATH&#125;/tmp/placement/ --recursive</span><br><span class="line">    $&#123;FILE_COMMAND_CP&#125; tmp/bigdata_mysql_placement_list.log $&#123;CLIENT_TMP_LOG_META_PATH&#125;/tmp/placement/</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>从数据库导出广告信息：<code>id</code>, <code>uuid</code>, <code>format(广告样式)</code> 到<code>广告列表文件</code></li><li>把本地数据更新到oss中</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">tmpfilename="tmp/bigdata_mysql_placement.log"</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">    select </span><br><span class="line">        id,</span><br><span class="line">        uuid,        </span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,      </span><br><span class="line">        name,        </span><br><span class="line">        format,      </span><br><span class="line">        remark,      </span><br><span class="line">        create_time, </span><br><span class="line">        update_time </span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_NAME&#125;.$&#123;stat_source&#125; </span><br><span class="line">    ;</span><br><span class="line">" --skip-column-names | sed 's/\t/|/g' &gt; $&#123;tmpfilename&#125;</span><br><span class="line"></span><br><span class="line">if [ -f "$&#123;tmpfilename&#125;" ]; then</span><br><span class="line"></span><br><span class="line">    target="$&#123;HIVE_DB_PATH&#125;/$&#123;T_BIGDATA_PLACEMENT&#125;/yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;/"</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_RM&#125; $&#123;target&#125; --recursive</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_CP&#125; $&#123;tmpfilename&#125; $&#123;target&#125;</span><br><span class="line"></span><br><span class="line">    echo "sync $&#123;tmpfilename&#125; to $&#123;target&#125;"</span><br><span class="line"></span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>导出数据广告位数据，并且以<code>|</code>符号作为分隔符，写入到<code>广告位文件</code></li><li>如果 <code>广告位</code> 文件存在的话，那么就把 <code>广告位文件</code> 从 <code>file-oss</code> 同步到 <code>hive-oss</code></li></ol><h4 id="同步广告聚合收益数据"><a href="#同步广告聚合收益数据" class="headerlink" title="同步广告聚合收益数据"></a>同步广告聚合收益数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">bigdata_unit_source='unit'</span><br><span class="line">bigdata_network_source='network'</span><br><span class="line">tmpAdsourcefilename="tmp/bigdata_mysql_unit.log"</span><br><span class="line">tmpAdsourceFbFilename="tmp/bigdata_mysql_unit_fb.log"</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">    select </span><br><span class="line">        a.id,     </span><br><span class="line">        a.publisher_id,</span><br><span class="line">        a.placement_id,</span><br><span class="line">        a.network_id,  </span><br><span class="line">        a.network_id,</span><br><span class="line">        0,  </span><br><span class="line">        a.name,</span><br><span class="line">        a.remote_unique,</span><br><span class="line">        a.remote_unit,</span><br><span class="line">        a.header_bidding_switch,</span><br><span class="line">        a.ecpm,</span><br><span class="line">        a.ecpm_currency,</span><br><span class="line">        a.cap_hour,</span><br><span class="line">        a.cap_hour_switch,</span><br><span class="line">        a.cap_day,</span><br><span class="line">        a.cap_day_switch,</span><br><span class="line">        a.pacing,</span><br><span class="line">        a.pacing_switch,</span><br><span class="line">        a.create_time,</span><br><span class="line">        a.update_time,</span><br><span class="line">        a.status,</span><br><span class="line">        b.nw_firm_id</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_NAME&#125;.$&#123;bigdata_unit_source&#125; a</span><br><span class="line">    left outer join</span><br><span class="line">         $&#123;DB_NAME&#125;.$&#123;bigdata_network_source&#125; b</span><br><span class="line">    on</span><br><span class="line">        a.network_id=b.id</span><br><span class="line">    where </span><br><span class="line">        b.nw_firm_id!=1</span><br><span class="line">    ;</span><br><span class="line">" --skip-column-names | sed 's/\t/|/g' &gt; $&#123;tmpAdsourcefilename&#125;</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">    select </span><br><span class="line">        a.id,     </span><br><span class="line">        a.publisher_id,</span><br><span class="line">        a.placement_id,</span><br><span class="line">        b.parent_id,  </span><br><span class="line">        a.network_id,</span><br><span class="line">        b.parent_id,  </span><br><span class="line">        a.name,</span><br><span class="line">        a.remote_unique,</span><br><span class="line">        a.remote_unit,</span><br><span class="line">        a.header_bidding_switch,</span><br><span class="line">        a.ecpm,</span><br><span class="line">        a.ecpm_currency,</span><br><span class="line">        a.cap_hour,</span><br><span class="line">        a.cap_hour_switch,</span><br><span class="line">        a.cap_day,</span><br><span class="line">        a.cap_day_switch,</span><br><span class="line">        a.pacing,</span><br><span class="line">        a.pacing_switch,</span><br><span class="line">        a.create_time,</span><br><span class="line">        a.update_time,</span><br><span class="line">        a.status,</span><br><span class="line">        b.nw_firm_id</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_NAME&#125;.$&#123;bigdata_unit_source&#125; a</span><br><span class="line">    left outer join</span><br><span class="line">         $&#123;DB_NAME&#125;.$&#123;bigdata_network_source&#125; b</span><br><span class="line">    on</span><br><span class="line">        a.network_id=b.id</span><br><span class="line">    where </span><br><span class="line">        b.nw_firm_id=1</span><br><span class="line">    ;</span><br><span class="line">" --skip-column-names | sed 's/\t/|/g' &gt; $&#123;tmpAdsourceFbFilename&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ -f "$&#123;tmpfilename&#125;" ]; then</span><br><span class="line"></span><br><span class="line">    target="$&#123;HIVE_DB_PATH&#125;/$&#123;T_BIGDATA_UNIT&#125;/yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;/"</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_RM&#125; $&#123;target&#125; --recursive</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_CP&#125; $&#123;tmpAdsourcefilename&#125; $&#123;target&#125;</span><br><span class="line">    $&#123;FILE_COMMAND_CP&#125; $&#123;tmpAdsourceFbFilename&#125; $&#123;target&#125;</span><br><span class="line"></span><br><span class="line">    echo "sync $&#123;tmpfilename&#125; to $&#123;target&#125;"</span><br><span class="line"></span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>把 <code>国内广告</code> 和 <code>国外广告</code> 数据导出分别放在<code>不同的文件</code>中</li><li>然后从 <code>file-oss</code> 同步到 <code>hive-oss</code></li></ol><blockquote><p>备注：这里采用的是判断${tmpfilename}是广告位的文件，暂不确定是不是说明如果广告位文件没数据的话，那么这个逻辑也不做处理了。</p></blockquote><h4 id="广告场景"><a href="#广告场景" class="headerlink" title="广告场景"></a>广告场景</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">bigdata_scenario_source='scenario'</span><br><span class="line">tmpScenariofilename="tmp/bigdata_mysql_scenario.log"</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">    select </span><br><span class="line">        id,</span><br><span class="line">        uuid,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        name,</span><br><span class="line">        remark,</span><br><span class="line">        create_time,</span><br><span class="line">        update_time,</span><br><span class="line">        status</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_NAME&#125;.$&#123;bigdata_scenario_source&#125;</span><br><span class="line">    ;</span><br><span class="line">" --skip-column-names | sed 's/\t/|/g' &gt; $&#123;tmpScenariofilename&#125;</span><br><span class="line"></span><br><span class="line">if [ -f "$&#123;tmpScenariofilename&#125;" ]; then</span><br><span class="line"></span><br><span class="line">    target="$&#123;HIVE_DB_PATH&#125;/$&#123;T_BIGDATA_SCENARIO&#125;/"</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_RM&#125; $&#123;target&#125; --recursive</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_CP&#125; $&#123;tmpScenariofilename&#125; $&#123;target&#125;</span><br><span class="line"></span><br><span class="line">    echo "sync $&#123;tmpScenariofilename&#125; to $&#123;target&#125;"</span><br><span class="line"></span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>把广告场景数据导入到广告场景文件中</li><li>然后从 <code>file-oss</code> 同步到 <code>hive-oss</code></li></ol><h4 id="等等…"><a href="#等等…" class="headerlink" title="等等…"></a>等等…</h4><h3 id="check-strategy-app-log-success"><a href="#check-strategy-app-log-success" class="headerlink" title="check_strategy_app_log_success"></a>check_strategy_app_log_success</h3><blockquote><p>检测app日志策略是否写入完成</p></blockquote><h3 id="check-strategy-placement-log-success"><a href="#check-strategy-placement-log-success" class="headerlink" title="check_strategy_placement_log_success"></a>check_strategy_placement_log_success</h3><blockquote><p>检测广告策略日志写入是否写入完成</p></blockquote><h3 id="parse-tk-batch"><a href="#parse-tk-batch" class="headerlink" title="parse_tk_batch"></a>parse_tk_batch</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dependencies=check_tk_batch_log_success,sync_mysql_config</span><br><span class="line">command=sh -x parse_tk_batch.sh</span><br></pre></td></tr></table></figure><blockquote><p>开始解析tk数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">log_type=18</span><br><span class="line">hadoop fs -rm -r $&#123;CLIENT_TMP_LOG_META_PATH&#125;/$&#123;T_BIGDATA_TK_BATCH&#125;/</span><br><span class="line">hadoop jar $&#123;parse_jar&#125; $&#123;LOG_TRACKING_BATCH_PATH&#125;/$&#123;yyyy&#125;/$&#123;mm&#125;/$&#123;dd&#125;/$&#123;hh&#125;/* $&#123;CLIENT_TMP_LOG_META_PATH&#125; $&#123;yyyy_mm_dd_hh&#125; $&#123;log_type&#125; $&#123;T_BIGDATA_TK_BATCH&#125; $&#123;T_BIGDATA_DEVICE_ACTIVE_HOUR&#125; $&#123;CLIENT_TMP_LOG_META_PATH&#125;/tmp/placement/bigdata_mysql_placement_list.log</span><br></pre></td></tr></table></figure><p>通过hadoop的<code>map-reduce</code>进行处理分布式处理数据</p><p>其实目前脚本来说，这里只有前5个参数有用</p><ol><li>第一个参数是原始日志的目录（有用）</li><li>第二个参数是输出日志的目录（没用）</li><li>第三个参数是日期时间</li><li>第四个参数是日志类型（这里=18）</li><li>第五个参数是表名（也是完整hive路径的一级目录）</li><li>第六个参数是输出结果表名（这里没用）</li><li>第七个参数是这里是广告日志文件路径</li></ol><p>TK原始日志的存储目录下，tk原始日志文件中里面有不同类型的数据，其中有一个<code>type</code>类型，可以叫做<code>tk_type</code>, 代表不同类型的数据(<code>TYPE_TRACKING_XXX</code>)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TrackingLogConst</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_REQUEST = <span class="number">1</span>; <span class="comment">// 请求</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_FILLED_REQUEST = <span class="number">2</span>; <span class="comment">// 有填充的请求</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_NO_FILLED_REQUEST = <span class="number">3</span>; <span class="comment">// 没填充的请求</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_IMPRESSION = <span class="number">4</span>; <span class="comment">// 展示</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_REFERSH_IMPRESSION = <span class="number">5</span>; <span class="comment">//刷新展示</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_CLICK = <span class="number">6</span>; <span class="comment">// 点击</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_VIDEO_PLAY = <span class="number">7</span>; <span class="comment">// 视频播放</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_RV_PLAY_START = <span class="number">8</span>;<span class="comment">// 激励视频播放开始</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_RV_PLAY_COMPLETE = <span class="number">9</span>;<span class="comment">// 激励视频播放完成</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_LOAD = <span class="number">10</span>;<span class="comment">// load调用数据</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_HEADER_BIDDING = <span class="number">11</span>;<span class="comment">// header bidding</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_LOADFILLED = <span class="number">12</span>;<span class="comment">// loadfilled数据</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_SHOW = <span class="number">13</span>;<span class="comment">// show调用</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_RAND_WATERFALL = <span class="number">15</span>;<span class="comment">// show调用</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_AD_SCENARIO = <span class="number">16</span>;<span class="comment">// 到达广告场景</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// myoffer的tracking对应类型</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_0 = <span class="string">"1"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_25 = <span class="string">"2"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_50 = <span class="string">"3"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_75 = <span class="string">"4"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_100 = <span class="string">"5"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_END_SHOW = <span class="string">"6"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_END_CLOSE = <span class="string">"7"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_IMPRESSION = <span class="string">"8"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_CLICK = <span class="string">"9"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> org.apache.hadoop.mapreduce.lib.output.MultipleOutputs&lt;Text, Text&gt; mos;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Mapper.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    mos = <span class="keyword">new</span> MultipleOutputs&lt;Text, Text&gt;(context);</span><br><span class="line">    Configuration conf = context.getConfiguration();</span><br><span class="line">    tableName = conf.get(<span class="string">"table_name"</span>);</span><br><span class="line">    deviceTable = conf.get(<span class="string">"result_table"</span>);</span><br><span class="line">    inputTime = conf.get(<span class="string">"date"</span>);</span><br><span class="line">    inputTimeSplit = inputTime.split(<span class="string">"-"</span>);</span><br><span class="line">    logType = Integer.parseInt(conf.get(<span class="string">"log_type"</span>));</span><br><span class="line"></span><br><span class="line">    Path[] uriList = context.getLocalCacheFiles();</span><br><span class="line"></span><br><span class="line">    placementMap = PlacementData.getPlacementListFromUri(uriList);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">super</span>.setup(context);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">writeMosString</span><span class="params">(StringBuilder stringBuilder, <span class="keyword">int</span> trackingType)</span> </span>&#123;</span><br><span class="line">    String resultString = stringBuilder.toString();</span><br><span class="line">    <span class="keyword">if</span> (LogFactory.isDebug) &#123;</span><br><span class="line">        System.out.println(<span class="string">"result:"</span> + resultString + <span class="string">" tableName:"</span> + tableName + <span class="string">"/yyyy="</span> + inputTimeSplit[<span class="number">0</span>] + <span class="string">"/mm="</span> + inputTimeSplit[<span class="number">1</span>] + <span class="string">"/dd="</span> + inputTimeSplit[<span class="number">2</span>] + <span class="string">"/hh="</span> + inputTimeSplit[<span class="number">3</span>] + <span class="string">"/"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 写结果表</span></span><br><span class="line">    <span class="keyword">if</span> (resultString != <span class="keyword">null</span> &amp;&amp; resultString != <span class="string">""</span> &amp;&amp; !LogFactory.isDebug) &#123;</span><br><span class="line">        <span class="comment">// 写结果后，会使用logtype_作为前缀</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            mos.write(<span class="keyword">new</span> Text(resultString), <span class="keyword">new</span> Text(), tableName + <span class="string">"/"</span> + trackingType + <span class="string">"/raw/"</span> + logType + <span class="string">"_"</span> + trackingType + <span class="string">"_"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">    String outputPathTmp = outputPath + <span class="string">"/"</span> + tableName + logType + <span class="string">"/"</span>;</span><br><span class="line">    FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">        fs = FileSystem.get(<span class="keyword">new</span> URI(inputPath), conf);</span><br><span class="line">        Path outPath = <span class="keyword">new</span> Path(outputPathTmp);</span><br><span class="line">        <span class="keyword">if</span> (fs.exists(outPath)) &#123;</span><br><span class="line">            fs.delete(outPath, <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (URISyntaxException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>父级路径位：<code>outputPathTmp</code>: <code>/{table}{logType}/</code></p><p>看到数据被解析之后，会被写入到如下子级路径：</p><p><code>{tableName} + &quot;/&quot; + {trackingType} + &quot;/raw/&quot; + {logType} + &quot;_&quot; + {trackingType} + &quot;_&quot;</code></p><p>在当前的解析任务中，以 <code>TYPE_TRACKING_IMPRESSION=4</code> 为例子，具体的例子如下：</p><p><code>{T_BIGDATA_TK_BATCH}/4/raw/18_4_xxx</code></p><p>具体用法需要串联下一个节点来看。</p><h3 id="copy-xxx-copy-impression为例"><a href="#copy-xxx-copy-impression为例" class="headerlink" title="copy_xxx(copy_impression为例)"></a>copy_xxx(copy_impression为例)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">&#123;FILE_COMMAND_RM&#125; <span class="variable">$&#123;HIVE_DB_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_IMPRESSION&#125;</span>/yyyy=<span class="variable">$&#123;yyyy&#125;</span>/mm=<span class="variable">$&#123;mm&#125;</span>/dd=<span class="variable">$&#123;dd&#125;</span>/hh=<span class="variable">$&#123;hh&#125;</span> --recursive</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;FILE_COMMAND_RM&#125; <span class="variable">$&#123;HIVE_DB_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_IMPRESSION_V2&#125;</span>/yyyy=<span class="variable">$&#123;yyyy&#125;</span>/mm=<span class="variable">$&#123;mm&#125;</span>/dd=<span class="variable">$&#123;dd&#125;</span>/hh=<span class="variable">$&#123;hh&#125;</span> --recursive</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;FILE_COMMAND_SYNC&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_META_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_TK_BATCH&#125;</span>18/<span class="variable">$&#123;T_BIGDATA_TK_BATCH&#125;</span>/4/raw/ <span class="variable">$&#123;HIVE_DB_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_IMPRESSION&#125;</span>/yyyy=<span class="variable">$&#123;yyyy&#125;</span>/mm=<span class="variable">$&#123;mm&#125;</span>/dd=<span class="variable">$&#123;dd&#125;</span>/hh=<span class="variable">$&#123;hh&#125;</span>/</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;FILE_COMMAND_SYNC&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_META_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_TK_BATCH&#125;</span>18/<span class="variable">$&#123;T_BIGDATA_TK_BATCH&#125;</span>/5/raw/ <span class="variable">$&#123;HIVE_DB_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_IMPRESSION&#125;</span>/yyyy=<span class="variable">$&#123;yyyy&#125;</span>/mm=<span class="variable">$&#123;mm&#125;</span>/dd=<span class="variable">$&#123;dd&#125;</span>/hh=<span class="variable">$&#123;hh&#125;</span>/</span></span><br><span class="line"></span><br><span class="line">hive -e "</span><br><span class="line">        use $&#123;DB_BIGDATA&#125;;</span><br><span class="line">        alter table $&#123;T_BIGDATA_IMPRESSION&#125; drop IF EXISTS  partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;',hh='$&#123;hh&#125;');</span><br><span class="line">        alter table $&#123;T_BIGDATA_IMPRESSION&#125; add partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;',hh='$&#123;hh&#125;') location 'yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;/hh=$&#123;hh&#125;';</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">hql=" select</span><br><span class="line">        cast(c_date as int) as c_date,</span><br><span class="line">        c_time,</span><br><span class="line">        cast(created as bigint) as created,</span><br><span class="line">        ip,</span><br><span class="line">        remote_ip,</span><br><span class="line">        server_id,</span><br><span class="line">        country_code,</span><br><span class="line">        cast((case when os_platform is null or os_platform='' then 1 else os_platform end) as int) as os_platform,</span><br><span class="line">        imei,</span><br><span class="line">        mac,</span><br><span class="line">        android_id,</span><br><span class="line">        gaid,</span><br><span class="line">        idfa,</span><br><span class="line">        os_vn,</span><br><span class="line">        os_vc,</span><br><span class="line">        model,</span><br><span class="line">        brand,</span><br><span class="line">        screen_size,</span><br><span class="line">        cast((case when orientation is null or orientation='' then 1 else orientation end) as int) as orientation,</span><br><span class="line">        network_type,</span><br><span class="line">        mcc,</span><br><span class="line">        mnc,</span><br><span class="line">        language,</span><br><span class="line">        time_zone,</span><br><span class="line">        user_agent,</span><br><span class="line">        gpv,</span><br><span class="line">        app_vn,</span><br><span class="line">        app_vc,</span><br><span class="line">        app_package,</span><br><span class="line">        sdk_version,</span><br><span class="line">        cast((case when publisher_id is null or publisher_id='' then 0 else publisher_id end) as int) as publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        cast((case when app_raw_id is null or app_raw_id='' then 0 else app_raw_id end) as int) as app_raw_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        cast((case when placement_raw_id is null or placement_raw_id='' then 0 else placement_raw_id end) as int) as placement_raw_id,</span><br><span class="line">        request_id,</span><br><span class="line">        psid,</span><br><span class="line">        sessionid,</span><br><span class="line">        cast((case when sdk_time is null or sdk_time='' then 0 else sdk_time end) as bigint) as sdk_time,</span><br><span class="line">        ug_id,</span><br><span class="line">        nw_version,</span><br><span class="line">        cast((case when nw_firm_id is null or nw_firm_id='' then 0 else nw_firm_id end) as int) as nw_firm_id,</span><br><span class="line">        cast((case when sc_type is null or sc_type='' then 0 else sc_type end) as int) as sc_type,</span><br><span class="line">        cast((case when group_id is null or group_id='' then 0 else group_id end) as int) as group_id,</span><br><span class="line">        cast((case when format is null or format='' then 0 else format end) as int) as format,</span><br><span class="line">        extra,</span><br><span class="line">        cast((case when is_refresh is null or is_refresh='' then 0 else is_refresh end) as int) as is_refresh,</span><br><span class="line">        cast((case when unit_id is null or unit_id='' then 0 else unit_id end) as int) as unit_id,</span><br><span class="line">        cast((case when system_type is null or system_type='' then 0 else system_type end) as int) as system_type,</span><br><span class="line">        cast((case when load_type is null or load_type='' then 0 else load_type end) as int) as load_type,</span><br><span class="line">        case when asid is null then '' else asid end as asid,</span><br><span class="line">        case when channel is null then '' else channel end as channel,</span><br><span class="line">        case when upid is null then '' else upid end as upid,</span><br><span class="line">        cast((case when auto_refresh is null or auto_refresh='' then 0 else auto_refresh end) as int) as auto_refresh,</span><br><span class="line">        cast((case when aprn_auto_req is null or aprn_auto_req='' then 0 else aprn_auto_req end) as int) as aprn_auto_req,</span><br><span class="line">        cast((case when bidtype is null or bidtype='' then 0 else bidtype end) as int) as bidtype,</span><br><span class="line">        cast((case when bidprice is null or bidprice='' then 0 else bidprice end) as float) as bidprice,</span><br><span class="line">        case when offer_pkg is null then '' else offer_pkg end as offer_pkg,</span><br><span class="line">        case when sub_channel is null then '' else sub_channel end as sub_channel,</span><br><span class="line">        case when idfv is null then '' else idfv end as idfv,</span><br><span class="line">        cast((case when traffic_group_id is null or traffic_group_id='' then 0 else traffic_group_id end) as int) as traffic_group_id,</span><br><span class="line">        cast((case when myoffer_show_type is null or myoffer_show_type='' then 0 else myoffer_show_type end) as int) as myoffer_show_type,</span><br><span class="line">        cast((case when ofl is null or ofl='' then 0 else ofl end) as int) as ofl,</span><br><span class="line">        cast((case when gdpr_cs is null or gdpr_cs='' then 0 else gdpr_cs end) as int) as gdpr_cs,</span><br><span class="line">        case when scenario is null then '1' else scenario end as scenario,</span><br><span class="line">        cast((case when deduction_res is null or deduction_res='' then 0 else deduction_res end) as int) as deduction_res,</span><br><span class="line">        cast((case when deduction_num is null or deduction_num='' then 1 else deduction_num end) as int) as deduction_num,</span><br><span class="line">        case when oaid is null then '' else oaid end as oaid,</span><br><span class="line">        cast((case when is_cn_sdk is null or is_cn_sdk='' then 0 else is_cn_sdk end) as int) as is_cn_sdk,</span><br><span class="line">        cast((case when adtype_day_show_times is null or adtype_day_show_times='' then 0 else adtype_day_show_times end) as int) as adtype_day_show_times,</span><br><span class="line">        cast((case when adtype_hour_show_times is null or adtype_hour_show_times='' then 0 else adtype_hour_show_times end) as int) as adtype_hour_show_times,</span><br><span class="line">        cast((case when placement_day_show_times is null or placement_day_show_times='' then 0 else placement_day_show_times end) as int) as placement_day_show_times,</span><br><span class="line">        cast((case when placement_hour_show_times is null or placement_hour_show_times='' then 0 else placement_hour_show_times end) as int) as placement_hour_show_times,</span><br><span class="line">        case when install_source is null then '' else install_source end as install_source,</span><br><span class="line">        protocol,</span><br><span class="line">        origin_num,</span><br><span class="line">        protocol_type,</span><br><span class="line">        abtest_id,</span><br><span class="line">        first_init_time,</span><br><span class="line">        days_from_first_init,</span><br><span class="line">        app_custom,</span><br><span class="line">        user_id,</span><br><span class="line">        age,</span><br><span class="line">        gender,</span><br><span class="line">        cl_imp,</span><br><span class="line">        ex_ad</span><br><span class="line">        from </span><br><span class="line">            $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_IMPRESSION&#125;</span><br><span class="line">        where </span><br><span class="line">            yyyy='$&#123;yyyy&#125;'</span><br><span class="line">            and mm='$&#123;mm&#125;'</span><br><span class="line">            and dd='$&#123;dd&#125;'</span><br><span class="line">            and hh='$&#123;hh&#125;' "</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.jobs.common.CommonSparkSaveORCJob \</span><br><span class="line">--name "BigData_CommonSparkDateTimeJob_copy_impression_dt$&#123;yyyy_mm_dd_hh&#125;" \</span><br><span class="line">--master yarn  \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--executor-memory 2g \</span><br><span class="line">--driver-memory 2g \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--num-executors 8 \</span><br><span class="line">--conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">--conf spark.dynamicAllocation.minExecutors=8 \</span><br><span class="line">--conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">--conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">--files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_HIVE_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;HIVE_DB_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_IMPRESSION_V2&#125;</span>/yyyy=<span class="variable">$&#123;yyyy&#125;</span>/mm=<span class="variable">$&#123;mm&#125;</span>/dd=<span class="variable">$&#123;dd&#125;</span>/hh=<span class="variable">$&#123;hh&#125;</span>/"</span>\</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> hive -e "</span><br><span class="line">    use $&#123;DB_BIGDATA&#125;;</span><br><span class="line">    alter table $&#123;T_BIGDATA_IMPRESSION_V2&#125; drop IF EXISTS  partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;',hh='$&#123;hh&#125;');</span><br><span class="line">    alter table $&#123;T_BIGDATA_IMPRESSION_V2&#125; add partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;',hh='$&#123;hh&#125;') location 'yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;/hh=$&#123;hh&#125;';</span><br><span class="line"> "</span><br></pre></td></tr></table></figure><p>这里接着上一个节点的分析，这里的<code>${CLIENT_TMP_LOG_META_PATH}/${T_BIGDATA_TK_BATCH}18/${T_BIGDATA_TK_BATCH}/4/raw/</code> 就是经过hadoop解析后输出文件的目录</p><ol><li>如果有历史的数据，则删除历史的数据，然后重新导入数据到表中</li><li>接着再把数据copy到 <code>impression</code> 对应的目录分区中</li><li>重建（修复）分区，把数据加载到hive中的<code>impression</code></li><li>通过sql把数据进行 <code>第一次</code> 清洗，经过这一级的清洗，通过spark把数据转成 <code>ORC</code> 格式进行存储到 <code>impression_v2</code> 表</li><li>重建（修复）分区，把数据加载到hive中<code>impression_v2</code></li></ol><h3 id="merge-xxx-merge-tk-impression为例"><a href="#merge-xxx-merge-tk-impression为例" class="headerlink" title="merge_xxx(merge_tk_impression为例)"></a>merge_xxx(merge_tk_impression为例)</h3><blockquote><p>清洗tk的impression数据到tk小时的orc表（此orc非物理上的orc表）</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line">hql="select</span><br><span class="line">        $&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;,</span><br><span class="line">        $&#123;hh&#125;,</span><br><span class="line">        a.nw_firm_id,</span><br><span class="line">        a.group_id,</span><br><span class="line">        a.unit_id,</span><br><span class="line">        a.system_type,</span><br><span class="line">        a.sdk_version,</span><br><span class="line">        a.app_vn,</span><br><span class="line">        a.os_platform,</span><br><span class="line">        a.country_code,</span><br><span class="line">        a.publisher_id,</span><br><span class="line">        a.app_raw_id,</span><br><span class="line">        a.placement_raw_id,</span><br><span class="line">        a.format,</span><br><span class="line">        a.sc_type,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        cast(count(a.request_id) as bigint),</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        a.channel,</span><br><span class="line">        a.sub_channel,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        $&#123;timeStamp&#125;,</span><br><span class="line">        0,</span><br><span class="line">        cast(b.network_id as int),</span><br><span class="line">        a.traffic_group_id,</span><br><span class="line">        a.bidtype,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        cast((sum(a.bidprice)/1000) as float),</span><br><span class="line">        case when (a.scenario is null or a.scenario='' or c.uuid is null or c.status&lt;&gt;3) then '1' else a.scenario end,</span><br><span class="line">        case when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.uuid is null) then 1 when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.status&lt;&gt;3) then 2 else 0 end,</span><br><span class="line">        case when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.uuid is null or a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.status&lt;&gt;3) then a.scenario else '' end,</span><br><span class="line">        cast(sum(case when a.deduction_num is null or a.deduction_num = '' then '1' else a.deduction_num end) as bigint),                </span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        case  when (a.is_cn_sdk is null or a.is_cn_sdk='null') then 0 else a.is_cn_sdk end,</span><br><span class="line">        case when os_platform=2 and length(model)&gt;=4 and upper(substr(model,1,4))='IPAD' then 2 else 1 end,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        case when (os_platform = '2' and ((length(idfa) &gt; 0 and idfa &lt;&gt; '00000000-0000-0000-0000-000000000000') or (idfa = '' and gdpr_cs = '1'))) then 1 else 0 end as idfa_exist_tag,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        a.abtest_id</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_IMPRESSION_V2&#125; as a</span><br><span class="line">    left outer join</span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_UNIT&#125; as b</span><br><span class="line">    on</span><br><span class="line">        a.yyyy='$&#123;yyyy&#125;'</span><br><span class="line">        and a.mm='$&#123;mm&#125;'</span><br><span class="line">        and a.dd='$&#123;dd&#125;'</span><br><span class="line">        and a.hh='$&#123;hh&#125;'</span><br><span class="line">        and b.yyyy='$&#123;yyyy&#125;'</span><br><span class="line">        and b.mm='$&#123;mm&#125;'</span><br><span class="line">        and b.dd='$&#123;dd&#125;'</span><br><span class="line">        and a.unit_id=b.id</span><br><span class="line">    left outer join</span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_SCENARIO&#125; as c</span><br><span class="line">    on</span><br><span class="line">        a.yyyy='$&#123;yyyy&#125;'</span><br><span class="line">        and a.mm='$&#123;mm&#125;'</span><br><span class="line">        and a.dd='$&#123;dd&#125;'</span><br><span class="line">        and a.hh='$&#123;hh&#125;'</span><br><span class="line">        and a.placement_raw_id=c.placement_id</span><br><span class="line">        and a.scenario=c.uuid</span><br><span class="line">    where </span><br><span class="line">        a.yyyy='$&#123;yyyy&#125;'</span><br><span class="line">        and a.mm='$&#123;mm&#125;'</span><br><span class="line">        and a.dd='$&#123;dd&#125;'</span><br><span class="line">        and a.hh='$&#123;hh&#125;'</span><br><span class="line">        and a.is_refresh=0</span><br><span class="line">        and a.unit_id&gt;0</span><br><span class="line">        and a.publisher_id is not null</span><br><span class="line">        and a.bidprice &lt;&gt; 'Infinity'</span><br><span class="line">        and a.bidprice &gt;= 0</span><br><span class="line">        and a.bidprice &lt;= 100000</span><br><span class="line">    group by </span><br><span class="line">        a.nw_firm_id, </span><br><span class="line">        a.group_id, </span><br><span class="line">        a.unit_id, </span><br><span class="line">        a.system_type, </span><br><span class="line">        a.sdk_version, </span><br><span class="line">        a.app_vn, </span><br><span class="line">        a.os_platform, </span><br><span class="line">        a.country_code, </span><br><span class="line">        a.publisher_id, </span><br><span class="line">        a.app_raw_id, </span><br><span class="line">        a.placement_raw_id, </span><br><span class="line">        a.format, </span><br><span class="line">        a.sc_type,</span><br><span class="line">        a.channel,</span><br><span class="line">        a.sub_channel,</span><br><span class="line">        b.network_id,</span><br><span class="line">        a.traffic_group_id,</span><br><span class="line">        a.bidtype,</span><br><span class="line">        case when (a.scenario is null or a.scenario='' or c.uuid is null or c.status&lt;&gt;3) then '1' else a.scenario end,</span><br><span class="line">        case when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.uuid is null) then 1 when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.status&lt;&gt;3) then 2 else 0 end,</span><br><span class="line">        case when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.uuid is null or a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.status&lt;&gt;3) then a.scenario else '' end,</span><br><span class="line">        case  when (a.is_cn_sdk is null or a.is_cn_sdk='null') then 0 else a.is_cn_sdk end,</span><br><span class="line">        case when os_platform=2 and length(model)&gt;=4 and upper(substr(model,1,4))='IPAD' then 2 else 1 end,</span><br><span class="line">        case when (os_platform = '2' and ((length(idfa) &gt; 0 and idfa &lt;&gt; '00000000-0000-0000-0000-000000000000') or (idfa = '' and gdpr_cs = '1'))) then 1 else 0 end,</span><br><span class="line">        a.abtest_id</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">--name "BigData_CommonSparkDateTimeJob_merge_impression_dt$&#123;yyyy_mm_dd_hh&#125;" \</span><br><span class="line">--master yarn  \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--executor-memory 2g \</span><br><span class="line">--driver-memory 2g \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--num-executors 8 \</span><br><span class="line">--conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">--conf spark.dynamicAllocation.minExecutors=8 \</span><br><span class="line">--conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">--conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">--files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_HIVE_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd_hh&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_BIGDATA&#125;</span>.<span class="variable">$&#123;T_BIGDATA_REPORT_TK_HOUR_ORC&#125;</span>"</span>  <span class="string">"dt='<span class="variable">$&#123;yyyy&#125;</span>-<span class="variable">$&#123;mm&#125;</span>-<span class="variable">$&#123;dd&#125;</span>', hh='<span class="variable">$&#123;hh&#125;</span>', dimen='3'"</span> <span class="string">"overwrite"</span>\</span></span><br></pre></td></tr></table></figure><ol><li>这里是操作的主表为<code>v2</code>表，join的表一般只能是<code>v1</code>表，因为文本的解析是一起执行的，但是<code>各个任务的v2表</code>什么时候更新完毕暂时是不确定的。</li><li>这里看到分区信息中有一个 <code>dimen = &#39;3&#39;</code>，是和接下来的 <code>${T_BIGDATA_REPORT_TK_HOUR_ORC}</code> 有关系。这是一个tk数据的汇总表，几乎所有维度的数据最后都会汇集在这里，加上我们有不同的任务的数据都写入到这个表，所以我们加一个dimen的分区，便于区分不同的<code>数据的来源</code>。</li></ol><h3 id="merge-tracking-hour"><a href="#merge-tracking-hour" class="headerlink" title="merge_tracking_hour"></a>merge_tracking_hour</h3><blockquote><p>清洗orc的表数据到非orc的表，数据基本可以认为是一份基本可以出仓的数据了</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line">hql="select</span><br><span class="line">        $&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;,</span><br><span class="line">        $&#123;hh&#125;,</span><br><span class="line">        case nw_firm_id when '' then 0 else nw_firm_id end,</span><br><span class="line">        case group_id when '' then 0 else group_id end,</span><br><span class="line">        case nw_firm_id when '35' then 1 else unit_id end,</span><br><span class="line">        case system_type when '' then 0 else system_type end,</span><br><span class="line">        case sdk_version when 'null' then '0' else sdk_version end,</span><br><span class="line">        case when app_vn = 'null' then '0' when length(app_vn) &gt;= 50 then '0' else regexp_replace(app_vn,'\\\\\\\\0000','') end as app_vn,</span><br><span class="line">        case os_platform when '' then 0 else os_platform end,</span><br><span class="line">        case geo_short when 'null' then '00' else geo_short end,</span><br><span class="line">        case publisher_id when '' then 0 else publisher_id end,</span><br><span class="line">        case app_id when '' then 0 else app_id end,</span><br><span class="line">        case placement_id when '' then 0 when 'null' then 0 else placement_id end,</span><br><span class="line">        case format when '' then 0 else format end,</span><br><span class="line">        case sc_type when '' then 0 else sc_type end,</span><br><span class="line">        cast(sum(request) as bigint),</span><br><span class="line">        cast(sum(filled_request) as bigint),</span><br><span class="line">        cast(sum(impression) as bigint),</span><br><span class="line">        cast(sum(click) as bigint),</span><br><span class="line">        cast(sum(load) as bigint),</span><br><span class="line">        cast(sum(filled_load) as bigint),</span><br><span class="line">        cast(sum(rv_play_start) as bigint),</span><br><span class="line">        cast(sum(rv_play_complete) as bigint),</span><br><span class="line">        case channel when '' then '' else channel end,</span><br><span class="line">        case sub_channel when '' then '' else sub_channel end,</span><br><span class="line">        cast(sum(app_request) as bigint),</span><br><span class="line">        cast(sum(placement_request) as bigint),</span><br><span class="line">        cast(sum(show) as bigint),</span><br><span class="line">        $&#123;timeStamp&#125;,</span><br><span class="line">        cast(sum(impression_optimize) as bigint),</span><br><span class="line">        case network_id when '' then 0 else network_id end,</span><br><span class="line">        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,</span><br><span class="line">        case  when (bidtype is null or bidtype='') then 0 else bidtype end,</span><br><span class="line">        cast(sum(bid_request) as bigint),</span><br><span class="line">        cast(sum(bid_response) as bigint),</span><br><span class="line">        cast(sum(case when dimen='12' then estimated_revenue else 0 end) as float),</span><br><span class="line">        case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">        case when (error_type is null or error_type='') then 0 else error_type end,</span><br><span class="line">        case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">        cast(sum(case when (fake_impression_optimize&gt;0 and dimen='12') then fake_impression_optimize else 0 end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_load is null) then 0 else fake_filled_load end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_request is null) then 0 else fake_filled_request end) as bigint),</span><br><span class="line">        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,</span><br><span class="line">        case when device_type is null then 1 else device_type end,</span><br><span class="line">        cast(sum(load_cost_time) as bigint),</span><br><span class="line">        cast(sum(request_cost_time) as bigint),</span><br><span class="line">        idfa_exist_tag,</span><br><span class="line">        case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end,</span><br><span class="line">        cast(sum(case when (scenario_entry is null or scenario_entry='') then 0 else scenario_entry end) as bigint),</span><br><span class="line">        cast(sum(case when (scenario_entry_ready is null or scenario_entry_ready='') then 0 else scenario_entry_ready end) as bigint),</span><br><span class="line">        abtest_id</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_REPORT_TK_HOUR_ORC&#125;</span><br><span class="line">    where </span><br><span class="line">        dt='$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;'</span><br><span class="line">        and hh='$&#123;hh&#125;'</span><br><span class="line">        and dimen in ('1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16')</span><br><span class="line">        and unit_id is not null</span><br><span class="line">        and publisher_id is not null</span><br><span class="line">        and app_id is not null</span><br><span class="line">        and placement_id is not null</span><br><span class="line">        and format is not null</span><br><span class="line">        and sc_type is not null</span><br><span class="line">        and system_type is not null </span><br><span class="line">        and os_platform is not null </span><br><span class="line">        and sdk_version is not null </span><br><span class="line">        and app_vn is not null </span><br><span class="line">        and channel is not null </span><br><span class="line">        and sub_channel is not null </span><br><span class="line">        and group_id is not null</span><br><span class="line">        and nw_firm_id is not null</span><br><span class="line">        and network_id is not null</span><br><span class="line">        and group_id&gt;=0</span><br><span class="line">        and group_id&lt;=2147483647</span><br><span class="line">        and format&lt;=10</span><br><span class="line">        and estimated_revenue &lt;&gt; 'Infinity'</span><br><span class="line">        and is_cn_sdk&lt;=1</span><br><span class="line">        and length(geo_short)&lt;=2</span><br><span class="line">    group by</span><br><span class="line">        case nw_firm_id when '' then 0 else nw_firm_id end,</span><br><span class="line">        case group_id when '' then 0 else group_id end,</span><br><span class="line">        case nw_firm_id when '35' then 1 else unit_id end,</span><br><span class="line">        case system_type when '' then 0 else system_type end,</span><br><span class="line">        case sdk_version when 'null' then '0' else sdk_version end,</span><br><span class="line">        case when app_vn = 'null' then '0' when length(app_vn) &gt;= 50 then '0' else regexp_replace(app_vn,'\\\\\\\\0000','') end,</span><br><span class="line">        case os_platform when '' then 0 else os_platform end,</span><br><span class="line">        case geo_short when 'null' then '00' else geo_short end,</span><br><span class="line">        case publisher_id when '' then 0 else publisher_id end,</span><br><span class="line">        case app_id when '' then 0 else app_id end,</span><br><span class="line">        case placement_id when '' then 0 when 'null' then 0 else placement_id end,</span><br><span class="line">        case format when '' then 0 else format end,</span><br><span class="line">        case sc_type when '' then 0 else sc_type end,</span><br><span class="line">        case channel when '' then '' else channel end,</span><br><span class="line">        case sub_channel when '' then '' else sub_channel end,</span><br><span class="line">        case network_id when '' then 0 else network_id end,</span><br><span class="line">        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,</span><br><span class="line">        case  when (bidtype is null or bidtype='') then 0 else bidtype end,</span><br><span class="line">        case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">        case when (error_type is null or error_type='') then 0 else error_type end,</span><br><span class="line">        case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,</span><br><span class="line">        case when device_type is null then 1 else device_type end,</span><br><span class="line">        idfa_exist_tag,</span><br><span class="line">        abtest_id</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">--name "BigData_CommonSparkDateTimeJob_merge_report_hour_dt$&#123;yyyy_mm_dd_hh&#125;" \</span><br><span class="line">--master yarn  \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--executor-memory 2g \</span><br><span class="line">--driver-memory 2g \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--num-executors 8 \</span><br><span class="line">--conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">--conf spark.dynamicAllocation.minExecutors=8 \</span><br><span class="line">--conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">--conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">--files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_HIVE_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd_hh&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_BIGDATA&#125;</span>.<span class="variable">$&#123;T_BIGDATA_REPORT_TK_HOUR&#125;</span>"</span>  <span class="string">"dt='<span class="variable">$&#123;yyyy&#125;</span>-<span class="variable">$&#123;mm&#125;</span>-<span class="variable">$&#123;dd&#125;</span>', hh='<span class="variable">$&#123;hh&#125;</span>', dimen='0'"</span> <span class="string">"overwrite"</span>\</span></span><br></pre></td></tr></table></figure><ol><li>where条件加上了<code>dimen in (&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;5&#39;,&#39;6&#39;,&#39;7&#39;,&#39;8&#39;,&#39;9&#39;,&#39;10&#39;,&#39;11&#39;,&#39;12&#39;,&#39;13&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;)</code>，代表要拿到所有父节点的任务数据</li><li>其他的where条件代表在这个节点，不可能存在这些字段没有数据</li><li>把数据写入到非orc的表中，并且 <code>dimen = &#39;0&#39;</code></li></ol><h3 id="to-db-tracking-hour"><a href="#to-db-tracking-hour" class="headerlink" title="to_db_tracking_hour"></a>to_db_tracking_hour</h3><blockquote><p>数据出仓到gp</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">dimension_tk_hour_field="date_time,hour,nw_firm_id,group_id,unit_id,system,sdk_version,app_version,platform,geo_short,publisher_id,app_id,placement_id,format,sc_type,channel,sub_channel,hour_timestamp,network_id,traffic_group_id,bid_type,scenario,error_type,error_msg,is_cn_sdk,device_type,idfa_exist_tag "</span><br><span class="line">hive_dimension_tk_hour_field="date_time,hour,nw_firm_id,group_id,unit_id,system_type,sdk_version,app_vn,os_platform,geo_short,publisher_id,app_id,placement_id,format,sc_type,channel,sub_channel,hour_timestamp,network_id,traffic_group_id,bidtype,scenario,error_type,error_msg,is_cn_sdk,device_type,idfa_exist_tag"</span><br><span class="line">select_tk_hour_field="$&#123;hive_dimension_tk_hour_field&#125;,cast(sum(request) as bigint),cast(sum(filled_request) as bigint),cast(sum(impression) as bigint),cast(sum(click) as bigint),cast(sum(load) as bigint),cast(sum(filled_load) as bigint),cast(sum(rv_play_start) as bigint),cast(sum(rv_play_complete) as bigint),cast(sum(app_request) as bigint),cast(sum(placement_request) as bigint),cast(sum(show) as bigint),cast(sum(impression_optimize) as bigint),cast(sum(bid_request) as bigint),cast(sum(bid_response) as bigint),cast(sum(estimated_revenue) as float),cast(sum(fake_impression_optimize) as bigint),cast(sum(fake_filled_load) as bigint),cast(sum(fake_filled_request) as bigint),cast(sum(load_cost_time) as bigint),cast(sum(request_cost_time) as bigint), case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end as bid_response_ecpm,cast(sum(scenario_entry) as bigint),cast(sum(scenario_entry_ready) as bigint) "</span><br><span class="line">export_tk_hour_field="$&#123;dimension_tk_hour_field&#125;,request,filled_request,impression,click,loads,filled_loads,rv_start,rv_complete,strategy_app_request,strategy_placement_request,shows,impression_optimize,bid_request,bid_filled_request,estimated_revenue,fake_impression_optimize,fake_filled_load,fake_filled_request,load_cost_time,request_cost_time,bid_filled_request_ecpm,scenario_entry,scenario_entry_ready"</span><br><span class="line"></span><br><span class="line">function export_tk_hour_func() &#123;</span><br><span class="line">  stat_source_hour='report_tk_hour'</span><br><span class="line">  gp_delete_timeStamp=$(expr $&#123;timeStamp&#125; + 1 \* 3600)</span><br><span class="line">  del_sql="delete from $&#123;stat_source_hour&#125; where date_time = $&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125; and hour=$&#123;hh&#125; and add_timestamp&lt;$&#123;gp_delete_timeStamp&#125; and source_type not in (2);"</span><br><span class="line">  select_sql="select $&#123;select_tk_hour_field&#125; from $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_REPORT_TK_HOUR&#125; where dt='$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;' and hh='$&#123;hh&#125;' and dimen='0' group by $&#123;hive_dimension_tk_hour_field&#125;"</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 针对两个库的删除和导入</span></span><br><span class="line">  export_to_pgsql_by_select_data "$&#123;select_sql&#125;" $&#123;stat_source_hour&#125; bigdata_job_base_data_report_hour_$&#123;RANDOM&#125;_tmp.log "$&#123;del_sql&#125;" '|' "($&#123;export_tk_hour_field&#125;)"</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">export_to_pgsql_by_select_data() &#123;</span><br><span class="line">  el_sql=$1</span><br><span class="line">  el_stat_source=$2</span><br><span class="line">  el_tmp_file=$3</span><br><span class="line">  el_delete_sql=$4</span><br><span class="line">  el_terminated=$5</span><br><span class="line">  el_rows=$6</span><br><span class="line"></span><br><span class="line">  filepath=$(</span><br><span class="line">    cd "$(dirname "$0")"</span><br><span class="line">    pwd</span><br><span class="line">  )</span><br><span class="line">  fileTmpDir=tmp_$&#123;el_stat_source&#125;/$&#123;el_stat_source&#125;/</span><br><span class="line"></span><br><span class="line">  if [ -f "$&#123;el_tmp_file&#125;" ]; then</span><br><span class="line">    rm $&#123;el_tmp_file&#125;</span><br><span class="line">  fi</span><br><span class="line">  hive -e "</span><br><span class="line">              INSERT OVERWRITE  DIRECTORY '$&#123;fileTmpDir&#125;'</span><br><span class="line">              ROW format delimited fields terminated BY '$&#123;el_terminated&#125;'</span><br><span class="line">              $&#123;el_sql&#125;</span><br><span class="line">            "</span><br><span class="line">  hadoop fs -getmerge $&#123;fileTmpDir&#125;* $&#123;el_tmp_file&#125;</span><br><span class="line">  head -n 20 $&#123;el_tmp_file&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"><span class="built_in">export</span> to pgsql</span></span><br><span class="line">  echo "copy $&#123;el_stat_source&#125;  $&#123;el_rows&#125; from STDIN delimiter as '$&#123;el_terminated&#125;';"</span><br><span class="line">  sql="copy $&#123;el_stat_source&#125;  $&#123;el_rows&#125; from STDIN delimiter as '$&#123;el_terminated&#125;'"</span><br><span class="line"></span><br><span class="line">  if [[ $&#123;PG_BI_DB_ENABLE&#125; = true ]]; then</span><br><span class="line">    psql "host=$&#123;PG_BI_DB_HOST&#125; port=$&#123;PG_BI_DB_PORT&#125; user=$&#123;PG_BI_DB_USER&#125; password=$&#123;PG_BI_DB_PWD&#125; dbname=$&#123;PG_BI_DB_NAME&#125;" -c "$&#123;el_delete_sql&#125;"</span><br><span class="line">    psql "host=$&#123;PG_BI_DB_HOST&#125; port=$&#123;PG_BI_DB_PORT&#125; user=$&#123;PG_BI_DB_USER&#125; password=$&#123;PG_BI_DB_PWD&#125; dbname=$&#123;PG_BI_DB_NAME&#125;" -c "$&#123;sql&#125;" &lt;$&#123;el_tmp_file&#125;</span><br><span class="line">  fi</span><br><span class="line"></span><br><span class="line">  if [[ $&#123;PG_REL_BI_DB_ENABLE&#125; = true ]]; then</span><br><span class="line">    psql "host=$&#123;PG_REL_BI_DB_HOST&#125; port=$&#123;PG_REL_BI_DB_PORT&#125; user=$&#123;PG_REL_BI_DB_USER&#125; password=$&#123;PG_REL_BI_DB_PWD&#125; dbname=$&#123;PG_REL_BI_DB_NAME&#125;" -c "$&#123;el_delete_sql&#125;"</span><br><span class="line">    psql "host=$&#123;PG_REL_BI_DB_HOST&#125; port=$&#123;PG_REL_BI_DB_PORT&#125; user=$&#123;PG_REL_BI_DB_USER&#125; password=$&#123;PG_REL_BI_DB_PWD&#125; dbname=$&#123;PG_REL_BI_DB_NAME&#125;" -c "$&#123;sql&#125;" &lt;$&#123;el_tmp_file&#125;</span><br><span class="line">  fi</span><br><span class="line"></span><br><span class="line">  rm $&#123;el_tmp_file&#125;</span><br><span class="line">  hadoop fs -rmr $&#123;fileTmpDir&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">export_tk_hour_func</span><br></pre></td></tr></table></figure><ol><li>把数据通过sql查出来，然后通过 <code>|</code> 符号进行分割，然后写入到一个临时文件中</li><li>删除当前小时周期下的数据</li><li>通过 <code>copy</code> 命令列出所有的字段，然后通过标准输入<code>STDIN</code> 作为分隔符，从<code>临时文件中</code>导入数据</li></ol><h3 id="to-db-traking"><a href="#to-db-traking" class="headerlink" title="to_db_traking"></a>to_db_traking</h3><blockquote><p>把小时级表的数据合并到天级表</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 天表的数据都来自于小时表，从小时表导出后导入天表</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> tk表及东八区的时间和小时表的时间一样，0时区和西八区需要特殊处理一下</span></span><br><span class="line">currentUnixTime=$(date '+%s')</span><br><span class="line">tmpTkHourFileName="/data/gp_tk_tmp/report_tk_utce8_$&#123;currentUnixTime&#125;.log" # 此文件是在GP服务器上面的，需要有专门的任务去做清除</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 参照收益任务hour小时数据到天级数据的处理方式: export_report_unit_hour.sh</span></span><br><span class="line">CurrentDay=$&#123;utce8_yyyy&#125;$&#123;utce8_mm&#125;$&#123;utce8_dd&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 机器为零时区</span></span><br><span class="line">startTimeStamp=`date -d "8 hour ago $&#123;utce8_yyyy&#125;-$&#123;utce8_mm&#125;-$&#123;utce8_dd&#125; 00:00:00" +%s`</span><br><span class="line">endTimeStamp=`date -d "8 hour ago $&#123;utce8_yyyy&#125;-$&#123;utce8_mm&#125;-$&#123;utce8_dd&#125; 23:59:59" +%s`</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> estimate_revenue_api,estimate_currency_revenue_api,ready_request,ready_success,show_failed 由ltv任务写入</span></span><br><span class="line">pgSearchSql="</span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;CurrentDay&#125;,</span></span><br><span class="line">  nw_firm_id,</span><br><span class="line">  group_id,</span><br><span class="line">  geo_short,</span><br><span class="line">  publisher_id,</span><br><span class="line">  channel,</span><br><span class="line">  sub_channel,</span><br><span class="line">  system,</span><br><span class="line">  platform,</span><br><span class="line">  app_id,</span><br><span class="line">  sdk_version,</span><br><span class="line">  app_version,</span><br><span class="line">  placement_id,</span><br><span class="line">  unit_id,</span><br><span class="line">  format,</span><br><span class="line">  sc_type,</span><br><span class="line">  SUM(request),</span><br><span class="line">  SUM(filled_request),</span><br><span class="line">  SUM(strategy_app_request),</span><br><span class="line">  SUM(strategy_placement_request),</span><br><span class="line">  SUM(impression),</span><br><span class="line">  SUM(shows),</span><br><span class="line">  SUM(click),</span><br><span class="line">  SUM(loads),</span><br><span class="line">  SUM(filled_loads),</span><br><span class="line">  SUM(rv_start),</span><br><span class="line">  SUM(rv_complete),</span><br><span class="line">  SUM(impression_optimize),</span><br><span class="line">  network_id,</span><br><span class="line">  bid_type,</span><br><span class="line">  SUM(estimated_revenue),</span><br><span class="line">  traffic_group_id,</span><br><span class="line">  SUM(bid_request),</span><br><span class="line">  SUM(bid_filled_request),</span><br><span class="line">  case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">  error_type,</span><br><span class="line">  case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">  SUM(fake_impression_optimize),</span><br><span class="line">  SUM(fake_filled_load),</span><br><span class="line">  SUM(fake_filled_request),</span><br><span class="line">  is_cn_sdk,</span><br><span class="line">  device_type,</span><br><span class="line">  source_type,</span><br><span class="line">  SUM(load_cost_time),</span><br><span class="line">  SUM(request_cost_time),</span><br><span class="line">  idfa_exist_tag,</span><br><span class="line">  case coalesce(sum(bid_filled_request),0) when 0  then 0.0 else cast(sum(bid_filled_request * bid_filled_request_ecpm) / sum(bid_filled_request) as float) end,</span><br><span class="line">  SUM(scenario_entry),</span><br><span class="line">  SUM(scenario_entry_ready)</span><br><span class="line">FROM</span><br><span class="line">  report_tk_hour</span><br><span class="line">WHERE</span><br><span class="line">  hour_timestamp &gt;= $&#123;startTimeStamp&#125;</span><br><span class="line">  AND hour_timestamp &lt;= $&#123;endTimeStamp&#125;</span><br><span class="line">  AND source_type NOT IN (2)</span><br><span class="line">  AND add_timestamp &lt; $&#123;gp_delete_timeStamp&#125;</span><br><span class="line">GROUP BY</span><br><span class="line">  nw_firm_id,</span><br><span class="line">  group_id,</span><br><span class="line">  geo_short,</span><br><span class="line">  publisher_id,</span><br><span class="line">  channel,</span><br><span class="line">  sub_channel,</span><br><span class="line">  system,</span><br><span class="line">  platform,</span><br><span class="line">  app_id,</span><br><span class="line">  sdk_version,</span><br><span class="line">  app_version,</span><br><span class="line">  placement_id,</span><br><span class="line">  unit_id,</span><br><span class="line">  format,</span><br><span class="line">  sc_type,</span><br><span class="line">  network_id,</span><br><span class="line">  bid_type,</span><br><span class="line">  traffic_group_id,</span><br><span class="line">  case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">  error_type,</span><br><span class="line">  case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">  is_cn_sdk,</span><br><span class="line">  device_type,</span><br><span class="line">  source_type,</span><br><span class="line">  idfa_exist_tag</span><br><span class="line">  "</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 导出数据，report_tk 和 report_tk_utce8 表数据一致，只用导出一次便可</span></span><br><span class="line">outputSql="COPY ( $&#123;pgSearchSql&#125; ) TO '$&#123;tmpTkHourFileName&#125;' WITH CSV;"</span><br><span class="line">export PGPASSWORD=$&#123;PG_BI_DB_PWD&#125;</span><br><span class="line">psql --host=$&#123;PG_BI_DB_HOST&#125; --port=$&#123;PG_BI_DB_PORT&#125; --user=$&#123;PG_BI_DB_USER&#125; --dbname=$&#123;PG_BI_DB_NAME&#125; -c "$&#123;outputSql&#125;"</span><br><span class="line"></span><br><span class="line">deleteSql="DELETE FROM report_tk_utce8 WHERE date_time = $&#123;CurrentDay&#125;  AND source_type NOT IN (2) AND add_timestamp &lt; $&#123;gp_delete_timeStamp&#125;;"</span><br><span class="line">inputSql="COPY report_tk_utce8 ( $&#123;rowNames&#125; ) FROM '$&#123;tmpTkHourFileName&#125;' WITH CSV;"</span><br><span class="line"></span><br><span class="line">export PGPASSWORD=$&#123;PG_BI_DB_PWD&#125;</span><br><span class="line">respTag10=`psql --host=$&#123;PG_BI_DB_HOST&#125; --port=$&#123;PG_BI_DB_PORT&#125; --user=$&#123;PG_BI_DB_USER&#125; --dbname=$&#123;PG_BI_DB_NAME&#125; &lt;&lt;EOF</span><br><span class="line">BEGIN;</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;deleteSql&#125;</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;inputSql&#125;</span></span><br><span class="line">COMMIT;</span><br><span class="line">EOF`</span><br><span class="line"></span><br><span class="line">echo $&#123;respTag10&#125;</span><br><span class="line">if [[ $&#123;respTag10&#125; =~ "ROLLBACK" ]] ; then</span><br><span class="line">  exit 1</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>先把数据导出到一个临时文件<code>${tmpTkHourFileName}</code></li><li>再把数据从临时文件导入到另外一个天级表<code>report_tk_utce8</code></li><li>utc0/utcw8时区的一样的操作</li></ol><h3 id="merge-tracking-hour-1"><a href="#merge-tracking-hour-1" class="headerlink" title="merge_tracking_hour"></a>merge_tracking_hour</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">转换成utc8时间</span></span><br><span class="line">utce8_day_start_timeStamp=`date -d "$&#123;utce8_yyyy&#125;-$&#123;utce8_mm&#125;-$&#123;utce8_dd&#125; 00:00:00" +%s`</span><br><span class="line">utce8_day_end_timeStamp=`date -d "$&#123;utce8_yyyy&#125;-$&#123;utce8_mm&#125;-$&#123;utce8_dd&#125; 23:00:00" +%s`</span><br><span class="line">while_run_stamp=$&#123;utce8_day_start_timeStamp&#125;</span><br><span class="line">utce8_utc0_hour_where='('</span><br><span class="line"></span><br><span class="line">while [ "$&#123;while_run_stamp&#125;" -le "$&#123;utce8_day_end_timeStamp&#125;" ]</span><br><span class="line">do</span><br><span class="line">    tmp_run_stamp=`expr $&#123;while_run_stamp&#125; - 8 \* 3600`</span><br><span class="line">    tmp_date_time=`date -d @$&#123;tmp_run_stamp&#125; "+%Y-%m-%d-%H"`</span><br><span class="line">    tmp_yyyy=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $1&#125;'`</span><br><span class="line">    tmp_mm=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $2&#125;'`</span><br><span class="line">    tmp_dd=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $3&#125;'`</span><br><span class="line">    tmp_hh=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $4&#125;'`</span><br><span class="line">    if [ "$&#123;while_run_stamp&#125;" == "$&#123;utce8_day_start_timeStamp&#125;" ]</span><br><span class="line">        then</span><br><span class="line">           utce8_utc0_hour_where="$&#123;utce8_utc0_hour_where&#125;dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hh='$&#123;tmp_hh&#125;'"</span><br><span class="line">        else</span><br><span class="line">           utce8_utc0_hour_where="$&#123;utce8_utc0_hour_where&#125; or dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hh='$&#123;tmp_hh&#125;'"</span><br><span class="line">        fi</span><br><span class="line">        while_run_stamp=`expr $&#123;while_run_stamp&#125; + 3600`</span><br><span class="line">done</span><br><span class="line">utce8_utc0_hour_where="$&#123;utce8_utc0_hour_where&#125;)"</span><br><span class="line"></span><br><span class="line">hql="select</span><br><span class="line">        $&#123;utce8_yyyy&#125;$&#123;utce8_mm&#125;$&#123;utce8_dd&#125;,</span><br><span class="line">        nw_firm_id,</span><br><span class="line">        group_id,</span><br><span class="line">        unit_id,</span><br><span class="line">        system_type,</span><br><span class="line">        sdk_version,</span><br><span class="line">        app_vn,</span><br><span class="line">        os_platform,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        format,</span><br><span class="line">        sc_type,</span><br><span class="line">        cast(sum(request) as bigint),</span><br><span class="line">        cast(sum(filled_request) as bigint),</span><br><span class="line">        cast(sum(impression) as bigint),</span><br><span class="line">        cast(sum(click) as bigint),</span><br><span class="line">        cast(sum(load) as bigint),</span><br><span class="line">        cast(sum(filled_load) as bigint),</span><br><span class="line">        cast(sum(rv_play_start) as bigint),</span><br><span class="line">        cast(sum(rv_play_complete) as bigint),</span><br><span class="line">        channel,</span><br><span class="line">        sub_channel,</span><br><span class="line">        cast(sum(app_request) as bigint),</span><br><span class="line">        cast(sum(placement_request) as bigint),</span><br><span class="line">        cast(sum(show) as bigint),</span><br><span class="line">        cast(sum(impression_optimize) as bigint),</span><br><span class="line">        case  when network_id is null then 0 else network_id end,</span><br><span class="line">        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,</span><br><span class="line">        case  when (bidtype is null or bidtype='') then 0 else bidtype end,</span><br><span class="line">        cast(sum(case  when (bid_request is null or bid_request='') then 0 else bid_request end) as bigint),</span><br><span class="line">        cast(sum(case  when (bid_response is null or bid_response='') then 0 else bid_response end) as bigint),</span><br><span class="line">        cast(sum(case  when (estimated_revenue is null or estimated_revenue='') then 0 else estimated_revenue end) as float),</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">        case when (error_type is null or error_type='') then 0 else error_type end,</span><br><span class="line">        case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">        cast(sum(case when (fake_impression_optimize is null or fake_impression_optimize='') then impression_optimize else fake_impression_optimize end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_load is null or fake_filled_load='') then filled_load else fake_filled_load end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_request is null or fake_filled_request='') then filled_request else fake_filled_request end) as bigint),</span><br><span class="line">        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        case when device_type is null then 1 else device_type end,</span><br><span class="line">        cast(sum(case when load_cost_time is null or load_cost_time&lt;0 then 0 else load_cost_time end) as bigint),</span><br><span class="line">        cast(sum(case when request_cost_time is null or request_cost_time&lt;0 then 0 else request_cost_time end) as bigint),</span><br><span class="line">        case when idfa_exist_tag is null then 0 else idfa_exist_tag end,</span><br><span class="line">        case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end,</span><br><span class="line">        cast(coalesce(sum(scenario_entry),0) as bigint),</span><br><span class="line">        cast(coalesce(sum(scenario_entry_ready),0) as bigint),</span><br><span class="line">        abtest_id</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_REPORT_TK_HOUR&#125;</span><br><span class="line">    where </span><br><span class="line">        $&#123;utce8_utc0_hour_where&#125;</span><br><span class="line">        and dimen='0'</span><br><span class="line">        and group_id&gt;=0</span><br><span class="line">        and group_id&lt;=2147483647</span><br><span class="line">    group by </span><br><span class="line">        nw_firm_id,</span><br><span class="line">        group_id,</span><br><span class="line">        unit_id,</span><br><span class="line">        system_type,</span><br><span class="line">        sdk_version,</span><br><span class="line">        app_vn,</span><br><span class="line">        os_platform,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        format,</span><br><span class="line">        sc_type,</span><br><span class="line">        channel,</span><br><span class="line">        sub_channel,</span><br><span class="line">        case</span><br><span class="line">            when network_id is null then 0</span><br><span class="line">        else network_id</span><br><span class="line">        end,</span><br><span class="line">        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,</span><br><span class="line">        case  when (bidtype is null or bidtype='') then 0 else bidtype end,</span><br><span class="line">        case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">        case when (error_type is null or error_type='') then 0 else error_type end,</span><br><span class="line">        case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,</span><br><span class="line">        case when device_type is null then 1 else device_type end,</span><br><span class="line">        case when idfa_exist_tag is null then 0 else idfa_exist_tag end,</span><br><span class="line">        abtest_id</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">--name "BigData_CommonSparkDateTimeJob_merge_report_utce8_dt$&#123;yyyy_mm_dd_hh&#125;" \</span><br><span class="line">--master yarn  \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--executor-memory 2g \</span><br><span class="line">--driver-memory 2g \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--num-executors 8 \</span><br><span class="line">--conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">--conf spark.dynamicAllocation.minExecutors=8 \</span><br><span class="line">--conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">--conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">--files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_HIVE_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd_hh&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_BIGDATA&#125;</span>.<span class="variable">$&#123;T_BIGDATA_REPORT_TK_UTCE8&#125;</span>"</span>  <span class="string">"dt='<span class="variable">$&#123;utce8_yyyy&#125;</span>-<span class="variable">$&#123;utce8_mm&#125;</span>-<span class="variable">$&#123;utce8_dd&#125;</span>', dimen='0'"</span> <span class="string">"overwrite"</span>\</span></span><br></pre></td></tr></table></figure><ol><li>数据通过小时表转成<code>report_tk</code>表，并且 <code>dimen=&#39;0&#39;</code></li></ol><h3 id="abtest-tk-xxx"><a href="#abtest-tk-xxx" class="headerlink" title="abtest_tk_xxx"></a>abtest_tk_xxx</h3><blockquote><p>业务需要，根据abtest_id，把数据分别成不同的traffi_group_id，原始的数据的abtest_id字段会变成&amp;&amp;，分别出来的会变成00</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br></pre></td><td class="code"><pre><span class="line">tk_dimen='0'</span><br><span class="line">abtest_tk_tmp_dimen="10$&#123;tk_dimen&#125;"</span><br><span class="line">zone_type=$1</span><br><span class="line"></span><br><span class="line">if [ -n "$&#123;run_type&#125;" ]; then</span><br><span class="line">  if [[ $&#123;run_type&#125; = 'utcw8' ]]; then</span><br><span class="line">    zone_type="3"</span><br><span class="line">  else</span><br><span class="line">    if [[ $&#123;run_type&#125; = 'utc0' ]]; then</span><br><span class="line">      zone_type="2"</span><br><span class="line">    else</span><br><span class="line">      zone_type="1"</span><br><span class="line">    fi</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">zone_yyyy="$&#123;yyyy&#125;"</span><br><span class="line">zone_mm="$&#123;mm&#125;"</span><br><span class="line">zone_dd="$&#123;dd&#125;"</span><br><span class="line">zone_tk_table="$&#123;T_BIGDATA_REPORT_TK_UTCE8&#125;"</span><br><span class="line">zone_abtest_tk_table="$&#123;T_BIGDATA_REPORT_ABTEST_TK_UTCE8&#125;"</span><br><span class="line">zone_gp_abtest_tk_table="report_abtest_tk_utce8"</span><br><span class="line"></span><br><span class="line">if [ "$&#123;zone_type&#125;" == "2" ]; then</span><br><span class="line">  zone_yyyy="$&#123;utc0_yyyy&#125;"</span><br><span class="line">  zone_mm="$&#123;utc0_mm&#125;"</span><br><span class="line">  zone_dd="$&#123;utc0_dd&#125;"</span><br><span class="line">  zone_tk_table="$&#123;T_BIGDATA_REPORT_TK_UTC0&#125;"</span><br><span class="line">  zone_abtest_tk_table="$&#123;T_BIGDATA_REPORT_ABTEST_TK_UTC0&#125;"</span><br><span class="line">  zone_gp_abtest_tk_table="report_abtest_tk_utc0"</span><br><span class="line">else</span><br><span class="line">  if [ "$&#123;zone_type&#125;" == "3" ]; then</span><br><span class="line">    zone_yyyy="$&#123;utcw8_yyyy&#125;"</span><br><span class="line">    zone_mm="$&#123;utcw8_mm&#125;"</span><br><span class="line">    zone_dd="$&#123;utcw8_dd&#125;"</span><br><span class="line">    zone_tk_table="$&#123;T_BIGDATA_REPORT_TK_UTCW8&#125;"</span><br><span class="line">    zone_abtest_tk_table="$&#123;T_BIGDATA_REPORT_ABTEST_TK_UTCW8&#125;"</span><br><span class="line">    zone_gp_abtest_tk_table="report_abtest_tk_utcw8"</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">hql="select</span><br><span class="line">        date_time,</span><br><span class="line">        nw_firm_id,</span><br><span class="line">        group_id,</span><br><span class="line">        unit_id,</span><br><span class="line">        sdk_version,</span><br><span class="line">        app_vn,</span><br><span class="line">        os_platform,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        format,</span><br><span class="line">        device_type,</span><br><span class="line">        channel,</span><br><span class="line">        network_id,</span><br><span class="line">        case when abtest_id is null then '' else abtest_id end as abtest_id,</span><br><span class="line">        traffic_group_id,</span><br><span class="line">        bidtype,</span><br><span class="line">        cast(sum(request) as bigint),</span><br><span class="line">        cast(sum(filled_request) as bigint),</span><br><span class="line">        cast(sum(impression) as bigint),</span><br><span class="line">        cast(sum(click) as bigint),</span><br><span class="line">        cast(sum(load) as bigint),</span><br><span class="line">        cast(sum(filled_load) as bigint),</span><br><span class="line">        cast(sum(rv_play_start) as bigint),</span><br><span class="line">        cast(sum(rv_play_complete) as bigint),</span><br><span class="line">        cast(sum(show) as bigint),</span><br><span class="line">        cast(sum(impression_optimize) as bigint),</span><br><span class="line">        cast(sum(case  when (bid_request is null or bid_request='') then 0 else bid_request end) as bigint),</span><br><span class="line">        cast(sum(case  when (bid_response is null or bid_response='') then 0 else bid_response end) as bigint),</span><br><span class="line">        cast(sum(case  when (estimated_revenue is null or estimated_revenue='') then 0 else estimated_revenue end) as float),</span><br><span class="line">        cast(sum(case  when (estimate_revenue_api is null or estimate_revenue_api='') then 0 else estimate_revenue_api end) as float),</span><br><span class="line">        cast(sum(case  when (estimate_currency_revenue_api is null or estimate_currency_revenue_api='') then 0 else estimate_currency_revenue_api end) as float),</span><br><span class="line">        cast(sum(case when (fake_impression_optimize is null or fake_impression_optimize='') then impression_optimize else fake_impression_optimize end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_load is null or fake_filled_load='') then filled_load else fake_filled_load end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_request is null or fake_filled_request='') then filled_request else fake_filled_request end) as bigint),</span><br><span class="line">        sum(ready_request),</span><br><span class="line">        sum(ready_success),</span><br><span class="line">        sum(show_failed)</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;zone_tk_table&#125;</span><br><span class="line">    where </span><br><span class="line">        dt='$&#123;zone_yyyy&#125;-$&#123;zone_mm&#125;-$&#123;zone_dd&#125;'</span><br><span class="line">        and dimen='$&#123;tk_dimen&#125;'</span><br><span class="line">    group by </span><br><span class="line">        date_time,</span><br><span class="line">        nw_firm_id,</span><br><span class="line">        group_id,</span><br><span class="line">        unit_id,</span><br><span class="line">        sdk_version,</span><br><span class="line">        app_vn,</span><br><span class="line">        os_platform,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        format,</span><br><span class="line">        device_type,</span><br><span class="line">        channel,</span><br><span class="line">        network_id,</span><br><span class="line">        case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">        traffic_group_id,</span><br><span class="line">        bidtype</span><br><span class="line">        "</span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.parse.jobs.ParseAndSpiltAbtestTkJob \</span><br><span class="line">  --name "BigData_ParseAndSpiltAbtestTkJob_abtest_dt$&#123;yyyy_mm_dd_hh&#125;_$&#123;zone_type&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory 2g \</span><br><span class="line">  --driver-memory 2g \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors 8 \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">  --files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd_hh&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"abtest_id"</span> <span class="string">"traffic_group_id"</span> <span class="string">"<span class="variable">$&#123;DB_BIGDATA&#125;</span>.<span class="variable">$&#123;zone_abtest_tk_table&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;zone_yyyy&#125;</span>-<span class="variable">$&#123;zone_mm&#125;</span>-<span class="variable">$&#123;zone_dd&#125;</span>', dimen='<span class="variable">$&#123;abtest_tk_tmp_dimen&#125;</span>'"</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 合并分解后的数据</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次减少维度数据</span></span><br><span class="line">merge_hql=" </span><br><span class="line">select</span><br><span class="line">        date_time,</span><br><span class="line">        0 as nw_firm_id,</span><br><span class="line">        0 as group_id,</span><br><span class="line">        0 as unit_id,</span><br><span class="line">        '',</span><br><span class="line">        '',</span><br><span class="line">        0 as os_platform,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        -1 as format,</span><br><span class="line">        -1 as device_type,</span><br><span class="line">        '',</span><br><span class="line">        0,</span><br><span class="line">        case when abtest_id &lt;&gt;'&amp;&amp;' then '00' else abtest_id end as abtest_id,</span><br><span class="line">        traffic_group_id,</span><br><span class="line">        -1 as bidtype,</span><br><span class="line">        cast(sum(request) as bigint),</span><br><span class="line">        cast(sum(filled_request) as bigint),</span><br><span class="line">        cast(sum(impression) as bigint),</span><br><span class="line">        cast(sum(click) as bigint),</span><br><span class="line">        cast(sum(load) as bigint),</span><br><span class="line">        cast(sum(filled_load) as bigint),</span><br><span class="line">        cast(sum(rv_play_start) as bigint),</span><br><span class="line">        cast(sum(rv_play_complete) as bigint),</span><br><span class="line">        cast(sum(show) as bigint),</span><br><span class="line">        cast(sum(impression_optimize) as bigint),</span><br><span class="line">        cast(sum(case  when (bid_request is null or bid_request='') then 0 else bid_request end) as bigint),</span><br><span class="line">        cast(sum(case  when (bid_response is null or bid_response='') then 0 else bid_response end) as bigint),</span><br><span class="line">        cast(sum(case  when (estimated_revenue is null or estimated_revenue='') then 0 else estimated_revenue end) as float),</span><br><span class="line">        cast(sum(case  when (estimate_revenue_api is null or estimate_revenue_api='') then 0 else estimate_revenue_api end) as float),</span><br><span class="line">        cast(sum(case  when (estimate_currency_revenue_api is null or estimate_currency_revenue_api='') then 0 else estimate_currency_revenue_api end) as float),</span><br><span class="line">        cast(sum(case when (fake_impression_optimize is null or fake_impression_optimize='') then impression_optimize else fake_impression_optimize end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_load is null or fake_filled_load='') then filled_load else fake_filled_load end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_request is null or fake_filled_request='') then filled_request else fake_filled_request end) as bigint),</span><br><span class="line">        sum(ready_request),</span><br><span class="line">        sum(ready_success),</span><br><span class="line">        sum(show_failed)</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;zone_abtest_tk_table&#125;</span><br><span class="line">    where </span><br><span class="line">        dt='$&#123;zone_yyyy&#125;-$&#123;zone_mm&#125;-$&#123;zone_dd&#125;'</span><br><span class="line">        and dimen='$&#123;abtest_tk_tmp_dimen&#125;'</span><br><span class="line">    group by </span><br><span class="line">        date_time,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        case when abtest_id &lt;&gt;'&amp;&amp;' then '00' else abtest_id end,</span><br><span class="line">        traffic_group_id</span><br><span class="line">    "</span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">  --name "BigData_CommonSparkDateTimeJob_merge_strategy_app_dt$&#123;yyyy_mm_dd_hh&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory 2g \</span><br><span class="line">  --driver-memory 2g \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors 8 \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">  --files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd_hh&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;merge_hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_BIGDATA&#125;</span>.<span class="variable">$&#123;zone_abtest_tk_table&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;zone_yyyy&#125;</span>-<span class="variable">$&#123;zone_mm&#125;</span>-<span class="variable">$&#123;zone_dd&#125;</span>', dimen='<span class="variable">$&#123;tk_dimen&#125;</span>'"</span> <span class="string">"overwrite"</span></span></span><br><span class="line"></span><br><span class="line">source ./export_tk_util.sh</span><br><span class="line"></span><br><span class="line">export_abtest_tk_func "$&#123;DB_BIGDATA&#125;.$&#123;zone_abtest_tk_table&#125;" " dt='$&#123;zone_yyyy&#125;-$&#123;zone_mm&#125;-$&#123;zone_dd&#125;' and dimen='$&#123;tk_dimen&#125;' and traffic_group_id&gt;0" "$&#123;zone_gp_abtest_tk_table&#125;" "date_time=$&#123;zone_yyyy&#125;$&#123;zone_mm&#125;$&#123;zone_dd&#125; and add_timestamp&lt;$&#123;gp_delete_timeStamp&#125; and source_type not in (2)"</span><br></pre></td></tr></table></figure><ol><li>把数据传递进到spark脚本中，在spark中把数据进行分裂，然后存放在对应的<code>dimen = &#39;100&#39;</code></li><li>从表中的<code>dimen = &#39;100&#39;</code>中提取数据，把数据的维度再次缩小</li></ol><p>spark代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">object ParseAndSpiltAbtestTkJob &#123;</span><br><span class="line">  def main(args: Array[String]): Unit &#x3D; &#123;</span><br><span class="line">    val tmpPath &#x3D; parseArg(args(0))</span><br><span class="line">    &#x2F;&#x2F;format:yyyy-mm-dd-hh</span><br><span class="line">    val dt &#x3D; args(1)</span><br><span class="line">    val selectSql &#x3D; parseArg(args(2))</span><br><span class="line">    val abtestField &#x3D; args(3)</span><br><span class="line">    val trafficGroupField &#x3D; args(4)</span><br><span class="line">    val outputTable &#x3D; parseArg(args(5))</span><br><span class="line">    val partition &#x3D; args(6)</span><br><span class="line">    var trafficGroupFieldRaw &#x3D; &quot;&amp;&amp;&quot;</span><br><span class="line">    var trafficGroupFieldNew &#x3D; &quot;&quot;</span><br><span class="line">    if (args.length &gt;&#x3D; 8) &#123;</span><br><span class="line">      trafficGroupFieldRaw &#x3D; args(7)</span><br><span class="line">    &#125;</span><br><span class="line">    if (args.length &gt;&#x3D; 9) &#123;</span><br><span class="line">      trafficGroupFieldNew &#x3D; args(8)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    val sparkSession: SparkSession &#x3D; SparkSession.builder</span><br><span class="line">      &#x2F;&#x2F;      .master(&quot;local[3]&quot;)</span><br><span class="line">      .enableHiveSupport() &#x2F;&#x2F; self-explanatory, isn&#39;t it?</span><br><span class="line">      .config(&quot;spark.sql.warehouse.dir&quot;, tmpPath)</span><br><span class="line">      .getOrCreate</span><br><span class="line"></span><br><span class="line">    sparkSession.sqlContext.setConf(&quot;hive.merge.mapfiles&quot;, &quot;true&quot;)</span><br><span class="line">    sparkSession.sqlContext.setConf(&quot;mapred.max.split.size&quot;, &quot;256000000&quot;)</span><br><span class="line">    sparkSession.sqlContext.setConf(&quot;mapred.min.split.size.per.node&quot;, &quot;192000000&quot;)</span><br><span class="line">    sparkSession.sqlContext.setConf(&quot;mapred.min.split.size.per.rack&quot;, &quot;192000000&quot;)</span><br><span class="line">    sparkSession.sqlContext.setConf(&quot;hive.input.format&quot;, &quot;org.apache.hadoop.hive.ql.io.CombineHiveInputFormat&quot;)</span><br><span class="line"></span><br><span class="line">    val rawData &#x3D; sparkSession.sql(selectSql)</span><br><span class="line">    val newRdd: RDD[Row] &#x3D; rawData.rdd.map(row &#x3D;&gt; &#123;</span><br><span class="line">      &#x2F;&#x2F;        System.out.println(&quot;--------------------------------------&quot;, row.toString())</span><br><span class="line">      var resultList: ArrayBuffer[Row] &#x3D; new ArrayBuffer[Row]()</span><br><span class="line">      val tkRows &#x3D; mapSpiltFunc(row, abtestField, trafficGroupField, trafficGroupFieldRaw, trafficGroupFieldNew)</span><br><span class="line">      if (tkRows !&#x3D; null &amp;&amp; tkRows.nonEmpty) &#123;</span><br><span class="line">        resultList ++&#x3D; tkRows</span><br><span class="line">      &#125;</span><br><span class="line">      resultList</span><br><span class="line">    &#125;).flatMap(row &#x3D;&gt; row)</span><br><span class="line">    &#x2F;&#x2F;通过时间戳随机表名</span><br><span class="line">    val time &#x3D; System.currentTimeMillis() % 100000000;</span><br><span class="line">    val tmpTable &#x3D; &quot;spark_CommonSparkDateTimeJob_&quot; + time + &quot;_table&quot;</span><br><span class="line">    sparkSession.createDataFrame(newRdd, rawData.schema).registerTempTable(tmpTable)</span><br><span class="line">    val insertString &#x3D; &quot;insert overwrite table &quot; + outputTable + &quot; partition(&quot; + partition + &quot;) select * from &quot; + tmpTable</span><br><span class="line">    sparkSession.sql(insertString)</span><br><span class="line">    sparkSession.stop()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def parseArg(arg: String): String &#x3D; &#123;</span><br><span class="line">    var tmpArg &#x3D; arg</span><br><span class="line">    if (tmpArg.startsWith(&quot;&#39;&quot;)) &#123;</span><br><span class="line">      tmpArg &#x3D; tmpArg.substring(1);</span><br><span class="line">    &#125;</span><br><span class="line">    if (tmpArg.endsWith(&quot;&#39;&quot;)) &#123;</span><br><span class="line">      tmpArg &#x3D; tmpArg.substring(0, tmpArg.length() - 1);</span><br><span class="line">    &#125;</span><br><span class="line">    tmpArg;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def mapSpiltFunc(row: Row, abtestField: String, trafficGroupField: String, trafficGroupFieldRaw: String, trafficGroupFieldNew: String): ArrayBuffer[Row] &#x3D; &#123;</span><br><span class="line">    var resultList: ArrayBuffer[Row] &#x3D; new ArrayBuffer[Row]()</span><br><span class="line">    val abtest &#x3D; row.getAs[String](abtestField)</span><br><span class="line">    val rowRawArray &#x3D; row.toSeq.toArray</span><br><span class="line">    val trafficGroupIndex &#x3D; row.fieldIndex(trafficGroupField)</span><br><span class="line">    val abtestGroupIndex &#x3D; row.fieldIndex(abtestField)</span><br><span class="line">    val curtGroupId &#x3D; row.getAs[String](trafficGroupField)</span><br><span class="line"></span><br><span class="line">    if (!TextUtils.isEmpty(curtGroupId) &amp;&amp; curtGroupId &gt; &quot;0&quot;) &#123;</span><br><span class="line">      val newCurGroupRow &#x3D; rowRawArray.clone()</span><br><span class="line">      if (trafficGroupFieldRaw.isEmpty) &#123;</span><br><span class="line">        newCurGroupRow(abtestGroupIndex) &#x3D; &quot;&amp;&amp;&quot;</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">        newCurGroupRow(abtestGroupIndex) &#x3D; trafficGroupFieldRaw;</span><br><span class="line">      &#125;</span><br><span class="line">      resultList +&#x3D; Row.fromSeq(newCurGroupRow)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (TextUtils.isEmpty(abtest) || abtest.equals(&quot;&#123;&#125;&quot;)) &#123;</span><br><span class="line">      return resultList</span><br><span class="line">    &#125;</span><br><span class="line">    val tGroupIDs &#x3D; AbtestTkParsing.getTrafficGroupIDs(abtest)</span><br><span class="line">    for (groupId &lt;- tGroupIDs) &#123;</span><br><span class="line">      if (!groupId.equals(curtGroupId)) &#123;</span><br><span class="line">        val newGroupRow &#x3D; rowRawArray.clone()</span><br><span class="line">        if (trafficGroupFieldNew.nonEmpty) &#123;</span><br><span class="line">          newGroupRow(abtestGroupIndex) &#x3D; trafficGroupFieldNew</span><br><span class="line">        &#125;</span><br><span class="line">        newGroupRow(trafficGroupIndex) &#x3D; groupId;</span><br><span class="line">        resultList +&#x3D; Row.fromSeq(newGroupRow)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    resultList</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>至此，一个基本的<code>小时任务</code>的大数据ETL服务就做完了该作的事情了</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;总结一下公司大数据的任务ETL离线工作流 - 小时任务&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="公司" scheme="http://blog.crazylaw.cn/tags/%E5%85%AC%E5%8F%B8/"/>
    
  </entry>
  
  <entry>
    <title>【广告行业】知识点</title>
    <link href="http://blog.crazylaw.cn/2022/04/12/%E5%85%AC%E5%8F%B8/%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%9A%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    <id>http://blog.crazylaw.cn/2022/04/12/%E5%85%AC%E5%8F%B8/%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%9A%E7%9F%A5%E8%AF%86%E7%82%B9/</id>
    <published>2022-04-12T01:53:00.000Z</published>
    <updated>2022-04-12T12:20:15.427Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于广告行业有众多的知识点，所以记录一篇文章用以了解相关的专业名词和术语，并且加深了解的印象。</p><a id="more"></a><h2 id="头部竞价"><a href="#头部竞价" class="headerlink" title="头部竞价"></a>头部竞价</h2><p><code>Header Bidding</code>，顾名思义，就是<code>头部竞价</code>，跟其相对应的就是<code>Waterfall</code>，瀑布流。在<code>Header Bidding</code>风靡<code>之前</code>，<code>Waterfall</code>才是各家广告平台的主流竞价方式。想要了解<code>Header Bidding</code>，那我们就需要先弄清楚什么是<code>Waterfall</code>了。</p><p>这里涉及到的角色有<code>开发者（publisher）</code>，<code>广告调解平台（mediation platform）</code>，<code>需求方（demand partner）</code>。首先，<code>广告调解平台</code>扮演一个（中立）的第三方角色，<code>接入了多家广告平台的广告源</code>，比如<code>Facebook</code>，<code>Vungle</code>，<code>Fyber</code>，<code>Applovin</code>等，即将各家的广告放到一个SDK中，这时候开发者如果想要变现自家的流量，只需接入广告调解平台的SDK即可，再通过一个简单的配置即可自主决定接通哪几家的广告源了，而不需要每家的广告SDK都接一遍，省时省力，是不是很棒？</p><p>那么，问题来了。开发者通过调解平台的SDK介入了多家的广告源后，流量改怎么分配呢？同一个<code>广告请求（ad request）</code>到底是该发给Facebook，还是google还是vungle还是其他人呢？这时候就涉及到调解平台的算法逻辑了，通常，这个调解平台会对给新介入的广告平台分配一定的流量，测试下其表现，并得到一个大概的<code>eCPM</code>的值；然后，调解平台会根据不同的广告平台在<code>过去24小时内的eCPM的高低来排序</code>，广告请求<code>优先</code>发给<code>eCPM最高的第一位选手</code>，若没有<code>填充（fill）</code>，就<code>下一个</code>，<code>没有填充</code>就<code>再下一个</code>，如此<code>循环往复</code>。<code>Waterfall</code>刚出来的时候真的是一个超级棒的概念，很好地解决了开发者流量变现最大化的问题。</p><p>但是，问题又来了。<strong>昨天排在第一的广告平台，谁能保证它今天给的eCPM也是足够高而排在第一位呢？</strong>又或者，昨天排在第三位的广告平台，今天有个爆款的单子推广，可以给到很高的价格，但是由于调解平台的算法机制，它不具有优先选择广告位的权利，而导致它并不能买到多少量。</p><p>这时候，聪明的移动互联网人就想到了借鉴桌面端广告的做法，没错，就是<code>Header Bidding</code>。头部竞价技术源于网页端，开发者通过在网页头部嵌入代码，从而似的广告请求在公开竞价之前可以发给开发者优选的合作伙伴，拿到优选合作伙伴的返回后将其价格与公开竞价价格做对比，价高者得。而这个模型也得以运用到移动端了。</p><p>调解平台一改往日的瀑布流的形式，将<strong>一个接一个地发广告请求的方式</strong> <code>改为</code> <strong>同时像所有的广告平台发请求</strong>，在一定的时间内将收到的返回最比较，<code>最高出价</code>即赢得广告的展示权。</p><h2 id="DSP（Demand-Side-Platform）需求方平台"><a href="#DSP（Demand-Side-Platform）需求方平台" class="headerlink" title="DSP（Demand-Side Platform）需求方平台"></a>DSP（Demand-Side Platform）需求方平台</h2><p>互联网广告DSP（Demand-Side Platform），就是需求方平台</p><p>DSP为需求方（即广告主或代理商）提供实时竞价投放平台。广告需求方可以在平台上管理广告活动及其投放策略，包括设置目标受众的定向条件、预算、出价、创意等。</p><h2 id="SSP（Supply-Side-Platform）供应方平台"><a href="#SSP（Supply-Side-Platform）供应方平台" class="headerlink" title="SSP（Supply-Side Platform）供应方平台"></a>SSP（Supply-Side Platform）供应方平台</h2><p>SSP服务于媒体方，可以作为分散的流量入口、大小媒体的聚合平台。</p><h2 id="ADN（Ad-Network）广告网盟"><a href="#ADN（Ad-Network）广告网盟" class="headerlink" title="ADN（Ad Network）广告网盟"></a>ADN（Ad Network）广告网盟</h2><p>ADN可以被理解为媒体代理公司，通过为广告主采购媒体方流量，赚取中间差价，其代表有百度网盟等。</p><h2 id="ADX（Ad-Exchange）广告交易平台"><a href="#ADX（Ad-Exchange）广告交易平台" class="headerlink" title="ADX（Ad Exchange）广告交易平台"></a>ADX（Ad Exchange）广告交易平台</h2><p>ADX提供的功能是交换，实现实时竞价、广告库存和广告需求的匹配。广告需求方可以随时改变自己的出价策略和所选择的资源。</p><h2 id="程序化广告-交易模式术语"><a href="#程序化广告-交易模式术语" class="headerlink" title="程序化广告-交易模式术语"></a>程序化广告-交易模式术语</h2><h3 id="RTB-real-time-bidding-实时竞价"><a href="#RTB-real-time-bidding-实时竞价" class="headerlink" title="RTB (real time bidding) 实时竞价"></a>RTB (real time bidding) 实时竞价</h3><p>Real Time Bidding(实时竞价)，也叫Open Auction（公开竞价），简称RTB</p><p>流量需求方在广告交易平台中，设定广告流量底价的情况下，当有流量过来时，与其他程序化广告买家一起对流量出价，广告交易平台收到各个程序化买家的出价后，进行比价，价高者获得流量并同步竞价成功的结果。整个过程都是通过程序化的方式在 100 毫秒内完成的。</p><p>品牌能够对单个展示广告位置进行竞价购买，而不是以预先固定的价格进行购买，从而使购买决策更加划算，避免广告主预算浪费</p><h3 id="PDB（Private-Direct-Buy）程序化直接购买"><a href="#PDB（Private-Direct-Buy）程序化直接购买" class="headerlink" title="PDB（Private Direct Buy）程序化直接购买"></a>PDB（Private Direct Buy）程序化直接购买</h3><blockquote><p>这个概念应该和直投是同一个概念</p></blockquote><p>是目前国内市场最为常见和主流应用的一种私有交易模式。</p><p>指流量需求方用确定的价格买断固定、优质的媒体资源，然后进行程序化广告的精准定向投放。常说的“保价保量”。</p><h3 id="PD（Preferred-Deals）优先交易"><a href="#PD（Preferred-Deals）优先交易" class="headerlink" title="PD（Preferred Deals）优先交易"></a>PD（Preferred Deals）优先交易</h3><p>与 PDB 区别在于，这种私有交易方式在广告资源上具有一定的不确定性。即流量需求方可以购买某一优质广告位，但其能获得多少曝光展示量却不能预先保证。常说的“保价不保量”。</p><h3 id="PA（Private-Auction）私有竞价"><a href="#PA（Private-Auction）私有竞价" class="headerlink" title="PA（Private Auction）私有竞价"></a>PA（Private Auction）私有竞价</h3><p>供应方平台将较优质的固定广告位资源专门拿出来，放在一个半公开市场中，仅由进入白名单的买方（VIP）进行竞价，价高者得。因此，广告位可以锁定，但采买价格和是否最终获得曝光都不能预先保证。常说的“不保价不保量”。</p><h2 id="程序化广告-效果术语"><a href="#程序化广告-效果术语" class="headerlink" title="程序化广告-效果术语"></a>程序化广告-效果术语</h2><p>广告传播影响受众的认知、心理、行为和态度，由此带来的直接和间接广告效益，对广告效果的评估的也有着多方面要素和维度。</p><h3 id="ROI"><a href="#ROI" class="headerlink" title="ROI"></a>ROI</h3><p><code>Return On Investment（投资回报率）</code>，简称<code>ROI</code>。即营销者通过广告投放得到的经济回报占广告投入（花费）的比例。</p><h3 id="Impression"><a href="#Impression" class="headerlink" title="Impression"></a>Impression</h3><p><code>Impression</code>，即<code>曝光量</code>，也被称为“展示量”、“展现量”。即投放期广告被展示的总次数。一般用户每浏览一次页面，同时页面中广告位的广告被展示一次，就是一个曝光。</p><h3 id="Click"><a href="#Click" class="headerlink" title="Click"></a>Click</h3><p>Click，即<code>点击量</code>，为投放期用户点击某个广告的总次数。</p><h3 id="CTR-Click-Through-Rate-点击率"><a href="#CTR-Click-Through-Rate-点击率" class="headerlink" title="CTR(Click-Through-Rate) 点击率"></a>CTR(Click-Through-Rate) 点击率</h3><p>广告被点击的次数与广告曝光次数的比例</p><p>计算公式：Click/Impression*100%</p><p>反映了广告的受关注程度，或用来衡量广告的吸引程度。</p><h3 id="RR（Reach-Rate）到达率"><a href="#RR（Reach-Rate）到达率" class="headerlink" title="RR（Reach Rate）到达率"></a>RR（Reach Rate）到达率</h3><p>到达量与点击量的比例（到达量/点击量*100%）</p><p>到达量：即有多少用户点击广告后进入落地页。</p><h3 id="CR（Conversion-Rate）转化率"><a href="#CR（Conversion-Rate）转化率" class="headerlink" title="CR（Conversion Rate）转化率"></a>CR（Conversion Rate）转化率</h3><p>转化量与点击量的比例（转化量/点击量*100%）</p><p>转化量：即有多少用户点击广告并进入落地页（活动页）后，继续发生咨询、注册、下载、加入购物车、下单等行为。</p><h3 id="留存率"><a href="#留存率" class="headerlink" title="留存率"></a>留存率</h3><p>特定周期内（如次日留存、七日留存等），留存用户数量（有多少用户留下来）占广告（当时）导入的新增用户数量的比例。留存率=留存用户数/新增用户数量*100%</p><h3 id="LT（Life-Time）生命周期"><a href="#LT（Life-Time）生命周期" class="headerlink" title="LT（Life Time）生命周期"></a>LT（Life Time）生命周期</h3><p>一个用户从第1次到最后1次参与游戏之间的时间段，一般按月计算平均值</p><h3 id="LTV-Life-Time-Value-用户终生价值"><a href="#LTV-Life-Time-Value-用户终生价值" class="headerlink" title="LTV(Life Time Value) 用户终生价值"></a>LTV(Life Time Value) 用户终生价值</h3><p>用户在生命周期内为该游戏创造的收入总计，可以看成是一个ARPU 值的长期累计。</p><p>计算公式：LTV = ARPUxLT。</p><h3 id="DAU-Daily-Active-Users-日活跃用户数量"><a href="#DAU-Daily-Active-Users-日活跃用户数量" class="headerlink" title="DAU(Daily Active Users) 日活跃用户数量"></a>DAU(Daily Active Users) 日活跃用户数量</h3><p>DAU 指的是某产品（网站、软件或游戏等）在一日之内登录或使用过的用户总数（不包括重复的用户）。</p><p>DAU 是一个比较基本的指标，能够相对片面地展现产品短时间内的热度。</p><p>一般来说只看产品的 DAU 其实意义不大，单纯通过 DAU 无法判断产品的真实质量，且 DAU 很容易伪造。</p><h3 id="MAU-Monthly-Active-Users-月活跃用户数量"><a href="#MAU-Monthly-Active-Users-月活跃用户数量" class="headerlink" title="MAU(Monthly Active Users) 月活跃用户数量"></a>MAU(Monthly Active Users) 月活跃用户数量</h3><p>MAU 指的是某产品（网站、软件或游戏等）在一个月（统计月）之内登录或使用过的用户总数（不包括重复的用户）。</p><p>MAU 同样也是一个比较基本的指标，能够相对片面的展现产品一段时间内的热度。</p><p>通过 DAU 和 MAU 虽然能够看出产品在一段时间内的热度，但是无法精确地判断产品的留存率，因为你无法得知用户的属性（是否为老用户）。此时 DNU 和 DOU 是时候出来救场了。</p><h3 id="DNU-amp-DOU"><a href="#DNU-amp-DOU" class="headerlink" title="DNU &amp; DOU"></a>DNU &amp; DOU</h3><p>「Daily New Users（日新增用户数量 ）&amp; Daily Old Users（日非新增用户数量）」</p><p>这两个词的意义非常明确，就是直接展现了产品短时间内的新老用户情况。</p><p>通过 DNU 和 DOU 加上 DAU 和 MAU 这几个指标能够比较直接地判断产品的留存率（即用户粘性）。</p><h3 id="ARPU-Average-Revenue-Per-User-每用户平均收益"><a href="#ARPU-Average-Revenue-Per-User-每用户平均收益" class="headerlink" title="ARPU(Average Revenue Per User) 每用户平均收益"></a>ARPU(Average Revenue Per User) 每用户平均收益</h3><p>目前 ARPU 这个概念在许多行业都有着广泛的应用，特别是在互联网游戏产业里面，随着免费游戏的兴起，ARPU 日渐成为游戏运营商着重关注的元素。</p><p>一般来说，不同的行业乃至不同的企业都有自己专属的 ARPU 计算方式。</p><p>常用计算公式：每用户平均收益 = 总收益 ÷ 总用户数</p><h2 id="广告相关"><a href="#广告相关" class="headerlink" title="广告相关"></a>广告相关</h2><h3 id="eCPM（Effective-Cost-Per-Mille）-每千次展示收益"><a href="#eCPM（Effective-Cost-Per-Mille）-每千次展示收益" class="headerlink" title="eCPM（Effective Cost Per Mille） 每千次展示收益"></a>eCPM（Effective Cost Per Mille） 每千次展示收益</h3><p>eCPM 是一个主要面向产品方的指标。</p><p>指的是在产品（网页、应用等等）中展示某广告 1000 次所带来的收益。</p><p>计算公式：每千次展示收益 = 总收益 ÷ 广告展示总次数 × 1000</p><blockquote><p>只要是有效展示就行，可以说是很简单粗暴的变现方式了…</p></blockquote><h3 id="CPM"><a href="#CPM" class="headerlink" title="CPM"></a>CPM</h3><p>「Cost Per Mille / Cost Per Thousand Impressions（每千次印象成本）」</p><p>CPM 是一种主要面向广告主的广告计费模式。</p><p>指的是广告投放过程中，平均每向 1000 人展示某广告 1 次需要的成本。一般同一 IP 在 24 小时内最多只有一次有效展示。</p><p>计算公式：每千次印象成本 = 总成本 ÷ 广告达到人数 × 1000</p><blockquote><p>你可以不看，但是我这个广告一定要播！</p></blockquote><h3 id="CPC（Cost-Per-Click）-每点击成本"><a href="#CPC（Cost-Per-Click）-每点击成本" class="headerlink" title="CPC（Cost Per Click） 每点击成本"></a>CPC（Cost Per Click） 每点击成本</h3><p>CPC 是一种主要面向广告主的广告计费模式。</p><p>指的是在广告投放中，广告主仅为用户的有效点击行为付费，而不再为广告的展示次数付费。</p><p>计算公式：每点击成本 = 总成本 ÷ 点击数</p><blockquote><p>不点不给钱！</p></blockquote><h3 id="CPA（Cost-Per-Action）-每行动成本"><a href="#CPA（Cost-Per-Action）-每行动成本" class="headerlink" title="CPA（Cost Per Action） 每行动成本"></a>CPA（Cost Per Action） 每行动成本</h3><p>CPA 是一种主要面向广告主的广告计费模式。</p><p>CPA 顾名思义是按照用户的行为（Action）作为指标来计费，这个行为可以是注册、咨询或加入购物车等等。</p><p>意思就是用户点击了广告还不算，需要用户有注册成功之类的行为才行，不过这种模式下广告费也相对较高。</p><blockquote><p>这是一个不受产品方待见的模式，条件太苛刻了…</p></blockquote><h3 id="CPS-Cost-Per-Sale-每销售成本"><a href="#CPS-Cost-Per-Sale-每销售成本" class="headerlink" title="CPS(Cost Per Sale) 每销售成本"></a>CPS(Cost Per Sale) 每销售成本</h3><p>CPS 是一种面向广告主的广告计费模式。</p><p>在该模式下，广告主的商品成功销售出去之后，产品方才可以获取到一定比例的佣金（提成）。</p><blockquote><p>这么说来似乎有点销售的意思（吃提成）</p></blockquote><h3 id="CPP（Cost-Per-Purchase）每购买成本"><a href="#CPP（Cost-Per-Purchase）每购买成本" class="headerlink" title="CPP（Cost Per Purchase）每购买成本"></a>CPP（Cost Per Purchase）每购买成本</h3><p>CPP 是一种面向广告主的广告计费模式。</p><p>在该模式下，用户点击广告并成功进行交易后，广告主按照销售笔数付给产品方广告费用。</p><blockquote><p>要注意了，CPP 是按照销售笔数来算钱的</p></blockquote><h3 id="CPR（Cost-Per-Response）每回应成本"><a href="#CPR（Cost-Per-Response）每回应成本" class="headerlink" title="CPR（Cost Per Response）每回应成本"></a>CPR（Cost Per Response）每回应成本</h3><p>CPR 是一种面向广告主的广告计费模式，这种模式的特点为：及时反应、直接互动、准确记录。</p><p>在 CPR 模式下，广告展示后，还需要用户给予广告主回应才算有效。所谓回应，一般是拨打电话之类的形式。例如电视购物广告，一般在固定时段播出，当用户拨打了广告中的电话之后才算作有效传播。</p><p>这种模式要求相对较高，也挺不受待见的，这广告费太难赚了…</p><blockquote><p>又想起了被电视购物广告支配的日子..</p></blockquote><h3 id="PPC（Pay-Per-Click）点击付费广告"><a href="#PPC（Pay-Per-Click）点击付费广告" class="headerlink" title="PPC（Pay Per Click）点击付费广告"></a>PPC（Pay Per Click）点击付费广告</h3><p>PPC 是大公司最常用的网络广告形式，这种方法费用很高，但效果也很好，比如百度竞价、搜狐和新浪首页上的 Banner 广告。</p><p>计价公式：起价 + (点击数 × 每次点击的价格)</p><p>越是著名的搜索引擎，起价越高，最高可达数万甚至数十万，而每次点击的价格在 0.30 元左右。</p><p>提供点击付费的网站非常多，主要有各大门户网站(如搜狐、新浪)和搜索引擎（Google 和百度），以及其他浏览量较大的网站，比如提供软件下载的华军等等。</p><blockquote><p>就是那种在搜索引擎搜素关键词，然后在展示在搜索结果前面的那种广告…</p></blockquote><h3 id="PPS（Pay-Per-Sale）-按销售付费"><a href="#PPS（Pay-Per-Sale）-按销售付费" class="headerlink" title="PPS（Pay Per Sale） 按销售付费"></a>PPS（Pay Per Sale） 按销售付费</h3><p>PPS 广告是根据网络广告所产生的直接销售数量而付费的一种定价模式。</p><p>PPS 和 CPS 基本一个意思，类似于淘宝客这类的服务。广义上不仅仅是指互联网广告范畴，应包括所有形式的基于成功销售而收取一定比例佣金的商业合作方式。</p><h2 id="网站相关"><a href="#网站相关" class="headerlink" title="网站相关"></a>网站相关</h2><h3 id="UV（Unique-Visitors）独立访客数"><a href="#UV（Unique-Visitors）独立访客数" class="headerlink" title="UV（Unique Visitors）独立访客数"></a>UV（Unique Visitors）独立访客数</h3><p>UV 表示某网站 1 天内（00:00 - 24:00）的独立访客总数。</p><p>所谓的“独立”访客，是以浏览器的 Cookie 为依据的，只要 Cookie 相同，那么就算更换了 IP 也都将被视为同一个访客，且当天无论访问多少次 UV 都只会加 1 个。</p><blockquote><p>通常是一部手机（电脑）一个坑~</p></blockquote><h3 id="PV（Page-Views）页面浏览量"><a href="#PV（Page-Views）页面浏览量" class="headerlink" title="PV（Page Views）页面浏览量"></a>PV（Page Views）页面浏览量</h3><p>PV 表示某页面在一定统计周期内的总浏览量。</p><p>在一定周期内，用户每次打开或刷新该页面都将被视为 1 次浏览。</p><blockquote><p>刷新一下多一个真好玩~</p></blockquote><h3 id="IP（Internet-Protocol）独立-IP-数"><a href="#IP（Internet-Protocol）独立-IP-数" class="headerlink" title="IP（Internet Protocol）独立 IP 数"></a>IP（Internet Protocol）独立 IP 数</h3><p>IP 表示 1 天内（00:00 - 24:00）访问某网站的 IP 总数。</p><p>该指标以广域网 IP 为依据，同一 IP 的设备无论访问多少次都只算一个计数，也就是说，连接同一路由器的不同设备在同一天内多次访问该网站，在正常情况下都只会增加一个 IP 计数。</p><blockquote><p>一条网线一个坑~</p></blockquote><h3 id="RV（Repeat-Visitors）重复访客数"><a href="#RV（Repeat-Visitors）重复访客数" class="headerlink" title="RV（Repeat Visitors）重复访客数"></a>RV（Repeat Visitors）重复访客数</h3><p>RV 指的是在一定统计周期内，访问某网站两次或两次以上的访客总数。</p><blockquote><p>俗称：回头客</p></blockquote><h3 id="TP（Time-On-Page）页面停留时间"><a href="#TP（Time-On-Page）页面停留时间" class="headerlink" title="TP（Time On Page）页面停留时间"></a>TP（Time On Page）页面停留时间</h3><p>TP 指的是（总的）用户在某个页面的平均停留时长。</p><p>TP 时长可以反映出某个页面对用户的吸引力，帮助判断用户的喜好。</p><blockquote><p>能看完这篇文章的话 TP 应该能有 5 分钟吧</p></blockquote><h3 id="TS（Time-On-Site）-网站停留时间"><a href="#TS（Time-On-Site）-网站停留时间" class="headerlink" title="TS（Time On Site） 网站停留时间"></a>TS（Time On Site） 网站停留时间</h3><p>TS 指的是（总的）用户在某网站（包括了该网站下的所有页面）的平均停留时长。</p><blockquote><p>反正视频网站的 TS 肯定都挺长的</p></blockquote><h3 id="SD（Session-Duration-）平均会话时长"><a href="#SD（Session-Duration-）平均会话时长" class="headerlink" title="SD（Session Duration ）平均会话时长"></a>SD（Session Duration ）平均会话时长</h3><p>SD 是在 Google Analytics 中使用的一个指标，用来统计网站的平均停留时长。</p><p>SD 的作用类似于 Time On Site，但是这两者的计算方式不一样。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;由于广告行业有众多的知识点，所以记录一篇文章用以了解相关的专业名词和术语，并且加深了解的印象。&lt;/p&gt;
    
    </summary>
    
    
      <category term="广告行业" scheme="http://blog.crazylaw.cn/categories/%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%9A/"/>
    
    
      <category term="广告行业" scheme="http://blog.crazylaw.cn/tags/%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%9A/"/>
    
  </entry>
  
  <entry>
    <title>【Mac】Mac安装软件流程</title>
    <link href="http://blog.crazylaw.cn/2022/03/29/Mac/Mac%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%B5%81%E7%A8%8B/"/>
    <id>http://blog.crazylaw.cn/2022/03/29/Mac/Mac%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%B5%81%E7%A8%8B/</id>
    <published>2022-03-29T08:35:30.000Z</published>
    <updated>2022-04-11T10:31:25.337Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近，准备重新打造我的mac电脑。</p><a id="more"></a><h2 id="iterm2"><a href="#iterm2" class="headerlink" title="iterm2"></a>iterm2</h2><p><img src="/images/%E6%9D%82/iterm2.png" alt="iterm2"></p><p><img src="/images/%E6%9D%82/iterm2-2.png" alt="iterm2"></p><p><img src="/images/%E6%9D%82/iterm2-fonts.png" alt="iterm2"></p><ul><li>安装zsh</li><li>安装 <a href="https://github.com/romkatv/powerlevel10k" target="_blank" rel="noopener">powerlevel10k</a> (安装方式参考官网文档)</li><li>替换 <code>.vimrc</code> 中的 <code>zsh主题</code>, <code>ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot;</code></li></ul><h2 id="vim相关"><a href="#vim相关" class="headerlink" title="vim相关"></a>vim相关</h2><p>我的个人vim配置 <a href="https://github.com/whiteCcinn/ccinn-vim" target="_blank" rel="noopener">ccinn-vim</a></p><p><img src="/images/%E6%9D%82/vim.png" alt="vim"></p><p>vim的插件管理选择有 <code>Vundle</code>, <code>vim-plug</code></p><h3 id="vim的目录插件"><a href="#vim的目录插件" class="headerlink" title="vim的目录插件"></a>vim的目录插件</h3><ul><li><a href="https://github.com/preservim/nerdtree" target="_blank" rel="noopener">scrooloose/nerdtree</a></li></ul><h3 id="vim的目录增强插件-字体和icon的下载和安装"><a href="#vim的目录增强插件-字体和icon的下载和安装" class="headerlink" title="vim的目录增强插件,字体和icon的下载和安装"></a>vim的目录增强插件,字体和icon的下载和安装</h3><p>可以在nerd目录下显示图标，其他字体等</p><ul><li><p><a href="https://github.com/ryanoasis/nerd-fonts" target="_blank" rel="noopener">ryanoasis/nerd-fonts</a></p></li><li><p><a href="https://github.com/ryanoasis/vim-devicons" target="_blank" rel="noopener">ryanoasis/vim-devicons</a></p></li></ul><blockquote><p>主体iterm2 的字体需要和nerd-fonts一致</p></blockquote><h3 id="vim-窗口状态栏"><a href="#vim-窗口状态栏" class="headerlink" title="vim 窗口状态栏"></a>vim 窗口状态栏</h3><ul><li><a href="https://github.com/vim-airline/vim-airline" target="_blank" rel="noopener">vim-airline/vim-airline</a></li><li><a href="https://github.com/vim-airline/vim-airline-themes" target="_blank" rel="noopener">vim-airline/vim-airline-themes</a></li></ul><h2 id="Clean-my-mac"><a href="#Clean-my-mac" class="headerlink" title="Clean my mac"></a>Clean my mac</h2><p>付费软件，清理电脑</p><h2 id="ntfs-for-mac"><a href="#ntfs-for-mac" class="headerlink" title="ntfs for mac"></a>ntfs for mac</h2><p>外置移动硬盘专用</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近，准备重新打造我的mac电脑。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Mac" scheme="http://blog.crazylaw.cn/categories/Mac/"/>
    
    
      <category term="Mac" scheme="http://blog.crazylaw.cn/tags/Mac/"/>
    
  </entry>
  
  <entry>
    <title>【DevOps】git命令场景用法</title>
    <link href="http://blog.crazylaw.cn/2022/03/19/DevOps/git%E5%91%BD%E4%BB%A4%E5%9C%BA%E6%99%AF%E7%94%A8%E6%B3%95/"/>
    <id>http://blog.crazylaw.cn/2022/03/19/DevOps/git%E5%91%BD%E4%BB%A4%E5%9C%BA%E6%99%AF%E7%94%A8%E6%B3%95/</id>
    <published>2022-03-19T06:35:30.000Z</published>
    <updated>2022-04-15T07:40:12.764Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>现在，git已经成为了大家的代码仓库管理的一个工具了。在日常工作，我们会遇到各种个样的git问题，因此，用一篇文章来累计记录，日常生活中，我们会遇到，但是不常用的命令。</p><a id="more"></a><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>其实 <code>git</code> 的概念，我们开发者应该很多有会了，存在以下几个区域：</p><ul><li>工作区   <code>（你的任何改动）</code></li><li>暂存区   <code>（git add）</code></li><li>本地仓库 <code>（git commit）</code></li><li>远端代码仓库 <code>（git push）</code></li></ul><h2 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h2><p>我们一般说合并其实是有</p><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;现在，git已经成为了大家的代码仓库管理的一个工具了。在日常工作，我们会遇到各种个样的git问题，因此，用一篇文章来累计记录，日常生活中，我们会遇到，但是不常用的命令。&lt;/p&gt;
    
    </summary>
    
    
      <category term="DevOps" scheme="http://blog.crazylaw.cn/categories/DevOps/"/>
    
    
      <category term="DevOps" scheme="http://blog.crazylaw.cn/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- go map源码阅读</title>
    <link href="http://blog.crazylaw.cn/2022/03/10/Golang/go%20map%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>http://blog.crazylaw.cn/2022/03/10/Golang/go%20map%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</id>
    <published>2022-03-10T07:55:51.000Z</published>
    <updated>2022-03-22T08:54:11.241Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近发现同事去面试，发现很多时候会被问到<code>go map</code>的底层结构。今天我们来记录一下map的底层实现。</p><a id="more"></a><p>当下的源码阅读基于1.17</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A header for a Go map.</span></span><br><span class="line"><span class="keyword">type</span> hmap <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go.</span></span><br><span class="line"><span class="comment">// Make sure this stays in sync with the compiler's definition.</span></span><br><span class="line">count     <span class="keyword">int</span> <span class="comment">// # live cells == size of map.  Must be first (used by len() builtin)</span></span><br><span class="line">flags     <span class="keyword">uint8</span></span><br><span class="line">B         <span class="keyword">uint8</span>  <span class="comment">// log_2 of # of buckets (can hold up to loadFactor * 2^B items)</span></span><br><span class="line">noverflow <span class="keyword">uint16</span> <span class="comment">// approximate number of overflow buckets; see incrnoverflow for details</span></span><br><span class="line">hash0     <span class="keyword">uint32</span> <span class="comment">// hash seed</span></span><br><span class="line"></span><br><span class="line">buckets    unsafe.Pointer <span class="comment">// array of 2^B Buckets. may be nil if count==0.</span></span><br><span class="line">oldbuckets unsafe.Pointer <span class="comment">// previous bucket array of half the size, non-nil only when growing</span></span><br><span class="line">nevacuate  <span class="keyword">uintptr</span>        <span class="comment">// progress counter for evacuation (buckets less than this have been evacuated)</span></span><br><span class="line"></span><br><span class="line">extra *mapextra <span class="comment">// optional fields</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这是一个map的头部结构，其中有几个关键结构，分别是</p><ul><li><code>count</code> 当前map的元素个数</li><li><code>buckets</code> 桶的数量，一般是2^B个</li><li><code>oldbuckets</code> 扩容前的buckets</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// mapextra holds fields that are not present on all maps.</span></span><br><span class="line"><span class="keyword">type</span> mapextra <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// If both key and elem do not contain pointers and are inline, then we mark bucket</span></span><br><span class="line"><span class="comment">// type as containing no pointers. This avoids scanning such maps.</span></span><br><span class="line"><span class="comment">// However, bmap.overflow is a pointer. In order to keep overflow buckets</span></span><br><span class="line"><span class="comment">// alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow.</span></span><br><span class="line"><span class="comment">// overflow and oldoverflow are only used if key and elem do not contain pointers.</span></span><br><span class="line"><span class="comment">// overflow contains overflow buckets for hmap.buckets.</span></span><br><span class="line"><span class="comment">// oldoverflow contains overflow buckets for hmap.oldbuckets.</span></span><br><span class="line"><span class="comment">// The indirection allows to store a pointer to the slice in hiter.</span></span><br><span class="line">overflow    *[]*bmap</span><br><span class="line">oldoverflow *[]*bmap</span><br><span class="line"></span><br><span class="line"><span class="comment">// nextOverflow holds a pointer to a free overflow bucket.</span></span><br><span class="line">nextOverflow *bmap</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>简单来说，这个可以忽略。</p></blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A bucket for a Go map.</span></span><br><span class="line"><span class="keyword">type</span> bmap <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// tophash generally contains the top byte of the hash value</span></span><br><span class="line"><span class="comment">// for each key in this bucket. If tophash[0] &lt; minTopHash,</span></span><br><span class="line"><span class="comment">// tophash[0] is a bucket evacuation state instead.</span></span><br><span class="line">tophash [bucketCnt]<span class="keyword">uint8</span></span><br><span class="line"><span class="comment">// Followed by bucketCnt keys and then bucketCnt elems.</span></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> packing all the keys together and then all the elems together makes the</span></span><br><span class="line"><span class="comment">// code a bit more complicated than alternating key/elem/key/elem/... but it allows</span></span><br><span class="line"><span class="comment">// us to eliminate padding which would be needed for, e.g., map[int64]int8.</span></span><br><span class="line"><span class="comment">// Followed by an overflow pointer.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>bmap有2个模块的属性是在编译注入的，在源码上没办法浏览。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">                                                    ┌─────────────────────────────────────┐</span><br><span class="line">                                                    │bmap                                 │</span><br><span class="line">┌─────────────────────────────────────┐             │                                     │</span><br><span class="line">│bmap                                 │             │                                     │</span><br><span class="line">│                                     │             │                                     │</span><br><span class="line">│                                     │             │    ┌──────────────────────────────┐ │</span><br><span class="line">│                                     │             │    │tohash[bucketCnt]uint8        │ │</span><br><span class="line">│    ┌──────────────────────────────┐ │             │    │                              │ │</span><br><span class="line">│    │tohash[bucketCnt]uint8        │ │             │    │                              │ │</span><br><span class="line">│    │                              │ │             │    │                              │ │</span><br><span class="line">│    │                              │ │             │    └──────────────────────────────┘ │</span><br><span class="line">│    │                              │ │             │                                     │</span><br><span class="line">│    └──────────────────────────────┘ │             │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">│                                     │             │    +  byte-array                  + │</span><br><span class="line">│    ++++++++++++++++++++++++++++++++ │             │    +        (save key-value)      + │</span><br><span class="line">│    +  byte-array                  + │     ┌──────►│    +                              + │</span><br><span class="line">│    +        (save key-value)      + │     │       │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">│    +                              + │     │       │                                     │</span><br><span class="line">│    ++++++++++++++++++++++++++++++++ │     │       │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">│                                     │     │       │    +   point to growed bucket     + │</span><br><span class="line">│    ++++++++++++++++++++++++++++++++ │     │       │    +                              + │</span><br><span class="line">│    +   point to growed bucket     + │     │       │    +                              + │</span><br><span class="line">│    +                              + ├─────┘       │    +++++++++++++─┐+++++++++++++++++ │</span><br><span class="line">│    +                              + │             │                  │                  │</span><br><span class="line">│    ++++++++++++++++++++++++++++++++ │             │                  │                  │</span><br><span class="line">│                                     │             └──────────────────┼──────────────────┘</span><br><span class="line">│                                     │                                │</span><br><span class="line">└─────────────────────────────────────┘                                │</span><br><span class="line">                                                                       │</span><br><span class="line">                                                                       ▼</span><br><span class="line">                                                     ┌─────────────────────────────────────┐</span><br><span class="line">                                                     │bmap                                 │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │    ┌──────────────────────────────┐ │</span><br><span class="line">                                                     │    │tohash[bucketCnt]uint8        │ │</span><br><span class="line">                                                     │    │                              │ │</span><br><span class="line">                                                     │    │                              │ │</span><br><span class="line">                                                     │    │                              │ │</span><br><span class="line">                                                     │    └──────────────────────────────┘ │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">                                                     │    +  byte-array                  + │</span><br><span class="line">                                                     │    +        (save key-value)      + │</span><br><span class="line">                                                     │    +                              + │</span><br><span class="line">                                                     │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">                                                     │    +   point to growed bucket     + │</span><br><span class="line">                                                     │    +                              + │</span><br><span class="line">                                                     │    +                              + │</span><br><span class="line">                                                     │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     └─────────────────────────────────────┘s</span><br></pre></td></tr></table></figure><p>相比于hmap，bucket的结构显得简单一些，<code>byte-array</code>是我们使用的map中的key和value就存储在这里。<code>高位哈希值</code>数组记录的是当前bucket中key相关的<code>索引</code></p><h2 id="mapassign-赋值过程"><a href="#mapassign-赋值过程" class="headerlink" title="mapassign 赋值过程"></a>mapassign 赋值过程</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 判断会否当前已经进行了写保护</span></span><br><span class="line"><span class="keyword">if</span> h.flags&amp;hashWriting != <span class="number">0</span> &#123;</span><br><span class="line">throw(<span class="string">"concurrent map writes"</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 2. 根据key计算哈希值</span></span><br><span class="line">hash := t.hasher(key, <span class="keyword">uintptr</span>(h.hash0))</span><br><span class="line"><span class="comment">// 3. 进行写保护</span></span><br><span class="line">h.flags ^= hashWriting</span><br><span class="line"><span class="comment">// 4. 计算hash的低位部分</span></span><br><span class="line">bucket := hash &amp; bucketMask(h.B)</span><br><span class="line"><span class="comment">// 5. 判断是否正在扩容，如果是，则数据迁移</span></span><br><span class="line"><span class="keyword">if</span> h.growing() &#123;</span><br><span class="line">growWork(t, h, bucket)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 6. 根据低位hash找到对应的bucket</span></span><br><span class="line">b := (*bmap)(add(h.buckets, bucket*<span class="keyword">uintptr</span>(t.bucketsize)))</span><br><span class="line"><span class="comment">// 7. 计算高位hash</span></span><br><span class="line">top := tophash(hash)</span><br><span class="line"><span class="comment">// 8. 从对应的bucket以及overflow buckets中找到对应的key的位置</span></span><br><span class="line"><span class="comment">// 9. 判断是否需要扩容，如果需要，则重新找到key的位置</span></span><br><span class="line"><span class="keyword">if</span> !h.growing() &amp;&amp; (overLoadFactor(h.count+<span class="number">1</span>, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) &#123;</span><br><span class="line">hashGrow(t, h)</span><br><span class="line"><span class="keyword">goto</span> again <span class="comment">// Growing the table invalidates everything, so try again</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 10. 拿着可以插入kv的内存地址进行赋值</span></span><br><span class="line"><span class="keyword">if</span> t.indirectkey() &#123;</span><br><span class="line">kmem := newobject(t.key)</span><br><span class="line">*(*unsafe.Pointer)(insertk) = kmem</span><br><span class="line">insertk = kmem</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> t.indirectelem() &#123;</span><br><span class="line">vmem := newobject(t.elem)</span><br><span class="line">*(*unsafe.Pointer)(elem) = vmem</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 11. 写保护检查，并且解除写保护</span></span><br><span class="line"><span class="keyword">if</span> h.flags&amp;hashWriting == <span class="number">0</span> &#123;</span><br><span class="line">throw(<span class="string">"concurrent map writes"</span>)</span><br><span class="line">&#125;</span><br><span class="line">h.flags &amp;^= hashWriting</span><br></pre></td></tr></table></figure><p>赋值过程就是：</p><ol><li>进行写保护</li><li>根据key计算哈希值</li><li>在低位哈希中找到bucket</li><li>计算高位hash</li><li>在bucket和overflow bucket桶中找到能插入key/value的位置</li><li>找到了就赋值</li><li>解除锁保护</li></ol><blockquote><p>其中有多次判断bucket是否需要扩容和是否正在扩容</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近发现同事去面试，发现很多时候会被问到&lt;code&gt;go map&lt;/code&gt;的底层结构。今天我们来记录一下map的底层实现。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Go源码剖析系列" scheme="http://blog.crazylaw.cn/categories/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
      <category term="Go源码剖析" scheme="http://blog.crazylaw.cn/tags/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- go time.Sleep源码阅读</title>
    <link href="http://blog.crazylaw.cn/2022/03/10/Golang/go%20time.Sleep%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>http://blog.crazylaw.cn/2022/03/10/Golang/go%20time.Sleep%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</id>
    <published>2022-03-10T07:55:51.000Z</published>
    <updated>2022-03-10T14:09:34.592Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于time.Sleep()会挂起我们的协程，我们来看一下它的底层原理。</p><a id="more"></a><h2 id="sleep-的实现"><a href="#sleep-的实现" class="headerlink" title="sleep 的实现"></a>sleep 的实现</h2><p>我们通常使用 <code>time.Sleep(1 * time.Second)</code> 来将 goroutine 暂时休眠一段时间。sleep 操作在底层实现也是基于 timer 实现的。</p><p>有一些比较有意思的地方，单独拿出来讲下。</p><p>我们固然也可以这么做来实现 goroutine 的休眠:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">timer := time.NewTimer(<span class="number">2</span> * time.Seconds)</span><br><span class="line">&lt;-timer.C</span><br></pre></td></tr></table></figure><p>这么做当然可以。但 golang 底层显然不是这么做的，因为这样有两个明显的额外性能损耗。</p><ul><li>每次调用 sleep 的时候，都要创建一个 timer 对象</li><li>需要一个 channel 来传递事件</li></ul><p>既然都可以放在 runtime 里面做。golang 里面做的更加干净：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// timeSleep puts the current goroutine to sleep for at least ns nanoseconds.</span></span><br><span class="line"><span class="comment">//go:linkname timeSleep time.Sleep</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">timeSleep</span><span class="params">(ns <span class="keyword">int64</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> ns &lt;= <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gp := getg()</span><br><span class="line">t := gp.timer</span><br><span class="line"><span class="keyword">if</span> t == <span class="literal">nil</span> &#123;</span><br><span class="line">t = <span class="built_in">new</span>(timer)</span><br><span class="line">gp.timer = t</span><br><span class="line">&#125;</span><br><span class="line">t.f = goroutineReady</span><br><span class="line">t.arg = gp</span><br><span class="line">t.nextwhen = nanotime() + ns</span><br><span class="line"><span class="keyword">if</span> t.nextwhen &lt; <span class="number">0</span> &#123; <span class="comment">// check for overflow.</span></span><br><span class="line">t.nextwhen = maxWhen</span><br><span class="line">&#125;</span><br><span class="line">gopark(resetForSleep, unsafe.Pointer(t), waitReasonSleep, traceEvGoSleep, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>在G对象上存在一个timer属性，在G的生命周期里timer都是唯一存在，解决了重复新建对象的问题</li><li>如果不存在timer，则在第一次的时候创建timer</li></ul><p>并且把<code>t.f</code>设置成<code>goroutineReay</code>(这个意思是time到了时间之后设置一个触发函数，这个触发函数就是唤醒我们当前G任务)。</p><p>然后通过<code>gopark</code>来挂起当前的G任务</p><h2 id="定时器的触发机制"><a href="#定时器的触发机制" class="headerlink" title="定时器的触发机制"></a>定时器的触发机制</h2><p>共分两种方式，分别为 <code>调度器触发</code> 和 <code>监控线程sysmon</code> 触发，两者主要是通过调用函数 <code>checkTimers()</code> 来实现的。</p><p>主要有两个地方会检查计时器，一个是 <code>runtime.schedule</code>，另一个是 <code>findrunnable</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runtime/proc.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">schedule</span><span class="params">()</span></span> &#123; </span><br><span class="line"> _g_ := getg() </span><br><span class="line"> </span><br><span class="line">top: </span><br><span class="line"> pp := _g_.m.p.ptr() </span><br><span class="line"> pp.preempt = <span class="literal">false</span> </span><br><span class="line"> </span><br><span class="line"> <span class="comment">// 处理调度时的计时器触发 </span></span><br><span class="line"> checkTimers(pp, <span class="number">0</span>) </span><br><span class="line"> ... </span><br><span class="line"> </span><br><span class="line"> execute(gp, inheritTime) </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>另外一种是当前处理器 P 没有可执行的 Timer，且没有可执行的 G。那么按照调度模型，就会去<code>窃取其他计时器</code>和 <code>G</code>：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runtime/proc.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">findrunnable</span><span class="params">()</span> <span class="params">(gp *g, inheritTime <span class="keyword">bool</span>)</span></span> &#123; </span><br><span class="line"> _g_ := getg() </span><br><span class="line"> </span><br><span class="line">top: </span><br><span class="line"> _p_ := _g_.m.p.ptr() </span><br><span class="line"> ... </span><br><span class="line"> now, pollUntil, _ := checkTimers(_p_, <span class="number">0</span>) </span><br><span class="line"> ... </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;由于time.Sleep()会挂起我们的协程，我们来看一下它的底层原理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Go源码剖析系列" scheme="http://blog.crazylaw.cn/categories/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
      <category term="Go源码剖析" scheme="http://blog.crazylaw.cn/tags/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- go channel源码阅读</title>
    <link href="http://blog.crazylaw.cn/2022/03/04/Golang/go%20channel%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>http://blog.crazylaw.cn/2022/03/04/Golang/go%20channel%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</id>
    <published>2022-03-03T16:43:51.000Z</published>
    <updated>2022-03-29T02:24:03.596Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>channel 是 Golang 中一个非常重要的特性，也是 <code>Golang CSP</code> 并发模型的一个重要体现。简单来说就是，goroutine 之间可以通过 channel 进行通信。</p><p>channel 在 Golang 如此重要，在代码中使用频率非常高，以至于不得不好奇其内部实现。本文将基于 <code>go 1.17</code> 的源码，分析 channel 的内部实现原理。</p><a id="more"></a><h2 id="channel-的基本使用"><a href="#channel-的基本使用" class="headerlink" title="channel 的基本使用"></a>channel 的基本使用</h2><p>在正式分析 channel 的实现之前，我们先看下 channel 的最基本用法，代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        c &lt;- <span class="number">1</span> <span class="comment">// send to channel</span></span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    x := &lt;-c <span class="comment">// recv from channel</span></span><br><span class="line"></span><br><span class="line">    fmt.Println(x)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在以上代码中，我们通过 <code>make(chan int)</code> 来创建了一个类型为 int 的 channel。<br>在一个 goroutine 中使用 <code>c &lt;- 1</code> 将数据发送到 channel 中。在主 goroutine 中通过 <code>x := &lt;- c</code> 从 channel 中读取数据并赋值给 x。</p><p>以上代码对应了 channel 的两种基本操作：</p><ul><li>send 操作 <code>c &lt;- 1</code> 表示发送数据到 channel</li><li>recv 操作 <code>x := &lt;- c</code> 表示从 channel 中接收数据。</li></ul><p>此外，channel 还分为<code>有缓存 channel</code> 和<code>无缓存 channel</code>。上述代码中，我们使用的是无缓冲的 channel。对于无缓冲的 channel，如果当前没有其他 goroutine 正在接收 channel 数据，则发送方会阻塞在发送语句处。</p><p>我们可以在 channel 初始化时指定缓冲区大小。例如，<code>make(chan int, 2)</code> 则指定缓冲区大小为 2。在缓冲区未满之前，发送方无阻塞地可以往 channel 发送数据，无需等待接收方准备好。而如果缓冲区已满，则发送方依然会阻塞。</p><h2 id="channel-对应的底层实现函数"><a href="#channel-对应的底层实现函数" class="headerlink" title="channel 对应的底层实现函数"></a>channel 对应的底层实现函数</h2><p>在探究 channel 源码之前，我们肯定首先需要先找到 channel 在 Golang 的具体实现在哪。因为我们在使用 channel 时，用的是 <code>&lt;- 符号</code>，并不能直接在 go 源码中找到其实现。但是 Golang 编译器必然会将 <code>&lt;-</code> 符号翻译成底层对应的实现。</p><p>我们可以使用 Go 自带的命令: <code>go tool compile -N -l -S hello.go</code>, 将代码翻译成对应的汇编指令。</p><p>或者，直接可以使用 <code>Compiler Explorer</code> 这个在线工具。对于上述示例代码可以直接在这个链接看其汇编结果: <a href="go.godbolt.org/z/3xw5Cj">go.godbolt.org/z/3xw5Cj</a>。如下图：</p><p><img src="/images/Go/%E6%BA%90%E7%A0%81/chansend1.png" alt="chansend1"></p><blockquote><p>chansend1</p></blockquote><p><img src="/images/Go/%E6%BA%90%E7%A0%81/chanrevc1.png" alt="chanrevc1"></p><blockquote><p>chanrevc1</p></blockquote><p>通过仔细查看以上示例代码对应的汇编指令，可以发现以下的对应关系：</p><p>channel 的构造语句 <code>make(chan int)</code>, 对应的是 <code>runtime.makechan</code> 函数<br>发送语句 <code>c &lt;- 1</code>, 对应的是 <code>runtime.chansend1</code> 函数<br>接收语句 <code>x := &lt;- c</code>, 对应的是 <code>runtime.chanrecv1</code> 函数<br>以上几个函数的实现都位于 go 源码中的 <code>runtime/chan.go</code> 代码文件中。我们接下来针对这几个函数，探究下 channel 的实现。</p><h2 id="channel-的构造"><a href="#channel-的构造" class="headerlink" title="channel 的构造"></a>channel 的构造</h2><p>channel 的构造语句 <code>make(chan int)</code>，将会被 golang 编译器翻译为 <code>runtime.makechan</code> 函数, 其函数签名如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">makechan</span><span class="params">(t *chantype, size <span class="keyword">int</span>)</span> *<span class="title">hchan</span></span></span><br></pre></td></tr></table></figure><p>其中，<code>t *chantype</code> 即构造 channel 时传入的元素类型。<code>size int</code> 即用户指定的 channel 缓冲区大小，不指定则为 0。该函数的返回值是 <code>*hchan</code>。hchan 则是 channel 在 golang 中的内部实现。其定义如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> hchan <span class="keyword">struct</span> &#123;</span><br><span class="line">qcount   <span class="keyword">uint</span>           <span class="comment">// buffer 中已放入的元素个数</span></span><br><span class="line">dataqsiz <span class="keyword">uint</span>           <span class="comment">// 用户构造 channel 时指定的 buf 大小</span></span><br><span class="line">buf      unsafe.Pointer <span class="comment">// buffer</span></span><br><span class="line">elemsize <span class="keyword">uint16</span>         <span class="comment">// buffer 中每个元素的大小</span></span><br><span class="line">closed   <span class="keyword">uint32</span>         <span class="comment">// channel 是否关闭，== 0 代表未 closed</span></span><br><span class="line">elemtype *_type         <span class="comment">// channel 元素的类型信息</span></span><br><span class="line">sendx    <span class="keyword">uint</span>           <span class="comment">// buffer 中已发送的索引位置 send index</span></span><br><span class="line">recvx    <span class="keyword">uint</span>           <span class="comment">// buffer 中已接收的索引位置 receive index</span></span><br><span class="line">recvq    waitq          <span class="comment">// 等待接收的 goroutine  list of recv waiters</span></span><br><span class="line">sendq    waitq          <span class="comment">// 等待发送的 goroutine list of send waiters</span></span><br><span class="line"></span><br><span class="line">lock mutex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>hchan 中的所有属性大致可以分为三类：</p><ul><li>buffer 相关的属性。例如 <code>buf</code>、<code>dataqsiz</code>、<code>qcount</code> 等。 当 channel 的缓冲区大小不为 0 时，buffer 中存放了待接收的数据。使用 <code>ring buffer</code> 实现。</li><li>waitq 相关的属性，可以理解为是一个 FIFO 的标准队列。其中 <code>recvq</code> 中是正在等待接收数据的 goroutine，<code>sendq</code> 中是等待发送数据的 goroutine。waitq 使用<code>双向链表</code>实现。</li><li>其他属性，例如 lock、elemtype、closed。</li></ul><p>通过简单分析 hchan 的属性，我们可以知道其中有两个重要的组件，<code>buffer</code> 和 <code>waitq</code>。hchan 所有行为和实现都是围绕这两个组件进行的。</p><h2 id="向-channel-中发送数据"><a href="#向-channel-中发送数据" class="headerlink" title="向 channel 中发送数据"></a>向 channel 中发送数据</h2><p>channel 的发送和接收流程很相似，我们先分析下 channel 的发送过程 (如 <code>c &lt;- 1</code>), 对应于 <code>runtime.chansend</code> 函数的实现。</p><p>在尝试向 channel 中发送数据时，如果 <code>recvq</code> 队列不为空，则首先会从 <code>recvq</code> 中头部取出一个等待接收数据的 goroutine 出来。并将数据直接发送给该 goroutine。代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">lock(&amp;c.lock)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> c.closed != <span class="number">0</span> &#123;</span><br><span class="line">unlock(&amp;c.lock)</span><br><span class="line"><span class="built_in">panic</span>(plainError(<span class="string">"send on closed channel"</span>))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> sg := c.recvq.dequeue(); sg != <span class="literal">nil</span> &#123;</span><br><span class="line">send(c, sg, ep, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; unlock(&amp;c.lock) &#125;, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>我们看到当我们整个send的过程是需要加锁处理的，并且也可以看到我们老生常谈的一个问题，当向cloesd的channel数据的时候，会导致panic产生</p></blockquote><p>recvq 中是正在等待接收数据的 goroutine。当某个 goroutine 使用 recv 操作 (例如，<code>x := &lt;- c</code>)，如果此时 channel 的缓存中没有数据，且没有其他 goroutine 正在等待发送数据 (即 <code>sendq</code> 为空)，会将该 goroutine 以及要接收的数据地址打包成 <code>sudog</code> 对象，并放入到 recvq 中。</p><p>继续接着讲上面的代码，如果此时 <code>recvq</code> 不为空，则调用 <code>send 函数</code>将数据拷贝到对应的 goroutine 的堆栈上。</p><p>这个时候<code>不经过</code>我们的<code>环形缓存！！！</code></p><p>send 函数的实现主要包含两点：</p><ol><li><code>memmove(dst, src, t.size)</code> 进行数据的转移，本质上就是一个内存拷贝。</li><li><code>goready(gp, skip+1)</code> goready 的作用是唤醒对应的 goroutine。</li></ol><p>而如果 <code>recvq</code> 队列为空，则说明此时<code>没有等待接收</code>数据的 goroutine，那么此时 channel 会尝试把数据放到缓存中。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> c.qcount &lt; c.dataqsiz &#123;</span><br><span class="line"><span class="comment">// Space is available in the channel buffer. Enqueue the element to send.</span></span><br><span class="line">qp := chanbuf(c, c.sendx)</span><br><span class="line"><span class="keyword">if</span> raceenabled &#123;</span><br><span class="line">racenotify(c, c.sendx, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br><span class="line">typedmemmove(c.elemtype, qp, ep)</span><br><span class="line">c.sendx++</span><br><span class="line"><span class="keyword">if</span> c.sendx == c.dataqsiz &#123;</span><br><span class="line">c.sendx = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line">c.qcount++</span><br><span class="line">unlock(&amp;c.lock)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码的作用其实非常简单，就是把数据放到 buffer 中而已。此过程涉及了 <code>ring buffer</code> 的操作，其中 <code>dataqsiz</code> 代表用户指定的 channel 的 buffer 大小，如果不指定则默认为 0。</p><p>如果用户使用的是无缓冲 channel 或者此时 buffer 已满，则 <code>c.qcount &lt; c.dataqsiz</code> 条件不会满足, 以上流程也并不会执行到。此时会将当前的 goroutine 以及要发送的数据放入到 <code>sendq</code> 队列中，同时会切出该 goroutine</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Block on the channel. Some receiver will complete our operation for us.</span></span><br><span class="line">gp := getg()</span><br><span class="line">mysg := acquireSudog()</span><br><span class="line">mysg.releasetime = <span class="number">0</span></span><br><span class="line"><span class="keyword">if</span> t0 != <span class="number">0</span> &#123;</span><br><span class="line">mysg.releasetime = <span class="number">-1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// No stack splits between assigning elem and enqueuing mysg</span></span><br><span class="line"><span class="comment">// on gp.waiting where copystack can find it.</span></span><br><span class="line">mysg.elem = ep</span><br><span class="line">mysg.waitlink = <span class="literal">nil</span></span><br><span class="line">mysg.g = gp</span><br><span class="line">mysg.isSelect = <span class="literal">false</span></span><br><span class="line">mysg.c = c</span><br><span class="line">gp.waiting = mysg</span><br><span class="line">gp.param = <span class="literal">nil</span></span><br><span class="line">c.sendq.enqueue(mysg)</span><br><span class="line"><span class="comment">// Signal to anyone trying to shrink our stack that we're about</span></span><br><span class="line"><span class="comment">// to park on a channel. The window between when this G's status</span></span><br><span class="line"><span class="comment">// changes and when we set gp.activeStackChans is not safe for</span></span><br><span class="line"><span class="comment">// stack shrinking.</span></span><br><span class="line">atomic.Store8(&amp;gp.parkingOnChan, <span class="number">1</span>)</span><br><span class="line"><span class="comment">// 将 goroutine 转入 waiting 状态</span></span><br><span class="line">gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, <span class="number">2</span>)</span><br><span class="line"><span class="comment">// Ensure the value being sent is kept alive until the</span></span><br><span class="line"><span class="comment">// receiver copies it out. The sudog has a pointer to the</span></span><br><span class="line"><span class="comment">// stack object, but sudogs aren't considered as roots of the</span></span><br><span class="line"><span class="comment">// stack tracer.</span></span><br><span class="line">KeepAlive(ep)</span><br><span class="line"><span class="comment">// 确保正在发送的值保持活动状态，直到接收者将其复制出来。sudog有一个指向堆栈对象的指针，但是sudog不被认为是堆栈跟踪程序的根。</span></span><br><span class="line"><span class="comment">// 总而言之：防止被GC</span></span><br></pre></td></tr></table></figure><p>调用 gopark 后，对于用户侧来看，该向 channel 发送数据的代码语句会进行阻塞。</p><p>以上过程就是 channel 的发送语句 (如，<code>c &lt;- 1</code>) 的内部工作流程，同时整个发送过程都使用 <code>c.lock</code> 进行加锁，保证并发安全。</p><p>简单来说，整个流程如下：</p><ol><li>检查 recvq 是否为空，如果不为空，则从 recvq 头部<code>取一个 goroutine</code>，将数据发送过去，并<code>唤醒对应的 goroutine</code> 即可</li><li>如果 recvq 为空，则将数据放入到 buffer 中</li><li>如果 buffer 已满，则将要发送的数据和当前 goroutine 打包成 <code>sudog</code> 对象放入到 <code>sendq</code> 中。并将当前 goroutine 置为 waiting 状态。</li></ol><p>从 channel 中接收数据的过程基本与发送过程类似，此处不再赘述了。</p><p>这里需要注意的是，channel 的<code>整个发送过程</code>和<code>接收过程</code>都使用 <code>runtime.mutex</code> 进行加锁。<code>runtime.mutex</code> 是 runtime 相关源码中常用到的一个<code>轻量级锁</code>。整个过程并不是最高效的 <code>lockfree</code> 的做法。</p><p>golang 在这里有个 <a href="https://github.com/golang/go/issues/8899" target="_blank" rel="noopener">issue:go/issues#8899</a>，给出了 <code>lockfree</code> 的 <code>channel</code> 的方案。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;channel 是 Golang 中一个非常重要的特性，也是 &lt;code&gt;Golang CSP&lt;/code&gt; 并发模型的一个重要体现。简单来说就是，goroutine 之间可以通过 channel 进行通信。&lt;/p&gt;
&lt;p&gt;channel 在 Golang 如此重要，在代码中使用频率非常高，以至于不得不好奇其内部实现。本文将基于 &lt;code&gt;go 1.17&lt;/code&gt; 的源码，分析 channel 的内部实现原理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Go源码剖析系列" scheme="http://blog.crazylaw.cn/categories/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
      <category term="Go源码剖析" scheme="http://blog.crazylaw.cn/tags/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- Sync包详解</title>
    <link href="http://blog.crazylaw.cn/2022/03/04/Golang/sync%E5%8C%85%E8%AF%A6%E8%A7%A3/"/>
    <id>http://blog.crazylaw.cn/2022/03/04/Golang/sync%E5%8C%85%E8%AF%A6%E8%A7%A3/</id>
    <published>2022-03-03T16:43:51.000Z</published>
    <updated>2022-04-15T07:40:12.764Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们直到sync包给我们提供了一系列并发安全的数据结构。之前有见过一次sync-map，但是这一次刚好复习整理一下sync包的知识点。</p><a id="more"></a><h2 id="Sync"><a href="#Sync" class="headerlink" title="Sync"></a>Sync</h2><ul><li>Sync.Map</li><li>Sync.Once</li><li>Sync.Pool</li><li>Sync.Cond</li><li>Sync.WaitGroup</li></ul><h2 id="sync-Map"><a href="#sync-Map" class="headerlink" title="sync.Map"></a>sync.Map</h2><ul><li>sync.Map主要针对于Map对于并发读写不支持的场景下提出实现的，其原理是通过对map的写操作进行加锁：Sync.RWMutex</li><li>同时sync.Map实现了读写分离，当对map进行读操作时，通过读read Map, 当read Map中不存在是去dirty map中读取</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Map <span class="keyword">struct</span> &#123;</span><br><span class="line">me Mutex</span><br><span class="line">read atomic.Value  <span class="comment">// readOnly,读数据</span></span><br><span class="line">dirty <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]*entry <span class="comment">// 包含最新的写入数据，当missed达到一定的值时，将值赋给read</span></span><br><span class="line">misses <span class="keyword">int</span>  <span class="comment">// 计数作用，每次从read中读失败，则missed加一</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// readOnly的数据结构</span></span><br><span class="line"><span class="keyword">type</span> readOnly <span class="keyword">struct</span>&#123;</span><br><span class="line">m <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]*entry</span><br><span class="line">amended <span class="keyword">bool</span>  <span class="comment">// Map.dirty中的数据和这里的m中的数据不同时值为true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// entry的数据结构：</span></span><br><span class="line"><span class="keyword">type</span> entry <span class="keyword">struct</span> &#123;</span><br><span class="line">p unsafe.Pointer <span class="comment">// *interface&#123;&#125;</span></span><br><span class="line"><span class="comment">// 可见value是一个指针值，虽然read和dirty存在冗余情况，但由于是指针类型，存储空间不会太多</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>sync.Map相关问题</p><ul><li>sync.Map的核心实现：两个map,一个用于写，一个用于读，这样的设计思想可以类比于缓存与数据库</li><li>sync.Map的局限性：如果写远高于读，dirty -&gt; readOnly这个类似于刷新数据的频率较高，不如直接使用mutex + map的效率高</li><li>sync.Map的设计思想：保证高频率读的无锁结构，空间换时间的思想</li></ul><h2 id="sync-WaitGroup"><a href="#sync-WaitGroup" class="headerlink" title="sync.WaitGroup"></a>sync.WaitGroup</h2><ul><li>sync.WaitGroup常用于针对goroutine的并发执行，通过WaitGroup可以等待所有的go程序执行结束之后再执行之后的逻辑</li><li>WaitGroup对象内部有一个计数器，最初重0开始，提供了三个方法：Add(),Done(),Wait()用来控制计数器的数量。Add(n)把计数器设置为n,Done()每次把计数器减一，Wait()会阻塞代码的执行，直到计数器的值减到0为止。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;我们直到sync包给我们提供了一系列并发安全的数据结构。之前有见过一次sync-map，但是这一次刚好复习整理一下sync包的知识点。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/categories/Golang/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>【大数据】- 在公司从0到1落地flink流计算任务</title>
    <link href="http://blog.crazylaw.cn/2022/02/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9C%A8%E5%85%AC%E5%8F%B8%E4%BB%8E0%E5%88%B01%E8%90%BD%E5%9C%B0flink%E6%B5%81%E8%AE%A1%E7%AE%97%E4%BB%BB%E5%8A%A1/"/>
    <id>http://blog.crazylaw.cn/2022/02/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9C%A8%E5%85%AC%E5%8F%B8%E4%BB%8E0%E5%88%B01%E8%90%BD%E5%9C%B0flink%E6%B5%81%E8%AE%A1%E7%AE%97%E4%BB%BB%E5%8A%A1/</id>
    <published>2022-02-15T03:10:40.000Z</published>
    <updated>2022-02-17T01:14:41.637Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在公司落地一套flink，总结到目前为止做了的事情。</p><a id="more"></a><h2 id="开发环境的部署"><a href="#开发环境的部署" class="headerlink" title="开发环境的部署"></a>开发环境的部署</h2><p>我们默认场景下，<code>flink</code>使用<code>hive-catalog</code>，所以<code>hive</code>安装在这里。</p><p>Hive使用<code>mysql</code>作为<code>外部数据存储</code>，所以这里使用<code>mysql</code></p><p>对于flink的开发，如果我想要一整套的本地的docker开发环境。</p><p>需要集成如下服务：</p><ul><li>hadoop</li><li>hive</li><li>flink</li><li>kafka</li><li>mysql</li></ul><p>所以做了一个<a href="https://github.com/whiteCcinn/flink-docker-compose" target="_blank" rel="noopener">flink-docker-compose</a></p><p>在该项目中，由于不是采用<code>CDH</code>来集成的，都是一个个源码包手动安装的。所以需要下载源码包。</p><p>目前的版本为：</p><ul><li>flink: 1.12.0_2.11</li><li>mysql: 5.6 （8.0-jdbc）</li><li>kafka: 2.12_2.11</li><li>maven: 3.6.3</li><li>jdk: 8/11 (默认jdk8)</li></ul><blockquote><p>本地环境的话，jdk需要自行处理好</p></blockquote><ul><li>hadoop: 3.1.1</li><li>hive: 3.1.0</li></ul><h3 id="一键下载源码包"><a href="#一键下载源码包" class="headerlink" title="一键下载源码包"></a>一键下载源码包</h3><p>为了方便方便大家下载，对应的镜像链接，也都集成在了<code>download.sh</code>中，如果需要利用<code>迅雷</code>等p2p加速下载软件，可以通过从中提取出来 <code>url</code> 进行下载。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./download.sh all</span><br></pre></td></tr></table></figure><h3 id="可设置的-env"><a href="#可设置的-env" class="headerlink" title="可设置的.env"></a>可设置的<code>.env</code></h3><p>利用<code>docker-compose</code>对 <code>.env</code>的支持，可以在当中设置<code>build image</code>的一些环境变量和参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Hadoop</span></span><br><span class="line">HADOOP_VERSION=3.1.1</span><br><span class="line"><span class="meta">#</span><span class="bash"> Hive</span></span><br><span class="line">HIVE_VERSION=3.1.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> Scala</span></span><br><span class="line">SCALA_VERSION=2.11</span><br><span class="line"><span class="meta">#</span><span class="bash"> Flink</span></span><br><span class="line">FLINK_VERSION=1.12.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> Kafka</span></span><br><span class="line">KAFKA_VERSION=2.4.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> Zookeeper</span></span><br><span class="line">ZOOKEEPER_VERSION=3.5.6</span><br><span class="line"><span class="meta">#</span><span class="bash"> Mysql</span></span><br><span class="line">MYSQL_VERSION=5.6</span><br><span class="line">MYSQL_DATABASE=default</span><br><span class="line">MYSQL_PORT=3306</span><br><span class="line">MYSQL_ROOT_PASSWORD=lnhzjm/B4qrSc</span><br><span class="line">MYSQL_ENTRYPOINT_INITDB=./deploy/mysql/docker-entrypoint-initdb.d</span><br><span class="line">MYSQL_TIMEZONE=UTC</span><br></pre></td></tr></table></figure><h3 id="kafka的网络"><a href="#kafka的网络" class="headerlink" title="kafka的网络"></a>kafka的网络</h3><p>我们知道kafka的网络协议是<code>支持多端口</code>的，由于我们有时候flink是在本地，有时候是在容器中，所以我们希望我们的kafka集群，支持容器内的网络，也支持和我们物理机的网络。</p><p>这个时候，我们需要设置kafka的2套端口协议。所以你可以看到</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kafka1:</span></span><br><span class="line">   <span class="attr">build:</span></span><br><span class="line">     <span class="attr">context:</span> <span class="string">./deploy/kafka</span></span><br><span class="line">     <span class="attr">args:</span></span><br><span class="line">       <span class="attr">scala_version:</span> <span class="string">$&#123;SCALA_VERSION&#125;</span></span><br><span class="line">       <span class="attr">kafka_version:</span> <span class="string">$&#123;KAFKA_VERSION&#125;</span></span><br><span class="line">   <span class="attr">container_name:</span> <span class="string">flink-kafka1</span></span><br><span class="line">   <span class="attr">ports:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'19092:19092'</span></span><br><span class="line">   <span class="attr">environment:</span></span><br><span class="line">     <span class="attr">KAFKA_PORT:</span> <span class="number">19092</span></span><br><span class="line">     <span class="attr">KAFKA_ADVERTISED_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://kafka1:19092</span></span><br><span class="line">     <span class="attr">KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:</span> <span class="string">PLAINTEXT:PLAINTEXT,EXTERNAL_PLAINTEXT:PLAINTEXT</span></span><br><span class="line">     <span class="attr">KAFKA_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://:19092</span></span><br><span class="line">     <span class="attr">KAFKA_ZOOKEEPER_CONNECT:</span> <span class="string">zookeeper:2181</span></span><br><span class="line">     <span class="attr">KAFKA_DEFAULT_REPLICATION_FACTOR:</span> <span class="number">3</span></span><br><span class="line">   <span class="attr">networks:</span></span><br><span class="line">     <span class="attr">flink-networks:</span></span><br><span class="line">       <span class="attr">ipv4_address:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.211</span></span><br><span class="line">   <span class="attr">extra_hosts:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'zookeeper:192.168.6.215'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka1:192.168.6.211'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka2:192.168.6.212'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka3:192.168.6.213'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka4:192.168.6.214'</span></span><br><span class="line">   <span class="attr">depends_on:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">zookeeper</span></span><br></pre></td></tr></table></figure><p>看到这里的</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">KAFKA_ADVERTISED_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://kafka1:19092</span></span><br><span class="line"><span class="attr">KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:</span> <span class="string">PLAINTEXT:PLAINTEXT,EXTERNAL_PLAINTEXT:PLAINTEXT</span></span><br><span class="line"><span class="attr">KAFKA_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://:19092</span></span><br></pre></td></tr></table></figure><p>这个就是决定我们的<code>2套协议</code>的关键所在，分别是对<code>9092（容器内）</code>和<code>19092(和物理机)</code>端口的支持。</p><p>但是设置完了这个，由于一般kafka-client会从可本机的可访问的<code>dns服务器</code>上寻找<code>host映射</code>，在连接的时候必备的流程。</p><p>在本地连接的时候，会通过<code>kafka1/kafka2</code>等hostname返回到client，client需要在本机找到所有的ip映射，所以我们需要设置一下<code>etc/hosts</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo "127.0.0.1 kafka1 kafka2 kafka3 kafka4" &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure><p>目前为止，我们所需要的环境变量已经处理完了。</p><h2 id="基于datastream-api的flink开发"><a href="#基于datastream-api的flink开发" class="headerlink" title="基于datastream-api的flink开发"></a>基于datastream-api的flink开发</h2><p>我们知道flink提供了3种API，分别是<code>datastream-api</code>,<code>table-api</code>,<code>sql-api</code></p><p><code>datastream</code>，也是flink的最原始的api，和flink集成一体，通过<code>datastream-api</code>，我们可以实现各种灵活的数据流处理。</p><p>按照我们以往对流计算数据的处理，在游戏公司中，一个游戏项目部署一个流计算的任务即为合理。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── README.md</span><br><span class="line">├── pom.xml</span><br><span class="line">└── src</span><br><span class="line">    └── main</span><br><span class="line">        ├── java</span><br><span class="line">        │   ├── deps</span><br><span class="line">        │   │   ├── oaYdSdk</span><br><span class="line">        │   │   │   ├── Youdu.java</span><br><span class="line">        │   │   │   └── test</span><br><span class="line">        │   │   │       └── YouduTest.java</span><br><span class="line">        │   │   └── util</span><br><span class="line">        │   │       ├── ParameterToolEnvironmentUtils.java</span><br><span class="line">        │   │       └── Util.java</span><br><span class="line">        │   └── org</span><br><span class="line">        │       └── cp</span><br><span class="line">        │           └── flink</span><br><span class="line">        │               ├── Bootstrap.java</span><br><span class="line">        │               ├── async</span><br><span class="line">        │               │   └── AsyncOaYdHttpClient.java</span><br><span class="line">        │               ├── events</span><br><span class="line">        │               │   ├── CommonEvent.java</span><br><span class="line">        │               │   ├── CommonEventHeader.java</span><br><span class="line">        │               │   ├── app_error</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_ban</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_client_loss</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_consume_gold</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_fcm_error</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_index_record</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_index_record_data</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_role_create</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   └── t_log_market</span><br><span class="line">        │               │       ├── Event.java</span><br><span class="line">        │               │       ├── EventHeader.java</span><br><span class="line">        │               │       └── EventLog.java</span><br><span class="line">        │               ├── jobs</span><br><span class="line">        │               │   ├── alarm</span><br><span class="line">        │               │   │   ├── ErrorReport_10008.java</span><br><span class="line">        │               │   │   ├── Job_10002.java</span><br><span class="line">        │               │   │   ├── Job_10008.java</span><br><span class="line">        │               │   │   ├── Job_19.java</span><br><span class="line">        │               │   │   ├── README.md</span><br><span class="line">        │               │   │   └── handler</span><br><span class="line">        │               │   │       ├── AbstractHandler.java</span><br><span class="line">        │               │   │       ├── errorReport_10008</span><br><span class="line">        │               │   │       │   ├── Logic.java</span><br><span class="line">        │               │   │       │   ├── Logic_10012.java</span><br><span class="line">        │               │   │       │   ├── Logic_19.java</span><br><span class="line">        │               │   │       │   └── Logic_20.java</span><br><span class="line">        │               │   │       ├── job_10002</span><br><span class="line">        │               │   │       │   ├── LogIndexRecordDataHandler.java</span><br><span class="line">        │               │   │       │   ├── LogIndexRecordHandler.java</span><br><span class="line">        │               │   │       │   └── model</span><br><span class="line">        │               │   │       │       ├── log_index_record</span><br><span class="line">        │               │   │       │       │   └── StatisticsMcfx2Model.java</span><br><span class="line">        │               │   │       │       └── log_index_record_data</span><br><span class="line">        │               │   │       │           └── StatisticsMcfx1Model.java</span><br><span class="line">        │               │   │       ├── job_10008</span><br><span class="line">        │               │   │       │   ├── AppErrorHandler.java</span><br><span class="line">        │               │   │       │   ├── LogFcmErrorHandler.java</span><br><span class="line">        │               │   │       │   └── model</span><br><span class="line">        │               │   │       │       ├── app_error</span><br><span class="line">        │               │   │       │       │   └── StatisticsAppErrorModel.java</span><br><span class="line">        │               │   │       │       └── log_fcm_error</span><br><span class="line">        │               │   │       │           └── StatisticsFcmErrorModel.java</span><br><span class="line">        │               │   │       └── job_19</span><br><span class="line">        │               │   │           ├── LogBanHandler.java</span><br><span class="line">        │               │   │           ├── LogClientLossHandler.java</span><br><span class="line">        │               │   │           ├── LogConsumeGoldHandler.java</span><br><span class="line">        │               │   │           ├── LogRoleCreateHandler.java</span><br><span class="line">        │               │   │           ├── TLogMarketHandler.java</span><br><span class="line">        │               │   │           └── model</span><br><span class="line">        │               │   │               ├── log_ban</span><br><span class="line">        │               │   │               │   └── StatisticsModel.java</span><br><span class="line">        │               │   │               ├── log_client_loss</span><br><span class="line">        │               │   │               │   └── IpMonitorModel.java</span><br><span class="line">        │               │   │               ├── log_consume_gold</span><br><span class="line">        │               │   │               │   ├── StatisticsBindGoldModel.java</span><br><span class="line">        │               │   │               │   └── StatisticsUnBindGoldModel.java</span><br><span class="line">        │               │   │               ├── log_role_create</span><br><span class="line">        │               │   │               │   └── SingleServerRoleCreateModel.java</span><br><span class="line">        │               │   │               └── t_log_market</span><br><span class="line">        │               │   │                   ├── MarketTransactionLogByBuyerModel.java</span><br><span class="line">        │               │   │                   └── MarketTransactionLogBySellerModel.java</span><br><span class="line">        │               │   └── stream</span><br><span class="line">        │               │       └── README.md</span><br><span class="line">        │               ├── mock</span><br><span class="line">        │               │   ├── MockAppError.java</span><br><span class="line">        │               │   ├── MockLogFcmError.java</span><br><span class="line">        │               │   └── README.md</span><br><span class="line">        │               ├── serializer</span><br><span class="line">        │               │   ├── AbstractSerializer.java</span><br><span class="line">        │               │   └── log_role_create</span><br><span class="line">        │               │       └── LogRoleCreateDeSerializer.java</span><br><span class="line">        │               └── sinks</span><br><span class="line">        │                   ├── AsyncOaYdSdkHttpSink.java</span><br><span class="line">        │                   ├── MysqlItem.java</span><br><span class="line">        │                   └── MysqlSink.java</span><br><span class="line">        └── resources</span><br><span class="line">            ├── application-dev.properties</span><br><span class="line">            ├── application-local.properties</span><br><span class="line">            ├── application-pro.properties</span><br><span class="line">            ├── application.properties</span><br><span class="line">            ├── jobs</span><br><span class="line">            │   ├── org.cp.flink.jobs.alarm.ErrorReport_10008</span><br><span class="line">            │   │   ├── application-dev.properties</span><br><span class="line">            │   │   ├── application-local.properties</span><br><span class="line">            │   │   ├── application-pro.properties</span><br><span class="line">            │   │   └── application.properties</span><br><span class="line">            │   ├── org.cp.flink.jobs.alarm.Job_10002</span><br><span class="line">            │   │   ├── application-dev.properties</span><br><span class="line">            │   │   ├── application-local.properties</span><br><span class="line">            │   │   ├── application-pro.properties</span><br><span class="line">            │   │   └── application.properties</span><br><span class="line">            │   ├── org.cp.flink.jobs.alarm.Job_10008</span><br><span class="line">            │   │   ├── application-dev.properties</span><br><span class="line">            │   │   ├── application-local.properties</span><br><span class="line">            │   │   ├── application-pro.properties</span><br><span class="line">            │   │   └── application.properties</span><br><span class="line">            │   └── org.cp.flink.jobs.alarm.Job_19</span><br><span class="line">            │       ├── application-dev.properties</span><br><span class="line">            │       ├── application-local.properties</span><br><span class="line">            │       ├── application-pro.properties</span><br><span class="line">            │       └── application.properties</span><br><span class="line">            └── log4j2.properties</span><br></pre></td></tr></table></figure><p>这是我们早期的一个<code>代码层级结构</code>，所有的流计算任务基于一个flink项目下，<code>resources</code>下的配置根据当前需要提交的项目和环境来进行区分加载具体的配置，可以做到支持<code>多环境</code>,<code>多项目</code>下配置灵活配置。</p><p>我们看到 <code>org.cp.flink</code>目下，就是我们的所有flink代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">➜  flinkjob git:(master) ✗ tree -d src/main/java/org</span><br><span class="line">src/main/java/org</span><br><span class="line">└── cp</span><br><span class="line">    └── flink</span><br><span class="line">        ├── async</span><br><span class="line">        ├── events</span><br><span class="line">        │   ├── app_error</span><br><span class="line">        │   ├── log_ban</span><br><span class="line">        │   ├── log_client_loss</span><br><span class="line">        │   ├── log_consume_gold</span><br><span class="line">        │   ├── log_fcm_error</span><br><span class="line">        │   ├── log_index_record</span><br><span class="line">        │   ├── log_index_record_data</span><br><span class="line">        │   ├── log_role_create</span><br><span class="line">        │   └── t_log_market</span><br><span class="line">        ├── jobs</span><br><span class="line">        │   ├── alarm</span><br><span class="line">        │   │   └── handler</span><br><span class="line">        │   │       ├── job_10002</span><br><span class="line">        │   │       │   └── model</span><br><span class="line">        │   │       │       ├── log_index_record</span><br><span class="line">        │   │       │       └── log_index_record_data</span><br><span class="line">        │   │       ├── job_10008</span><br><span class="line">        │   │       │   └── model</span><br><span class="line">        │   │       │       ├── app_error</span><br><span class="line">        │   │       │       └── log_fcm_error</span><br><span class="line">        │   │       └── job_19</span><br><span class="line">        │   │           └── model</span><br><span class="line">        │   │               ├── log_ban</span><br><span class="line">        │   │               ├── log_client_loss</span><br><span class="line">        │   │               ├── log_consume_gold</span><br><span class="line">        │   │               ├── log_role_create</span><br><span class="line">        │   │               └── t_log_market</span><br><span class="line">        │   └── stream</span><br><span class="line">        ├── mock</span><br><span class="line">        ├── serializer</span><br><span class="line">        │   └── log_role_create</span><br><span class="line">        └── sinks</span><br></pre></td></tr></table></figure><p>我们先看到，<code>jobs</code>目录下的，分为了2种类型，我们平时用的流计算任务可以分为2种，一种是常规的<code>告警属性</code>，另一种是<code>产品属性(类似BI系统需要的实时数据)</code>。</p><p>我们看到<code>alarm/handler/job_xxx</code>就是我们具体的项目。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">src/main/java/org/cp/flink/jobs/alarm/</span></span><br><span class="line"><span class="string">├──</span> <span class="string">Job_10002.java</span></span><br><span class="line"><span class="string">├──</span> <span class="string">Job_10008.java</span></span><br><span class="line"><span class="string">├──</span> <span class="string">Job_19.java</span></span><br><span class="line"><span class="string">├──</span> <span class="string">README.md</span></span><br><span class="line"><span class="string">└──</span> <span class="string">handler</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">AbstractHandler.java</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">errorReport_10008</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">Logic.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">Logic_10012.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">Logic_19.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">└──</span> <span class="string">Logic_20.java</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">job_10002</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">LogIndexRecordDataHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">LogIndexRecordHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">└──</span> <span class="string">model</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">├──</span> <span class="string">log_index_record</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsMcfx2Model.java</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">└──</span> <span class="string">log_index_record_data</span></span><br><span class="line">    <span class="string">│</span>           <span class="string">└──</span> <span class="string">StatisticsMcfx1Model.java</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">job_10008</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">AppErrorHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">LogFcmErrorHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">└──</span> <span class="string">model</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">├──</span> <span class="string">app_error</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsAppErrorModel.java</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">└──</span> <span class="string">log_fcm_error</span></span><br><span class="line">    <span class="string">│</span>           <span class="string">└──</span> <span class="string">StatisticsFcmErrorModel.java</span></span><br><span class="line">    <span class="string">└──</span> <span class="string">job_19</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogBanHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogClientLossHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogConsumeGoldHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogRoleCreateHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">TLogMarketHandler.java</span></span><br><span class="line">        <span class="string">└──</span> <span class="string">model</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_ban</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsModel.java</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_client_loss</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">IpMonitorModel.java</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_consume_gold</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">├──</span> <span class="string">StatisticsBindGoldModel.java</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsUnBindGoldModel.java</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_role_create</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">SingleServerRoleCreateModel.java</span></span><br><span class="line">            <span class="string">└──</span> <span class="string">t_log_market</span></span><br><span class="line">                <span class="string">├──</span> <span class="string">MarketTransactionLogByBuyerModel.java</span></span><br><span class="line">                <span class="string">└──</span> <span class="string">MarketTransactionLogBySellerModel.java</span></span><br></pre></td></tr></table></figure><p>对于各个项目的<code>错误告警监控</code>，这里分为了多个<code>job</code>。</p><ul><li>Job_10002.java</li><li>Job_10008.java</li><li>Job_19.java</li></ul><p>我们从入口开始看</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.jobs.alarm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> deps.util.Util;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.ProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.OutputTag;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.Bootstrap;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_10008.AppErrorHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_10008.LogFcmErrorHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.CommonEvent;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.app_error.Event;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Job_10008</span> <span class="keyword">extends</span> <span class="title">Bootstrap</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(Job_10008<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env = getStreamExecutionEnvironment(args, Job_10008<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        env.enableCheckpointing(<span class="number">5000</span>); <span class="comment">// checkpoint every 5000 msecs</span></span><br><span class="line"></span><br><span class="line">        ParameterTool parameterTool = (ParameterTool) env.getConfig().getGlobalJobParameters();</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.setProperty(<span class="string">"bootstrap.servers"</span>, parameterTool.get(<span class="string">"kafka.source.bootstrap.servers"</span>));</span><br><span class="line">        props.setProperty(<span class="string">"group.id"</span>, parameterTool.get(<span class="string">"kafka.source.group"</span>));</span><br><span class="line">        props.put(<span class="string">"enable.auto.commit"</span>, parameterTool.get(<span class="string">"kafka.source.enable.auto.commit"</span>));</span><br><span class="line">        props.put(<span class="string">"auto.commit.interval.ms"</span>, parameterTool.get(<span class="string">"kafka.source.auto.commit.interval.ms"</span>));</span><br><span class="line">        props.put(<span class="string">"session.timeout.ms"</span>, parameterTool.get(<span class="string">"kafka.source.session.timeout.ms"</span>));</span><br><span class="line">        props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置kafka并行度</span></span><br><span class="line">        env.setParallelism(parameterTool.getInt(<span class="string">"kafka.source.parallelism"</span>, <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        DataStream&lt;String&gt; stream = env</span><br><span class="line">                .addSource(<span class="keyword">new</span> FlinkKafkaConsumer&lt;&gt;(Arrays.asList(parameterTool.get(<span class="string">"kafka.source.topic"</span>).split(<span class="string">","</span>)), <span class="keyword">new</span> SimpleStringSchema(), props));</span><br><span class="line"></span><br><span class="line">        env.setParallelism(parameterTool.getInt(<span class="string">"app.parallelism"</span>, <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;CommonEvent&gt; s0 = stream.filter((String json) -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                JSONObject.parseObject(json, CommonEvent<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">                logger.error(json);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;).map(</span><br><span class="line">                (String json) -&gt; JSONObject.parseObject(json, CommonEvent<span class="class">.<span class="keyword">class</span>).<span class="title">setOriginJson</span>(<span class="title">json</span>)</span></span><br><span class="line"><span class="class">        ).<span class="title">returns</span>(<span class="title">CommonEvent</span>.<span class="title">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> OutputTag&lt;CommonEvent&gt; outputTagAppError = <span class="keyword">new</span> OutputTag&lt;CommonEvent&gt;(AppErrorHandler<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()) </span>&#123;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">final</span> OutputTag&lt;CommonEvent&gt; outputTagLogFcmError = <span class="keyword">new</span> OutputTag&lt;CommonEvent&gt;(LogFcmErrorHandler<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()) </span>&#123;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 主流不需要了, 所以不需要调用collector.collect()</span></span><br><span class="line">        <span class="comment">// 2. 只要旁路输出流，因为要区分数据进行处理</span></span><br><span class="line">        <span class="comment">// 利用low-level-api的process算子处理旁路输出采集数据</span></span><br><span class="line">        SingleOutputStreamOperator&lt;CommonEvent&gt; s1 = s0.process(<span class="keyword">new</span> ProcessFunction&lt;CommonEvent, CommonEvent&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(CommonEvent event, Context context, Collector&lt;CommonEvent&gt; collector)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">switch</span> (event.getHeaders().getLogName()) &#123;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">"app_error"</span>:</span><br><span class="line">                        context.output(outputTagAppError, event);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">"log_fcm_error"</span>:</span><br><span class="line">                        context.output(outputTagLogFcmError, event);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;CommonEvent&gt; AppErrorSource = s1.getSideOutput(outputTagAppError);</span><br><span class="line">        DataStream&lt;CommonEvent&gt; LogFcmErrorSource = s1.getSideOutput(outputTagLogFcmError);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Event&gt; AppErrorSource_s0 = AppErrorSource.map((CommonEvent event) -&gt; JSONObject.parseObject(event.getOriginJson(), Event<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">        ).<span class="title">returns</span>(<span class="title">Event</span>.<span class="title">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        DataStream&lt;org.cp.flink.events.log_fcm_error.Event&gt; LogFcmErrorSource_s0 = LogFcmErrorSource.map((CommonEvent event) -&gt; JSONObject.parseObject(event.getOriginJson(), org.cp.flink.events.log_fcm_error.Event<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">        ).<span class="title">returns</span>(<span class="title">org</span>.<span class="title">cp</span>.<span class="title">flink</span>.<span class="title">events</span>.<span class="title">log_fcm_error</span>.<span class="title">Event</span>.<span class="title">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        AppErrorHandler.build().handle(AppErrorSource_s0);</span><br><span class="line">        LogFcmErrorHandler.build().handle(LogFcmErrorSource_s0);</span><br><span class="line"></span><br><span class="line">        env.execute(Util.getCurrentJobName(((ParameterTool) env.getConfig().getGlobalJobParameters())));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于我们一个topic只能够可能存在多种数据，所以这里利用了<code>旁路由</code>进行了分流。把数据流分发到不同的<code>子流</code>中，我们再把<code>子流</code>传递不同的<code>Handler</code>进行处理。</p><p>这里例如: <code>AppErrorHandler</code>。我们以此为例子进行说明。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.jobs.alarm.handler.job_10008;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.ProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.OutputTag;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.AbstractHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_10008.model.app_error.StatisticsAppErrorModel;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.app_error.Event;</span><br><span class="line"></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AppErrorHandler</span> <span class="keyword">extends</span> <span class="title">AbstractHandler</span>&lt;<span class="title">Event</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> AppErrorHandler instance;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> AppErrorHandler <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> AppErrorHandler();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(DataStream&lt;Event&gt; s0)</span> </span>&#123;</span><br><span class="line">        ParameterTool parameterTool = <span class="keyword">this</span>.getParameterTool(s0);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 利用旁路输出多流到对应到model</span></span><br><span class="line">        <span class="comment">// StatisticsAppErrorModel</span></span><br><span class="line">        <span class="keyword">final</span> OutputTag&lt;Event&gt; outputTagStatisticsAppError = <span class="keyword">new</span> OutputTag&lt;Event&gt;(StatisticsAppErrorModel<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()) </span>&#123;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;Event&gt; s1 = s0.process(<span class="keyword">new</span> ProcessFunction&lt;Event, Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(Event event, Context context, Collector&lt;Event&gt; collector)</span> </span>&#123;</span><br><span class="line">                context.output(outputTagStatisticsAppError, event);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Event&gt; sideOutputStreamAppError = s1.getSideOutput(outputTagStatisticsAppError);</span><br><span class="line"></span><br><span class="line">        StatisticsAppErrorModel.build().handle(sideOutputStreamAppError);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (parameterTool.getBoolean(<span class="string">"app.handler.print.console"</span>, <span class="keyword">false</span>)) &#123;</span><br><span class="line">            s0.print(AppErrorHandler<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于，我们希望到一条数据从<code>kafka</code>被<code>pull</code>下来到时候，可以用于多个不同的<code>流计算模型model</code>，所以我们在这里需要<code>copy</code>到多个<code>旁路输出</code>，但是这里我们只有一个<code>stream-model</code>，所以我们就只用一个来处理即可，从旁路输出拿到<code>datastream</code>之后，在对应的模型中进行<code>核心逻辑</code>处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.jobs.alarm.handler.job_10008.model.app_error;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> deps.util.Util;</span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.functions.KeySelector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple3;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple5;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.WindowedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.windowing.WindowFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.TimeWindow;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.runtime.operators.util.AssignerWithPeriodicWatermarksAdapter;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.AbstractHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.app_error.Event;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_19.model.log_ban.StatisticsModel;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.sinks.MysqlItem;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.sinks.MysqlSink;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 错误日志统计</span></span><br><span class="line"><span class="comment"> * 窗口：滚动事件窗口，每1分钟统计一次</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StatisticsAppErrorModel</span> <span class="keyword">extends</span> <span class="title">AbstractHandler</span>&lt;<span class="title">Event</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_SINK_DATABASE = <span class="string">"db_app_log_alarm"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_SINK_TABLE = <span class="string">"t_log_app_error_alarm_164"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(StatisticsAppErrorModel<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> StatisticsAppErrorModel instance;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> StatisticsAppErrorModel <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> StatisticsAppErrorModel();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(DataStream&lt;Event&gt; s0)</span> </span>&#123;</span><br><span class="line">        s0.getExecutionConfig().setAutoWatermarkInterval(<span class="number">5000L</span>);</span><br><span class="line"></span><br><span class="line">        logger.debug(<span class="string">"getAutoWatermarkInterval: &#123;&#125;"</span>, s0.getExecutionConfig().getAutoWatermarkInterval());</span><br><span class="line">        ParameterTool parameterTool = <span class="keyword">this</span>.getParameterTool(s0);</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;Event&gt; s1 = s0.assignTimestampsAndWatermarks(<span class="keyword">new</span> AssignerWithPeriodicWatermarksAdapter.Strategy&lt;&gt;(</span><br><span class="line">                        <span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;Event&gt;(Time.of(<span class="number">1</span>, TimeUnit.SECONDS)) &#123;</span><br><span class="line"></span><br><span class="line">                            <span class="meta">@Override</span></span><br><span class="line">                            <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                                Long ts = event.getLogs().getMtime() * <span class="number">1000L</span>;</span><br><span class="line">                                logger.debug(</span><br><span class="line">                                        <span class="string">"thread-id: &#123;&#125;, eventTime: [&#123;&#125;|&#123;&#125;], watermark: [&#123;&#125;|&#123;&#125;]"</span>,</span><br><span class="line">                                        Thread.currentThread().getId(),</span><br><span class="line">                                        ts,</span><br><span class="line">                                        sdf.format(ts),</span><br><span class="line">                                        <span class="keyword">this</span>.getCurrentWatermark().getTimestamp(),</span><br><span class="line">                                        sdf.format(<span class="keyword">this</span>.getCurrentWatermark().getTimestamp())</span><br><span class="line">                                );</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">return</span> ts;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                )</span><br><span class="line">                        <span class="comment">// 尽可能和窗口大小保持一致，所以如果其中一个并行度出现问题的情况下</span></span><br><span class="line">                        <span class="comment">// 最大的延迟计算结果是一个窗口大小的时间</span></span><br><span class="line">                        .withIdleness(Duration.ofMinutes(<span class="number">1L</span>))</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        WindowedStream&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt; s2 = s1.keyBy(<span class="keyword">new</span> KeySelector&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple5&lt;Integer, String, String, Integer, String&gt; <span class="title">getKey</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> Tuple5.of(</span><br><span class="line">                        event.getLogs().getRelatedAppId(),</span><br><span class="line">                        event.getLogs().getChildApp(),</span><br><span class="line">                        event.getLogs().getSummary(),</span><br><span class="line">                        event.getLogs().getLevel(),</span><br><span class="line">                        event.getLogs().getIp()</span><br><span class="line">                );</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">                .window(TumblingEventTimeWindows.of(Time.minutes(<span class="number">1L</span>)));</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; s3 = s2.apply(<span class="keyword">new</span> WindowFunction&lt;Event, Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(Tuple5&lt;Integer, String, String, Integer, String&gt; key, TimeWindow timeWindow, Iterable&lt;Event&gt; iterable, Collector&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span> (Event event : iterable) &#123;</span><br><span class="line">                    sum++;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                logger.debug(<span class="string">"聚合窗口key: &#123;&#125;, 窗口中的数量:&#123;&#125;, 此时的窗口范围是[&#123;&#125;,&#123;&#125;)"</span>, key, sum, sdf.format(timeWindow.getStart()), sdf.format(timeWindow.getEnd()));</span><br><span class="line">                collector.collect(Tuple3.of(key, iterable.iterator().next(), sum));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        String sinkDatabase = parameterTool.get(StatisticsModel.class.getName() + ".sink_database", DEFAULT_SINK_DATABASE);</span><br><span class="line">        String sinkTable = parameterTool.get(StatisticsModel.class.getName() + ".sink_table", DEFAULT_SINK_TABLE);</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;MysqlItem&gt; s4 = s3.map(e -&gt; &#123;</span><br><span class="line">                    HashMap&lt;String, Object&gt; kv = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">                    kv.put(<span class="string">"related_app_id"</span>, e.f1.getLogs().getRelatedAppId());</span><br><span class="line">                    kv.put(<span class="string">"child_app"</span>, e.f1.getLogs().getChildApp());</span><br><span class="line">                    kv.put(<span class="string">"summary"</span>, e.f1.getLogs().getSummary());</span><br><span class="line">                    kv.put(<span class="string">"level"</span>, e.f1.getLogs().getLevel());</span><br><span class="line">                    kv.put(<span class="string">"ip"</span>, e.f1.getLogs().getIp());</span><br><span class="line"></span><br><span class="line">                    kv.put(<span class="string">"mtime"</span>, e.f1.getLogs().getMtime());</span><br><span class="line">                    kv.put(<span class="string">"mdate"</span>, Util.timeStamp2Date(Integer.toString(e.f1.getLogs().getMtime()), <span class="string">"yyyy-MM-dd"</span>));</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 来自聚合窗口统计的结果</span></span><br><span class="line">                    kv.put(<span class="string">"cnt"</span>, e.f2);</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">return</span> MysqlItem.builder()</span><br><span class="line">                            .database(sinkDatabase)</span><br><span class="line">                            .table(sinkTable)</span><br><span class="line">                            .kv(kv)</span><br><span class="line">                            .build();</span><br><span class="line">                &#125;</span><br><span class="line">        ).returns(MysqlItem<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        s4.addSink(<span class="keyword">new</span> MysqlSink(parameterTool))</span><br><span class="line">                .setParallelism(parameterTool.getInt(<span class="string">"mysql.sink.parallelism"</span>, <span class="number">1</span>))</span><br><span class="line">                .name(<span class="string">"MysqlSink"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (parameterTool.getBoolean(<span class="string">"app.handler.print.console"</span>, <span class="keyword">false</span>)) &#123;</span><br><span class="line">            s0.print(StatisticsAppErrorModel<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的整体中，我们这里先看到设置<code>watermark</code>的逻辑，这个<code>watermark</code>决定了我们的flink的数据的有序性，是一个比较重要的处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 每5s-flink需要获取新的watermark</span></span><br><span class="line">s0.getExecutionConfig().setAutoWatermarkInterval(<span class="number">5000L</span>);</span><br><span class="line"></span><br><span class="line">logger.debug(<span class="string">"getAutoWatermarkInterval: &#123;&#125;"</span>, s0.getExecutionConfig().getAutoWatermarkInterval());</span><br><span class="line">ParameterTool parameterTool = <span class="keyword">this</span>.getParameterTool(s0);</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;Event&gt; s1 = s0.assignTimestampsAndWatermarks(<span class="keyword">new</span> AssignerWithPeriodicWatermarksAdapter.Strategy&lt;&gt;(</span><br><span class="line"><span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;Event&gt;(Time.of(<span class="number">1</span>, TimeUnit.SECONDS)) &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">Long ts = event.getLogs().getMtime() * <span class="number">1000L</span>;</span><br><span class="line">logger.debug(</span><br><span class="line"><span class="string">"thread-id: &#123;&#125;, eventTime: [&#123;&#125;|&#123;&#125;], watermark: [&#123;&#125;|&#123;&#125;]"</span>,</span><br><span class="line">Thread.currentThread().getId(),</span><br><span class="line">ts,</span><br><span class="line">sdf.format(ts),</span><br><span class="line"><span class="keyword">this</span>.getCurrentWatermark().getTimestamp(),</span><br><span class="line">sdf.format(<span class="keyword">this</span>.getCurrentWatermark().getTimestamp())</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> ts;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">)</span><br><span class="line"><span class="comment">// 尽可能和窗口大小保持一致，所以如果其中一个并行度出现问题的情况下</span></span><br><span class="line"><span class="comment">// 最大的延迟计算结果是一个窗口大小的时间</span></span><br><span class="line">.withIdleness(Duration.ofMinutes(<span class="number">1L</span>))</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>我们这里通过<code>AssignerWithPeriodicWatermarksAdapter</code>设置一个<code>watermark</code>生成的策略。</p><p>当数据到来的时候，允许<code>1秒延迟</code>的情况下，解析数据的<code>事件时间(event-time)</code>作为我们的<code>watermark</code>，这里需要注意的是，这里从event-time提取的时间的单位需要是<code>毫秒</code>级别。</p><p>再通过<code>.withIdleness</code>，进行当某个窗口下<code>idle</code>了，那么也会刷新<code>watermark</code>。这个知识点，在kafka中是一个很重要的逻辑，由于flink在kafka的topic在多partition下，在partition的数据<code>watermark</code>对齐的情况，才会进行，所以为了防止，由于防止kafka的partition的数据倾斜对我们造成业务逻辑一直无法更新watermark的问题。这个十分必要。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">WindowedStream&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt; s2 = s1.keyBy(<span class="keyword">new</span> KeySelector&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Tuple5&lt;Integer, String, String, Integer, String&gt; <span class="title">getKey</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> Tuple5.of(</span><br><span class="line">event.getLogs().getRelatedAppId(),</span><br><span class="line">event.getLogs().getChildApp(),</span><br><span class="line">event.getLogs().getSummary(),</span><br><span class="line">event.getLogs().getLevel(),</span><br><span class="line">event.getLogs().getIp()</span><br><span class="line">);</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line">.window(TumblingEventTimeWindows.of(Time.minutes(<span class="number">1L</span>)));</span><br></pre></td></tr></table></figure><p>对于<code>windowstream</code>，主要是定义<code>窗口的时间大小</code>， <code>窗口数据的唯一主键</code>。</p><p>在这里，由于我的需求是每1分钟统计一次，所以这里可以看到我的窗口是基于<code>EventTime（事件时间）</code>的窗口，并且大小范围为<code>1分钟</code>。而数据的唯一主键则是通过<code>getKet(Event event)</code>方法来处理。通过flink内置的便捷的<code>Tuple5</code>这个类来处理的原因是因为我这里有5个元素组成的key。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; s3 = s2.apply(<span class="keyword">new</span> WindowFunction&lt;Event, Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(Tuple5&lt;Integer, String, String, Integer, String&gt; key, TimeWindow timeWindow, Iterable&lt;Event&gt; iterable, Collector&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span> (Event event : iterable) &#123;</span><br><span class="line">                    sum++;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                logger.debug(<span class="string">"聚合窗口key: &#123;&#125;, 窗口中的数量:&#123;&#125;, 此时的窗口范围是[&#123;&#125;,&#123;&#125;)"</span>, key, sum, sdf.format(timeWindow.getStart()), sdf.format(timeWindow.getEnd()));</span><br><span class="line">                collector.collect(Tuple3.of(key, iterable.iterator().next(), sum));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure><p>接下来就是<code>聚合(统计)</code>的逻辑了，当<code>window-trigger-condition</code>满足条件之后，就会把当前窗口内的所有数据推到下一个<code>算子</code>，在这个<code>算子</code>的<code>apply()</code>中，我们可以看到我们只是简单的做了一个数据统计，也就是<code>sum++</code>，经过这一操作之后，经过<code>collector</code>对进行进行<code>收集</code>，准备用于下一个<code>算子</code>中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;MysqlItem&gt; s4 = s3.map(e -&gt; &#123;</span><br><span class="line">                    HashMap&lt;String, Object&gt; kv = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">                    kv.put(<span class="string">"related_app_id"</span>, e.f1.getLogs().getRelatedAppId());</span><br><span class="line">                    kv.put(<span class="string">"child_app"</span>, e.f1.getLogs().getChildApp());</span><br><span class="line">                    kv.put(<span class="string">"summary"</span>, e.f1.getLogs().getSummary());</span><br><span class="line">                    kv.put(<span class="string">"level"</span>, e.f1.getLogs().getLevel());</span><br><span class="line">                    kv.put(<span class="string">"ip"</span>, e.f1.getLogs().getIp());</span><br><span class="line"></span><br><span class="line">                    kv.put(<span class="string">"mtime"</span>, e.f1.getLogs().getMtime());</span><br><span class="line">                    kv.put(<span class="string">"mdate"</span>, Util.timeStamp2Date(Integer.toString(e.f1.getLogs().getMtime()), <span class="string">"yyyy-MM-dd"</span>));</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 来自聚合窗口统计的结果</span></span><br><span class="line">                    kv.put(<span class="string">"cnt"</span>, e.f2);</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">return</span> MysqlItem.builder()</span><br><span class="line">                            .database(sinkDatabase)</span><br><span class="line">                            .table(sinkTable)</span><br><span class="line">                            .kv(kv)</span><br><span class="line">                            .build();</span><br><span class="line">                &#125;</span><br><span class="line">        ).returns(MysqlItem<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">s4.addSink(<span class="keyword">new</span> MysqlSink(parameterTool))</span><br><span class="line">.setParallelism(parameterTool.getInt(<span class="string">"mysql.sink.parallelism"</span>, <span class="number">1</span>))</span><br><span class="line">.name(<span class="string">"MysqlSink"</span>);</span><br></pre></td></tr></table></figure><p>在这个前面到算子中，我们拿到了一些我们所期待到数据了，接下来就是把数据转换成为我们需要入库的一个结构。通过<code>MysqlItem</code>对象，我们把所有的结构化的对象通过<code>MysqlSink</code>方法进行发送给mysql。<code>mysqlsink</code>是我们自己封的一个<code>sinker</code>，其中的代码实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.sinks;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.Setter;</span><br><span class="line"><span class="keyword">import</span> lombok.experimental.Accessors;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.RichSinkFunction;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager;</span><br><span class="line"><span class="keyword">import</span> java.sql.PreparedStatement;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Setter</span></span><br><span class="line"><span class="meta">@Accessors</span>(chain = <span class="keyword">true</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MysqlSink</span> <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>&lt;<span class="title">MysqlItem</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(MysqlSink<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    ParameterTool parameterTool;</span><br><span class="line">    <span class="keyword">private</span> Connection connection;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MysqlSink</span><span class="params">(ParameterTool parameterTool)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.parameterTool = parameterTool;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.open(parameters);</span><br><span class="line">        <span class="keyword">if</span> (connection == <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection = <span class="keyword">this</span>.getConnection();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.close();</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * todo: 再考虑一下如果插入失败的话是否需要重试之类的</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> item</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">(MysqlItem item, Context context)</span> </span>&#123;</span><br><span class="line">        logger.debug(<span class="string">"mysql-item: &#123;&#125;"</span>, item);</span><br><span class="line">        MysqlItem.Sql sqlInfo = item.toInsertIgnoreSql();</span><br><span class="line">        String sql = sqlInfo.getPreSql();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            PreparedStatement ps = <span class="keyword">this</span>.connection.prepareStatement(sql);</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= sqlInfo.getValues().size(); i++) &#123;</span><br><span class="line">                ps.setObject(i, sqlInfo.getValues().get(i-<span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">            logger.debug(ps.toString());</span><br><span class="line">            ps.execute();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            logger.error(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Connection <span class="title">getConnection</span><span class="params">()</span> <span class="keyword">throws</span> ClassNotFoundException, SQLException </span>&#123;</span><br><span class="line">        Class.forName(<span class="string">"com.mysql.cj.jdbc.Driver"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> DriverManager.getConnection(</span><br><span class="line">                String.format(</span><br><span class="line">                        <span class="string">"jdbc:mysql://%s:%s/?useUnicode=true&amp;characterEncoding=%s&amp;useSSL=false&amp;autoReconnect=true"</span>,</span><br><span class="line">                        <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.host"</span>),</span><br><span class="line">                        <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.port"</span>),</span><br><span class="line">                        <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.characterEncoding"</span>, StandardCharsets.UTF_8.toString())</span><br><span class="line">                ),</span><br><span class="line">                <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.user"</span>),</span><br><span class="line">                <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.password"</span>)</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到此，一个基于<code>datastream-api</code>的job，就完成了。</p><p>但是由于这是<code>java技术栈</code>，对于不是<code>java技术栈</code>的团队而言，这是一件比较麻烦的事情。就算是<code>java技术栈</code>，也需要去属于了解flink的原理，然后去编写对应的flink代码，这对于不熟悉<code>datastream-api</code>的小伙伴来说，也是一种头痛的事情。</p><p>所以对于这个问题，我们考虑使用上层一些的api，也就是<code>table-api</code>和<code>sql-api</code>。</p><p>但是由于此类api还是需要熟悉api的细节，所以我们看到了flink提供了一个叫<code>sql-client</code>的东西。但是由于<code>sql-client</code>的不稳定性（某些版本下存在比较严重的bug），且某些需求无法满足我们，为了灵活和可控性，我们最终解决了自行开发<code>flink-sql-client</code>。</p><h2 id="基于自研sql-client的flink开发"><a href="#基于自研sql-client的flink开发" class="headerlink" title="基于自研sql-client的flink开发"></a>基于自研<code>sql-client</code>的flink开发</h2><p>具体的实现方式在 <a href="https://github.com/whiteCcinn/flink-sql-submit" target="_blank" rel="noopener">flink-sql-submit</a></p><p>实现原理其实也不复杂，其实就是通过一个flink项目，封装成为一个类似cmd的命令，然后通过此方式来提交我们的<code>sql或者sql文件</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">src/main/java/</span><br><span class="line">├── deps</span><br><span class="line">│   └── util</span><br><span class="line">│       ├── ParameterToolEnvironmentUtils.java</span><br><span class="line">│       ├── SqlCommandParser.java</span><br><span class="line">│       └── Util.java</span><br><span class="line">└── org</span><br><span class="line">    └── client</span><br><span class="line">        └── flink</span><br><span class="line">            ├── Bootstrap.java</span><br><span class="line">            ├── SqlSubmit.java</span><br><span class="line">            ├── cmds</span><br><span class="line">            │   ├── AbstractCommand.java</span><br><span class="line">            │   ├── HelpCommand.java</span><br><span class="line">            │   ├── HiveCatalogCommand.java</span><br><span class="line">            │   ├── ICommand.java</span><br><span class="line">            │   ├── JobCommand.java</span><br><span class="line">            │   └── SqlParserCommand.java</span><br><span class="line">            ├── enums</span><br><span class="line">            │   └── PlanType.java</span><br><span class="line">            ├── internals</span><br><span class="line">            └── udfs</span><br></pre></td></tr></table></figure><p>我们可以看到，整个项目只有少量文件。提供了几个命令：</p><ul><li>help 帮助命令</li><li>hivecatalog 管理<ul><li>增</li><li>删</li><li>查</li></ul></li><li>job 提交任务<ul><li>sql</li><li>sql-file</li></ul></li><li>sql-parser 调试解析sql</li></ul><p>我们以一个<code>sql-file</code>为例子，其他大家可以在github上查看源码。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 以":"为分隔符，分别代表：catalog_type, hive_conf_path, catalog_name</span></span><br><span class="line"><span class="comment">-- "-" 代表使用默认值</span></span><br><span class="line">CATALOG_INFO = hive:/opt/hadoopclient/Hive/config/:-;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> mstream_alarm <span class="keyword">COMMENT</span> <span class="string">'告警系统流计算'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">USE</span> mstream_alarm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> <span class="string">'pipeline.name'</span> = <span class="string">'每1分钟基础服务告警'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'table.exec.emit.early-fire.enabled'</span> = <span class="string">'true'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'table.exec.emit.early-fire.delay'</span> = <span class="string">'10s'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'mc.local.time.zone'</span> = <span class="string">'Asia/Shanghai'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'table.exec.sink.not-null-enforcer'</span> = <span class="string">'drop'</span>;</span><br><span class="line"><span class="comment">-- checkpoint配置</span></span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.mode'</span> = <span class="string">'EXACTLY_ONCE'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.interval'</span> = <span class="string">'2min'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.timeout'</span> = <span class="string">'1min'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.prefer-checkpoint-for-recovery'</span> = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.externalized-checkpoint-retention'</span> = <span class="string">'RETAIN_ON_CANCELLATION'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'mc.state.backend.fs.checkpointdir'</span> = <span class="string">'hdfs:///flink/checkpoints/&#123;db&#125;/&#123;pipeline.name&#125;'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'mc.execution.savepoint.dir'</span> = <span class="string">'hdfs:///flink/savepoints/&#123;db&#125;/&#123;pipeline.name&#125;'</span>;</span><br><span class="line"><span class="comment">-- 重启策略</span></span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy'</span> = <span class="string">'failure-rate'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy.failure-rate.delay'</span> = <span class="string">'10s'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy.failure-rate.failure-rate-interval'</span> = <span class="string">'5min'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy.failure-rate.max-failures-per-interval'</span> = <span class="string">'10'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> app_error_To_t_log_app_error_alarm_164 (</span><br><span class="line">    headers <span class="keyword">ROW</span>&lt;<span class="string">`app_id`</span> <span class="built_in">int</span>,<span class="string">`log_name`</span> <span class="keyword">string</span>&gt;,</span><br><span class="line">    <span class="keyword">logs</span> <span class="keyword">ROW</span>&lt;<span class="string">`related_app_id`</span> <span class="built_in">int</span>, <span class="string">`child_app`</span> <span class="built_in">varchar</span>(<span class="number">200</span>), <span class="string">`summary`</span> <span class="keyword">string</span>,<span class="string">`level`</span> <span class="built_in">int</span>,<span class="string">`ip`</span> <span class="built_in">varchar</span>(<span class="number">200</span>),<span class="string">`detail`</span> <span class="built_in">varchar</span>(<span class="number">100</span>), <span class="string">`mtime`</span> <span class="built_in">int</span>&gt;,</span><br><span class="line">    etime <span class="keyword">as</span> TO_TIMESTAMP(FROM_UNIXTIME(logs.<span class="string">`mtime`</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">for</span> etime <span class="keyword">AS</span> etime <span class="comment">-- defines watermark on ts column, marks ts as event-time attribute</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'kafka'</span>,</span><br><span class="line">    <span class="string">'topic'</span> = <span class="string">'mfeilog_dsp_10008_app_error'</span>,</span><br><span class="line">    <span class="string">'properties.bootstrap.servers'</span> = <span class="string">'127.0.0.1:9092'</span>,</span><br><span class="line">    <span class="string">'properties.group.id'</span> = <span class="string">'app_error_to_t_log_app_error_alarm_164'</span>,</span><br><span class="line">    <span class="string">'format'</span> = <span class="string">'json'</span>,</span><br><span class="line">    <span class="string">'scan.startup.mode'</span> = <span class="string">'latest-offset'</span>,</span><br><span class="line">    <span class="string">'json.fail-on-missing-field'</span> = <span class="string">'false'</span>,</span><br><span class="line">    <span class="string">'json.ignore-parse-errors'</span> = <span class="string">'false'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`t_log_app_error_alarm_164`</span> (</span><br><span class="line">  <span class="string">`related_app_id`</span> <span class="built_in">int</span>,</span><br><span class="line">  <span class="string">`child_app`</span> <span class="built_in">varchar</span>(<span class="number">200</span>),</span><br><span class="line">  <span class="string">`summary`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`level`</span> <span class="built_in">int</span>,</span><br><span class="line">  <span class="string">`ip`</span> <span class="built_in">varchar</span>(<span class="number">200</span>) ,</span><br><span class="line">  <span class="string">`cnt`</span> <span class="built_in">varchar</span>(<span class="number">200</span>) <span class="keyword">COMMENT</span> <span class="string">'calculate the detail of count()'</span>,</span><br><span class="line">  <span class="string">`mdate`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`mtime`</span> <span class="built_in">int</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`related_app_id`</span>,<span class="string">`child_app`</span>,<span class="string">`summary`</span>,<span class="string">`level`</span>,<span class="string">`ip`</span>) <span class="keyword">NOT</span> <span class="keyword">ENFORCED</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">'connector'</span> = <span class="string">'jdbc'</span>,</span><br><span class="line">   <span class="string">'url'</span> = <span class="string">'jdbc:mysql://127.0.0.1:60701/db_app_log_alarm?useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true'</span>,</span><br><span class="line">   <span class="string">'driver'</span> = <span class="string">'com.mysql.cj.jdbc.Driver'</span>,</span><br><span class="line">   <span class="string">'table-name'</span> = <span class="string">'t_log_app_error_alarm_164'</span>,</span><br><span class="line">   <span class="string">'username'</span> = <span class="string">'flink_mstream_alarm'</span>,</span><br><span class="line">   <span class="string">'password'</span> = <span class="string">'xxxx'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_log_app_error_alarm_164 (</span><br><span class="line">    <span class="keyword">select</span> t1.<span class="string">`related_app_id`</span>,t1.<span class="string">`child_app`</span>,t1.<span class="string">`summary`</span>,t1.<span class="string">`level`</span>,t1.<span class="string">`ip`</span>,<span class="keyword">cast</span>(t1.<span class="string">`cnt`</span> <span class="keyword">as</span> <span class="built_in">VARCHAR</span>(<span class="number">200</span>)) <span class="keyword">as</span> <span class="string">`cnt`</span>,t1.<span class="string">`mdate`</span>,<span class="keyword">cast</span> (t1.<span class="string">`mtime`</span> <span class="keyword">as</span> <span class="built_in">INT</span>)  <span class="keyword">from</span> (</span><br><span class="line">        <span class="keyword">select</span></span><br><span class="line">            logs.<span class="string">`related_app_id`</span> <span class="keyword">as</span> <span class="string">`related_app_id`</span>,</span><br><span class="line">            logs.<span class="string">`child_app`</span> <span class="keyword">as</span> <span class="string">`child_app`</span>,</span><br><span class="line">            logs.<span class="string">`summary`</span> <span class="keyword">as</span> <span class="string">`summary`</span>,</span><br><span class="line">            logs.<span class="string">`level`</span> <span class="keyword">as</span> <span class="string">`level`</span>,</span><br><span class="line">            logs.<span class="string">`ip`</span> <span class="keyword">as</span> <span class="string">`ip`</span>,</span><br><span class="line">            <span class="keyword">DATE_FORMAT</span>(TUMBLE_START(etime, <span class="built_in">INTERVAL</span> <span class="string">'1'</span> <span class="keyword">MINUTE</span>), <span class="string">'yyyy-MM-dd'</span>) <span class="keyword">as</span> <span class="string">`mdate`</span>,</span><br><span class="line">            <span class="keyword">UNIX_TIMESTAMP</span>(<span class="keyword">DATE_FORMAT</span>(TUMBLE_START(etime, <span class="built_in">INTERVAL</span> <span class="string">'1'</span> <span class="keyword">MINUTE</span>), <span class="string">'yyyy-MM-dd HH:mm:ss'</span>)) <span class="keyword">as</span> <span class="string">`mtime`</span>,</span><br><span class="line">            <span class="keyword">COUNT</span>(logs.<span class="string">`detail`</span>) <span class="keyword">as</span> <span class="string">`cnt`</span></span><br><span class="line">        <span class="keyword">FROM</span> app_error_To_t_log_app_error_alarm_164</span><br><span class="line">        <span class="keyword">GROUP</span> <span class="keyword">BY</span> logs.<span class="string">`related_app_id`</span>, logs.<span class="string">`child_app`</span>,logs.<span class="string">`summary`</span>,logs.<span class="string">`level`</span>,logs.<span class="string">`ip`</span>,TUMBLE(etime, <span class="built_in">INTERVAL</span> <span class="string">'1'</span> <span class="keyword">MINUTE</span>)</span><br><span class="line">    ) t1</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>我们可以看到这个<code>sql-file</code>，支持了一些<code>关键字</code>，这些关键字被开发在<code>client</code>当中了，所以可以被正常解析到。</p><p>通过解析到关键字，再调用对应的API，我们就可以设置对应的行为了。</p><p>我们可以看到我们从繁杂的<code>datastreamapi</code>中，已经把剥离了出来，通过sql这种DSL的方式，让不同语言技术栈的同事都可以定制自己的job。</p><p>并且支持了自定义重启策略，保证每一个算子在异常或者正常的情况下，都可以从正确的数据中进行恢复重启。</p><p>这一套sql编写下来，做的事情和我们上面的<code>datastream</code>做的事情是一样的，但是却无需了解太多其中的细节。</p><h4 id="UDF的运用"><a href="#UDF的运用" class="headerlink" title="UDF的运用"></a>UDF的运用</h4><p>例如我们需要ip转地址字符串，这个时候，我们就需要udf来协助我们完成这件事。</p><p>client项目可以内置一些我们所需要的UDF，然后连同job一起生效。</p><p>例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@127.0,0.1_A ~]# flink run -yid `cat /data/flink-stream/mstream/mstream_xx/yid` /data/flink-stream/flink-sql-submit-1.0-SNAPSHOT.jar job --sql "CATALOG_INFO = hive:/opt/hadoopclient/Hive/config/:-;USE mstream_alarm;SELECT ip2location('219.135.155.76');"</span><br><span class="line"> Interface ana-group-1byez.dad44e53-24e6-41be-bfd5-a4055f4c6604.com:32263 of application 'application_1641337362340_6699'.</span><br><span class="line">Job has been submitted with JobID 824af5a31aba88db6e0137f5e834f26b</span><br><span class="line">+----+--------------------------------+</span><br><span class="line">| op |                         EXPR$0 |</span><br><span class="line">+----+--------------------------------+</span><br><span class="line">| +I |                 中国,广东,广州 |</span><br><span class="line">+----+--------------------------------+</span><br></pre></td></tr></table></figure><p>我们可以看到，通过<code>ip2localtion()</code>，我们完成了一个udf，并且可以实现在sql的模式上。用过ip地址转为为了地址。</p><h2 id="落地实战"><a href="#落地实战" class="headerlink" title="落地实战"></a>落地实战</h2><p>由于资源的有限，我们在flink的架构上，采用的是每个项目对应一个<code>application</code>的方法，每个<code>application通过yarn来分配来分配资源容器</code>，然后再通过<code>yarn-session</code>(非<code>per on job</code>)的方式来管理我们的flink应用。</p><h3 id="申请资源应用"><a href="#申请资源应用" class="headerlink" title="申请资源应用"></a>申请资源应用</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-session.sh -jm 1024 -tm 1024 -s 16 -nm '告警流计算应用' -yd</span><br></pre></td></tr></table></figure><p><img src="/images/FLINK/application.png" alt="application"></p><h3 id="client-例子"><a href="#client-例子" class="headerlink" title="client 例子"></a>client 例子</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">help</span></span></span><br><span class="line">root@41c5967b5948:/www# flink run target/mc-flink-sql-submit-1.0-SNAPSHOT.jar help</span><br><span class="line">帮助命令</span><br><span class="line"></span><br><span class="line">Usage of "flink run &lt;.jar&gt; help [options]"</span><br><span class="line"></span><br><span class="line">Available Commands</span><br><span class="line">   job          提交job作业</span><br><span class="line">   sql-parser   解析sql文件</span><br><span class="line">   help         帮助命令</span><br><span class="line">   hive-catalog hive-catalog的相关</span><br><span class="line"></span><br><span class="line">Global Options:</span><br><span class="line">   --app.force.remote bool</span><br><span class="line">       是否启动远端环境变量: false</span><br><span class="line">   --app.config.debug bool</span><br><span class="line">       是否打印用户参数: false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> job</span></span><br><span class="line">root@41c5967b5948:/www# flink run target/mc-flink-sql-submit-1.0-SNAPSHOT.jar job help</span><br><span class="line">提交job</span><br><span class="line"></span><br><span class="line">Usage of "flink run &lt;.jar&gt; job [options]"</span><br><span class="line">   --sql string</span><br><span class="line">       执行的sql (*)</span><br><span class="line">   --plan string</span><br><span class="line">       选择执行计划器:</span><br><span class="line">           flink-streaming</span><br><span class="line">           flink-batch</span><br><span class="line">           blink-streaming</span><br><span class="line">           flink-batch</span><br><span class="line"></span><br><span class="line">Global Options:</span><br><span class="line">   --app.force.remote bool</span><br><span class="line">       是否启动远端环境变量: false</span><br><span class="line">   --app.config.debug bool</span><br><span class="line">       是否打印用户参数: false</span><br></pre></td></tr></table></figure><h3 id="flink-stream-sql-mctl-用法"><a href="#flink-stream-sql-mctl-用法" class="headerlink" title="flink-stream-sql-mctl 用法"></a>flink-stream-sql-mctl 用法</h3><p>这是一个集成脚本，所以存在约定的规则和部署的架构约束。</p><p>这便于我们管理所有的applition和flink种的所有flink-job。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">flink-sql-submit git:(master) ✗ ./flink-stream-sql-mctl.sh</span><br><span class="line"></span><br><span class="line">  flink-stream-sql-mctl.sh [OPTION] &lt;COMMAND&gt;</span><br><span class="line"></span><br><span class="line">  Flink流计算SQL-Client的执行脚本</span><br><span class="line"></span><br><span class="line">  Command:</span><br><span class="line">    run          [FILE]            运行</span><br><span class="line">    stop         [FILE]            停止</span><br><span class="line">    list         [FILE]            列出FILE所在yid下的所有job任务列表</span><br><span class="line">    drop_table   [FILE]            删除所有表</span><br><span class="line">    rebuild_run  [FILE]            删除所有表，然后重跑(继承savepoint）</span><br><span class="line"></span><br><span class="line">  Command-Common-Options:</span><br><span class="line">    -c, --clientpath  [LEVEL]    flink-sql-submit.jar路径  (Default is '/data/tmp/mc-flink-sql-submit-1.0-SNAPSHOT.jar')</span><br><span class="line">    -f   是否强制运行，忽略以往savepoint</span><br><span class="line"></span><br><span class="line">  Common-Options:</span><br><span class="line">    -h, --help              Display this help and exit</span><br><span class="line">    --loglevel [LEVEL]      One of: FATAL, ERROR, WARN, INFO, NOTICE, DEBUG, ALL, OFF</span><br><span class="line">                            (Default is 'ERROR')</span><br><span class="line">    --logfile [FILE]        Full PATH to logfile.  (Default is '/Users/caiwenhui/logs/flink-stream-sql-mctl.sh.log')</span><br><span class="line">    -n, --dryrun            Non-destructive. Makes no permanent changes.</span><br><span class="line">    -q, --quiet             Quiet (no output)</span><br><span class="line">    -v, --verbose           Output more information. (Items echoed to 'verbose')</span><br><span class="line">    --force                 Skip all user interaction.  Implied 'Yes' to all actions.</span><br></pre></td></tr></table></figure><p>约定规则：</p><ul><li>模型所在父目录的至少有一个yid文件（取最近的一个父节点的yid）对应所在的应用id</li><li>默认情况下，模型启动的时候会取最近一次savepoint的数据进行恢复，如果不存在，则直接启动</li></ul><h3 id="停止所有模型"><a href="#停止所有模型" class="headerlink" title="停止所有模型"></a>停止所有模型</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(find /data/flink-stream/mstream_alarm/ -type f -name "*.sql");do /data/flink-stream/flink-stream-sql-mctl stop $i;done</span><br></pre></td></tr></table></figure><h3 id="启动所有模型"><a href="#启动所有模型" class="headerlink" title="启动所有模型"></a>启动所有模型</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(find /data/flink-stream/mstream_alarm/ -type f -name "*.sql");do /data/flink-stream/flink-stream-sql-mctl run $i;done</span><br></pre></td></tr></table></figure><h3 id="删除所有表"><a href="#删除所有表" class="headerlink" title="删除所有表"></a>删除所有表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(find /data/flink-stream/mstream_alarm/ -type f -name "*.sql");do /data/flink-stream/flink-stream-sql-mctl drop_table $i;done</span><br></pre></td></tr></table></figure><h3 id="相关的一些落地后截图信息"><a href="#相关的一些落地后截图信息" class="headerlink" title="相关的一些落地后截图信息"></a>相关的一些落地后截图信息</h3><p><img src="/images/FLINK/server.png" alt="server"></p><p><img src="/images/FLINK/detail-0.png" alt="detail-0"></p><p><img src="/images/FLINK/detail-1.png" alt="detail-1"></p><p><img src="/images/FLINK/detail-2.png" alt="detail-2"></p><p><img src="/images/FLINK/detail-3.png" alt="detail-3"></p><p>到此为止，我们的flink相关的流计算应用，从0到1的过程暂时画上一个里程碑。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在公司落地一套flink，总结到目前为止做了的事情。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://blog.crazylaw.cn/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- 基于gnet的端口复用支持多协议的客服聊天监控服务</title>
    <link href="http://blog.crazylaw.cn/2022/02/12/Golang/%E5%9F%BA%E4%BA%8Egnet%E7%9A%84%E5%AE%A2%E6%9C%8D%E8%81%8A%E5%A4%A9%E7%9B%91%E6%8E%A7%E6%9C%8D%E5%8A%A1/"/>
    <id>http://blog.crazylaw.cn/2022/02/12/Golang/%E5%9F%BA%E4%BA%8Egnet%E7%9A%84%E5%AE%A2%E6%9C%8D%E8%81%8A%E5%A4%A9%E7%9B%91%E6%8E%A7%E6%9C%8D%E5%8A%A1/</id>
    <published>2022-02-11T16:46:51.000Z</published>
    <updated>2022-02-12T03:45:01.017Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近，公司以前有一些旧的服务，由于各种原因，导致各种问题，并且架构设计行也不是那么友好和不利于维护。<br>所以准备重构设计一些服务。</p><p>在游戏公司中，GM客服的其中一个职能就是监督舆论，从玩家平日的聊天中进行监控。</p><p>我们从<code>业务需求</code>+<code>技术架构</code>层面进行整理。</p><a id="more"></a><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p>在过去中，由于当时php还是如日中天，旧的则是采集的<code>swoole1.x</code>的版本进行开发的服务。<br>受限于php一个语言特性，注定无法实现一些高性能的中间件，或者说大数据生态十分欠缺。当时用php除了<code>fastcgi</code>的<code>web系统</code>外，最多就只能做一些基本的<code>常驻</code>任务。</p><p>消息中间件最多也就是用到<code>rabbitmq</code>，<code>rocketmq</code>等等。</p><p>而常驻，一般无非就是直接<code>cli</code>，外加一个<code>循环+sleep</code>的组合套餐。而要实现<code>websocket-server</code>这种常驻服务，一般是借助<code>swoole</code>来处理。毕竟<code>reactor</code>的模式，怎么都比<code>单进程</code>的实现好。</p><p>分为了3个模块（每个模块=每个角色=一个进程=一个服务）：</p><ul><li>chat_record （聊天记录角色）（weboccket_client, tcp_clinet）</li><li>db_server （数据层角色) (tcp_server)</li><li>websocket_server (连接层角色) (webocket_server)</li></ul><p>由于当时php基本无法多线程编程(可用，但是不友好)，只能采用这种委婉的<code>伪多进程</code>的模拟进行<code>不同任务的处理</code>和<code>数据的交互</code>。</p><p><img src="/images/Go/chat_monitor.png" alt="旧服务的数据流图"></p><h2 id="新服务"><a href="#新服务" class="headerlink" title="新服务"></a>新服务</h2><p><img src="/images/Go/chat_monitor_new.png" alt="新服务的数据流图"></p><blockquote><p>但是由于种种原因，后面并未如此拆分架构，而是将<code>websocket-server网络连接层</code>的和<code>业务层</code>合并成为了一个<code>单体服务</code></p></blockquote><p>技术选型上</p><ul><li>go</li><li>gnet</li><li>kafka</li></ul><h3 id="为什么核心的网络层需要采用gnet呢？"><a href="#为什么核心的网络层需要采用gnet呢？" class="headerlink" title="为什么核心的网络层需要采用gnet呢？"></a>为什么核心的网络层需要采用<code>gnet</code>呢？</h3><p>一般Go语言的TCP(和HTTP)的处理都是<code>每一个连接</code>启动<code>一个goroutine</code>去处理，因为我们被教导<code>goroutine</code>的不像<code>thread</code>, 它是很便宜的，可以在服务器上启动成<code>千上万的goroutine</code>。</p><p>但是对于<code>一百万</code>的连接，这种<code>goroutine-per-connection</code>的模式就<code>至少</code>要启动<code>一百万个goroutine</code>，这对资源的消耗也是极大的。</p><p>针对不同的操作系统和不同的Go版本，一个goroutine锁使用的最小的栈大小是<code>2KB ~ 8 KB (go stack)</code>,如果在每个goroutine中在<code>分配byte buffer</code>用以从连接中读写数据，<code>几十G的内存</code>轻轻松松就分配出去了。</p><p><code>吞吐率</code>和<code>延迟</code>需要数据来支撑，但是显然这个<code>单goroutine</code>处理的模式<code>不适合耗时较长</code>的业务处理，<code>&quot;hello world&quot;</code>或者<code>直接的简单的memory操作</code>应该没有问题。</p><p>对于百万连接<code>但是并发量很小</code>的场景，比如消息推送、页游等场景，这种实现应该是没有问题的。</p><p>但是对于并发量很大，延迟要求比较低的场景，这种实现可能会存在问题。</p><p><code>gnet</code>采用了类似<code>netty</code>的<code>reactor</code>模式，基于<code>epoll</code>或者<code>kqueue</code>实现io多路复用。并且基于golang的语言特性，其实现原理为<code>带线程/go程池的主从 Reactors 多线程</code>模式，在网络层上性能上有极大的优化。</p><p>我们通过gnet提供的tcp网络层，在应用层，实现了http和webocket的端口复用的形式。</p><p>http用于提供<code>prometheus</code>的<code>metrics</code>指标，例如<code>连接数/各种类型引发的error数/每条数据被多少个GM客服监视着</code>等等</p><p>websocket则是用于在我们的<code>GM客服</code>中，提一个实时的聊天数据获取</p><h3 id="为什么采用kafka"><a href="#为什么采用kafka" class="headerlink" title="为什么采用kafka"></a>为什么采用kafka</h3><p>由于我们整套日志服务都是基于kafka作为核心组件的，所以在数据的实时上，可以保证到数据的实效性。</p><p>从而取消了以往从mysql中分库分表去查询数据。也不需要通过其他<code>OLAP</code>的服务进行处理。</p><h3 id="端口复用实现支持多协议"><a href="#端口复用实现支持多协议" class="headerlink" title="端口复用实现支持多协议"></a>端口复用实现支持多协议</h3><p>这个是网络连接层，也是链接的核心业务逻辑，在gnet中当有数据到来的时候，由<code>IO多路复用</code>的<code>epoll</code>模型，会触发<code>OnTraffic(c gnet.Conn)</code>的回调函数，在这个过程中，我们就可以通过网络层中获取的数据进行加工处理，形成自己想要的<code>应用协议</code>。</p><p>由于刚才介绍到了，我们需要实现核心需求：<code>端口多协议复用</code></p><p>在这里，先列出核心的逻辑：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">type</span> ApplicationLayerProto <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alp ApplicationLayerProto)</span> <span class="title">String</span><span class="params">()</span> <span class="params">(s <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">switch</span> alp &#123;</span><br><span class="line"><span class="keyword">case</span> HttpApplicationLayerProto:</span><br><span class="line">s = <span class="string">"http"</span></span><br><span class="line"><span class="keyword">case</span> WebsocketApplicationLayerProto:</span><br><span class="line">s = <span class="string">"websocket"</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">s = <span class="string">"unknown"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">HttpApplicationLayerProto ApplicationLayerProto = <span class="literal">iota</span></span><br><span class="line">WebsocketApplicationLayerProto</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> codec <span class="keyword">struct</span> &#123;</span><br><span class="line">proto ApplicationLayerProto</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *codec)</span> <span class="title">isHttp</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> c.proto == HttpApplicationLayerProto &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *codec)</span> <span class="title">isWebsocket</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> c.proto == WebsocketApplicationLayerProto &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> httpCodec <span class="keyword">struct</span> &#123;</span><br><span class="line">*codec</span><br><span class="line">parser *wildcat.HTTPParser</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> wsCodec <span class="keyword">struct</span> &#123;</span><br><span class="line">*codec</span><br><span class="line">connected <span class="keyword">bool</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(serv *server)</span> <span class="title">OnOpen</span><span class="params">(c gnet.Conn)</span> <span class="params">([]<span class="keyword">byte</span>, gnet.Action)</span></span> &#123;</span><br><span class="line">c.SetContext(<span class="built_in">new</span>(codec))</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, gnet.None</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(serv *server)</span> <span class="title">OnTraffic</span><span class="params">(c gnet.Conn)</span> <span class="title">gnet</span>.<span class="title">Action</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> buffer *bytes.Buffer</span><br><span class="line"><span class="keyword">var</span> buff []<span class="keyword">byte</span></span><br><span class="line">pipeline:</span><br><span class="line"><span class="keyword">switch</span> cdc := c.Context().(<span class="keyword">type</span>) &#123;</span><br><span class="line"><span class="keyword">case</span> *codec:</span><br><span class="line">buf, err := c.Next(<span class="number">-1</span>)</span><br><span class="line">buff = <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="built_in">len</span>(buf))</span><br><span class="line"><span class="built_in">copy</span>(buff, buf)</span><br><span class="line">buffer = bytes.NewBuffer(buff)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line">hc := &amp;httpCodec&#123;parser: wildcat.NewHTTPParser(), codec: cdc&#125;</span><br><span class="line">_, err = hc.parser.Parse(buf)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"http parser error: %v"</span>, err)&#125;)</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> upgrade := hc.parser.FindHeader([]<span class="keyword">byte</span>(<span class="string">"Upgrade"</span>)); upgrade != <span class="literal">nil</span> &amp;&amp; bytes.Equal(upgrade, []<span class="keyword">byte</span>(<span class="string">"websocket"</span>)) &#123;</span><br><span class="line">cdc.proto = WebsocketApplicationLayerProto</span><br><span class="line">wc := &amp;wsCodec&#123;</span><br><span class="line">codec: cdc,</span><br><span class="line">&#125;</span><br><span class="line">c.SetContext(wc)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">cdc.proto = HttpApplicationLayerProto</span><br><span class="line">c.SetContext(hc)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">goto</span> pipeline</span><br><span class="line"><span class="keyword">case</span> *httpCodec:</span><br><span class="line">buf := bufio.NewReader(buffer)</span><br><span class="line">req, err := http.ReadRequest(buf)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"request from http error: %v"</span>, err)&#125;)</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line">metrics.TotalConnectedCounter.WithLabelValues(HttpApplicationLayerProto.String()).Inc()</span><br><span class="line">resp := route.NewResponse(c)</span><br><span class="line">h, _ := serv.serverMux.Handler(req)</span><br><span class="line">h.ServeHTTP(resp, req)</span><br><span class="line"><span class="keyword">if</span> _, err = resp.Close(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"write to http error: %v"</span>, err)&#125;)</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line"><span class="keyword">case</span> *wsCodec:</span><br><span class="line"><span class="keyword">if</span> !cdc.connected &#123;</span><br><span class="line">wcb := &amp;wsConnBridge&#123;</span><br><span class="line">buff: buffer,</span><br><span class="line">c:    c,</span><br><span class="line">&#125;</span><br><span class="line">_, err := ws.Upgrade(wcb)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"upgrade[%s] to websocket error: %v"</span>, c.RemoteAddr().String(), err)&#125;)</span><br><span class="line">&#125;</span><br><span class="line">log.Debugf(log.NetServerDebugCategory&#123;&#125;, <span class="string">"conn[%v] upgrade websocket protocol"</span>, c.RemoteAddr().String())</span><br><span class="line">cdc.connected = <span class="literal">true</span></span><br><span class="line">metrics.ConnectedGauge.Inc()</span><br><span class="line">metrics.TotalConnectedCounter.WithLabelValues(WebsocketApplicationLayerProto.String()).Inc()</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">msg, op, err := wsutil.ReadClientData(c)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> _, ok := err.(wsutil.ClosedError); !ok &#123;</span><br><span class="line">log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"[%s] receive ws message error: %v"</span>, c.RemoteAddr().String(), err)&#125;)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line">log.Debugf(log.NetServerDebugCategory&#123;&#125;, <span class="string">"conn[%v] receive [op=%v] [msg=%v]"</span>, c.RemoteAddr().String(), op, <span class="keyword">string</span>(msg))</span><br><span class="line"><span class="keyword">if</span> op == ws.OpText &#123;</span><br><span class="line"><span class="keyword">if</span> rs := route.MatchRequestSpec(msg); rs == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> route.GlobalWsRouter.DefaultHandler().ServeWebsocket(<span class="string">"/"</span>, msg, c, op)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> route.GlobalWsRouter.MatchHandler(rs.Path).ServeWebsocket(rs.Path, rs.Params, c, op)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> gnet.None</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里，我们可以看到，当存在新链接进来的啥时候，首先经过<code>OnOpen(c gnet.Conn)</code>方法，这个时候，我们会在<code>gnet.Conn</code>中设置一个我们用户的一个<code>上下文环境Context</code>，在这个Context下，我们为每个连接都初始化了<code>codec</code>的结构体对象，当开始接收数据的时候，触发到了<code>OnTraffic(c gnet.Conn)</code>方法，这个以后，我们需要把网络层接收到的数据拿出来，由于<code>流</code>的存在，使得我们无法重复在同一个连接中，多次重复获取流，所以如果后面需要用到的话，利用取出来的<code>byte-buffer</code>生成一个新的<code>流</code>，以供后续使用。</p><p>所以你会发现有一段代码为:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">buf, err := c.Next(<span class="number">-1</span>)</span><br><span class="line">buff = <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="built_in">len</span>(buf))</span><br><span class="line"><span class="built_in">copy</span>(buff, buf)</span><br><span class="line">buffer = bytes.NewBuffer(buff)</span><br></pre></td></tr></table></figure><p>接下来，需要做的事情就是解析数据为http协议对象，由于我这里的<code>端口复用</code>的逻辑是<code>http+webocket</code>复用，所以都是基于<code>http协议</code>的，所以这里可以简单粗暴的处理，然后通过判断<code>http协议</code>中是否包含了需要升级为<code>webocket协议</code>的关键字段<code>Upgrade:webocket</code>，如果包含，则表示本次请求是一个websocket连接，否则就是一个单纯http连接。以此来达到复用的需求。</p><p>在这个基础之上，我们也更新了当前连接的<code>上下文环境Context</code>，升级为了<code>httpCodec</code>和<code>wsCodec</code>，通过<code>goto+断言</code>语法，我们可以进入到，我们所需要进入的逻辑阶段。不要觉得这就完事了，麻烦的事情才刚开始，现在你只是知道了开头。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">buf := bufio.NewReader(buffer)</span><br><span class="line">req, err := http.ReadRequest(buf)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"request from http error: %v"</span>, err)&#125;)</span><br><span class="line">    <span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line">metrics.TotalConnectedCounter.WithLabelValues(HttpApplicationLayerProto.String()).Inc()</span><br><span class="line">resp := route.NewResponse(c)</span><br><span class="line">h, _ := serv.serverMux.Handler(req)</span><br><span class="line">h.ServeHTTP(resp, req)</span><br><span class="line"><span class="keyword">if</span> _, err = resp.Close(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"write to http error: %v"</span>, err)&#125;)</span><br><span class="line">    <span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br></pre></td></tr></table></figure><p>如果是<code>http协议</code>，那么我们就不需要升级协议了。但是有一个问题就是，在golang的<code>http/server.go</code>中，我们所熟悉的接口</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A Handler responds to an HTTP request.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// ServeHTTP should write reply headers and data to the ResponseWriter</span></span><br><span class="line"><span class="comment">// and then return. Returning signals that the request is finished; it</span></span><br><span class="line"><span class="comment">// is not valid to use the ResponseWriter or read from the</span></span><br><span class="line"><span class="comment">// Request.Body after or concurrently with the completion of the</span></span><br><span class="line"><span class="comment">// ServeHTTP call.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Depending on the HTTP client software, HTTP protocol version, and</span></span><br><span class="line"><span class="comment">// any intermediaries between the client and the Go server, it may not</span></span><br><span class="line"><span class="comment">// be possible to read from the Request.Body after writing to the</span></span><br><span class="line"><span class="comment">// ResponseWriter. Cautious handlers should read the Request.Body</span></span><br><span class="line"><span class="comment">// first, and then reply.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Except for reading the body, handlers should not modify the</span></span><br><span class="line"><span class="comment">// provided Request.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If ServeHTTP panics, the server (the caller of ServeHTTP) assumes</span></span><br><span class="line"><span class="comment">// that the effect of the panic was isolated to the active request.</span></span><br><span class="line"><span class="comment">// It recovers the panic, logs a stack trace to the server error log,</span></span><br><span class="line"><span class="comment">// and either closes the network connection or sends an HTTP/2</span></span><br><span class="line"><span class="comment">// RST_STREAM, depending on the HTTP protocol. To abort a handler so</span></span><br><span class="line"><span class="comment">// the client sees an interrupted response but the server doesn't log</span></span><br><span class="line"><span class="comment">// an error, panic with the value ErrAbortHandler.</span></span><br><span class="line"><span class="keyword">type</span> Handler <span class="keyword">interface</span> &#123;</span><br><span class="line">ServeHTTP(ResponseWriter, *Request)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们看到这个<code>Handler</code>interface，需要实现<code>ServeHTTP(ResponseWriter, *Request)</code>，而这个<code>Request</code>，对于我们目前来是，是不存在的，所以我们需要想办法构造一个<code>Request</code>对象出来。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ReadRequest reads and parses an incoming request from b.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// ReadRequest is a low-level function and should only be used for</span></span><br><span class="line"><span class="comment">// specialized applications; most code should use the Server to read</span></span><br><span class="line"><span class="comment">// requests and handle them via the Handler interface. ReadRequest</span></span><br><span class="line"><span class="comment">// only supports HTTP/1.x requests. For HTTP/2, use golang.org/x/net/http2.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ReadRequest</span><span class="params">(b *bufio.Reader)</span> <span class="params">(*Request, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> readRequest(b, deleteHostHeader)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好在标准包中提供一个<code>ReadRequest(b *bufio.Reader) (*Request, error)</code>的方法，可以通过<code>bufio.Reader</code>去读取<code>http协议</code>，然后构造出我们所需要的<code>Request</code>对象，所以你会看到，我们在一开始<code>copy(buff, buf)</code>的意义就体现在此了。<br>还会那句话，因为这是一个<code>流</code>，无法重复读取，所以我们利用<code>[]byte</code>构造一个全新的可度的字节流。</p><p>解决了<code>Request</code>的问题之后，另外一个问题也来了，<code>ResponseWriter</code>是一个和Response相关可写的字节流。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A ResponseWriter interface is used by an HTTP handler to</span></span><br><span class="line"><span class="comment">// construct an HTTP response.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// A ResponseWriter may not be used after the Handler.ServeHTTP method</span></span><br><span class="line"><span class="comment">// has returned.</span></span><br><span class="line"><span class="keyword">type</span> ResponseWriter <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// Header returns the header map that will be sent by</span></span><br><span class="line"><span class="comment">// WriteHeader. The Header map also is the mechanism with which</span></span><br><span class="line"><span class="comment">// Handlers can set HTTP trailers.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Changing the header map after a call to WriteHeader (or</span></span><br><span class="line"><span class="comment">// Write) has no effect unless the modified headers are</span></span><br><span class="line"><span class="comment">// trailers.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// There are two ways to set Trailers. The preferred way is to</span></span><br><span class="line"><span class="comment">// predeclare in the headers which trailers you will later</span></span><br><span class="line"><span class="comment">// send by setting the "Trailer" header to the names of the</span></span><br><span class="line"><span class="comment">// trailer keys which will come later. In this case, those</span></span><br><span class="line"><span class="comment">// keys of the Header map are treated as if they were</span></span><br><span class="line"><span class="comment">// trailers. See the example. The second way, for trailer</span></span><br><span class="line"><span class="comment">// keys not known to the Handler until after the first Write,</span></span><br><span class="line"><span class="comment">// is to prefix the Header map keys with the TrailerPrefix</span></span><br><span class="line"><span class="comment">// constant value. See TrailerPrefix.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// To suppress automatic response headers (such as "Date"), set</span></span><br><span class="line"><span class="comment">// their value to nil.</span></span><br><span class="line">Header() Header</span><br><span class="line"></span><br><span class="line"><span class="comment">// Write writes the data to the connection as part of an HTTP reply.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If WriteHeader has not yet been called, Write calls</span></span><br><span class="line"><span class="comment">// WriteHeader(http.StatusOK) before writing the data. If the Header</span></span><br><span class="line"><span class="comment">// does not contain a Content-Type line, Write adds a Content-Type set</span></span><br><span class="line"><span class="comment">// to the result of passing the initial 512 bytes of written data to</span></span><br><span class="line"><span class="comment">// DetectContentType. Additionally, if the total size of all written</span></span><br><span class="line"><span class="comment">// data is under a few KB and there are no Flush calls, the</span></span><br><span class="line"><span class="comment">// Content-Length header is added automatically.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Depending on the HTTP protocol version and the client, calling</span></span><br><span class="line"><span class="comment">// Write or WriteHeader may prevent future reads on the</span></span><br><span class="line"><span class="comment">// Request.Body. For HTTP/1.x requests, handlers should read any</span></span><br><span class="line"><span class="comment">// needed request body data before writing the response. Once the</span></span><br><span class="line"><span class="comment">// headers have been flushed (due to either an explicit Flusher.Flush</span></span><br><span class="line"><span class="comment">// call or writing enough data to trigger a flush), the request body</span></span><br><span class="line"><span class="comment">// may be unavailable. For HTTP/2 requests, the Go HTTP server permits</span></span><br><span class="line"><span class="comment">// handlers to continue to read the request body while concurrently</span></span><br><span class="line"><span class="comment">// writing the response. However, such behavior may not be supported</span></span><br><span class="line"><span class="comment">// by all HTTP/2 clients. Handlers should read before writing if</span></span><br><span class="line"><span class="comment">// possible to maximize compatibility.</span></span><br><span class="line">Write([]<span class="keyword">byte</span>) (<span class="keyword">int</span>, error)</span><br><span class="line"></span><br><span class="line"><span class="comment">// WriteHeader sends an HTTP response header with the provided</span></span><br><span class="line"><span class="comment">// status code.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If WriteHeader is not called explicitly, the first call to Write</span></span><br><span class="line"><span class="comment">// will trigger an implicit WriteHeader(http.StatusOK).</span></span><br><span class="line"><span class="comment">// Thus explicit calls to WriteHeader are mainly used to</span></span><br><span class="line"><span class="comment">// send error codes.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The provided code must be a valid HTTP 1xx-5xx status code.</span></span><br><span class="line"><span class="comment">// Only one header may be written. Go does not currently</span></span><br><span class="line"><span class="comment">// support sending user-defined 1xx informational headers,</span></span><br><span class="line"><span class="comment">// with the exception of 100-continue response header that the</span></span><br><span class="line"><span class="comment">// Server sends automatically when the Request.Body is read.</span></span><br><span class="line">WriteHeader(statusCode <span class="keyword">int</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>秉着面向接口开发的原则，并且为了更好的兼容第三方的API，所以我们需要实现一个自己的<code>ResponseWriter</code>对象，于是就有了<code>route.NewResponse(c)</code>，这个<code>resp</code>实现了上述的接口.</p><p>兼容了<code>promhttp</code>提供的<code>Handler</code>，也兼容了自己的<code>helloworld</code>接口。</p><p>接着我们通过<code>cmux</code>进行一个路由匹配，然后调用到对应的<code>ServeHTTP</code>,处理完逻辑之后，在<code>resp</code>的<code>Close()</code>阶段，把缓存区的所有<code>[]byte</code>，推送到连接层，然后通过返回<code>gnet.Close</code>进行网络层的断开，至此，一个简单而完整的<code>http交互流程</code>完毕。</p><p>对于<code>Websocket</code>协议来说，要做的事情也是十分繁琐（由于用了开源协议库，相对简化了很多），请先看下面的应用层协议处理逻辑。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> !cdc.connected &#123;</span><br><span class="line">        wcb := &amp;wsConnBridge&#123;</span><br><span class="line">            buff: buffer,</span><br><span class="line">            c:    c,</span><br><span class="line">        &#125;</span><br><span class="line">        _, err := ws.Upgrade(wcb)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"upgrade[%s] to websocket error: %v"</span>, c.RemoteAddr().String(), err)&#125;)</span><br><span class="line">        &#125;</span><br><span class="line">        log.Debugf(log.NetServerDebugCategory&#123;&#125;, <span class="string">"conn[%v] upgrade websocket protocol"</span>, c.RemoteAddr().String())</span><br><span class="line">        cdc.connected = <span class="literal">true</span></span><br><span class="line">        metrics.ConnectedGauge.Inc()</span><br><span class="line">        metrics.TotalConnectedCounter.WithLabelValues(WebsocketApplicationLayerProto.String()).Inc()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        msg, op, err := wsutil.ReadClientData(c)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> _, ok := err.(wsutil.ClosedError); !ok &#123;</span><br><span class="line">                log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"[%s] receive ws message error: %v"</span>, c.RemoteAddr().String(), err)&#125;)</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> gnet.Close</span><br><span class="line">        &#125;</span><br><span class="line">        log.Debugf(log.NetServerDebugCategory&#123;&#125;, <span class="string">"conn[%v] receive [op=%v] [msg=%v]"</span>, c.RemoteAddr().String(), op, <span class="keyword">string</span>(msg))</span><br><span class="line">        <span class="keyword">if</span> op == ws.OpText &#123;</span><br><span class="line">            <span class="keyword">if</span> rs := route.MatchRequestSpec(msg); rs == <span class="literal">nil</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> route.GlobalWsRouter.DefaultHandler().ServeWebsocket(<span class="string">"/"</span>, msg, c, op)</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> route.GlobalWsRouter.MatchHandler(rs.Path).ServeWebsocket(rs.Path, rs.Params, c, op)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>升级协议的过程中，我们用到了<code>github.com/gobwas/ws</code>这个协议库。</p><p>我们在接受到<code>websocket</code>前的时候需要先升级为websocket协议，但是这里遇到了一个问题，还是同理，我们的<code>gnet.Conn</code>的数据已经被我们取出来了，而升级的API显然就是需要提供一个可读可写的IO。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Upgrade is like Upgrader&#123;&#125;.Upgrade().</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Upgrade</span><span class="params">(conn io.ReadWriter)</span> <span class="params">(Handshake, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> DefaultUpgrader.Upgrade(conn)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ReadWriter is the interface that groups the basic Read and Write methods.</span></span><br><span class="line"><span class="keyword">type</span> ReadWriter <span class="keyword">interface</span> &#123;</span><br><span class="line">Reader</span><br><span class="line">Writer</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Reader <span class="keyword">interface</span> &#123;</span><br><span class="line">Read(p []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Writer <span class="keyword">interface</span> &#123;</span><br><span class="line">Write(p []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此，我们又需要实现一个自己的<code>wsConnBridge</code>对象，主要是实现上述的接口，但是这个结构体相对来说就比较简单了，分别保存之前提出来的<code>[]byte</code>的buffer用于读行为，再保存一个<code>gnet.Conn</code>用于写行为即可。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> wsConnBridge <span class="keyword">struct</span> &#123;</span><br><span class="line">buff *bytes.Buffer</span><br><span class="line">c    gnet.Conn</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *wsConnBridge)</span> <span class="title">Read</span><span class="params">(p []<span class="keyword">byte</span>)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> w.buff.Read(p)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *wsConnBridge)</span> <span class="title">Write</span><span class="params">(p []<span class="keyword">byte</span>)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> w.c.Write(p)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>升级完了，我们需要给当前的<code>上下文环境的Context</code>标记为已经升级连接完毕。</p><p>然后就是进入到数据的收发环节了。</p><p><code>github.com/gobwas/ws</code>提供了<code>api</code>来进行数据的收发，分别有<code>high-level</code>和<code>low-level</code>，这里，我们可优先选择<code>high-level-api</code>，然后读取数据。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> WebsocketHandler <span class="keyword">interface</span> &#123;</span><br><span class="line">ServeWebsocket(path <span class="keyword">string</span>, data []<span class="keyword">byte</span>, w io.Writer, op ws.OpCode) gnet.Action</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>读取到数据之后，又因为我需要和http的route能有一个高度匹配的代码写法，所以在路由匹配上，也是做了一个类似的<code>Match</code>的行为，然后选择到对应的<code>Handler</code>，触发统一的<code>ServeWebsocket()</code>接口（为了和http的<code>ServeHttp()</code>对应）。</p><p>到此，从<code>网络层到应用层</code>的<code>端口复用实现多协议</code>原理就到此为止了。</p><p>接着就是处理自己的业务逻辑数据了。</p><h2 id="业务逻辑概述"><a href="#业务逻辑概述" class="headerlink" title="业务逻辑概述"></a>业务逻辑概述</h2><ol><li>记录客服需要监控的数据规则和连接关联</li><li>kafka-client从监控规则中匹配合适的数据，推送到对应的fd中 </li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">var</span> i <span class="keyword">int64</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">ListenChatRuleMap.Range(<span class="function"><span class="keyword">func</span><span class="params">(key, value <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> Match(key.(<span class="keyword">string</span>), kmsKey) &#123;</span><br><span class="line">        wg.Add(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(c gnet.Conn, wsp *WsSendPayload)</span></span> &#123;</span><br><span class="line">            <span class="keyword">defer</span> wg.Done()</span><br><span class="line">            err := wsutil.WriteServerMessage(c, ws.OpText, wsp.Json())</span><br><span class="line">            <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">                log.Errorf(log.AppErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"[wsWriteServerMessage failed] [err=%v]"</span>, err)&#125;, <span class="string">"[key=%s],[data=%s]"</span>, key.(<span class="keyword">string</span>), <span class="keyword">string</span>(wsp.Json()))</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            &#125;</span><br><span class="line">            atomic.AddInt64(&amp;i, <span class="number">1</span>)</span><br><span class="line">        &#125;(value.(gnet.Conn), wsp)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;)</span><br><span class="line">wg.Wait()</span><br><span class="line">metrics.ChatLogCounterClientHistogram.WithLabelValues(strconv.FormatUint(<span class="keyword">uint64</span>(lrc.Pid), <span class="number">10</span>), strconv.Itoa(wsp.ServerId), strconv.Itoa(wsp.AgentId)).Observe(<span class="keyword">float64</span>(atomic.LoadInt64(&amp;i)))</span><br><span class="line"><span class="comment">// ...</span></span><br></pre></td></tr></table></figure><p>至此，网络层和业务层的所有需求大体已经完毕了。</p><h2 id="prometheus-指标"><a href="#prometheus-指标" class="headerlink" title="prometheus 指标"></a>prometheus 指标</h2><p>部分的指标如下，后续可以通过一些指标对服务的稳定和可靠性进行优化升级处理。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># HELP chat_monitor_app_handle_chat_total Counter of handle.</span><br><span class="line"># TYPE chat_monitor_app_handle_chat_total counter</span><br><span class="line">chat_monitor_app_handle_chat_total&#123;agent_id="29",app_id="19",server_id="6558"&#125; 3</span><br><span class="line"># HELP chat_monitor_net_client_recv_counter number of chat log for client</span><br><span class="line"># TYPE chat_monitor_net_client_recv_counter histogram</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="1"&#125; 0</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="2"&#125; 0</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="4"&#125; 2</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="8"&#125; 3</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="16"&#125; 3</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="32"&#125; 3</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="64"&#125; 3</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="+Inf"&#125; 3</span><br><span class="line">chat_monitor_net_client_recv_counter_sum&#123;agent_id="29",pid="1643890670000002",server_id="6558"&#125; 12</span><br><span class="line">chat_monitor_net_client_recv_counter_count&#123;agent_id="29",pid="1643890670000002",server_id="6558"&#125; 3</span><br><span class="line"># HELP chat_monitor_net_current_connected Current Counter Gauge of ws-connected.</span><br><span class="line"># TYPE chat_monitor_net_current_connected gauge</span><br><span class="line">chat_monitor_net_current_connected 4</span><br><span class="line"># HELP chat_monitor_net_total_connected The Total Counter of connected.</span><br><span class="line"># TYPE chat_monitor_net_total_connected counter</span><br><span class="line">chat_monitor_net_total_connected&#123;type="http"&#125; 15</span><br><span class="line">chat_monitor_net_total_connected&#123;type="websocket"&#125; 5</span><br><span class="line"># HELP chat_monitor_server_error_total Counter of error.</span><br><span class="line"># TYPE chat_monitor_server_error_total counter</span><br><span class="line">chat_monitor_server_error_total&#123;type="network_server_error"&#125; 1</span><br><span class="line"># HELP chat_monitor_server_gogc The value of GOGC</span><br><span class="line"># TYPE chat_monitor_server_gogc gauge</span><br><span class="line">chat_monitor_server_gogc 100</span><br><span class="line"># HELP chat_monitor_server_info Indicate the chat_monitor server info, and the value is the start timestamp (s).</span><br><span class="line"># TYPE chat_monitor_server_info gauge</span><br><span class="line">chat_monitor_server_info 1.644568978e+09</span><br><span class="line"># HELP chat_monitor_server_maxprocs The value of GOMAXPROCS.</span><br><span class="line"># TYPE chat_monitor_server_maxprocs gauge</span><br><span class="line">chat_monitor_server_maxprocs 6</span><br></pre></td></tr></table></figure><p>到这里，一些基础而核心的逻辑也介绍完了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近，公司以前有一些旧的服务，由于各种原因，导致各种问题，并且架构设计行也不是那么友好和不利于维护。&lt;br&gt;所以准备重构设计一些服务。&lt;/p&gt;
&lt;p&gt;在游戏公司中，GM客服的其中一个职能就是监督舆论，从玩家平日的聊天中进行监控。&lt;/p&gt;
&lt;p&gt;我们从&lt;code&gt;业务需求&lt;/code&gt;+&lt;code&gt;技术架构&lt;/code&gt;层面进行整理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/categories/Golang/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>TIDB源码剖析（一）</title>
    <link href="http://blog.crazylaw.cn/2022/01/24/TIDB/TIDB%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://blog.crazylaw.cn/2022/01/24/TIDB/TIDB%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2022-01-24T02:28:33.000Z</published>
    <updated>2022-01-25T03:01:50.165Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>这一章，作为我们的起始章节，跟着源码，我们一步步来熟悉TIDB的整体代码结构</p><hr><a id="more"></a><h2 id="Select"><a href="#Select" class="headerlink" title="Select"></a>Select</h2><p>当我们有一条基本的sql如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> mysql.user;</span><br></pre></td></tr></table></figure><p>我们从接收到客户端连接开始，<code>执行</code>，<code>解析</code>，<code>逻辑优化器</code>，<code>物理优化器</code>，到<code>最终结果</code>开始分析。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;planner.optimize at optimize.go:335</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;planner.Optimize at optimize.go:211</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;executor.(*Compiler).Compile at compiler.go:77</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;session.(*session).ExecuteStmt at session.go:1696</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*TiDBContext).ExecuteStmt at driver_tidb.go:220</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*clientConn).handleStmt at conn.go:1977</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*clientConn).handleQuery at conn.go:1846</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*clientConn).dispatch at conn.go:1341</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*clientConn).Run at conn.go:1091</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*Server).onConn at server.go:556</span><br><span class="line">runtime.goexit at asm_amd64.s:1371</span><br><span class="line"> - Async stack trace</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*Server).startNetworkListener at server.go:453</span><br></pre></td></tr></table></figure><p>上面这是一个基本的执行流程，我们跟着这一段堆栈来进行分析。</p><h2 id="github-com-pingcap-tidb-server-Server-onConn-at-server-go-连接处理逻辑"><a href="#github-com-pingcap-tidb-server-Server-onConn-at-server-go-连接处理逻辑" class="headerlink" title="github.com/pingcap/tidb/server.(*Server).onConn at server.go (连接处理逻辑)"></a>github.com/pingcap/tidb/server.(*Server).onConn at server.go (连接处理逻辑)</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conn.Run(ctx)</span><br></pre></td></tr></table></figure><p>这里，我们看到了这是进入到了一个<code>clientConn</code>的 <code>Run</code> 方法。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Run reads client query and writes query result to client in for loop, if there is a panic during query handling,</span></span><br><span class="line"><span class="comment">// it will be recovered and log the panic error.</span></span><br><span class="line"><span class="comment">// This function returns and the connection is closed if there is an IO error or there is a panic.</span></span><br><span class="line"><span class="comment">// 在for循环中，执行读取客户端查询，并将查询结果写入客户端，如果在处理查询时出现panic，</span></span><br><span class="line"><span class="comment">// 它将被恢复并记录panic错误。</span></span><br><span class="line"><span class="comment">// 如果出现IO错误或panic，该函数返回并关闭连接。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *clientConn)</span> <span class="title">Run</span><span class="params">(ctx context.Context)</span></span></span><br></pre></td></tr></table></figure><p>这里我们看到了有一段文字帮助我们理解注意事项。</p><p>我们按照过程式的顺序来从上往下看源码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">   <span class="keyword">const</span> size = <span class="number">4096</span></span><br><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">r := <span class="built_in">recover</span>()</span><br><span class="line"><span class="keyword">if</span> r != <span class="literal">nil</span> &#123;</span><br><span class="line">buf := <span class="built_in">make</span>([]<span class="keyword">byte</span>, size)</span><br><span class="line">stackSize := runtime.Stack(buf, <span class="literal">false</span>)</span><br><span class="line">buf = buf[:stackSize]</span><br><span class="line">logutil.Logger(ctx).Error(<span class="string">"connection running loop panic"</span>,</span><br><span class="line">zap.Stringer(<span class="string">"lastSQL"</span>, getLastStmtInConn&#123;cc&#125;),</span><br><span class="line">zap.String(<span class="string">"err"</span>, fmt.Sprintf(<span class="string">"%v"</span>, r)),</span><br><span class="line">zap.String(<span class="string">"stack"</span>, <span class="keyword">string</span>(buf)),</span><br><span class="line">)</span><br><span class="line">err := cc.writeError(ctx, errors.New(fmt.Sprintf(<span class="string">"%v"</span>, r)))</span><br><span class="line">terror.Log(err)</span><br><span class="line">metrics.PanicCounter.WithLabelValues(metrics.LabelSession).Inc()</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> atomic.LoadInt32(&amp;cc.status) != connStatusShutdown &#123;</span><br><span class="line">err := cc.Close()</span><br><span class="line">terror.Log(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br></pre></td></tr></table></figure><p>这段代码，我们看到了几点。</p><ul><li>通过 <code>recover()</code> 方法来阻止<code>panic</code>引起的程序异常崩溃，如果是panic的话，那么将会有一段特殊的逻辑处理<br>  1.1 通过 <code>runtime.Stack(buf,false)</code> 的第二个参数来控制只获取当前协程下的堆栈信息，并且写入到<code>buf</code>变量中<br>  1.2 由于 <code>const size = 4096</code> 的原因，我们拿到的buf未必是那么多，因此，通过 <code>buf[:stackSize]</code> 来进行切片处理，把变量的指针重新指向新的数据区域<br>  1.3 通过日志组件来记录详细信息， 有意思的是，这里通过了<code>getLastStmtInConn结构体</code>里面的<code>String()</code>方法来进行序列化自己想要的内容信息，其他的就是基本的<code>err</code>, <code>stack</code>的信息了<br>  1.4 我们不单单需要在服务器上记录信息，还要把对应的用户错误信息也记录下来并且发送给客户端。所以通过了 <code>err := cc.writeError(ctx, errors.New(fmt.Sprintf(&quot;%v&quot;, r)))</code> 来实现这一点。<br>  1.5 然后就是记录相关的<code>metrics</code>，因为发生了一次 <code>panic</code>，所以需要通过<code>PanicCounter</code>记录下来，用于统计由于<code>session</code>引起的<code>panic</code>总共有多少次</li><li>如果是非panic引起的函数析构，那么还要通过原子性草走来判断状态是否为关闭状态，如果是关闭状态，那么在这里就需要把连接断开，并且记录下错误信息</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Usually, client connection status changes between [dispatching] &lt;=&gt; [reading].</span></span><br><span class="line"><span class="comment">// When some event happens, server may notify this client connection by setting</span></span><br><span class="line"><span class="comment">// the status to special values, for example: kill or graceful shutdown.</span></span><br><span class="line"><span class="comment">// The client connection would detect the events when it fails to change status</span></span><br><span class="line"><span class="comment">// by CAS operation, it would then take some actions accordingly.</span></span><br><span class="line"><span class="comment">// 通常情况下，客户端连接状态在[dispatching] &lt;=&gt; [reading]之间变化。</span></span><br><span class="line"><span class="comment">// 当某个事件发生时，服务器可以通过设置来通知这个客户端连接</span></span><br><span class="line"><span class="comment">// 将状态设置为特殊值，例如:kill或graceful shutdown。</span></span><br><span class="line"><span class="comment">// 当CAS操作改变状态失败时，客户端连接将检测到事件，然后采取相应的动作。</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">if</span> !atomic.CompareAndSwapInt32(&amp;cc.status, connStatusDispatching, connStatusReading) ||</span><br><span class="line"><span class="comment">// The judge below will not be hit by all means,</span></span><br><span class="line"><span class="comment">// But keep it stayed as a reminder and for the code reference for connStatusWaitShutdown.</span></span><br><span class="line">atomic.LoadInt32(&amp;cc.status) == connStatusWaitShutdown &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>我们看到这是一个循环操作，并且通过原子性操作<code>atomic.CompareAndSwapInt32</code>（比较然后再交换，所以符合CAS原则，乐观锁）来判断session连接是否能是否能切换到<code>connStatusDispatching</code> =&gt; <code>connStatusReading</code> 状态</li><li>如果不可以切换，那么则结束该方法</li><li>如果连接状态为等待关闭状态，那么也结束该方法</li></ul><p>对于其中的 <code>...</code>，现在会在下面进一步说明。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">cc.alloc.Reset()</span><br><span class="line"><span class="comment">// close connection when idle time is more than wait_timeout</span></span><br><span class="line">waitTimeout := cc.getSessionVarsWaitTimeout(ctx)</span><br><span class="line">cc.pkt.setReadTimeout(time.Duration(waitTimeout) * time.Second)</span><br><span class="line">start := time.Now()</span><br><span class="line">data, err := cc.readPacket()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> terror.ErrorNotEqual(err, io.EOF) &#123;</span><br><span class="line"><span class="keyword">if</span> netErr, isNetErr := errors.Cause(err).(net.Error); isNetErr &amp;&amp; netErr.Timeout() &#123;</span><br><span class="line">idleTime := time.Since(start)</span><br><span class="line">logutil.Logger(ctx).Info(<span class="string">"read packet timeout, close this connection"</span>,</span><br><span class="line">zap.Duration(<span class="string">"idle"</span>, idleTime),</span><br><span class="line">zap.Uint64(<span class="string">"waitTimeout"</span>, waitTimeout),</span><br><span class="line">zap.Error(err),</span><br><span class="line">)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">errStack := errors.ErrorStack(err)</span><br><span class="line"><span class="keyword">if</span> !strings.Contains(errStack, <span class="string">"use of closed network connection"</span>) &#123;</span><br><span class="line">logutil.Logger(ctx).Warn(<span class="string">"read packet failed, close this connection"</span>,</span><br><span class="line">zap.Error(errors.SuspendStack(err)))</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">disconnectByClientWithError.Inc()</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><code>cc.alloc.Reset()</code>重置内存池大小</li><li>当空闲时间大于等待超时时间的话那么将会关闭丽连接。<code>cc.pkt.setReadTimeout(time.Duration(waitTimeout) * time.Second)</code></li><li>从客户端读取数据，如果存在错误，那么将会记录下来相关信息，例如从读取数据到最后的时间，来统计idletime，通过<code>metrics.DisconnectionCounter.WithLabelValues(metrics.LblError)</code>来记录因为err导致连接断开的次数</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> !atomic.CompareAndSwapInt32(&amp;cc.status, connStatusReading, connStatusDispatching) &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同理，经过cas乐观锁，把状态从 <code>connStatusReading</code> =&gt; <code>connStatusDispatching</code>如果，交换设置失败，那么就结束函数。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">startTime := time.Now()</span><br><span class="line">err = cc.dispatch(ctx, data)</span><br></pre></td></tr></table></figure><h2 id="github-com-pingcap-tidb-server-clientConn-dispatch-（分发逻辑）"><a href="#github-com-pingcap-tidb-server-clientConn-dispatch-（分发逻辑）" class="headerlink" title="github.com/pingcap/tidb/server.(*clientConn).dispatch （分发逻辑）"></a>github.com/pingcap/tidb/server.(*clientConn).dispatch （分发逻辑）</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// dispatch handles client request based on command which is the first byte of the data.</span></span><br><span class="line"><span class="comment">// It also gets a token from server which is used to limit the concurrently handling clients.</span></span><br><span class="line"><span class="comment">// The most frequently used command is ComQuery.</span></span><br><span class="line"><span class="comment">// dispatch根据命令处理客户端请求，命令是数据的第一个字节。</span></span><br><span class="line"><span class="comment">// 它也从服务器获取一个令牌，用于限制并发处理客户端。</span></span><br><span class="line"><span class="comment">// 最常用的命令是ComQuery。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *clientConn)</span> <span class="title">dispatch</span><span class="params">(ctx context.Context, data []<span class="keyword">byte</span>)</span> <span class="title">error</span></span></span><br></pre></td></tr></table></figure><p>下面的方法都是dispatch的过程顺序逻辑</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// reset killed for each request</span></span><br><span class="line">atomic.StoreUint32(&amp;cc.ctx.GetSessionVars().Killed, <span class="number">0</span>)</span><br><span class="line">&#125;()</span><br><span class="line">t := time.Now()</span><br><span class="line"><span class="keyword">if</span> (cc.ctx.Status() &amp; mysql.ServerStatusInTrans) &gt; <span class="number">0</span> &#123;</span><br><span class="line">connIdleDurationHistogramInTxn.Observe(t.Sub(cc.lastActive).Seconds())</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">connIdleDurationHistogramNotInTxn.Observe(t.Sub(cc.lastActive).Seconds())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>这里可以看到这里有一个defer，当函数结束的时候，会重置session的Killed次数</li><li><code>cc.ctx.Status() &amp; mysql.ServerStatusInTrans</code> 这里因为兼容了mysql的无状态协议，所以通过第一个<code>位运算</code>来判断当前状态<ol><li>如果当前链接处于一个<code>事务</code>状态下的话，那么通过<code>connIdleDurationHistogramInTxn.Observe(t.Sub(cc.lastActive).Seconds())</code> 用直方图监控从最后一次活跃时间到当前分发时间</li><li>否则则用另一个<code>metrics</code>来记录</li></ol></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">span := opentracing.StartSpan(<span class="string">"server.dispatch"</span>)</span><br><span class="line">cfg := config.GetGlobalConfig()</span><br><span class="line"><span class="keyword">if</span> cfg.OpenTracing.Enable &#123;</span><br><span class="line">ctx = opentracing.ContextWithSpan(ctx, span)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> cancelFunc context.CancelFunc</span><br><span class="line">ctx, cancelFunc = context.WithCancel(ctx)</span><br><span class="line">cc.mu.Lock()</span><br><span class="line">cc.mu.cancelFunc = cancelFunc</span><br><span class="line">cc.mu.Unlock()</span><br></pre></td></tr></table></figure><ul><li>通过<code>opentracing</code>来开始进行<code>分布式追踪</code>，<code>cc.mu</code> 主要是用来在<code>事务</code>中取消事务用的。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cc.lastPacket = data</span><br><span class="line">cmd := data[<span class="number">0</span>]</span><br><span class="line">data = data[<span class="number">1</span>:]</span><br><span class="line"><span class="keyword">if</span> topsqlstate.TopSQLEnabled() &#123;</span><br><span class="line"><span class="keyword">defer</span> pprof.SetGoroutineLabels(ctx)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> variable.EnablePProfSQLCPU.Load() &#123;</span><br><span class="line">label := getLastStmtInConn&#123;cc&#125;.PProfLabel()</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(label) &gt; <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">defer</span> pprof.SetGoroutineLabels(ctx)</span><br><span class="line">ctx = pprof.WithLabels(ctx, pprof.Labels(<span class="string">"sql"</span>, label))</span><br><span class="line">pprof.SetGoroutineLabels(ctx)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>把当前session接收到的数据记录在<code>lastPakcet</code>中</li><li><code>第一个字节</code>代表<code>命令</code></li><li><code>后面的字节</code>代表<code>数据</code></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">token := cc.server.getToken()</span><br><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// if handleChangeUser failed, cc.ctx may be nil</span></span><br><span class="line"><span class="keyword">if</span> cc.ctx != <span class="literal">nil</span> &#123;</span><br><span class="line">cc.ctx.SetProcessInfo(<span class="string">""</span>, t, mysql.ComSleep, <span class="number">0</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cc.server.releaseToken(token)</span><br><span class="line">span.Finish()</span><br><span class="line">cc.lastActive = time.Now()</span><br><span class="line">&#125;()</span><br></pre></td></tr></table></figure><p>这里需要关注一下<code>defer</code>里面的内容</p><ul><li>根据mysql协议，当命令为<code>mysql.ComSleep</code>的时候，代表execute已经完成了。所以当结束的时候，需要设置一下这个<code>ProcessInfo</code></li><li>然后释放本次token，并且span也需要标记为完成</li><li>更新最后一次活跃时间</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vars := cc.ctx.GetSessionVars()</span><br><span class="line"><span class="comment">// reset killed for each request</span></span><br><span class="line">atomic.StoreUint32(&amp;vars.Killed, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> cmd &lt; mysql.ComEnd &#123;</span><br><span class="line">cc.ctx.SetCommandValue(cmd)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>获取当前session的变量</li><li>重置其中的killed属性</li><li>如果<code>cmd</code>在范围内的，更新当前命令的值</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dataStr := <span class="keyword">string</span>(hack.String(data))</span><br><span class="line"><span class="keyword">switch</span> cmd &#123;</span><br><span class="line"><span class="keyword">case</span> mysql.ComPing, mysql.ComStmtClose, mysql.ComStmtSendLongData, mysql.ComStmtReset,</span><br><span class="line">mysql.ComSetOption, mysql.ComChangeUser:</span><br><span class="line">cc.ctx.SetProcessInfo(<span class="string">""</span>, t, cmd, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">case</span> mysql.ComInitDB:</span><br><span class="line">cc.ctx.SetProcessInfo(<span class="string">"use "</span>+dataStr, t, cmd, <span class="number">0</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>这里利用了golang种的<code>hack（黑科技）</code>的方式来把<code>byte</code>转换成<code>string</code>，其实主要就是因为底层用的都有一样的结构体，所以可以直接通过<code>unsafe.pointer</code>来直接操作内容指针，进行<code>zero-copy</code></li><li>对cmd进行<code>processinfo</code>的处理，如果是<code>use db</code>的命令的话，则需要传递数据库</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span> cmd &#123;</span><br><span class="line"><span class="keyword">case</span> mysql.ComSleep:</span><br><span class="line"><span class="comment">// <span class="doctag">TODO:</span> According to mysql document, this command is supposed to be used only internally.</span></span><br><span class="line"><span class="comment">// So it's just a temp fix, not sure if it's done right.</span></span><br><span class="line"><span class="comment">// Investigate this command and write test case later.</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line"><span class="keyword">case</span> mysql.ComQuit:</span><br><span class="line"><span class="keyword">return</span> io.EOF</span><br><span class="line"><span class="keyword">case</span> mysql.ComInitDB:</span><br><span class="line"><span class="keyword">if</span> err := cc.useDB(ctx, dataStr); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> cc.writeOK(ctx)</span><br><span class="line"><span class="keyword">case</span> mysql.ComQuery: <span class="comment">// Most frequently used command.</span></span><br><span class="line"><span class="comment">// For issue 1989</span></span><br><span class="line"><span class="comment">// Input payload may end with byte '\0', we didn't find related mysql document about it, but mysql</span></span><br><span class="line"><span class="comment">// implementation accept that case. So trim the last '\0' here as if the payload an EOF string.</span></span><br><span class="line"><span class="comment">// See http://dev.mysql.com/doc/internals/en/com-query.html</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(data) &gt; <span class="number">0</span> &amp;&amp; data[<span class="built_in">len</span>(data)<span class="number">-1</span>] == <span class="number">0</span> &#123;</span><br><span class="line">data = data[:<span class="built_in">len</span>(data)<span class="number">-1</span>]</span><br><span class="line">dataStr = <span class="keyword">string</span>(hack.String(data))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> cc.handleQuery(ctx, dataStr)</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我复制了一部分，因为我们重点关注<code>mysql.ComQuery</code>命令。</p><ul><li>根据提示，我们发现因为mysql协议说明了输入载体可能以<code>\0</code>作为最后字节，所以这里一定要减去client发送的多余的最后一个字节。所以长度进行了-1操作</li><li>然后进入到<code>cc.handleQuery(ctx, dataStr)</code></li></ul><h2 id="github-com-pingcap-tidb-server-clientConn-handleQuery"><a href="#github-com-pingcap-tidb-server-clientConn-handleQuery" class="headerlink" title="github.com/pingcap/tidb/server.(*clientConn).handleQuery"></a>github.com/pingcap/tidb/server.(*clientConn).handleQuery</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// handleQuery executes the sql query string and writes result set or result ok to the client.</span></span><br><span class="line"><span class="comment">// As the execution time of this function represents the performance of TiDB, we do time log and metrics here.</span></span><br><span class="line"><span class="comment">// There is a special query `load data` that does not return result, which is handled differently.</span></span><br><span class="line"><span class="comment">// Query `load stats` does not return result either.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *clientConn)</span> <span class="title">handleQuery</span><span class="params">(ctx context.Context, sql <span class="keyword">string</span>)</span> <span class="params">(err error)</span></span></span><br></pre></td></tr></table></figure><p>这个方法，终于开始正式进入我们的主题了</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">defer</span> trace.StartRegion(ctx, <span class="string">"handleQuery"</span>).End()</span><br><span class="line">sc := cc.ctx.GetSessionVars().StmtCtx</span><br><span class="line">prevWarns := sc.GetWarnings()</span><br><span class="line">stmts, err := cc.ctx.Parse(ctx, sql)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(stmts) == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> cc.writeOK(ctx)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>defer进行了当函数结束的时候，标记<code>handleQuery</code>结束</li><li>拿到<code>statement</code>的上下文环境</li><li>从上下文中拿到所有的<code>warinning</code>警告</li><li>通过<code>cc.ctx.Parse(ctx, sql)</code>来进行解析sql，这里属于一个大的篇章，暂时不张开讲，主要涉及到的内容有<code>编译原理</code>,<code>AST-Tree</code>，<code>Yacc</code>。我们通过这里可以拿到一棵抽象语法树，实质是<code>SelectStmt</code>，内部包含了如下内容：<ol><li>dmlNode（因为select语句属于dml语句）</li><li>其他的都是常规的例如<code>FROM</code>, <code>WHERE</code>, <code>FIELDS</code>, <code>DISTINCT</code> 等等</li></ol></li><li>如果没有一个完成的抽象语法书，则直接返回响应协议和对应的内容</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> pointPlans []plannercore.Plan</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(stmts) &gt; <span class="number">1</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The client gets to choose if it allows multi-statements, and</span></span><br><span class="line"><span class="comment">// probably defaults OFF. This helps prevent against SQL injection attacks</span></span><br><span class="line"><span class="comment">// by early terminating the first statement, and then running an entirely</span></span><br><span class="line"><span class="comment">// new statement.</span></span><br><span class="line"></span><br><span class="line">capabilities := cc.ctx.GetSessionVars().ClientCapability</span><br><span class="line"><span class="keyword">if</span> capabilities&amp;mysql.ClientMultiStatements &lt; <span class="number">1</span> &#123;</span><br><span class="line"><span class="comment">// The client does not have multi-statement enabled. We now need to determine</span></span><br><span class="line"><span class="comment">// how to handle an unsafe situation based on the multiStmt sysvar.</span></span><br><span class="line"><span class="keyword">switch</span> cc.ctx.GetSessionVars().MultiStatementMode &#123;</span><br><span class="line"><span class="keyword">case</span> variable.OffInt:</span><br><span class="line">err = errMultiStatementDisabled</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line"><span class="keyword">case</span> variable.OnInt:</span><br><span class="line"><span class="comment">// multi statement is fully permitted, do nothing</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">warn := stmtctx.SQLWarn&#123;Level: stmtctx.WarnLevelWarning, Err: errMultiStatementDisabled&#125;</span><br><span class="line">parserWarns = <span class="built_in">append</span>(parserWarns, warn)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Only pre-build point plans for multi-statement query</span></span><br><span class="line">pointPlans, err = cc.prefetchPointPlanKeys(ctx, stmts)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>通过Session中的var中的<code>ClientCapability</code>的<code>位运算</code>来判断是否支持<code>mysql.ClientMultiStatements</code>（多sql语句）</li><li>如果<code>sysvar</code>也不支持<code>MultiStatementMode</code>,也就是<code>variable.OffInt</code>，那么就直接返回err</li><li>如果没有能力支持client多statement的话，但是var又开启了的话，目前啥事也没做</li><li>默认就是不支持，但是会通过warn来展示给客户端</li><li>只有在多statement的场景下预取目标计划关键字</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, stmt := <span class="keyword">range</span> stmts &#123;</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pointPlans) &gt; <span class="number">0</span> &#123;</span><br><span class="line"><span class="comment">// Save the point plan in Session, so we don't need to build the point plan again.</span></span><br><span class="line">cc.ctx.SetValue(plannercore.PointPlanKey, plannercore.PointPlanVal&#123;Plan: pointPlans[i]&#125;)</span><br><span class="line">&#125;</span><br><span class="line">retryable, err = cc.handleStmt(ctx, stmt, parserWarns, i == <span class="built_in">len</span>(stmts)<span class="number">-1</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> !retryable || !errors.ErrorEqual(err, storeerr.ErrTiFlashServerTimeout) &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">_, allowTiFlashFallback := cc.ctx.GetSessionVars().AllowFallbackToTiKV[kv.TiFlash]</span><br><span class="line"><span class="keyword">if</span> !allowTiFlashFallback &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// When the TiFlash server seems down, we append a warning to remind the user to check the status of the TiFlash</span></span><br><span class="line"><span class="comment">// server and fallback to TiKV.</span></span><br><span class="line">warns := <span class="built_in">append</span>(parserWarns, stmtctx.SQLWarn&#123;Level: stmtctx.WarnLevelError, Err: err&#125;)</span><br><span class="line"><span class="built_in">delete</span>(cc.ctx.GetSessionVars().IsolationReadEngines, kv.TiFlash)</span><br><span class="line">_, err = cc.handleStmt(ctx, stmt, warns, i == <span class="built_in">len</span>(stmts)<span class="number">-1</span>)</span><br><span class="line">cc.ctx.GetSessionVars().IsolationReadEngines[kv.TiFlash] = <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>如果有目标计划的话，那么只需要在上下文中设置value即可，不需要再次构建目标计划</li><li><code>cc.handleStmt(ctx, stmt, parserWarns, i == len(stmts)-1)</code> 这是我们的核心中的核心，这里面就是处理<code>抽象语法树</code>的逻辑，包含了<code>逻辑优化</code>, <code>物理优化</code>, <code>执行器</code>，<code>tikv</code>交互等等</li><li>todo：留着回来分析</li></ul><h2 id="github-com-pingcap-tidb-server-clientConn-handleStmt"><a href="#github-com-pingcap-tidb-server-clientConn-handleStmt" class="headerlink" title="github.com/pingcap/tidb/server.(*clientConn).handleStmt"></a>github.com/pingcap/tidb/server.(*clientConn).handleStmt</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The first return value indicates whether the call of handleStmt has no side effect and can be retried.</span></span><br><span class="line"><span class="comment">// Currently, the first return value is used to fall back to TiKV when TiFlash is down.</span></span><br><span class="line"><span class="comment">// 第一个返回值表示调用handleStmt是否没有副作用，是否可以重试</span></span><br><span class="line"><span class="comment">// 当前，第一个返回值用于在TiFlash down时回落到TiKV</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *clientConn)</span> <span class="title">handleStmt</span><span class="params">(ctx context.Context, stmt ast.StmtNode, warns []stmtctx.SQLWarn, lastStmt <span class="keyword">bool</span>)</span> <span class="params">(<span class="keyword">bool</span>, error)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ctx = context.WithValue(ctx, execdetails.StmtExecDetailKey, &amp;execdetails.StmtExecDetails&#123;&#125;)</span><br><span class="line">ctx = context.WithValue(ctx, util.ExecDetailsKey, &amp;util.ExecDetails&#123;&#125;)</span><br><span class="line">reg := trace.StartRegion(ctx, <span class="string">"ExecuteStmt"</span>)</span><br><span class="line">cc.audit(plugin.Starting)</span><br><span class="line">rs, err := cc.ctx.ExecuteStmt(ctx, stmt)</span><br></pre></td></tr></table></figure><ul><li>上下文带上value，设置主要是<code>StmtExecDetails</code>，里面记录了写入sql到响应的时间</li><li>上下文带上value，设置主要是<code>ExecDetails</code>，里面记录了<code>execution</code>的详情信息，分别有</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;这一章，作为我们的起始章节，跟着源码，我们一步步来熟悉TIDB的整体代码结构&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
    
      <category term="TIDB" scheme="http://blog.crazylaw.cn/categories/TIDB/"/>
    
    
      <category term="TIDB" scheme="http://blog.crazylaw.cn/tags/TIDB/"/>
    
  </entry>
  
  <entry>
    <title>2022杂乱知识点总结</title>
    <link href="http://blog.crazylaw.cn/2022/01/19/2022%E6%9D%82%E4%B9%B1%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"/>
    <id>http://blog.crazylaw.cn/2022/01/19/2022%E6%9D%82%E4%B9%B1%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</id>
    <published>2022-01-19T06:38:06.000Z</published>
    <updated>2022-02-05T06:14:45.964Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>记录一下常规下的一些知识点。</p><hr><a id="more"></a><h2 id="Go"><a href="#Go" class="headerlink" title="Go"></a>Go</h2><h3 id="go-channel-close后读的问题"><a href="#go-channel-close后读的问题" class="headerlink" title="go channel close后读的问题"></a>go channel close后读的问题</h3>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;记录一下常规下的一些知识点。&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
    
      <category term="知识点" scheme="http://blog.crazylaw.cn/categories/%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    
    
      <category term="2022杂乱知识点总结" scheme="http://blog.crazylaw.cn/tags/2022%E6%9D%82%E4%B9%B1%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>【2021】 2021年终总结</title>
    <link href="http://blog.crazylaw.cn/2022/01/02/2021%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    <id>http://blog.crazylaw.cn/2022/01/02/2021%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/</id>
    <published>2022-01-02T15:54:00.000Z</published>
    <updated>2022-01-25T03:01:32.272Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>2021已经过去了，在这里回忆一下，我的2021的年终总结。</p><a id="more"></a><h2 id="困难与挑战"><a href="#困难与挑战" class="headerlink" title="困难与挑战"></a>困难与挑战</h2><p>工作中，在过去的一年里，迎接了不少的挑战，在公司中落地大数据相关的服务了从<code>erlang</code>到<code>golang</code>的转换。我们整套新的体系称为：<code>mfeilog</code></p><ol><li><p>在公司中，积累了许多go语言的组件，并且不断的完善修复相关的bug，例如，mfeilog的核心数据源：<code>msource</code>，mfeilog的基础组件：<code>daemon组件</code>/<code>no-named-pipe组件</code>，<code>logbdev组件</code>，<code>sink_mysql</code>/<code>sink_kafka</code>等组件。</p></li><li><p>说到这个<code>msource</code>服务，这是一个基于<code>rocksdb</code>实现的支持<code>sql</code>语法的轻量级小型定制<code>数据库服务</code>，可以说是经过了不断优化，升级，修复内部各种内置功能，才得以现在的稳定和高效。给应用层提供了一个高可靠，稳定，的数据源功能。其中有一个bug，印象特别深刻，也是我始料未及的一个bug，因为<code>发号器</code>是附属在<code>Table</code>当中的，我需要<code>自定义序列化</code>后存储在底层的<code>rocksdb</code>中，所以在我<code>反序列化</code>出来的时候，启动了多个发号器，导致每个<code>field-colunm</code>都实例化了一个新的对象，而非同一个对象，引发了发号器错乱，从而导致数据丢失的问题(内存被覆盖，错误ack掉了数据)。这个问题排查也是十分不易！！！所以可以说是血的教训。</p></li><li><p>并且也为公司推广 “服务器日志查询方案” 中，确定了以<code>GPL（grafna+protomal+loki）</code>的日志查询架构，统一了日志查询的入口，大大提高了日志查询的效率。</p></li><li><p>在 <code>go服务流量录制和回放方案和实现</code> 中，为了实现流量闭环，特意去调研查看了 滴滴的 <code>《写轮眼》</code>项目，并且知道了通过类似注入的方式，可以在用户层编解码上替换到原来的函数指针，从而实现在用户层替换go底层源码的方式，但是由于性价比问题，在公司中最后并未推广，也没有进行研发。该需求后面被搁置了。</p></li><li><p>在 <code>配置服务方案</code> 中，这个需求在以往其实已经试过才用<code>consule</code>来做配置服务中心，原因是早期我们想要对服务做一个<code>服务注册和发现</code>，在 <code>php</code> 这种<code>fastcgi</code>的方式来说，consule的主动发现服务，就比很多类似<code>etcd</code>被动发现注册服务好用。但是由于最终因为我们的服务目前来说比较零散，并且需求的任务不是着急，这件事后面也被搁置了，后面今天再次提了一个这样子的类似的需求，实现了通过 go语言写的的工具，类似于<code>k8s</code>的<code>kubectl</code>的工具，进行配置的同步和管理，分别分为了2个模式，一个是C端的工具，一个是S端的同步服务，中间的枢纽，最终选择了以<code>etcd</code>为配置分布式存储服务。我们服务的部署特点，利用<code>jenkins</code>的<code>多阶段自定义编译</code>的<code>jenkins-shared-library</code>实现了灵活编译，根据现有的服务灵活部署，从而达到非嵌入式的配置同步方式。</p></li><li><p>因为公司成立得比较早，代码仓库一直从未进行变更，所以其中一个需求就是 <code>gitbucket</code> 到 <code>gitlab</code> 的代码仓库迁移，写了一个小工具，从而实现了从 gitbucket到 gitlab一键自动化无缝迁移代码，包括项目组，项目的历史<code>commit</code>，<code>tag</code>，<code>branch</code>等等都自动化完成，大大减轻了项目迁移的负担。</p></li><li><p>对 <code>jenkins</code> 的<code>shard-library</code> 模块进行优化升级，编写了一个<code>python的支持多凭据认证的脚本</code>，并且支持自定义编译代码。</p></li><li><p>集成了一套，<code>本地的大数据docker环境</code>，我们都知道大数据环境十分的繁杂，并且还需要多台机器才能处理，这对我们本地开发来说十分的不友好，但是网上又没有那些很好的开箱即用的<code>docker-compose</code>环境，因此整理了一套本地的大数据docker环境(非CDH版本)</p></li><li><p>优化升级部分 <code>mproxy</code> 的代码，从而让测试人员更友好的在该项目中完成<code>自动化测试</code>的脚本功能。</p></li><li><p>推动<code>flink</code>的落地，由于我们早期的流计算，是单机的，并且存在严重的外部依赖属性，所以，我们推动了flink的落地，探究了几种开发方式，分别是用纯<code>java</code> 写的<code>datastream-api</code>方式，这个方式有一个好处就是，所有的上层的api都是基于<code>datastream</code>的，一些上层的api无法满足我们的需求，我们通过datastream可以很轻松的实现各类需求。在这个过程中，我踩了不少的坑，主要是来自于<code>watermark</code>和<code>window</code>的概念，咋一看其实都是一些比较好理解的概念，但是其实在配合大数据专用的<code>kafka</code>消息队列中间件，一切就变得复杂起来，由于<code>kafka</code>的<code>partition</code>只能有一个client去消费的原因，加上flink自身的概念<code>并行度</code>，这一切结合在一起，就会出现一些让你疑惑的点。经过了大量反复的摸索和钻研，最终才掌握了在多partition下flink的watermark和window-trigger机制方式，但是由于该方式不够直观，也不管灵活，所以我们最终推广了<code>sql-api</code>。好家伙，你以为这就完了吗，并没有，由于flink自身带有<code>sql-client</code>的原因，我一开始尝试了用<code>sql-client</code>来编写流计算的模型，但是发现这个工具有太多问题了，不同的版本有不用的调用方式，不同版本下，对于<code>SET</code>支持的粒度也是不一致的，这让我很头疼。所以最终选择了，基于flink编写了一个自研的<code>flink-sql-client</code>，通过<code>flink run flink-sql-client.jar</code>的方式，我们就可以轻松的提交sql任务或者做其他的需求（例如查看hive的cataglog等等）。然而到了这里还没有结束，由于<code>sql</code>的部分，我们没办法控制，是由<code>flink-core</code>自身标准化了流程，所以有一些bug我们没办法解决，例如在 <code>flink-1.12.0</code> 种，就会因为<code>watermark</code>在<code>idle</code>的情况下，无法推进watermark，从而导致窗口在少量数据情况下，根本不能及时的统计和计算（这和号称实时分析的流计算违背），所以我们只能想了一些版本做了一些迂回的操作。从而最终解决类似这种由于底层bug所带来的问题。</p></li></ol><h2 id="自己的学习上"><a href="#自己的学习上" class="headerlink" title="自己的学习上"></a>自己的学习上</h2><ol><li><p>对<code>golang</code>的<code>protobuf</code>服务有一些的了解，并且学会了<code>protobuf</code>的插件开发。了解了protobuf的协议。</p></li><li><p>对<code>rust</code>上的生态更为清晰了，利用了其中的一些<code>actor</code>模型，<code>async-io</code>等分别实现了一些基础的工具。</p></li><li><p>对<code>flutter</code>也有了一定的了解，利用<code>dart</code>编写了一个可以用于自定义通信的库。s</p></li><li><p>对<code>linux</code> 种的一些磁盘io，网络io，已经shell命令的灵活运用更加深刻。</p></li></ol><blockquote><p>未完待续！！</p></blockquote><p>(悄咪咪的告诉大家，我买房了。嘿嘿)</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;2021已经过去了，在这里回忆一下，我的2021的年终总结。&lt;/p&gt;
    
    </summary>
    
    
      <category term="年终总结" scheme="http://blog.crazylaw.cn/categories/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="年终总结" scheme="http://blog.crazylaw.cn/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
</feed>
