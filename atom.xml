<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>白菜君の技术库</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.crazylaw.cn/"/>
  <updated>2022-05-27T11:12:44.819Z</updated>
  <id>http://blog.crazylaw.cn/</id>
  
  <author>
    <name>白菜(whiteCcinn)</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>大数据任务-重分配任务</title>
    <link href="http://blog.crazylaw.cn/2022/05/27/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E9%87%8D%E5%88%86%E9%85%8D%E4%BB%BB%E5%8A%A1/"/>
    <id>http://blog.crazylaw.cn/2022/05/27/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E9%87%8D%E5%88%86%E9%85%8D%E4%BB%BB%E5%8A%A1/</id>
    <published>2022-05-27T10:52:40.000Z</published>
    <updated>2022-05-27T11:12:44.819Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>总结一下公司大数据的任务ETL离线工作流 - 重分配任务</p><a id="more"></a><p>公司的ETL服务，目前采用的是组件为：</p><ul><li>数仓 (hadoop)</li><li>任务调度器 (azkaban)</li><li>出仓 (gp)</li><li>数仓查询 (hue)(hive)(spark)</li></ul><h2 id="job-tk-reassign（重分配任务）"><a href="#job-tk-reassign（重分配任务）" class="headerlink" title="job_tk_reassign（重分配任务）"></a>job_tk_reassign（重分配任务）</h2><ul><li>schedule: <code>30 10 * * *</code></li></ul><blockquote><p>按 <code>天</code> 为一个周期</p></blockquote><p>天级指标：</p><ul><li><code>isready</code></li><li><code>isready_success</code></li><li><code>showfailed</code></li></ul><p>所以在查看报表数据的时候，这3个指标是<code>天级</code>的。</p><p>除了上面所说的，代码也包含了<code>source_type = 2</code>，即实时的数据。但是目前来说，已经没有<code>source_type=2</code>的数据了，主要是业务导向。</p><p><img src="/images/%E5%85%AC%E5%8F%B8/tk_reassign.png" alt="重分配任务"></p><h3 id="sync-mysql-unit-and-placement"><a href="#sync-mysql-unit-and-placement" class="headerlink" title="sync_mysql_unit_and_placement"></a>sync_mysql_unit_and_placement</h3><blockquote><p>拉取最新的广告位数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">stat_source='placement'</span><br><span class="line"></span><br><span class="line">tmpfilename="tmp/uparpu_mysql_placement.log"</span><br><span class="line"></span><br><span class="line">mkdir -p tmp</span><br><span class="line"></span><br><span class="line">if [ -f "$&#123;tmpfilename&#125;" ]; then</span><br><span class="line"></span><br><span class="line">  rm -f $&#123;tmpfilename&#125;</span><br><span class="line">  echo "delete $&#123;tmpfilename&#125;"</span><br><span class="line"></span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">    select </span><br><span class="line">        id,</span><br><span class="line">        uuid,        </span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,      </span><br><span class="line">        name,        </span><br><span class="line">        format,      </span><br><span class="line">        remark,      </span><br><span class="line">        create_time, </span><br><span class="line">        update_time </span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_NAME&#125;.$&#123;stat_source&#125;</span><br><span class="line">    ;</span><br><span class="line">" --skip-column-names | sed 's/\t/|/g' &gt;$&#123;tmpfilename&#125;</span><br><span class="line"></span><br><span class="line">if [ -f "$&#123;tmpfilename&#125;" ]; then</span><br><span class="line"></span><br><span class="line">  target="$&#123;HIVE_DB_PATH&#125;/$&#123;T_UPARPU_PLACEMENT&#125;/yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;/"</span><br><span class="line"></span><br><span class="line">  hadoop fs -rm -r $&#123;target&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;FILE_COMMAND_CP&#125; <span class="variable">$&#123;tmpfilename&#125;</span> <span class="variable">$&#123;target&#125;</span></span></span><br><span class="line"></span><br><span class="line">  hive -e "</span><br><span class="line">        use $&#123;DB_UPARPU&#125;;</span><br><span class="line">        alter table $&#123;T_UPARPU_PLACEMENT&#125; drop partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;');</span><br><span class="line">        alter table $&#123;T_UPARPU_PLACEMENT&#125; add partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;') location 'yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;';</span><br><span class="line">    "</span><br><span class="line"></span><br><span class="line">  echo "sync $&#123;tmpfilename&#125; to $&#123;target&#125;"</span><br><span class="line"></span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>从mysql把出最新的广告位数据，然后同步到对应的hive表中</li></ol><h3 id="merge-isready"><a href="#merge-isready" class="headerlink" title="merge_isready"></a>merge_isready</h3><blockquote><p>统计isready的数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">清洗isready数据，写入report_tk,dt&amp;dimen=15</span></span><br><span class="line">hourGap=0</span><br><span class="line">date_time_timeStamp=$(date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s)</span><br><span class="line">next_date_time_timeStamp=$(expr $&#123;date_time_timeStamp&#125; + 86400)</span><br><span class="line">next_date_time=$(date -d @$&#123;next_date_time_timeStamp&#125; "+%Y-%m-%d")</span><br><span class="line"></span><br><span class="line">where_dt="dt='$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;'"</span><br><span class="line">if [[ $&#123;run_type&#125; = 'utc0' ]]; then</span><br><span class="line">  hourGap=8</span><br><span class="line">  where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">else</span><br><span class="line">  if [[ $&#123;run_type&#125; = 'utcw8' ]]; then</span><br><span class="line">    hourGap=16</span><br><span class="line">    where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">  else</span><br><span class="line">    hourGap=0</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">转换成utc8时间</span></span><br><span class="line">day_start_timeStamp=$(date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s)</span><br><span class="line">day_end_timeStamp=$(date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 23:00:00" +%s)</span><br><span class="line">while_run_stamp=$&#123;day_start_timeStamp&#125;</span><br><span class="line">where_hour='('</span><br><span class="line"></span><br><span class="line">while [ "$&#123;while_run_stamp&#125;" -le "$&#123;day_end_timeStamp&#125;" ]; do</span><br><span class="line">  tmp_run_stamp=$(expr $&#123;while_run_stamp&#125; + $&#123;hourGap&#125; \* 3600)</span><br><span class="line">  tmp_date_time=$(date -d @$&#123;tmp_run_stamp&#125; "+%Y-%m-%d-%H")</span><br><span class="line">  tmp_yyyy=$(echo $&#123;tmp_date_time&#125; | awk -F- '&#123;print $1&#125;')</span><br><span class="line">  tmp_mm=$(echo $&#123;tmp_date_time&#125; | awk -F- '&#123;print $2&#125;')</span><br><span class="line">  tmp_dd=$(echo $&#123;tmp_date_time&#125; | awk -F- '&#123;print $3&#125;')</span><br><span class="line">  tmp_hh=$(echo $&#123;tmp_date_time&#125; | awk -F- '&#123;print $4&#125;')</span><br><span class="line">  if [ "$&#123;while_run_stamp&#125;" == "$&#123;day_start_timeStamp&#125;" ]; then</span><br><span class="line">    where_hour="$&#123;where_hour&#125;dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">  else</span><br><span class="line">    where_hour="$&#123;where_hour&#125; or dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">  fi</span><br><span class="line">  while_run_stamp=$(expr $&#123;while_run_stamp&#125; + 3600)</span><br><span class="line">done</span><br><span class="line">where_hour="$&#123;where_hour&#125;)"</span><br><span class="line"></span><br><span class="line">hql="</span><br><span class="line">      select</span><br><span class="line">          '$&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;',</span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          1,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          1,</span><br><span class="line">          0,</span><br><span class="line">          '',</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          cast(sum(case  when (a.key_count is null or a.key_count='') then 0 else a.key_count end) as bigint),</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">          0</span><br><span class="line">      from </span><br><span class="line">          (</span><br><span class="line">            select </span><br><span class="line">                  nw_firm_id,</span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id,</span><br><span class="line">                  cast(sum(case  when (key_count is null or key_count='') then 0 else key_count end) as bigint) key_count</span><br><span class="line">            from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_EVENT_ANALYSIS_COUNT&#125;</span><br><span class="line">            where</span><br><span class="line">                 $&#123;where_dt&#125;</span><br><span class="line">                 and key='1004632'</span><br><span class="line">                 and $&#123;where_hour&#125;</span><br><span class="line">                 $&#123;whereInPublisherList&#125;</span><br><span class="line">            group by </span><br><span class="line">                  nw_firm_id,</span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id</span><br><span class="line">          ) as a</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,uuid,app_id,format</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_PLACEMENT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">                group by id,uuid,app_id,format</span><br><span class="line">          ) as b</span><br><span class="line">      on </span><br><span class="line">          a.placement_id=b.uuid and a.app_raw_id=b.app_id</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,network_id,nw_firm_id</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_UNIT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">          ) as c</span><br><span class="line">      on </span><br><span class="line">          a.unit_id=c.id</span><br><span class="line">      where</span><br><span class="line">         cast(a.group_id as bigint)&lt;=2147483647</span><br><span class="line">         and b.uuid is not null</span><br><span class="line">      group by </span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.topon.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">  --name "TopOn_CommonSparkDateTimeJob_report_isready_dt$&#123;yyyy_mm_dd&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory "$&#123;SPARK_EXECUTOR_MEMORY&#125;" \</span><br><span class="line">  --driver-memory "$&#123;SPARK_DRIVER_MEMORY&#125;" \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors "$&#123;SPARK_NUM_EXECUTORS&#125;" \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_UPARPU&#125;</span>.<span class="variable">$&#123;T_RUN_REASSIGN_REPORT_TK&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;ymd&#125;</span>', dimen='15'"</span> <span class="string">"overwrite"</span></span></span><br></pre></td></tr></table></figure><ol><li><code>key=&#39;1004632&#39;</code> 的数据为<code>isready</code>的数据</li><li>由于原始数据已经有统计，所以<code>sum(key_count)</code>的总和就是<code>isready</code>的<code>对应维度</code>的总数</li><li>数据写入到 <code>dimen = &#39;15&#39;</code> 的分区</li></ol><h3 id="merge-isready-success"><a href="#merge-isready-success" class="headerlink" title="merge_isready_success"></a>merge_isready_success</h3><blockquote><p>统计isready_success的数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">清洗isready_success数据，写入report_tk,dt&amp;dimen=16</span></span><br><span class="line">hourGap=0</span><br><span class="line">date_time_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s`</span><br><span class="line">next_date_time_timeStamp=`expr $&#123;date_time_timeStamp&#125; + 86400`</span><br><span class="line">next_date_time=`date -d @$&#123;next_date_time_timeStamp&#125; "+%Y-%m-%d"`</span><br><span class="line"></span><br><span class="line">where_dt="dt='$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;'"</span><br><span class="line">if [[ $&#123;run_type&#125; = 'utc0' ]]</span><br><span class="line">  then</span><br><span class="line">     hourGap=8</span><br><span class="line">     where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">  else</span><br><span class="line">      if [[ $&#123;run_type&#125; = 'utcw8' ]] </span><br><span class="line">      then</span><br><span class="line">          hourGap=16</span><br><span class="line">          where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">      else</span><br><span class="line">          hourGap=0</span><br><span class="line">      fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">转换成utc8时间</span></span><br><span class="line">day_start_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s`</span><br><span class="line">day_end_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 23:00:00" +%s`</span><br><span class="line">while_run_stamp=$&#123;day_start_timeStamp&#125;</span><br><span class="line">where_hour='('</span><br><span class="line"></span><br><span class="line">while [ "$&#123;while_run_stamp&#125;" -le "$&#123;day_end_timeStamp&#125;" ]</span><br><span class="line">do</span><br><span class="line">      tmp_run_stamp=`expr $&#123;while_run_stamp&#125; + $&#123;hourGap&#125; \* 3600`</span><br><span class="line">      tmp_date_time=`date -d @$&#123;tmp_run_stamp&#125; "+%Y-%m-%d-%H"`</span><br><span class="line">      tmp_yyyy=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $1&#125;'`</span><br><span class="line">      tmp_mm=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $2&#125;'`</span><br><span class="line">      tmp_dd=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $3&#125;'`</span><br><span class="line">      tmp_hh=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $4&#125;'`</span><br><span class="line">      if [ "$&#123;while_run_stamp&#125;" == "$&#123;day_start_timeStamp&#125;" ]</span><br><span class="line">        then</span><br><span class="line">           where_hour="$&#123;where_hour&#125;dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">        else</span><br><span class="line">           where_hour="$&#123;where_hour&#125; or dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">        fi</span><br><span class="line">        while_run_stamp=`expr $&#123;while_run_stamp&#125; + 3600`</span><br><span class="line">done</span><br><span class="line">where_hour="$&#123;where_hour&#125;)"</span><br><span class="line"></span><br><span class="line">hql="</span><br><span class="line">      select</span><br><span class="line">          '$&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;',</span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          1,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          1,</span><br><span class="line">          0,</span><br><span class="line">          '',</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          0,</span><br><span class="line">          cast(sum(case  when (a.key_count is null or a.key_count='') then 0 else a.key_count end) as bigint),</span><br><span class="line">          0,</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">          0</span><br><span class="line">      from </span><br><span class="line">          (</span><br><span class="line">            select </span><br><span class="line">                  nw_firm_id,</span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id,</span><br><span class="line">                  cast(sum(case  when (key_count is null or key_count='') then 0 else key_count end) as bigint) key_count</span><br><span class="line">            from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_EVENT_ANALYSIS_COUNT&#125;</span><br><span class="line">            where</span><br><span class="line">                 $&#123;where_dt&#125;</span><br><span class="line">                 and key='1004632'</span><br><span class="line">                 and extra3='1'</span><br><span class="line">                 and $&#123;where_hour&#125;</span><br><span class="line">                 $&#123;whereInPublisherList&#125;</span><br><span class="line">            group by </span><br><span class="line">                  nw_firm_id,</span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id</span><br><span class="line">          ) as a</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,uuid,app_id,format</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_PLACEMENT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">                group by id,uuid,app_id,format</span><br><span class="line">          ) as b</span><br><span class="line">      on </span><br><span class="line">          a.placement_id=b.uuid and a.app_raw_id=b.app_id</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,network_id,nw_firm_id</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_UNIT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">          ) as c</span><br><span class="line">      on </span><br><span class="line">          a.unit_id=c.id</span><br><span class="line">      where</span><br><span class="line">         cast(a.group_id as bigint)&lt;=2147483647</span><br><span class="line">         and b.uuid is not null</span><br><span class="line">      group by </span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.topon.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">  --name "TopOn_CommonSparkDateTimeJob_report_isready_success_dt$&#123;yyyy_mm_dd&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory "$&#123;SPARK_EXECUTOR_MEMORY&#125;" \</span><br><span class="line">  --driver-memory "$&#123;SPARK_DRIVER_MEMORY&#125;" \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors "$&#123;SPARK_NUM_EXECUTORS&#125;" \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_UPARPU&#125;</span>.<span class="variable">$&#123;T_RUN_REASSIGN_REPORT_TK&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;ymd&#125;</span>', dimen='16'"</span> <span class="string">"overwrite"</span></span></span><br></pre></td></tr></table></figure><ol><li><code>key=&#39;1004632&#39; and extra3=&#39;1&#39;</code> 代表 isready 下，并且相应成功的数据</li><li>由于原始数据已经有统计，所以<code>sum(key_count)</code>的总和就是<code>isready_success</code>的<code>对应维度</code>的总数</li><li>写入到 <code>dimen = &#39;16&#39;</code> 的分区</li></ol><h3 id="merge-showfailed"><a href="#merge-showfailed" class="headerlink" title="merge_showfailed"></a>merge_showfailed</h3><blockquote><p>统计广告展示失败</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">清洗isready数据，写入report_tk,dt&amp;dimen=15</span></span><br><span class="line">hourGap=0</span><br><span class="line">date_time_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s`</span><br><span class="line">next_date_time_timeStamp=`expr $&#123;date_time_timeStamp&#125; + 86400`</span><br><span class="line">next_date_time=`date -d @$&#123;next_date_time_timeStamp&#125; "+%Y-%m-%d"`</span><br><span class="line"></span><br><span class="line">where_dt="dt='$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;'"</span><br><span class="line">if [[ $&#123;run_type&#125; = 'utc0' ]]</span><br><span class="line">  then</span><br><span class="line">     hourGap=8</span><br><span class="line">     where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">  else</span><br><span class="line">      if [[ $&#123;run_type&#125; = 'utcw8' ]] </span><br><span class="line">      then</span><br><span class="line">          hourGap=16</span><br><span class="line">          where_dt="dt in ('$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;','$&#123;next_date_time&#125;')"</span><br><span class="line">      else</span><br><span class="line">          hourGap=0</span><br><span class="line">      fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">转换成utc8时间</span></span><br><span class="line">day_start_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 00:00:00" +%s`</span><br><span class="line">day_end_timeStamp=`date -d "$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125; 23:00:00" +%s`</span><br><span class="line">while_run_stamp=$&#123;day_start_timeStamp&#125;</span><br><span class="line">where_hour='('</span><br><span class="line"></span><br><span class="line">while [ "$&#123;while_run_stamp&#125;" -le "$&#123;day_end_timeStamp&#125;" ]</span><br><span class="line">do</span><br><span class="line">      tmp_run_stamp=`expr $&#123;while_run_stamp&#125; + $&#123;hourGap&#125; \* 3600`</span><br><span class="line">      tmp_date_time=`date -d @$&#123;tmp_run_stamp&#125; "+%Y-%m-%d-%H"`</span><br><span class="line">      tmp_yyyy=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $1&#125;'`</span><br><span class="line">      tmp_mm=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $2&#125;'`</span><br><span class="line">      tmp_dd=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $3&#125;'`</span><br><span class="line">      tmp_hh=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $4&#125;'`</span><br><span class="line">      if [ "$&#123;while_run_stamp&#125;" == "$&#123;day_start_timeStamp&#125;" ]</span><br><span class="line">        then</span><br><span class="line">           where_hour="$&#123;where_hour&#125;dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">        else</span><br><span class="line">           where_hour="$&#123;where_hour&#125; or dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hour='$&#123;tmp_hh&#125;'"</span><br><span class="line">        fi</span><br><span class="line">        while_run_stamp=`expr $&#123;while_run_stamp&#125; + 3600`</span><br><span class="line">done</span><br><span class="line">where_hour="$&#123;where_hour&#125;)"</span><br><span class="line"></span><br><span class="line">hql="</span><br><span class="line">      select</span><br><span class="line">          '$&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;',</span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          1,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          1,</span><br><span class="line">          0,</span><br><span class="line">          '',</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          cast(sum(case  when (a.key_count is null or a.key_count='') then 0 else a.key_count end) as bigint),</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          0,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">          0</span><br><span class="line">      from </span><br><span class="line">          (</span><br><span class="line">            select </span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id,</span><br><span class="line">                  cast(sum(case  when (key_count is null or key_count='') then 0 else key_count end) as bigint) key_count</span><br><span class="line">            from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_EVENT_ANALYSIS_COUNT&#125;</span><br><span class="line">            where</span><br><span class="line">                 $&#123;where_dt&#125;</span><br><span class="line">                 and key='1004633'</span><br><span class="line">                 and $&#123;where_hour&#125;</span><br><span class="line">                 $&#123;whereInPublisherList&#125;</span><br><span class="line">            group by </span><br><span class="line">                  group_id,</span><br><span class="line">                  unit_id,</span><br><span class="line">                  placement_id,</span><br><span class="line">                  sdk_version,</span><br><span class="line">                  app_vn,</span><br><span class="line">                  os_platform,</span><br><span class="line">                  geo_short,</span><br><span class="line">                  publisher_id,</span><br><span class="line">                  app_raw_id,</span><br><span class="line">                  channel,</span><br><span class="line">                  sub_channel,</span><br><span class="line">                  traffic_group_id,</span><br><span class="line">                  is_cn_sdk,</span><br><span class="line">                  device_type,</span><br><span class="line">                  abtest_id</span><br><span class="line">          ) as a</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,uuid,app_id,format</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_PLACEMENT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">                group by id,uuid,app_id,format</span><br><span class="line">          ) as b</span><br><span class="line">      on </span><br><span class="line">          a.placement_id=b.uuid and a.app_raw_id=b.app_id</span><br><span class="line">      left outer join</span><br><span class="line">          (</span><br><span class="line">                select id,network_id,nw_firm_id</span><br><span class="line">                from $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_UNIT&#125;</span><br><span class="line">                where yyyy='$&#123;yyyy&#125;' and mm='$&#123;mm&#125;' and dd='$&#123;dd&#125;' $&#123;whereInPublisherList&#125;</span><br><span class="line">          ) as c</span><br><span class="line">      on </span><br><span class="line">          a.unit_id=c.id</span><br><span class="line">      where</span><br><span class="line">         cast(a.group_id as bigint)&lt;=2147483647</span><br><span class="line">         and b.uuid is not null</span><br><span class="line">      group by </span><br><span class="line">          case  when (c.nw_firm_id is null) then '0' else c.nw_firm_id end,</span><br><span class="line">          case  when (a.group_id is null or a.group_id='' or cast(a.group_id as int) is null) then '0' else a.group_id end,</span><br><span class="line">          case c.nw_firm_id when '35' then '1' else case  when (a.unit_id is null or a.unit_id='' or cast(a.unit_id as int) is null) then '0' else a.unit_id end end,</span><br><span class="line">          a.sdk_version,</span><br><span class="line">          a.app_vn,</span><br><span class="line">          a.os_platform,</span><br><span class="line">          a.geo_short,</span><br><span class="line">          a.publisher_id,</span><br><span class="line">          a.app_raw_id,</span><br><span class="line">          b.id,</span><br><span class="line">          b.format,</span><br><span class="line">          case  when (a.channel is null) then '' else a.channel end,</span><br><span class="line">          case  when (a.sub_channel is null) then '' else a.sub_channel end,</span><br><span class="line">          case  when (c.network_id is null) then '0' else c.network_id end,</span><br><span class="line">          case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">          case when (a.is_cn_sdk is null or  cast(a.is_cn_sdk as int) is null) then '0' else a.is_cn_sdk end,</span><br><span class="line">          case when device_type is null then 1 else device_type end,</span><br><span class="line">          case when abtest_id is null then '' else abtest_id end</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.topon.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">  --name "TopOn_CommonSparkDateTimeJob_report_showfailed_dt$&#123;yyyy_mm_dd&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory "$&#123;SPARK_EXECUTOR_MEMORY&#125;" \</span><br><span class="line">  --driver-memory "$&#123;SPARK_DRIVER_MEMORY&#125;" \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors "$&#123;SPARK_NUM_EXECUTORS&#125;" \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_UPARPU&#125;</span>.<span class="variable">$&#123;T_RUN_REASSIGN_REPORT_TK&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;ymd&#125;</span>', dimen='17'"</span> <span class="string">"overwrite"</span></span></span><br></pre></td></tr></table></figure><ol><li><code>key=&#39;1004633&#39;</code> 代表 <code>showfailed</code> 的数据</li><li>由于原始数据已经有统计，所以<code>sum(key_count)</code>的总和就是<code>showfailed</code>的<code>对应维度</code>的总数</li><li>写入到 <code>dimen = &#39;17&#39;</code> 的分区</li></ol><h3 id="merge-revenue"><a href="#merge-revenue" class="headerlink" title="merge_revenue"></a>merge_revenue</h3><blockquote><p>统计收益数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">hql="</span><br><span class="line">        select</span><br><span class="line">            '$&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;',</span><br><span class="line">            case  when (a.nw_firm_id is null or a.nw_firm_id='' or a.nw_firm_id not rlike '^\\\\\\d+$') then '0' else a.nw_firm_id end,</span><br><span class="line">            case  when (a.group_id is null or a.group_id='' or a.group_id not rlike '^\\\\\\d+$') then '0' else a.group_id end,</span><br><span class="line">            case  when (a.unit_id is null or a.unit_id='' or a.unit_id not rlike '^\\\\\\d+$') then '0' else a.unit_id end,</span><br><span class="line">            a.system_type,</span><br><span class="line">            a.sdk_version,</span><br><span class="line">            case a.app_vn when 'null' then '0' else regexp_replace(a.app_vn,'\\\\\\\\0000','') end,</span><br><span class="line">            a.os_platform,</span><br><span class="line">            a.geo_short,</span><br><span class="line">            a.publisher_id,</span><br><span class="line">            a.app_id,</span><br><span class="line">            a.placement_id,</span><br><span class="line">            a.format,</span><br><span class="line">            a.sc_type,</span><br><span class="line">            cast(sum(a.request) as bigint),</span><br><span class="line">            cast(sum(a.filled_request) as bigint),</span><br><span class="line">            cast(sum(a.impression) as bigint),</span><br><span class="line">            cast(sum(a.click) as bigint),</span><br><span class="line">            cast(sum(a.load) as bigint),</span><br><span class="line">            cast(sum(a.filled_load) as bigint),</span><br><span class="line">            cast(sum(a.rv_play_start) as bigint),</span><br><span class="line">            cast(sum(a.rv_play_complete) as bigint),</span><br><span class="line">            a.channel,</span><br><span class="line">            a.sub_channel,</span><br><span class="line">            cast(sum(a.app_request) as bigint),</span><br><span class="line">            cast(sum(a.placement_request) as bigint),</span><br><span class="line">            cast(sum(a.show) as bigint),</span><br><span class="line">            cast(sum(a.impression_optimize) as bigint),</span><br><span class="line">            a.network_id,</span><br><span class="line">            case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">            case  when (a.bidtype is null or a.bidtype='') then '0' else a.bidtype end,</span><br><span class="line">            cast(sum(case  when (a.bid_request is null or a.bid_request='') then '0' else a.bid_request end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.bid_response is null or a.bid_response='') then '0' else a.bid_response end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.estimated_revenue is null or a.estimated_revenue='') then '0' else a.estimated_revenue end) as float),</span><br><span class="line">            case </span><br><span class="line">                when (sum(case when a.fake_impression_optimize is not null then a.fake_impression_optimize else a.impression_optimize end)* sum(b.total_revenue) / sum(b.total_impression)) is null then '0' </span><br><span class="line">                else cast((sum(case when a.fake_impression_optimize is not null then a.fake_impression_optimize else a.impression_optimize end) * sum(b.total_revenue) / sum(b.total_impression)) as float) </span><br><span class="line">            end,</span><br><span class="line">            case </span><br><span class="line">                when (sum(case when a.fake_impression_optimize is not null then a.fake_impression_optimize else a.impression_optimize end)* sum(b.total_currency_revenue) / sum(b.total_impression)) is null then '0' </span><br><span class="line">                else cast((sum(case when a.fake_impression_optimize is not null then a.fake_impression_optimize else a.impression_optimize end) * sum(b.total_currency_revenue) / sum(b.total_impression)) as float) </span><br><span class="line">            end,</span><br><span class="line">            case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">            case when (error_type is null or error_type='') then '0' else error_type end,</span><br><span class="line">            case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">            cast(sum(case  when (a.fake_impression_optimize is null or a.fake_impression_optimize='') then a.impression_optimize else a.fake_impression_optimize end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.fake_filled_load is null or a.fake_filled_load='') then a.filled_load else a.fake_filled_load end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.fake_filled_request is null or a.fake_filled_request='') then a.filled_request else a.fake_filled_request end) as bigint),</span><br><span class="line">            case when (a.is_cn_sdk is null or a.is_cn_sdk not rlike '^\\\\\\d+$') then '0' else a.is_cn_sdk end,</span><br><span class="line">            cast(sum(case  when (a.ready_request is null or a.ready_request='' or a.ready_request='(null)') then 0 else a.ready_request end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.ready_success is null or a.ready_success='' or a.ready_success='(null)') then 0 else a.ready_success end) as bigint),</span><br><span class="line">            cast(sum(case  when (a.show_failed is null or a.show_failed='' or a.show_failed='(null)') then 0 else a.show_failed end) as bigint),</span><br><span class="line">            case when device_type is null then 1 else device_type end,</span><br><span class="line">            cast(sum(case when load_cost_time is null or load_cost_time&lt;0 then 0 else load_cost_time end) as bigint),</span><br><span class="line">            cast(sum(case when request_cost_time is null or request_cost_time&lt;0 then 0 else request_cost_time end) as bigint),</span><br><span class="line">            case when idfa_exist_tag is null then 0 else idfa_exist_tag end,</span><br><span class="line">            case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end,</span><br><span class="line">            cast(coalesce(sum(scenario_entry),0) as bigint),</span><br><span class="line">            cast(coalesce(sum(scenario_entry_ready),0) as bigint),</span><br><span class="line">            case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">            case when ofl is null then 0 else ofl end</span><br><span class="line">        from </span><br><span class="line">            (select *</span><br><span class="line">            from $&#123;DB_UPARPU&#125;.$&#123;T_RUN_REPORT_TK&#125;</span><br><span class="line">            where</span><br><span class="line">                dt = '$&#123;ymd&#125;'</span><br><span class="line">                and dimen in ('0','15','16','17','18')</span><br><span class="line">                and os_platform is not null</span><br><span class="line">                and length(sdk_version) &lt; 15</span><br><span class="line">                and bidtype&lt;=20</span><br><span class="line">                and bidtype&gt;=0</span><br><span class="line">                and format&gt;=0</span><br><span class="line">                $&#123;whereInPublisherList&#125;</span><br><span class="line">            ) as a</span><br><span class="line">        left join</span><br><span class="line">            (</span><br><span class="line">           select </span><br><span class="line">              app_id,</span><br><span class="line">              placement_id,</span><br><span class="line">              geo_short,</span><br><span class="line">              unit_id,</span><br><span class="line">              tk_impression as total_impression,</span><br><span class="line">              revenue as total_revenue,</span><br><span class="line">              currency_revenue as total_currency_revenue,</span><br><span class="line">              dt</span><br><span class="line">            from</span><br><span class="line">              $&#123;DB_UPARPU&#125;.$&#123;T_UPARPU_TK_UNIT_ECPM&#125;</span><br><span class="line">            where</span><br><span class="line">              dt = '$&#123;ymd&#125;'</span><br><span class="line">              $&#123;whereInPublisherList&#125;</span><br><span class="line">            ) as b</span><br><span class="line">        on </span><br><span class="line">            a.app_id = b.app_id and</span><br><span class="line">            a.placement_id=b.placement_id and</span><br><span class="line">            a.geo_short = b.geo_short and</span><br><span class="line">            a.unit_id = b.unit_id</span><br><span class="line">            and a.dt = '$&#123;ymd&#125;'</span><br><span class="line">            and b.dt = '$&#123;ymd&#125;'</span><br><span class="line">            and a.dimen in ('0','15','16','17','18')</span><br><span class="line">        where </span><br><span class="line">            a.dt = '$&#123;ymd&#125;'</span><br><span class="line">            and a.dimen in ('0','15','16','17','18')</span><br><span class="line">        group by </span><br><span class="line">            case  when (a.nw_firm_id is null or a.nw_firm_id='' or a.nw_firm_id not rlike '^\\\\\\d+$') then '0' else a.nw_firm_id end,</span><br><span class="line">            case  when (a.group_id is null or a.group_id='' or a.group_id not rlike '^\\\\\\d+$') then '0' else a.group_id end,</span><br><span class="line">            case  when (a.unit_id is null or a.unit_id='' or a.unit_id not rlike '^\\\\\\d+$') then '0' else a.unit_id end,</span><br><span class="line">            a.system_type,</span><br><span class="line">            a.sdk_version,</span><br><span class="line">            case a.app_vn when 'null' then '0' else regexp_replace(a.app_vn,'\\\\\\\\0000','') end,</span><br><span class="line">            a.os_platform,</span><br><span class="line">            a.geo_short,</span><br><span class="line">            a.publisher_id,</span><br><span class="line">            a.app_id,</span><br><span class="line">            a.placement_id,</span><br><span class="line">            a.format,</span><br><span class="line">            a.sc_type,</span><br><span class="line">            a.channel,</span><br><span class="line">            a.sub_channel,</span><br><span class="line">            a.network_id,</span><br><span class="line">            case  when (a.traffic_group_id is null or a.traffic_group_id='') then '0' else a.traffic_group_id end,</span><br><span class="line">            case  when (a.bidtype is null or a.bidtype='') then '0' else a.bidtype end,</span><br><span class="line">            case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">            case when (error_type is null or error_type='') then '0' else error_type end,</span><br><span class="line">            case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">            case when (a.is_cn_sdk is null or a.is_cn_sdk not rlike '^\\\\\\d+$') then '0' else a.is_cn_sdk end,</span><br><span class="line">            case when device_type is null then 1 else device_type end,</span><br><span class="line">            case when idfa_exist_tag is null then 0 else idfa_exist_tag end,</span><br><span class="line">            case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">            case when ofl is null then 0 else ofl end</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.topon.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">  --name "TopOn_CommonSparkDateTimeJob_ltv_tk_reassign_revenue_dt$&#123;yyyy_mm_dd&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory "$&#123;SPARK_EXECUTOR_MEMORY&#125;" \</span><br><span class="line">  --driver-memory "$&#123;SPARK_DRIVER_MEMORY&#125;" \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors "$&#123;SPARK_NUM_EXECUTORS&#125;" \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;ymd&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_UPARPU&#125;</span>.<span class="variable">$&#123;T_RUN_REASSIGN_REPORT_TK&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;ymd&#125;</span>', dimen='00'"</span> <span class="string">"overwrite"</span></span></span><br></pre></td></tr></table></figure><ol><li><code>dimen in (&#39;0&#39;,&#39;15&#39;,&#39;16&#39;,&#39;17&#39;,&#39;18&#39;)</code>，分别是<code>0=原来的小时任务统计出来的数据，15=isready数据, 16=isready_success数据,17=showfailed数据, 18=source_type=2的实时数据</code>，拿到所有的数据，然后进行重新写入</li><li>重新写入到 <code>dimen = &#39;00&#39;</code> 的分区中</li></ol><h3 id="to-db"><a href="#to-db" class="headerlink" title="to_db"></a>to_db</h3><blockquote><p>数据出仓到gp</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">source ./export_tk_util.sh</span><br><span class="line">export_tk_func "$&#123;DB_UPARPU&#125;.$&#123;T_RUN_REASSIGN_REPORT_TK&#125;" "$&#123;T_RUN_REPORT_TK_SOURCE&#125;" "dt='$&#123;ymd&#125;' AND dimen='00'" " date_time =$&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;  $&#123;whereInPublisherList&#125; "</span><br></pre></td></tr></table></figure><ol><li>把当天的数据delete掉</li><li>把所有数据重新写入到gp</li></ol><p>重分配到任务做的事情处理完毕。注意这里涉及到了<code>收益</code>数据，由于业务导向是聚合平台，所以会收益是从多个平台拉取回来的数据，可能存在拉取收益数据失败的情况，所以需要有重试机制，所以这里的的任务有分为<code>跑前1天</code>，<code>跑前2天</code>，<code>跑前3天</code>的数据，如果超过3天，都拉取失败，那么这部分数据我们需要手动重跑。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;总结一下公司大数据的任务ETL离线工作流 - 重分配任务&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="公司" scheme="http://blog.crazylaw.cn/tags/%E5%85%AC%E5%8F%B8/"/>
    
  </entry>
  
  <entry>
    <title>大数据任务-小时任务</title>
    <link href="http://blog.crazylaw.cn/2022/05/26/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E5%B0%8F%E6%97%B6%E4%BB%BB%E5%8A%A1/"/>
    <id>http://blog.crazylaw.cn/2022/05/26/%E5%85%AC%E5%8F%B8/%E5%A4%A7%E6%95%B0%E6%8D%AE-%E5%B0%8F%E6%97%B6%E4%BB%BB%E5%8A%A1/</id>
    <published>2022-05-26T03:52:40.000Z</published>
    <updated>2022-05-27T10:44:13.097Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>总结一下公司大数据的任务ETL离线工作流 - 小时任务</p><a id="more"></a><p>公司的ETL服务，目前采用的是组件为：</p><ul><li>数仓 (hadoop)</li><li>任务调度器 (azkaban)</li><li>出仓 (gp)</li><li>数仓查询 (hue)(hive)(spark)</li></ul><h2 id="job-hour（小时任务）"><a href="#job-hour（小时任务）" class="headerlink" title="job_hour（小时任务）"></a>job_hour（小时任务）</h2><ul><li>schedule: <code>30 * * * *</code></li></ul><blockquote><p>每小时30分的时候进行启动任务</p></blockquote><p><img src="/images/%E5%85%AC%E5%8F%B8/bigdata-hour.png" alt="小时任务"></p><h3 id="check-tk-batch-log-success"><a href="#check-tk-batch-log-success" class="headerlink" title="check_tk_batch_log_success"></a>check_tk_batch_log_success</h3><blockquote><p>检测tk服务是否把原始日志已经上传到oss服务中</p></blockquote><p>核心流程如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">path=$&#123;LOG_TRACKING_BATCH_PATH&#125;</span><br><span class="line"></span><br><span class="line">path=$&#123;path&#125;/$&#123;yyyy&#125;/$&#123;mm&#125;/$&#123;dd&#125;/$&#123;hh&#125;/_SUCCESS</span><br><span class="line"></span><br><span class="line">hadoop fs -test -e $&#123;path&#125;</span><br></pre></td></tr></table></figure><p>数据是根据每个小时为一个基本单位，通过<code>_SUCCESS</code>文件来标志当前小时的数据是否已经同步到OSS完毕。</p><h3 id="sync-mysql-config"><a href="#sync-mysql-config" class="headerlink" title="sync_mysql_config"></a>sync_mysql_config</h3><blockquote><p>同步mysql的当前配置信息</p></blockquote><h4 id="同步广告位数据"><a href="#同步广告位数据" class="headerlink" title="同步广告位数据"></a>同步广告位数据</h4><p>核心流程如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">stat_source='placement'</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">select id,uuid,format from $&#123;DB_NAME&#125;.$&#123;stat_source&#125;</span><br><span class="line">" &gt; tmp/bigdata_mysql_placement_list.log</span><br><span class="line"></span><br><span class="line">if [ -f "tmp/bigdata_mysql_placement_list.log" ]; then</span><br><span class="line">    # hadoop fs -rm -r $&#123;CLIENT_TMP_LOG_META_PATH&#125;/tmp/placement/</span><br><span class="line">    $&#123;FILE_COMMAND_RM&#125; $&#123;CLIENT_TMP_LOG_META_PATH&#125;/tmp/placement/ --recursive</span><br><span class="line">    $&#123;FILE_COMMAND_CP&#125; tmp/bigdata_mysql_placement_list.log $&#123;CLIENT_TMP_LOG_META_PATH&#125;/tmp/placement/</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>从数据库导出广告信息：<code>id</code>, <code>uuid</code>, <code>format(广告样式)</code> 到<code>广告列表文件</code></li><li>把本地数据更新到oss中</li></ol><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">tmpfilename="tmp/bigdata_mysql_placement.log"</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">    select </span><br><span class="line">        id,</span><br><span class="line">        uuid,        </span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,      </span><br><span class="line">        name,        </span><br><span class="line">        format,      </span><br><span class="line">        remark,      </span><br><span class="line">        create_time, </span><br><span class="line">        update_time </span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_NAME&#125;.$&#123;stat_source&#125; </span><br><span class="line">    ;</span><br><span class="line">" --skip-column-names | sed 's/\t/|/g' &gt; $&#123;tmpfilename&#125;</span><br><span class="line"></span><br><span class="line">if [ -f "$&#123;tmpfilename&#125;" ]; then</span><br><span class="line"></span><br><span class="line">    target="$&#123;HIVE_DB_PATH&#125;/$&#123;T_BIGDATA_PLACEMENT&#125;/yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;/"</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_RM&#125; $&#123;target&#125; --recursive</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_CP&#125; $&#123;tmpfilename&#125; $&#123;target&#125;</span><br><span class="line"></span><br><span class="line">    echo "sync $&#123;tmpfilename&#125; to $&#123;target&#125;"</span><br><span class="line"></span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>导出数据广告位数据，并且以<code>|</code>符号作为分隔符，写入到<code>广告位文件</code></li><li>如果 <code>广告位</code> 文件存在的话，那么就把 <code>广告位文件</code> 从 <code>file-oss</code> 同步到 <code>hive-oss</code></li></ol><h4 id="同步广告聚合收益数据"><a href="#同步广告聚合收益数据" class="headerlink" title="同步广告聚合收益数据"></a>同步广告聚合收益数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">bigdata_unit_source='unit'</span><br><span class="line">bigdata_network_source='network'</span><br><span class="line">tmpAdsourcefilename="tmp/bigdata_mysql_unit.log"</span><br><span class="line">tmpAdsourceFbFilename="tmp/bigdata_mysql_unit_fb.log"</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">    select </span><br><span class="line">        a.id,     </span><br><span class="line">        a.publisher_id,</span><br><span class="line">        a.placement_id,</span><br><span class="line">        a.network_id,  </span><br><span class="line">        a.network_id,</span><br><span class="line">        0,  </span><br><span class="line">        a.name,</span><br><span class="line">        a.remote_unique,</span><br><span class="line">        a.remote_unit,</span><br><span class="line">        a.header_bidding_switch,</span><br><span class="line">        a.ecpm,</span><br><span class="line">        a.ecpm_currency,</span><br><span class="line">        a.cap_hour,</span><br><span class="line">        a.cap_hour_switch,</span><br><span class="line">        a.cap_day,</span><br><span class="line">        a.cap_day_switch,</span><br><span class="line">        a.pacing,</span><br><span class="line">        a.pacing_switch,</span><br><span class="line">        a.create_time,</span><br><span class="line">        a.update_time,</span><br><span class="line">        a.status,</span><br><span class="line">        b.nw_firm_id</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_NAME&#125;.$&#123;bigdata_unit_source&#125; a</span><br><span class="line">    left outer join</span><br><span class="line">         $&#123;DB_NAME&#125;.$&#123;bigdata_network_source&#125; b</span><br><span class="line">    on</span><br><span class="line">        a.network_id=b.id</span><br><span class="line">    where </span><br><span class="line">        b.nw_firm_id!=1</span><br><span class="line">    ;</span><br><span class="line">" --skip-column-names | sed 's/\t/|/g' &gt; $&#123;tmpAdsourcefilename&#125;</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">    select </span><br><span class="line">        a.id,     </span><br><span class="line">        a.publisher_id,</span><br><span class="line">        a.placement_id,</span><br><span class="line">        b.parent_id,  </span><br><span class="line">        a.network_id,</span><br><span class="line">        b.parent_id,  </span><br><span class="line">        a.name,</span><br><span class="line">        a.remote_unique,</span><br><span class="line">        a.remote_unit,</span><br><span class="line">        a.header_bidding_switch,</span><br><span class="line">        a.ecpm,</span><br><span class="line">        a.ecpm_currency,</span><br><span class="line">        a.cap_hour,</span><br><span class="line">        a.cap_hour_switch,</span><br><span class="line">        a.cap_day,</span><br><span class="line">        a.cap_day_switch,</span><br><span class="line">        a.pacing,</span><br><span class="line">        a.pacing_switch,</span><br><span class="line">        a.create_time,</span><br><span class="line">        a.update_time,</span><br><span class="line">        a.status,</span><br><span class="line">        b.nw_firm_id</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_NAME&#125;.$&#123;bigdata_unit_source&#125; a</span><br><span class="line">    left outer join</span><br><span class="line">         $&#123;DB_NAME&#125;.$&#123;bigdata_network_source&#125; b</span><br><span class="line">    on</span><br><span class="line">        a.network_id=b.id</span><br><span class="line">    where </span><br><span class="line">        b.nw_firm_id=1</span><br><span class="line">    ;</span><br><span class="line">" --skip-column-names | sed 's/\t/|/g' &gt; $&#123;tmpAdsourceFbFilename&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if [ -f "$&#123;tmpfilename&#125;" ]; then</span><br><span class="line"></span><br><span class="line">    target="$&#123;HIVE_DB_PATH&#125;/$&#123;T_BIGDATA_UNIT&#125;/yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;/"</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_RM&#125; $&#123;target&#125; --recursive</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_CP&#125; $&#123;tmpAdsourcefilename&#125; $&#123;target&#125;</span><br><span class="line">    $&#123;FILE_COMMAND_CP&#125; $&#123;tmpAdsourceFbFilename&#125; $&#123;target&#125;</span><br><span class="line"></span><br><span class="line">    echo "sync $&#123;tmpfilename&#125; to $&#123;target&#125;"</span><br><span class="line"></span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>把 <code>国内广告</code> 和 <code>国外广告</code> 数据导出分别放在<code>不同的文件</code>中</li><li>然后从 <code>file-oss</code> 同步到 <code>hive-oss</code></li></ol><blockquote><p>备注：这里采用的是判断${tmpfilename}是广告位的文件，暂不确定是不是说明如果广告位文件没数据的话，那么这个逻辑也不做处理了。</p></blockquote><h4 id="广告场景"><a href="#广告场景" class="headerlink" title="广告场景"></a>广告场景</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">bigdata_scenario_source='scenario'</span><br><span class="line">tmpScenariofilename="tmp/bigdata_mysql_scenario.log"</span><br><span class="line"></span><br><span class="line">mysql -u$&#123;DB_USER&#125; -P$&#123;DB_PORT&#125; -p$&#123;DB_PWD&#125; -h$&#123;DB_HOST&#125; -e "</span><br><span class="line">    select </span><br><span class="line">        id,</span><br><span class="line">        uuid,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        name,</span><br><span class="line">        remark,</span><br><span class="line">        create_time,</span><br><span class="line">        update_time,</span><br><span class="line">        status</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_NAME&#125;.$&#123;bigdata_scenario_source&#125;</span><br><span class="line">    ;</span><br><span class="line">" --skip-column-names | sed 's/\t/|/g' &gt; $&#123;tmpScenariofilename&#125;</span><br><span class="line"></span><br><span class="line">if [ -f "$&#123;tmpScenariofilename&#125;" ]; then</span><br><span class="line"></span><br><span class="line">    target="$&#123;HIVE_DB_PATH&#125;/$&#123;T_BIGDATA_SCENARIO&#125;/"</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_RM&#125; $&#123;target&#125; --recursive</span><br><span class="line"></span><br><span class="line">    $&#123;FILE_COMMAND_CP&#125; $&#123;tmpScenariofilename&#125; $&#123;target&#125;</span><br><span class="line"></span><br><span class="line">    echo "sync $&#123;tmpScenariofilename&#125; to $&#123;target&#125;"</span><br><span class="line"></span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>把广告场景数据导入到广告场景文件中</li><li>然后从 <code>file-oss</code> 同步到 <code>hive-oss</code></li></ol><h4 id="等等…"><a href="#等等…" class="headerlink" title="等等…"></a>等等…</h4><h3 id="check-strategy-app-log-success"><a href="#check-strategy-app-log-success" class="headerlink" title="check_strategy_app_log_success"></a>check_strategy_app_log_success</h3><blockquote><p>检测app日志策略是否写入完成</p></blockquote><h3 id="check-strategy-placement-log-success"><a href="#check-strategy-placement-log-success" class="headerlink" title="check_strategy_placement_log_success"></a>check_strategy_placement_log_success</h3><blockquote><p>检测广告策略日志写入是否写入完成</p></blockquote><h3 id="parse-tk-batch"><a href="#parse-tk-batch" class="headerlink" title="parse_tk_batch"></a>parse_tk_batch</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dependencies=check_tk_batch_log_success,sync_mysql_config</span><br><span class="line">command=sh -x parse_tk_batch.sh</span><br></pre></td></tr></table></figure><blockquote><p>开始解析tk数据</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">log_type=18</span><br><span class="line">hadoop fs -rm -r $&#123;CLIENT_TMP_LOG_META_PATH&#125;/$&#123;T_BIGDATA_TK_BATCH&#125;/</span><br><span class="line">hadoop jar $&#123;parse_jar&#125; $&#123;LOG_TRACKING_BATCH_PATH&#125;/$&#123;yyyy&#125;/$&#123;mm&#125;/$&#123;dd&#125;/$&#123;hh&#125;/* $&#123;CLIENT_TMP_LOG_META_PATH&#125; $&#123;yyyy_mm_dd_hh&#125; $&#123;log_type&#125; $&#123;T_BIGDATA_TK_BATCH&#125; $&#123;T_BIGDATA_DEVICE_ACTIVE_HOUR&#125; $&#123;CLIENT_TMP_LOG_META_PATH&#125;/tmp/placement/bigdata_mysql_placement_list.log</span><br></pre></td></tr></table></figure><p>通过hadoop的<code>map-reduce</code>进行处理分布式处理数据</p><p>其实目前脚本来说，这里只有前5个参数有用</p><ol><li>第一个参数是原始日志的目录（有用）</li><li>第二个参数是输出日志的目录（没用）</li><li>第三个参数是日期时间</li><li>第四个参数是日志类型（这里=18）</li><li>第五个参数是表名（也是完整hive路径的一级目录）</li><li>第六个参数是输出结果表名（这里没用）</li><li>第七个参数是这里是广告日志文件路径</li></ol><p>TK原始日志的存储目录下，tk原始日志文件中里面有不同类型的数据，其中有一个<code>type</code>类型，可以叫做<code>tk_type</code>, 代表不同类型的数据(<code>TYPE_TRACKING_XXX</code>)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TrackingLogConst</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_REQUEST = <span class="number">1</span>; <span class="comment">// 请求</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_FILLED_REQUEST = <span class="number">2</span>; <span class="comment">// 有填充的请求</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_NO_FILLED_REQUEST = <span class="number">3</span>; <span class="comment">// 没填充的请求</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_IMPRESSION = <span class="number">4</span>; <span class="comment">// 展示</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_REFERSH_IMPRESSION = <span class="number">5</span>; <span class="comment">//刷新展示</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_CLICK = <span class="number">6</span>; <span class="comment">// 点击</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_VIDEO_PLAY = <span class="number">7</span>; <span class="comment">// 视频播放</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_RV_PLAY_START = <span class="number">8</span>;<span class="comment">// 激励视频播放开始</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_RV_PLAY_COMPLETE = <span class="number">9</span>;<span class="comment">// 激励视频播放完成</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_LOAD = <span class="number">10</span>;<span class="comment">// load调用数据</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_HEADER_BIDDING = <span class="number">11</span>;<span class="comment">// header bidding</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_LOADFILLED = <span class="number">12</span>;<span class="comment">// loadfilled数据</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_SHOW = <span class="number">13</span>;<span class="comment">// show调用</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_RAND_WATERFALL = <span class="number">15</span>;<span class="comment">// show调用</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TYPE_TRACKING_AD_SCENARIO = <span class="number">16</span>;<span class="comment">// 到达广告场景</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// myoffer的tracking对应类型</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_0 = <span class="string">"1"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_25 = <span class="string">"2"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_50 = <span class="string">"3"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_75 = <span class="string">"4"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_100 = <span class="string">"5"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_END_SHOW = <span class="string">"6"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_RV_END_CLOSE = <span class="string">"7"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_IMPRESSION = <span class="string">"8"</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String TYPE_MYOFFER_TRACKING_CLICK = <span class="string">"9"</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> org.apache.hadoop.mapreduce.lib.output.MultipleOutputs&lt;Text, Text&gt; mos;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">setup</span><span class="params">(Mapper.Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    mos = <span class="keyword">new</span> MultipleOutputs&lt;Text, Text&gt;(context);</span><br><span class="line">    Configuration conf = context.getConfiguration();</span><br><span class="line">    tableName = conf.get(<span class="string">"table_name"</span>);</span><br><span class="line">    deviceTable = conf.get(<span class="string">"result_table"</span>);</span><br><span class="line">    inputTime = conf.get(<span class="string">"date"</span>);</span><br><span class="line">    inputTimeSplit = inputTime.split(<span class="string">"-"</span>);</span><br><span class="line">    logType = Integer.parseInt(conf.get(<span class="string">"log_type"</span>));</span><br><span class="line"></span><br><span class="line">    Path[] uriList = context.getLocalCacheFiles();</span><br><span class="line"></span><br><span class="line">    placementMap = PlacementData.getPlacementListFromUri(uriList);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">super</span>.setup(context);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">writeMosString</span><span class="params">(StringBuilder stringBuilder, <span class="keyword">int</span> trackingType)</span> </span>&#123;</span><br><span class="line">    String resultString = stringBuilder.toString();</span><br><span class="line">    <span class="keyword">if</span> (LogFactory.isDebug) &#123;</span><br><span class="line">        System.out.println(<span class="string">"result:"</span> + resultString + <span class="string">" tableName:"</span> + tableName + <span class="string">"/yyyy="</span> + inputTimeSplit[<span class="number">0</span>] + <span class="string">"/mm="</span> + inputTimeSplit[<span class="number">1</span>] + <span class="string">"/dd="</span> + inputTimeSplit[<span class="number">2</span>] + <span class="string">"/hh="</span> + inputTimeSplit[<span class="number">3</span>] + <span class="string">"/"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 写结果表</span></span><br><span class="line">    <span class="keyword">if</span> (resultString != <span class="keyword">null</span> &amp;&amp; resultString != <span class="string">""</span> &amp;&amp; !LogFactory.isDebug) &#123;</span><br><span class="line">        <span class="comment">// 写结果后，会使用logtype_作为前缀</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            mos.write(<span class="keyword">new</span> Text(resultString), <span class="keyword">new</span> Text(), tableName + <span class="string">"/"</span> + trackingType + <span class="string">"/raw/"</span> + logType + <span class="string">"_"</span> + trackingType + <span class="string">"_"</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">    String outputPathTmp = outputPath + <span class="string">"/"</span> + tableName + logType + <span class="string">"/"</span>;</span><br><span class="line">    FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">        fs = FileSystem.get(<span class="keyword">new</span> URI(inputPath), conf);</span><br><span class="line">        Path outPath = <span class="keyword">new</span> Path(outputPathTmp);</span><br><span class="line">        <span class="keyword">if</span> (fs.exists(outPath)) &#123;</span><br><span class="line">            fs.delete(outPath, <span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (URISyntaxException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>父级路径位：<code>outputPathTmp</code>: <code>/{table}{logType}/</code></p><p>看到数据被解析之后，会被写入到如下子级路径：</p><p><code>{tableName} + &quot;/&quot; + {trackingType} + &quot;/raw/&quot; + {logType} + &quot;_&quot; + {trackingType} + &quot;_&quot;</code></p><p>在当前的解析任务中，以 <code>TYPE_TRACKING_IMPRESSION=4</code> 为例子，具体的例子如下：</p><p><code>{T_BIGDATA_TK_BATCH}/4/raw/18_4_xxx</code></p><p>具体用法需要串联下一个节点来看。</p><h3 id="copy-xxx-copy-impression为例"><a href="#copy-xxx-copy-impression为例" class="headerlink" title="copy_xxx(copy_impression为例)"></a>copy_xxx(copy_impression为例)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash">&#123;FILE_COMMAND_RM&#125; <span class="variable">$&#123;HIVE_DB_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_IMPRESSION&#125;</span>/yyyy=<span class="variable">$&#123;yyyy&#125;</span>/mm=<span class="variable">$&#123;mm&#125;</span>/dd=<span class="variable">$&#123;dd&#125;</span>/hh=<span class="variable">$&#123;hh&#125;</span> --recursive</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;FILE_COMMAND_RM&#125; <span class="variable">$&#123;HIVE_DB_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_IMPRESSION_V2&#125;</span>/yyyy=<span class="variable">$&#123;yyyy&#125;</span>/mm=<span class="variable">$&#123;mm&#125;</span>/dd=<span class="variable">$&#123;dd&#125;</span>/hh=<span class="variable">$&#123;hh&#125;</span> --recursive</span></span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;FILE_COMMAND_SYNC&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_META_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_TK_BATCH&#125;</span>18/<span class="variable">$&#123;T_BIGDATA_TK_BATCH&#125;</span>/4/raw/ <span class="variable">$&#123;HIVE_DB_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_IMPRESSION&#125;</span>/yyyy=<span class="variable">$&#123;yyyy&#125;</span>/mm=<span class="variable">$&#123;mm&#125;</span>/dd=<span class="variable">$&#123;dd&#125;</span>/hh=<span class="variable">$&#123;hh&#125;</span>/</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;FILE_COMMAND_SYNC&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_META_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_TK_BATCH&#125;</span>18/<span class="variable">$&#123;T_BIGDATA_TK_BATCH&#125;</span>/5/raw/ <span class="variable">$&#123;HIVE_DB_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_IMPRESSION&#125;</span>/yyyy=<span class="variable">$&#123;yyyy&#125;</span>/mm=<span class="variable">$&#123;mm&#125;</span>/dd=<span class="variable">$&#123;dd&#125;</span>/hh=<span class="variable">$&#123;hh&#125;</span>/</span></span><br><span class="line"></span><br><span class="line">hive -e "</span><br><span class="line">        use $&#123;DB_BIGDATA&#125;;</span><br><span class="line">        alter table $&#123;T_BIGDATA_IMPRESSION&#125; drop IF EXISTS  partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;',hh='$&#123;hh&#125;');</span><br><span class="line">        alter table $&#123;T_BIGDATA_IMPRESSION&#125; add partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;',hh='$&#123;hh&#125;') location 'yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;/hh=$&#123;hh&#125;';</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">hql=" select</span><br><span class="line">        cast(c_date as int) as c_date,</span><br><span class="line">        c_time,</span><br><span class="line">        cast(created as bigint) as created,</span><br><span class="line">        ip,</span><br><span class="line">        remote_ip,</span><br><span class="line">        server_id,</span><br><span class="line">        country_code,</span><br><span class="line">        cast((case when os_platform is null or os_platform='' then 1 else os_platform end) as int) as os_platform,</span><br><span class="line">        imei,</span><br><span class="line">        mac,</span><br><span class="line">        android_id,</span><br><span class="line">        gaid,</span><br><span class="line">        idfa,</span><br><span class="line">        os_vn,</span><br><span class="line">        os_vc,</span><br><span class="line">        model,</span><br><span class="line">        brand,</span><br><span class="line">        screen_size,</span><br><span class="line">        cast((case when orientation is null or orientation='' then 1 else orientation end) as int) as orientation,</span><br><span class="line">        network_type,</span><br><span class="line">        mcc,</span><br><span class="line">        mnc,</span><br><span class="line">        language,</span><br><span class="line">        time_zone,</span><br><span class="line">        user_agent,</span><br><span class="line">        gpv,</span><br><span class="line">        app_vn,</span><br><span class="line">        app_vc,</span><br><span class="line">        app_package,</span><br><span class="line">        sdk_version,</span><br><span class="line">        cast((case when publisher_id is null or publisher_id='' then 0 else publisher_id end) as int) as publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        cast((case when app_raw_id is null or app_raw_id='' then 0 else app_raw_id end) as int) as app_raw_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        cast((case when placement_raw_id is null or placement_raw_id='' then 0 else placement_raw_id end) as int) as placement_raw_id,</span><br><span class="line">        request_id,</span><br><span class="line">        psid,</span><br><span class="line">        sessionid,</span><br><span class="line">        cast((case when sdk_time is null or sdk_time='' then 0 else sdk_time end) as bigint) as sdk_time,</span><br><span class="line">        ug_id,</span><br><span class="line">        nw_version,</span><br><span class="line">        cast((case when nw_firm_id is null or nw_firm_id='' then 0 else nw_firm_id end) as int) as nw_firm_id,</span><br><span class="line">        cast((case when sc_type is null or sc_type='' then 0 else sc_type end) as int) as sc_type,</span><br><span class="line">        cast((case when group_id is null or group_id='' then 0 else group_id end) as int) as group_id,</span><br><span class="line">        cast((case when format is null or format='' then 0 else format end) as int) as format,</span><br><span class="line">        extra,</span><br><span class="line">        cast((case when is_refresh is null or is_refresh='' then 0 else is_refresh end) as int) as is_refresh,</span><br><span class="line">        cast((case when unit_id is null or unit_id='' then 0 else unit_id end) as int) as unit_id,</span><br><span class="line">        cast((case when system_type is null or system_type='' then 0 else system_type end) as int) as system_type,</span><br><span class="line">        cast((case when load_type is null or load_type='' then 0 else load_type end) as int) as load_type,</span><br><span class="line">        case when asid is null then '' else asid end as asid,</span><br><span class="line">        case when channel is null then '' else channel end as channel,</span><br><span class="line">        case when upid is null then '' else upid end as upid,</span><br><span class="line">        cast((case when auto_refresh is null or auto_refresh='' then 0 else auto_refresh end) as int) as auto_refresh,</span><br><span class="line">        cast((case when aprn_auto_req is null or aprn_auto_req='' then 0 else aprn_auto_req end) as int) as aprn_auto_req,</span><br><span class="line">        cast((case when bidtype is null or bidtype='' then 0 else bidtype end) as int) as bidtype,</span><br><span class="line">        cast((case when bidprice is null or bidprice='' then 0 else bidprice end) as float) as bidprice,</span><br><span class="line">        case when offer_pkg is null then '' else offer_pkg end as offer_pkg,</span><br><span class="line">        case when sub_channel is null then '' else sub_channel end as sub_channel,</span><br><span class="line">        case when idfv is null then '' else idfv end as idfv,</span><br><span class="line">        cast((case when traffic_group_id is null or traffic_group_id='' then 0 else traffic_group_id end) as int) as traffic_group_id,</span><br><span class="line">        cast((case when myoffer_show_type is null or myoffer_show_type='' then 0 else myoffer_show_type end) as int) as myoffer_show_type,</span><br><span class="line">        cast((case when ofl is null or ofl='' then 0 else ofl end) as int) as ofl,</span><br><span class="line">        cast((case when gdpr_cs is null or gdpr_cs='' then 0 else gdpr_cs end) as int) as gdpr_cs,</span><br><span class="line">        case when scenario is null then '1' else scenario end as scenario,</span><br><span class="line">        cast((case when deduction_res is null or deduction_res='' then 0 else deduction_res end) as int) as deduction_res,</span><br><span class="line">        cast((case when deduction_num is null or deduction_num='' then 1 else deduction_num end) as int) as deduction_num,</span><br><span class="line">        case when oaid is null then '' else oaid end as oaid,</span><br><span class="line">        cast((case when is_cn_sdk is null or is_cn_sdk='' then 0 else is_cn_sdk end) as int) as is_cn_sdk,</span><br><span class="line">        cast((case when adtype_day_show_times is null or adtype_day_show_times='' then 0 else adtype_day_show_times end) as int) as adtype_day_show_times,</span><br><span class="line">        cast((case when adtype_hour_show_times is null or adtype_hour_show_times='' then 0 else adtype_hour_show_times end) as int) as adtype_hour_show_times,</span><br><span class="line">        cast((case when placement_day_show_times is null or placement_day_show_times='' then 0 else placement_day_show_times end) as int) as placement_day_show_times,</span><br><span class="line">        cast((case when placement_hour_show_times is null or placement_hour_show_times='' then 0 else placement_hour_show_times end) as int) as placement_hour_show_times,</span><br><span class="line">        case when install_source is null then '' else install_source end as install_source,</span><br><span class="line">        protocol,</span><br><span class="line">        origin_num,</span><br><span class="line">        protocol_type,</span><br><span class="line">        abtest_id,</span><br><span class="line">        first_init_time,</span><br><span class="line">        days_from_first_init,</span><br><span class="line">        app_custom,</span><br><span class="line">        user_id,</span><br><span class="line">        age,</span><br><span class="line">        gender,</span><br><span class="line">        cl_imp,</span><br><span class="line">        ex_ad</span><br><span class="line">        from </span><br><span class="line">            $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_IMPRESSION&#125;</span><br><span class="line">        where </span><br><span class="line">            yyyy='$&#123;yyyy&#125;'</span><br><span class="line">            and mm='$&#123;mm&#125;'</span><br><span class="line">            and dd='$&#123;dd&#125;'</span><br><span class="line">            and hh='$&#123;hh&#125;' "</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.jobs.common.CommonSparkSaveORCJob \</span><br><span class="line">--name "BigData_CommonSparkDateTimeJob_copy_impression_dt$&#123;yyyy_mm_dd_hh&#125;" \</span><br><span class="line">--master yarn  \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--executor-memory 2g \</span><br><span class="line">--driver-memory 2g \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--num-executors 8 \</span><br><span class="line">--conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">--conf spark.dynamicAllocation.minExecutors=8 \</span><br><span class="line">--conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">--conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">--files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_HIVE_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;HIVE_DB_PATH&#125;</span>/<span class="variable">$&#123;T_BIGDATA_IMPRESSION_V2&#125;</span>/yyyy=<span class="variable">$&#123;yyyy&#125;</span>/mm=<span class="variable">$&#123;mm&#125;</span>/dd=<span class="variable">$&#123;dd&#125;</span>/hh=<span class="variable">$&#123;hh&#125;</span>/"</span>\</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"> hive -e "</span><br><span class="line">    use $&#123;DB_BIGDATA&#125;;</span><br><span class="line">    alter table $&#123;T_BIGDATA_IMPRESSION_V2&#125; drop IF EXISTS  partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;',hh='$&#123;hh&#125;');</span><br><span class="line">    alter table $&#123;T_BIGDATA_IMPRESSION_V2&#125; add partition (yyyy='$&#123;yyyy&#125;',mm='$&#123;mm&#125;',dd='$&#123;dd&#125;',hh='$&#123;hh&#125;') location 'yyyy=$&#123;yyyy&#125;/mm=$&#123;mm&#125;/dd=$&#123;dd&#125;/hh=$&#123;hh&#125;';</span><br><span class="line"> "</span><br></pre></td></tr></table></figure><p>这里接着上一个节点的分析，这里的<code>${CLIENT_TMP_LOG_META_PATH}/${T_BIGDATA_TK_BATCH}18/${T_BIGDATA_TK_BATCH}/4/raw/</code> 就是经过hadoop解析后输出文件的目录</p><ol><li>如果有历史的数据，则删除历史的数据，然后重新导入数据到表中</li><li>接着再把数据copy到 <code>impression</code> 对应的目录分区中</li><li>重建（修复）分区，把数据加载到hive中的<code>impression</code></li><li>通过sql把数据进行 <code>第一次</code> 清洗，经过这一级的清洗，通过spark把数据转成 <code>ORC</code> 格式进行存储到 <code>impression_v2</code> 表</li><li>重建（修复）分区，把数据加载到hive中<code>impression_v2</code></li></ol><h3 id="merge-xxx-merge-tk-impression为例"><a href="#merge-xxx-merge-tk-impression为例" class="headerlink" title="merge_xxx(merge_tk_impression为例)"></a>merge_xxx(merge_tk_impression为例)</h3><blockquote><p>清洗tk的impression数据到tk小时的orc表（此orc非物理上的orc表）</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line">hql="select</span><br><span class="line">        $&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;,</span><br><span class="line">        $&#123;hh&#125;,</span><br><span class="line">        a.nw_firm_id,</span><br><span class="line">        a.group_id,</span><br><span class="line">        a.unit_id,</span><br><span class="line">        a.system_type,</span><br><span class="line">        a.sdk_version,</span><br><span class="line">        a.app_vn,</span><br><span class="line">        a.os_platform,</span><br><span class="line">        a.country_code,</span><br><span class="line">        a.publisher_id,</span><br><span class="line">        a.app_raw_id,</span><br><span class="line">        a.placement_raw_id,</span><br><span class="line">        a.format,</span><br><span class="line">        a.sc_type,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        cast(count(a.request_id) as bigint),</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        a.channel,</span><br><span class="line">        a.sub_channel,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        $&#123;timeStamp&#125;,</span><br><span class="line">        0,</span><br><span class="line">        cast(b.network_id as int),</span><br><span class="line">        a.traffic_group_id,</span><br><span class="line">        a.bidtype,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        cast((sum(a.bidprice)/1000) as float),</span><br><span class="line">        case when (a.scenario is null or a.scenario='' or c.uuid is null or c.status&lt;&gt;3) then '1' else a.scenario end,</span><br><span class="line">        case when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.uuid is null) then 1 when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.status&lt;&gt;3) then 2 else 0 end,</span><br><span class="line">        case when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.uuid is null or a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.status&lt;&gt;3) then a.scenario else '' end,</span><br><span class="line">        cast(sum(case when a.deduction_num is null or a.deduction_num = '' then '1' else a.deduction_num end) as bigint),                </span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        case  when (a.is_cn_sdk is null or a.is_cn_sdk='null') then 0 else a.is_cn_sdk end,</span><br><span class="line">        case when os_platform=2 and length(model)&gt;=4 and upper(substr(model,1,4))='IPAD' then 2 else 1 end,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        case when (os_platform = '2' and ((length(idfa) &gt; 0 and idfa &lt;&gt; '00000000-0000-0000-0000-000000000000') or (idfa = '' and gdpr_cs = '1'))) then 1 else 0 end as idfa_exist_tag,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        a.abtest_id</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_IMPRESSION_V2&#125; as a</span><br><span class="line">    left outer join</span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_UNIT&#125; as b</span><br><span class="line">    on</span><br><span class="line">        a.yyyy='$&#123;yyyy&#125;'</span><br><span class="line">        and a.mm='$&#123;mm&#125;'</span><br><span class="line">        and a.dd='$&#123;dd&#125;'</span><br><span class="line">        and a.hh='$&#123;hh&#125;'</span><br><span class="line">        and b.yyyy='$&#123;yyyy&#125;'</span><br><span class="line">        and b.mm='$&#123;mm&#125;'</span><br><span class="line">        and b.dd='$&#123;dd&#125;'</span><br><span class="line">        and a.unit_id=b.id</span><br><span class="line">    left outer join</span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_SCENARIO&#125; as c</span><br><span class="line">    on</span><br><span class="line">        a.yyyy='$&#123;yyyy&#125;'</span><br><span class="line">        and a.mm='$&#123;mm&#125;'</span><br><span class="line">        and a.dd='$&#123;dd&#125;'</span><br><span class="line">        and a.hh='$&#123;hh&#125;'</span><br><span class="line">        and a.placement_raw_id=c.placement_id</span><br><span class="line">        and a.scenario=c.uuid</span><br><span class="line">    where </span><br><span class="line">        a.yyyy='$&#123;yyyy&#125;'</span><br><span class="line">        and a.mm='$&#123;mm&#125;'</span><br><span class="line">        and a.dd='$&#123;dd&#125;'</span><br><span class="line">        and a.hh='$&#123;hh&#125;'</span><br><span class="line">        and a.is_refresh=0</span><br><span class="line">        and a.unit_id&gt;0</span><br><span class="line">        and a.publisher_id is not null</span><br><span class="line">        and a.bidprice &lt;&gt; 'Infinity'</span><br><span class="line">        and a.bidprice &gt;= 0</span><br><span class="line">        and a.bidprice &lt;= 100000</span><br><span class="line">    group by </span><br><span class="line">        a.nw_firm_id, </span><br><span class="line">        a.group_id, </span><br><span class="line">        a.unit_id, </span><br><span class="line">        a.system_type, </span><br><span class="line">        a.sdk_version, </span><br><span class="line">        a.app_vn, </span><br><span class="line">        a.os_platform, </span><br><span class="line">        a.country_code, </span><br><span class="line">        a.publisher_id, </span><br><span class="line">        a.app_raw_id, </span><br><span class="line">        a.placement_raw_id, </span><br><span class="line">        a.format, </span><br><span class="line">        a.sc_type,</span><br><span class="line">        a.channel,</span><br><span class="line">        a.sub_channel,</span><br><span class="line">        b.network_id,</span><br><span class="line">        a.traffic_group_id,</span><br><span class="line">        a.bidtype,</span><br><span class="line">        case when (a.scenario is null or a.scenario='' or c.uuid is null or c.status&lt;&gt;3) then '1' else a.scenario end,</span><br><span class="line">        case when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.uuid is null) then 1 when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.status&lt;&gt;3) then 2 else 0 end,</span><br><span class="line">        case when (a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.uuid is null or a.scenario is not null and a.scenario&lt;&gt;'' and a.scenario&lt;&gt;'1' and c.status&lt;&gt;3) then a.scenario else '' end,</span><br><span class="line">        case  when (a.is_cn_sdk is null or a.is_cn_sdk='null') then 0 else a.is_cn_sdk end,</span><br><span class="line">        case when os_platform=2 and length(model)&gt;=4 and upper(substr(model,1,4))='IPAD' then 2 else 1 end,</span><br><span class="line">        case when (os_platform = '2' and ((length(idfa) &gt; 0 and idfa &lt;&gt; '00000000-0000-0000-0000-000000000000') or (idfa = '' and gdpr_cs = '1'))) then 1 else 0 end,</span><br><span class="line">        a.abtest_id</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">--name "BigData_CommonSparkDateTimeJob_merge_impression_dt$&#123;yyyy_mm_dd_hh&#125;" \</span><br><span class="line">--master yarn  \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--executor-memory 2g \</span><br><span class="line">--driver-memory 2g \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--num-executors 8 \</span><br><span class="line">--conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">--conf spark.dynamicAllocation.minExecutors=8 \</span><br><span class="line">--conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">--conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">--files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_HIVE_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd_hh&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_BIGDATA&#125;</span>.<span class="variable">$&#123;T_BIGDATA_REPORT_TK_HOUR_ORC&#125;</span>"</span>  <span class="string">"dt='<span class="variable">$&#123;yyyy&#125;</span>-<span class="variable">$&#123;mm&#125;</span>-<span class="variable">$&#123;dd&#125;</span>', hh='<span class="variable">$&#123;hh&#125;</span>', dimen='3'"</span> <span class="string">"overwrite"</span>\</span></span><br></pre></td></tr></table></figure><ol><li>这里是操作的主表为<code>v2</code>表，join的表一般只能是<code>v1</code>表，因为文本的解析是一起执行的，但是<code>各个任务的v2表</code>什么时候更新完毕暂时是不确定的。</li><li>这里看到分区信息中有一个 <code>dimen = &#39;3&#39;</code>，是和接下来的 <code>${T_BIGDATA_REPORT_TK_HOUR_ORC}</code> 有关系。这是一个tk数据的汇总表，几乎所有维度的数据最后都会汇集在这里，加上我们有不同的任务的数据都写入到这个表，所以我们加一个dimen的分区，便于区分不同的<code>数据的来源</code>。</li></ol><h3 id="merge-tracking-hour"><a href="#merge-tracking-hour" class="headerlink" title="merge_tracking_hour"></a>merge_tracking_hour</h3><blockquote><p>清洗orc的表数据到非orc的表，数据基本可以认为是一份基本可以出仓的数据了</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line">hql="select</span><br><span class="line">        $&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125;,</span><br><span class="line">        $&#123;hh&#125;,</span><br><span class="line">        case nw_firm_id when '' then 0 else nw_firm_id end,</span><br><span class="line">        case group_id when '' then 0 else group_id end,</span><br><span class="line">        case nw_firm_id when '35' then 1 else unit_id end,</span><br><span class="line">        case system_type when '' then 0 else system_type end,</span><br><span class="line">        case sdk_version when 'null' then '0' else sdk_version end,</span><br><span class="line">        case when app_vn = 'null' then '0' when length(app_vn) &gt;= 50 then '0' else regexp_replace(app_vn,'\\\\\\\\0000','') end as app_vn,</span><br><span class="line">        case os_platform when '' then 0 else os_platform end,</span><br><span class="line">        case geo_short when 'null' then '00' else geo_short end,</span><br><span class="line">        case publisher_id when '' then 0 else publisher_id end,</span><br><span class="line">        case app_id when '' then 0 else app_id end,</span><br><span class="line">        case placement_id when '' then 0 when 'null' then 0 else placement_id end,</span><br><span class="line">        case format when '' then 0 else format end,</span><br><span class="line">        case sc_type when '' then 0 else sc_type end,</span><br><span class="line">        cast(sum(request) as bigint),</span><br><span class="line">        cast(sum(filled_request) as bigint),</span><br><span class="line">        cast(sum(impression) as bigint),</span><br><span class="line">        cast(sum(click) as bigint),</span><br><span class="line">        cast(sum(load) as bigint),</span><br><span class="line">        cast(sum(filled_load) as bigint),</span><br><span class="line">        cast(sum(rv_play_start) as bigint),</span><br><span class="line">        cast(sum(rv_play_complete) as bigint),</span><br><span class="line">        case channel when '' then '' else channel end,</span><br><span class="line">        case sub_channel when '' then '' else sub_channel end,</span><br><span class="line">        cast(sum(app_request) as bigint),</span><br><span class="line">        cast(sum(placement_request) as bigint),</span><br><span class="line">        cast(sum(show) as bigint),</span><br><span class="line">        $&#123;timeStamp&#125;,</span><br><span class="line">        cast(sum(impression_optimize) as bigint),</span><br><span class="line">        case network_id when '' then 0 else network_id end,</span><br><span class="line">        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,</span><br><span class="line">        case  when (bidtype is null or bidtype='') then 0 else bidtype end,</span><br><span class="line">        cast(sum(bid_request) as bigint),</span><br><span class="line">        cast(sum(bid_response) as bigint),</span><br><span class="line">        cast(sum(case when dimen='12' then estimated_revenue else 0 end) as float),</span><br><span class="line">        case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">        case when (error_type is null or error_type='') then 0 else error_type end,</span><br><span class="line">        case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">        cast(sum(case when (fake_impression_optimize&gt;0 and dimen='12') then fake_impression_optimize else 0 end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_load is null) then 0 else fake_filled_load end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_request is null) then 0 else fake_filled_request end) as bigint),</span><br><span class="line">        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,</span><br><span class="line">        case when device_type is null then 1 else device_type end,</span><br><span class="line">        cast(sum(load_cost_time) as bigint),</span><br><span class="line">        cast(sum(request_cost_time) as bigint),</span><br><span class="line">        idfa_exist_tag,</span><br><span class="line">        case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end,</span><br><span class="line">        cast(sum(case when (scenario_entry is null or scenario_entry='') then 0 else scenario_entry end) as bigint),</span><br><span class="line">        cast(sum(case when (scenario_entry_ready is null or scenario_entry_ready='') then 0 else scenario_entry_ready end) as bigint),</span><br><span class="line">        abtest_id</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_REPORT_TK_HOUR_ORC&#125;</span><br><span class="line">    where </span><br><span class="line">        dt='$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;'</span><br><span class="line">        and hh='$&#123;hh&#125;'</span><br><span class="line">        and dimen in ('1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16')</span><br><span class="line">        and unit_id is not null</span><br><span class="line">        and publisher_id is not null</span><br><span class="line">        and app_id is not null</span><br><span class="line">        and placement_id is not null</span><br><span class="line">        and format is not null</span><br><span class="line">        and sc_type is not null</span><br><span class="line">        and system_type is not null </span><br><span class="line">        and os_platform is not null </span><br><span class="line">        and sdk_version is not null </span><br><span class="line">        and app_vn is not null </span><br><span class="line">        and channel is not null </span><br><span class="line">        and sub_channel is not null </span><br><span class="line">        and group_id is not null</span><br><span class="line">        and nw_firm_id is not null</span><br><span class="line">        and network_id is not null</span><br><span class="line">        and group_id&gt;=0</span><br><span class="line">        and group_id&lt;=2147483647</span><br><span class="line">        and format&lt;=10</span><br><span class="line">        and estimated_revenue &lt;&gt; 'Infinity'</span><br><span class="line">        and is_cn_sdk&lt;=1</span><br><span class="line">        and length(geo_short)&lt;=2</span><br><span class="line">    group by</span><br><span class="line">        case nw_firm_id when '' then 0 else nw_firm_id end,</span><br><span class="line">        case group_id when '' then 0 else group_id end,</span><br><span class="line">        case nw_firm_id when '35' then 1 else unit_id end,</span><br><span class="line">        case system_type when '' then 0 else system_type end,</span><br><span class="line">        case sdk_version when 'null' then '0' else sdk_version end,</span><br><span class="line">        case when app_vn = 'null' then '0' when length(app_vn) &gt;= 50 then '0' else regexp_replace(app_vn,'\\\\\\\\0000','') end,</span><br><span class="line">        case os_platform when '' then 0 else os_platform end,</span><br><span class="line">        case geo_short when 'null' then '00' else geo_short end,</span><br><span class="line">        case publisher_id when '' then 0 else publisher_id end,</span><br><span class="line">        case app_id when '' then 0 else app_id end,</span><br><span class="line">        case placement_id when '' then 0 when 'null' then 0 else placement_id end,</span><br><span class="line">        case format when '' then 0 else format end,</span><br><span class="line">        case sc_type when '' then 0 else sc_type end,</span><br><span class="line">        case channel when '' then '' else channel end,</span><br><span class="line">        case sub_channel when '' then '' else sub_channel end,</span><br><span class="line">        case network_id when '' then 0 else network_id end,</span><br><span class="line">        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,</span><br><span class="line">        case  when (bidtype is null or bidtype='') then 0 else bidtype end,</span><br><span class="line">        case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">        case when (error_type is null or error_type='') then 0 else error_type end,</span><br><span class="line">        case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,</span><br><span class="line">        case when device_type is null then 1 else device_type end,</span><br><span class="line">        idfa_exist_tag,</span><br><span class="line">        abtest_id</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">--name "BigData_CommonSparkDateTimeJob_merge_report_hour_dt$&#123;yyyy_mm_dd_hh&#125;" \</span><br><span class="line">--master yarn  \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--executor-memory 2g \</span><br><span class="line">--driver-memory 2g \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--num-executors 8 \</span><br><span class="line">--conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">--conf spark.dynamicAllocation.minExecutors=8 \</span><br><span class="line">--conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">--conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">--files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_HIVE_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd_hh&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_BIGDATA&#125;</span>.<span class="variable">$&#123;T_BIGDATA_REPORT_TK_HOUR&#125;</span>"</span>  <span class="string">"dt='<span class="variable">$&#123;yyyy&#125;</span>-<span class="variable">$&#123;mm&#125;</span>-<span class="variable">$&#123;dd&#125;</span>', hh='<span class="variable">$&#123;hh&#125;</span>', dimen='0'"</span> <span class="string">"overwrite"</span>\</span></span><br></pre></td></tr></table></figure><ol><li>where条件加上了<code>dimen in (&#39;1&#39;,&#39;2&#39;,&#39;3&#39;,&#39;4&#39;,&#39;5&#39;,&#39;6&#39;,&#39;7&#39;,&#39;8&#39;,&#39;9&#39;,&#39;10&#39;,&#39;11&#39;,&#39;12&#39;,&#39;13&#39;,&#39;14&#39;,&#39;15&#39;,&#39;16&#39;)</code>，代表要拿到所有父节点的任务数据</li><li>其他的where条件代表在这个节点，不可能存在这些字段没有数据</li><li>把数据写入到非orc的表中，并且 <code>dimen = &#39;0&#39;</code></li></ol><h3 id="to-db-tracking-hour"><a href="#to-db-tracking-hour" class="headerlink" title="to_db_tracking_hour"></a>to_db_tracking_hour</h3><blockquote><p>数据出仓到gp</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">dimension_tk_hour_field="date_time,hour,nw_firm_id,group_id,unit_id,system,sdk_version,app_version,platform,geo_short,publisher_id,app_id,placement_id,format,sc_type,channel,sub_channel,hour_timestamp,network_id,traffic_group_id,bid_type,scenario,error_type,error_msg,is_cn_sdk,device_type,idfa_exist_tag "</span><br><span class="line">hive_dimension_tk_hour_field="date_time,hour,nw_firm_id,group_id,unit_id,system_type,sdk_version,app_vn,os_platform,geo_short,publisher_id,app_id,placement_id,format,sc_type,channel,sub_channel,hour_timestamp,network_id,traffic_group_id,bidtype,scenario,error_type,error_msg,is_cn_sdk,device_type,idfa_exist_tag"</span><br><span class="line">select_tk_hour_field="$&#123;hive_dimension_tk_hour_field&#125;,cast(sum(request) as bigint),cast(sum(filled_request) as bigint),cast(sum(impression) as bigint),cast(sum(click) as bigint),cast(sum(load) as bigint),cast(sum(filled_load) as bigint),cast(sum(rv_play_start) as bigint),cast(sum(rv_play_complete) as bigint),cast(sum(app_request) as bigint),cast(sum(placement_request) as bigint),cast(sum(show) as bigint),cast(sum(impression_optimize) as bigint),cast(sum(bid_request) as bigint),cast(sum(bid_response) as bigint),cast(sum(estimated_revenue) as float),cast(sum(fake_impression_optimize) as bigint),cast(sum(fake_filled_load) as bigint),cast(sum(fake_filled_request) as bigint),cast(sum(load_cost_time) as bigint),cast(sum(request_cost_time) as bigint), case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end as bid_response_ecpm,cast(sum(scenario_entry) as bigint),cast(sum(scenario_entry_ready) as bigint) "</span><br><span class="line">export_tk_hour_field="$&#123;dimension_tk_hour_field&#125;,request,filled_request,impression,click,loads,filled_loads,rv_start,rv_complete,strategy_app_request,strategy_placement_request,shows,impression_optimize,bid_request,bid_filled_request,estimated_revenue,fake_impression_optimize,fake_filled_load,fake_filled_request,load_cost_time,request_cost_time,bid_filled_request_ecpm,scenario_entry,scenario_entry_ready"</span><br><span class="line"></span><br><span class="line">function export_tk_hour_func() &#123;</span><br><span class="line">  stat_source_hour='report_tk_hour'</span><br><span class="line">  gp_delete_timeStamp=$(expr $&#123;timeStamp&#125; + 1 \* 3600)</span><br><span class="line">  del_sql="delete from $&#123;stat_source_hour&#125; where date_time = $&#123;yyyy&#125;$&#123;mm&#125;$&#123;dd&#125; and hour=$&#123;hh&#125; and add_timestamp&lt;$&#123;gp_delete_timeStamp&#125; and source_type not in (2);"</span><br><span class="line">  select_sql="select $&#123;select_tk_hour_field&#125; from $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_REPORT_TK_HOUR&#125; where dt='$&#123;yyyy&#125;-$&#123;mm&#125;-$&#123;dd&#125;' and hh='$&#123;hh&#125;' and dimen='0' group by $&#123;hive_dimension_tk_hour_field&#125;"</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 针对两个库的删除和导入</span></span><br><span class="line">  export_to_pgsql_by_select_data "$&#123;select_sql&#125;" $&#123;stat_source_hour&#125; bigdata_job_base_data_report_hour_$&#123;RANDOM&#125;_tmp.log "$&#123;del_sql&#125;" '|' "($&#123;export_tk_hour_field&#125;)"</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">export_to_pgsql_by_select_data() &#123;</span><br><span class="line">  el_sql=$1</span><br><span class="line">  el_stat_source=$2</span><br><span class="line">  el_tmp_file=$3</span><br><span class="line">  el_delete_sql=$4</span><br><span class="line">  el_terminated=$5</span><br><span class="line">  el_rows=$6</span><br><span class="line"></span><br><span class="line">  filepath=$(</span><br><span class="line">    cd "$(dirname "$0")"</span><br><span class="line">    pwd</span><br><span class="line">  )</span><br><span class="line">  fileTmpDir=tmp_$&#123;el_stat_source&#125;/$&#123;el_stat_source&#125;/</span><br><span class="line"></span><br><span class="line">  if [ -f "$&#123;el_tmp_file&#125;" ]; then</span><br><span class="line">    rm $&#123;el_tmp_file&#125;</span><br><span class="line">  fi</span><br><span class="line">  hive -e "</span><br><span class="line">              INSERT OVERWRITE  DIRECTORY '$&#123;fileTmpDir&#125;'</span><br><span class="line">              ROW format delimited fields terminated BY '$&#123;el_terminated&#125;'</span><br><span class="line">              $&#123;el_sql&#125;</span><br><span class="line">            "</span><br><span class="line">  hadoop fs -getmerge $&#123;fileTmpDir&#125;* $&#123;el_tmp_file&#125;</span><br><span class="line">  head -n 20 $&#123;el_tmp_file&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"><span class="built_in">export</span> to pgsql</span></span><br><span class="line">  echo "copy $&#123;el_stat_source&#125;  $&#123;el_rows&#125; from STDIN delimiter as '$&#123;el_terminated&#125;';"</span><br><span class="line">  sql="copy $&#123;el_stat_source&#125;  $&#123;el_rows&#125; from STDIN delimiter as '$&#123;el_terminated&#125;'"</span><br><span class="line"></span><br><span class="line">  if [[ $&#123;PG_BI_DB_ENABLE&#125; = true ]]; then</span><br><span class="line">    psql "host=$&#123;PG_BI_DB_HOST&#125; port=$&#123;PG_BI_DB_PORT&#125; user=$&#123;PG_BI_DB_USER&#125; password=$&#123;PG_BI_DB_PWD&#125; dbname=$&#123;PG_BI_DB_NAME&#125;" -c "$&#123;el_delete_sql&#125;"</span><br><span class="line">    psql "host=$&#123;PG_BI_DB_HOST&#125; port=$&#123;PG_BI_DB_PORT&#125; user=$&#123;PG_BI_DB_USER&#125; password=$&#123;PG_BI_DB_PWD&#125; dbname=$&#123;PG_BI_DB_NAME&#125;" -c "$&#123;sql&#125;" &lt;$&#123;el_tmp_file&#125;</span><br><span class="line">  fi</span><br><span class="line"></span><br><span class="line">  if [[ $&#123;PG_REL_BI_DB_ENABLE&#125; = true ]]; then</span><br><span class="line">    psql "host=$&#123;PG_REL_BI_DB_HOST&#125; port=$&#123;PG_REL_BI_DB_PORT&#125; user=$&#123;PG_REL_BI_DB_USER&#125; password=$&#123;PG_REL_BI_DB_PWD&#125; dbname=$&#123;PG_REL_BI_DB_NAME&#125;" -c "$&#123;el_delete_sql&#125;"</span><br><span class="line">    psql "host=$&#123;PG_REL_BI_DB_HOST&#125; port=$&#123;PG_REL_BI_DB_PORT&#125; user=$&#123;PG_REL_BI_DB_USER&#125; password=$&#123;PG_REL_BI_DB_PWD&#125; dbname=$&#123;PG_REL_BI_DB_NAME&#125;" -c "$&#123;sql&#125;" &lt;$&#123;el_tmp_file&#125;</span><br><span class="line">  fi</span><br><span class="line"></span><br><span class="line">  rm $&#123;el_tmp_file&#125;</span><br><span class="line">  hadoop fs -rmr $&#123;fileTmpDir&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">export_tk_hour_func</span><br></pre></td></tr></table></figure><ol><li>把数据通过sql查出来，然后通过 <code>|</code> 符号进行分割，然后写入到一个临时文件中</li><li>删除当前小时周期下的数据</li><li>通过 <code>copy</code> 命令列出所有的字段，然后通过标准输入<code>STDIN</code> 作为分隔符，从<code>临时文件中</code>导入数据</li></ol><h3 id="to-db-traking"><a href="#to-db-traking" class="headerlink" title="to_db_traking"></a>to_db_traking</h3><blockquote><p>把小时级表的数据合并到天级表</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 天表的数据都来自于小时表，从小时表导出后导入天表</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> tk表及东八区的时间和小时表的时间一样，0时区和西八区需要特殊处理一下</span></span><br><span class="line">currentUnixTime=$(date '+%s')</span><br><span class="line">tmpTkHourFileName="/data/gp_tk_tmp/report_tk_utce8_$&#123;currentUnixTime&#125;.log" # 此文件是在GP服务器上面的，需要有专门的任务去做清除</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 参照收益任务hour小时数据到天级数据的处理方式: export_report_unit_hour.sh</span></span><br><span class="line">CurrentDay=$&#123;utce8_yyyy&#125;$&#123;utce8_mm&#125;$&#123;utce8_dd&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 机器为零时区</span></span><br><span class="line">startTimeStamp=`date -d "8 hour ago $&#123;utce8_yyyy&#125;-$&#123;utce8_mm&#125;-$&#123;utce8_dd&#125; 00:00:00" +%s`</span><br><span class="line">endTimeStamp=`date -d "8 hour ago $&#123;utce8_yyyy&#125;-$&#123;utce8_mm&#125;-$&#123;utce8_dd&#125; 23:59:59" +%s`</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> estimate_revenue_api,estimate_currency_revenue_api,ready_request,ready_success,show_failed 由ltv任务写入</span></span><br><span class="line">pgSearchSql="</span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;CurrentDay&#125;,</span></span><br><span class="line">  nw_firm_id,</span><br><span class="line">  group_id,</span><br><span class="line">  geo_short,</span><br><span class="line">  publisher_id,</span><br><span class="line">  channel,</span><br><span class="line">  sub_channel,</span><br><span class="line">  system,</span><br><span class="line">  platform,</span><br><span class="line">  app_id,</span><br><span class="line">  sdk_version,</span><br><span class="line">  app_version,</span><br><span class="line">  placement_id,</span><br><span class="line">  unit_id,</span><br><span class="line">  format,</span><br><span class="line">  sc_type,</span><br><span class="line">  SUM(request),</span><br><span class="line">  SUM(filled_request),</span><br><span class="line">  SUM(strategy_app_request),</span><br><span class="line">  SUM(strategy_placement_request),</span><br><span class="line">  SUM(impression),</span><br><span class="line">  SUM(shows),</span><br><span class="line">  SUM(click),</span><br><span class="line">  SUM(loads),</span><br><span class="line">  SUM(filled_loads),</span><br><span class="line">  SUM(rv_start),</span><br><span class="line">  SUM(rv_complete),</span><br><span class="line">  SUM(impression_optimize),</span><br><span class="line">  network_id,</span><br><span class="line">  bid_type,</span><br><span class="line">  SUM(estimated_revenue),</span><br><span class="line">  traffic_group_id,</span><br><span class="line">  SUM(bid_request),</span><br><span class="line">  SUM(bid_filled_request),</span><br><span class="line">  case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">  error_type,</span><br><span class="line">  case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">  SUM(fake_impression_optimize),</span><br><span class="line">  SUM(fake_filled_load),</span><br><span class="line">  SUM(fake_filled_request),</span><br><span class="line">  is_cn_sdk,</span><br><span class="line">  device_type,</span><br><span class="line">  source_type,</span><br><span class="line">  SUM(load_cost_time),</span><br><span class="line">  SUM(request_cost_time),</span><br><span class="line">  idfa_exist_tag,</span><br><span class="line">  case coalesce(sum(bid_filled_request),0) when 0  then 0.0 else cast(sum(bid_filled_request * bid_filled_request_ecpm) / sum(bid_filled_request) as float) end,</span><br><span class="line">  SUM(scenario_entry),</span><br><span class="line">  SUM(scenario_entry_ready)</span><br><span class="line">FROM</span><br><span class="line">  report_tk_hour</span><br><span class="line">WHERE</span><br><span class="line">  hour_timestamp &gt;= $&#123;startTimeStamp&#125;</span><br><span class="line">  AND hour_timestamp &lt;= $&#123;endTimeStamp&#125;</span><br><span class="line">  AND source_type NOT IN (2)</span><br><span class="line">  AND add_timestamp &lt; $&#123;gp_delete_timeStamp&#125;</span><br><span class="line">GROUP BY</span><br><span class="line">  nw_firm_id,</span><br><span class="line">  group_id,</span><br><span class="line">  geo_short,</span><br><span class="line">  publisher_id,</span><br><span class="line">  channel,</span><br><span class="line">  sub_channel,</span><br><span class="line">  system,</span><br><span class="line">  platform,</span><br><span class="line">  app_id,</span><br><span class="line">  sdk_version,</span><br><span class="line">  app_version,</span><br><span class="line">  placement_id,</span><br><span class="line">  unit_id,</span><br><span class="line">  format,</span><br><span class="line">  sc_type,</span><br><span class="line">  network_id,</span><br><span class="line">  bid_type,</span><br><span class="line">  traffic_group_id,</span><br><span class="line">  case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">  error_type,</span><br><span class="line">  case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">  is_cn_sdk,</span><br><span class="line">  device_type,</span><br><span class="line">  source_type,</span><br><span class="line">  idfa_exist_tag</span><br><span class="line">  "</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 导出数据，report_tk 和 report_tk_utce8 表数据一致，只用导出一次便可</span></span><br><span class="line">outputSql="COPY ( $&#123;pgSearchSql&#125; ) TO '$&#123;tmpTkHourFileName&#125;' WITH CSV;"</span><br><span class="line">export PGPASSWORD=$&#123;PG_BI_DB_PWD&#125;</span><br><span class="line">psql --host=$&#123;PG_BI_DB_HOST&#125; --port=$&#123;PG_BI_DB_PORT&#125; --user=$&#123;PG_BI_DB_USER&#125; --dbname=$&#123;PG_BI_DB_NAME&#125; -c "$&#123;outputSql&#125;"</span><br><span class="line"></span><br><span class="line">deleteSql="DELETE FROM report_tk_utce8 WHERE date_time = $&#123;CurrentDay&#125;  AND source_type NOT IN (2) AND add_timestamp &lt; $&#123;gp_delete_timeStamp&#125;;"</span><br><span class="line">inputSql="COPY report_tk_utce8 ( $&#123;rowNames&#125; ) FROM '$&#123;tmpTkHourFileName&#125;' WITH CSV;"</span><br><span class="line"></span><br><span class="line">export PGPASSWORD=$&#123;PG_BI_DB_PWD&#125;</span><br><span class="line">respTag10=`psql --host=$&#123;PG_BI_DB_HOST&#125; --port=$&#123;PG_BI_DB_PORT&#125; --user=$&#123;PG_BI_DB_USER&#125; --dbname=$&#123;PG_BI_DB_NAME&#125; &lt;&lt;EOF</span><br><span class="line">BEGIN;</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;deleteSql&#125;</span></span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;inputSql&#125;</span></span><br><span class="line">COMMIT;</span><br><span class="line">EOF`</span><br><span class="line"></span><br><span class="line">echo $&#123;respTag10&#125;</span><br><span class="line">if [[ $&#123;respTag10&#125; =~ "ROLLBACK" ]] ; then</span><br><span class="line">  exit 1</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><ol><li>先把数据导出到一个临时文件<code>${tmpTkHourFileName}</code></li><li>再把数据从临时文件导入到另外一个天级表<code>report_tk_utce8</code></li><li>utc0/utcw8时区的一样的操作</li></ol><h3 id="merge-tracking-hour-1"><a href="#merge-tracking-hour-1" class="headerlink" title="merge_tracking_hour"></a>merge_tracking_hour</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">转换成utc8时间</span></span><br><span class="line">utce8_day_start_timeStamp=`date -d "$&#123;utce8_yyyy&#125;-$&#123;utce8_mm&#125;-$&#123;utce8_dd&#125; 00:00:00" +%s`</span><br><span class="line">utce8_day_end_timeStamp=`date -d "$&#123;utce8_yyyy&#125;-$&#123;utce8_mm&#125;-$&#123;utce8_dd&#125; 23:00:00" +%s`</span><br><span class="line">while_run_stamp=$&#123;utce8_day_start_timeStamp&#125;</span><br><span class="line">utce8_utc0_hour_where='('</span><br><span class="line"></span><br><span class="line">while [ "$&#123;while_run_stamp&#125;" -le "$&#123;utce8_day_end_timeStamp&#125;" ]</span><br><span class="line">do</span><br><span class="line">    tmp_run_stamp=`expr $&#123;while_run_stamp&#125; - 8 \* 3600`</span><br><span class="line">    tmp_date_time=`date -d @$&#123;tmp_run_stamp&#125; "+%Y-%m-%d-%H"`</span><br><span class="line">    tmp_yyyy=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $1&#125;'`</span><br><span class="line">    tmp_mm=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $2&#125;'`</span><br><span class="line">    tmp_dd=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $3&#125;'`</span><br><span class="line">    tmp_hh=`echo $&#123;tmp_date_time&#125;|awk -F- '&#123;print $4&#125;'`</span><br><span class="line">    if [ "$&#123;while_run_stamp&#125;" == "$&#123;utce8_day_start_timeStamp&#125;" ]</span><br><span class="line">        then</span><br><span class="line">           utce8_utc0_hour_where="$&#123;utce8_utc0_hour_where&#125;dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hh='$&#123;tmp_hh&#125;'"</span><br><span class="line">        else</span><br><span class="line">           utce8_utc0_hour_where="$&#123;utce8_utc0_hour_where&#125; or dt='$&#123;tmp_yyyy&#125;-$&#123;tmp_mm&#125;-$&#123;tmp_dd&#125;' and hh='$&#123;tmp_hh&#125;'"</span><br><span class="line">        fi</span><br><span class="line">        while_run_stamp=`expr $&#123;while_run_stamp&#125; + 3600`</span><br><span class="line">done</span><br><span class="line">utce8_utc0_hour_where="$&#123;utce8_utc0_hour_where&#125;)"</span><br><span class="line"></span><br><span class="line">hql="select</span><br><span class="line">        $&#123;utce8_yyyy&#125;$&#123;utce8_mm&#125;$&#123;utce8_dd&#125;,</span><br><span class="line">        nw_firm_id,</span><br><span class="line">        group_id,</span><br><span class="line">        unit_id,</span><br><span class="line">        system_type,</span><br><span class="line">        sdk_version,</span><br><span class="line">        app_vn,</span><br><span class="line">        os_platform,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        format,</span><br><span class="line">        sc_type,</span><br><span class="line">        cast(sum(request) as bigint),</span><br><span class="line">        cast(sum(filled_request) as bigint),</span><br><span class="line">        cast(sum(impression) as bigint),</span><br><span class="line">        cast(sum(click) as bigint),</span><br><span class="line">        cast(sum(load) as bigint),</span><br><span class="line">        cast(sum(filled_load) as bigint),</span><br><span class="line">        cast(sum(rv_play_start) as bigint),</span><br><span class="line">        cast(sum(rv_play_complete) as bigint),</span><br><span class="line">        channel,</span><br><span class="line">        sub_channel,</span><br><span class="line">        cast(sum(app_request) as bigint),</span><br><span class="line">        cast(sum(placement_request) as bigint),</span><br><span class="line">        cast(sum(show) as bigint),</span><br><span class="line">        cast(sum(impression_optimize) as bigint),</span><br><span class="line">        case  when network_id is null then 0 else network_id end,</span><br><span class="line">        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,</span><br><span class="line">        case  when (bidtype is null or bidtype='') then 0 else bidtype end,</span><br><span class="line">        cast(sum(case  when (bid_request is null or bid_request='') then 0 else bid_request end) as bigint),</span><br><span class="line">        cast(sum(case  when (bid_response is null or bid_response='') then 0 else bid_response end) as bigint),</span><br><span class="line">        cast(sum(case  when (estimated_revenue is null or estimated_revenue='') then 0 else estimated_revenue end) as float),</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">        case when (error_type is null or error_type='') then 0 else error_type end,</span><br><span class="line">        case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">        cast(sum(case when (fake_impression_optimize is null or fake_impression_optimize='') then impression_optimize else fake_impression_optimize end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_load is null or fake_filled_load='') then filled_load else fake_filled_load end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_request is null or fake_filled_request='') then filled_request else fake_filled_request end) as bigint),</span><br><span class="line">        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        0,</span><br><span class="line">        case when device_type is null then 1 else device_type end,</span><br><span class="line">        cast(sum(case when load_cost_time is null or load_cost_time&lt;0 then 0 else load_cost_time end) as bigint),</span><br><span class="line">        cast(sum(case when request_cost_time is null or request_cost_time&lt;0 then 0 else request_cost_time end) as bigint),</span><br><span class="line">        case when idfa_exist_tag is null then 0 else idfa_exist_tag end,</span><br><span class="line">        case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end,</span><br><span class="line">        cast(coalesce(sum(scenario_entry),0) as bigint),</span><br><span class="line">        cast(coalesce(sum(scenario_entry_ready),0) as bigint),</span><br><span class="line">        abtest_id</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;T_BIGDATA_REPORT_TK_HOUR&#125;</span><br><span class="line">    where </span><br><span class="line">        $&#123;utce8_utc0_hour_where&#125;</span><br><span class="line">        and dimen='0'</span><br><span class="line">        and group_id&gt;=0</span><br><span class="line">        and group_id&lt;=2147483647</span><br><span class="line">    group by </span><br><span class="line">        nw_firm_id,</span><br><span class="line">        group_id,</span><br><span class="line">        unit_id,</span><br><span class="line">        system_type,</span><br><span class="line">        sdk_version,</span><br><span class="line">        app_vn,</span><br><span class="line">        os_platform,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        format,</span><br><span class="line">        sc_type,</span><br><span class="line">        channel,</span><br><span class="line">        sub_channel,</span><br><span class="line">        case</span><br><span class="line">            when network_id is null then 0</span><br><span class="line">        else network_id</span><br><span class="line">        end,</span><br><span class="line">        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,</span><br><span class="line">        case  when (bidtype is null or bidtype='') then 0 else bidtype end,</span><br><span class="line">        case when (scenario is null or scenario='') then '1' else scenario end,</span><br><span class="line">        case when (error_type is null or error_type='') then 0 else error_type end,</span><br><span class="line">        case when (error_msg is null or error_msg='') then '' else error_msg end,</span><br><span class="line">        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,</span><br><span class="line">        case when device_type is null then 1 else device_type end,</span><br><span class="line">        case when idfa_exist_tag is null then 0 else idfa_exist_tag end,</span><br><span class="line">        abtest_id</span><br><span class="line">"</span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">--name "BigData_CommonSparkDateTimeJob_merge_report_utce8_dt$&#123;yyyy_mm_dd_hh&#125;" \</span><br><span class="line">--master yarn  \</span><br><span class="line">--deploy-mode cluster \</span><br><span class="line">--executor-memory 2g \</span><br><span class="line">--driver-memory 2g \</span><br><span class="line">--executor-cores 2 \</span><br><span class="line">--num-executors 8 \</span><br><span class="line">--conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">--conf spark.dynamicAllocation.minExecutors=8 \</span><br><span class="line">--conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">--conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">--files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_HIVE_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd_hh&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_BIGDATA&#125;</span>.<span class="variable">$&#123;T_BIGDATA_REPORT_TK_UTCE8&#125;</span>"</span>  <span class="string">"dt='<span class="variable">$&#123;utce8_yyyy&#125;</span>-<span class="variable">$&#123;utce8_mm&#125;</span>-<span class="variable">$&#123;utce8_dd&#125;</span>', dimen='0'"</span> <span class="string">"overwrite"</span>\</span></span><br></pre></td></tr></table></figure><ol><li>数据通过小时表转成<code>report_tk</code>表，并且 <code>dimen=&#39;0&#39;</code></li></ol><h3 id="abtest-tk-xxx"><a href="#abtest-tk-xxx" class="headerlink" title="abtest_tk_xxx"></a>abtest_tk_xxx</h3><blockquote><p>业务需要，根据abtest_id，把数据分别成不同的traffi_group_id，原始的数据的abtest_id字段会变成&amp;&amp;，分别出来的会变成00</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br></pre></td><td class="code"><pre><span class="line">tk_dimen='0'</span><br><span class="line">abtest_tk_tmp_dimen="10$&#123;tk_dimen&#125;"</span><br><span class="line">zone_type=$1</span><br><span class="line"></span><br><span class="line">if [ -n "$&#123;run_type&#125;" ]; then</span><br><span class="line">  if [[ $&#123;run_type&#125; = 'utcw8' ]]; then</span><br><span class="line">    zone_type="3"</span><br><span class="line">  else</span><br><span class="line">    if [[ $&#123;run_type&#125; = 'utc0' ]]; then</span><br><span class="line">      zone_type="2"</span><br><span class="line">    else</span><br><span class="line">      zone_type="1"</span><br><span class="line">    fi</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">zone_yyyy="$&#123;yyyy&#125;"</span><br><span class="line">zone_mm="$&#123;mm&#125;"</span><br><span class="line">zone_dd="$&#123;dd&#125;"</span><br><span class="line">zone_tk_table="$&#123;T_BIGDATA_REPORT_TK_UTCE8&#125;"</span><br><span class="line">zone_abtest_tk_table="$&#123;T_BIGDATA_REPORT_ABTEST_TK_UTCE8&#125;"</span><br><span class="line">zone_gp_abtest_tk_table="report_abtest_tk_utce8"</span><br><span class="line"></span><br><span class="line">if [ "$&#123;zone_type&#125;" == "2" ]; then</span><br><span class="line">  zone_yyyy="$&#123;utc0_yyyy&#125;"</span><br><span class="line">  zone_mm="$&#123;utc0_mm&#125;"</span><br><span class="line">  zone_dd="$&#123;utc0_dd&#125;"</span><br><span class="line">  zone_tk_table="$&#123;T_BIGDATA_REPORT_TK_UTC0&#125;"</span><br><span class="line">  zone_abtest_tk_table="$&#123;T_BIGDATA_REPORT_ABTEST_TK_UTC0&#125;"</span><br><span class="line">  zone_gp_abtest_tk_table="report_abtest_tk_utc0"</span><br><span class="line">else</span><br><span class="line">  if [ "$&#123;zone_type&#125;" == "3" ]; then</span><br><span class="line">    zone_yyyy="$&#123;utcw8_yyyy&#125;"</span><br><span class="line">    zone_mm="$&#123;utcw8_mm&#125;"</span><br><span class="line">    zone_dd="$&#123;utcw8_dd&#125;"</span><br><span class="line">    zone_tk_table="$&#123;T_BIGDATA_REPORT_TK_UTCW8&#125;"</span><br><span class="line">    zone_abtest_tk_table="$&#123;T_BIGDATA_REPORT_ABTEST_TK_UTCW8&#125;"</span><br><span class="line">    zone_gp_abtest_tk_table="report_abtest_tk_utcw8"</span><br><span class="line">  fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">hql="select</span><br><span class="line">        date_time,</span><br><span class="line">        nw_firm_id,</span><br><span class="line">        group_id,</span><br><span class="line">        unit_id,</span><br><span class="line">        sdk_version,</span><br><span class="line">        app_vn,</span><br><span class="line">        os_platform,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        format,</span><br><span class="line">        device_type,</span><br><span class="line">        channel,</span><br><span class="line">        network_id,</span><br><span class="line">        case when abtest_id is null then '' else abtest_id end as abtest_id,</span><br><span class="line">        traffic_group_id,</span><br><span class="line">        bidtype,</span><br><span class="line">        cast(sum(request) as bigint),</span><br><span class="line">        cast(sum(filled_request) as bigint),</span><br><span class="line">        cast(sum(impression) as bigint),</span><br><span class="line">        cast(sum(click) as bigint),</span><br><span class="line">        cast(sum(load) as bigint),</span><br><span class="line">        cast(sum(filled_load) as bigint),</span><br><span class="line">        cast(sum(rv_play_start) as bigint),</span><br><span class="line">        cast(sum(rv_play_complete) as bigint),</span><br><span class="line">        cast(sum(show) as bigint),</span><br><span class="line">        cast(sum(impression_optimize) as bigint),</span><br><span class="line">        cast(sum(case  when (bid_request is null or bid_request='') then 0 else bid_request end) as bigint),</span><br><span class="line">        cast(sum(case  when (bid_response is null or bid_response='') then 0 else bid_response end) as bigint),</span><br><span class="line">        cast(sum(case  when (estimated_revenue is null or estimated_revenue='') then 0 else estimated_revenue end) as float),</span><br><span class="line">        cast(sum(case  when (estimate_revenue_api is null or estimate_revenue_api='') then 0 else estimate_revenue_api end) as float),</span><br><span class="line">        cast(sum(case  when (estimate_currency_revenue_api is null or estimate_currency_revenue_api='') then 0 else estimate_currency_revenue_api end) as float),</span><br><span class="line">        cast(sum(case when (fake_impression_optimize is null or fake_impression_optimize='') then impression_optimize else fake_impression_optimize end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_load is null or fake_filled_load='') then filled_load else fake_filled_load end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_request is null or fake_filled_request='') then filled_request else fake_filled_request end) as bigint),</span><br><span class="line">        sum(ready_request),</span><br><span class="line">        sum(ready_success),</span><br><span class="line">        sum(show_failed)</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;zone_tk_table&#125;</span><br><span class="line">    where </span><br><span class="line">        dt='$&#123;zone_yyyy&#125;-$&#123;zone_mm&#125;-$&#123;zone_dd&#125;'</span><br><span class="line">        and dimen='$&#123;tk_dimen&#125;'</span><br><span class="line">    group by </span><br><span class="line">        date_time,</span><br><span class="line">        nw_firm_id,</span><br><span class="line">        group_id,</span><br><span class="line">        unit_id,</span><br><span class="line">        sdk_version,</span><br><span class="line">        app_vn,</span><br><span class="line">        os_platform,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        format,</span><br><span class="line">        device_type,</span><br><span class="line">        channel,</span><br><span class="line">        network_id,</span><br><span class="line">        case when abtest_id is null then '' else abtest_id end,</span><br><span class="line">        traffic_group_id,</span><br><span class="line">        bidtype</span><br><span class="line">        "</span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.parse.jobs.ParseAndSpiltAbtestTkJob \</span><br><span class="line">  --name "BigData_ParseAndSpiltAbtestTkJob_abtest_dt$&#123;yyyy_mm_dd_hh&#125;_$&#123;zone_type&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory 2g \</span><br><span class="line">  --driver-memory 2g \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors 8 \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">  --files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd_hh&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;hql&#125;</span>"</span> <span class="string">"abtest_id"</span> <span class="string">"traffic_group_id"</span> <span class="string">"<span class="variable">$&#123;DB_BIGDATA&#125;</span>.<span class="variable">$&#123;zone_abtest_tk_table&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;zone_yyyy&#125;</span>-<span class="variable">$&#123;zone_mm&#125;</span>-<span class="variable">$&#123;zone_dd&#125;</span>', dimen='<span class="variable">$&#123;abtest_tk_tmp_dimen&#125;</span>'"</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 合并分解后的数据</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 再次减少维度数据</span></span><br><span class="line">merge_hql=" </span><br><span class="line">select</span><br><span class="line">        date_time,</span><br><span class="line">        0 as nw_firm_id,</span><br><span class="line">        0 as group_id,</span><br><span class="line">        0 as unit_id,</span><br><span class="line">        '',</span><br><span class="line">        '',</span><br><span class="line">        0 as os_platform,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        -1 as format,</span><br><span class="line">        -1 as device_type,</span><br><span class="line">        '',</span><br><span class="line">        0,</span><br><span class="line">        case when abtest_id &lt;&gt;'&amp;&amp;' then '00' else abtest_id end as abtest_id,</span><br><span class="line">        traffic_group_id,</span><br><span class="line">        -1 as bidtype,</span><br><span class="line">        cast(sum(request) as bigint),</span><br><span class="line">        cast(sum(filled_request) as bigint),</span><br><span class="line">        cast(sum(impression) as bigint),</span><br><span class="line">        cast(sum(click) as bigint),</span><br><span class="line">        cast(sum(load) as bigint),</span><br><span class="line">        cast(sum(filled_load) as bigint),</span><br><span class="line">        cast(sum(rv_play_start) as bigint),</span><br><span class="line">        cast(sum(rv_play_complete) as bigint),</span><br><span class="line">        cast(sum(show) as bigint),</span><br><span class="line">        cast(sum(impression_optimize) as bigint),</span><br><span class="line">        cast(sum(case  when (bid_request is null or bid_request='') then 0 else bid_request end) as bigint),</span><br><span class="line">        cast(sum(case  when (bid_response is null or bid_response='') then 0 else bid_response end) as bigint),</span><br><span class="line">        cast(sum(case  when (estimated_revenue is null or estimated_revenue='') then 0 else estimated_revenue end) as float),</span><br><span class="line">        cast(sum(case  when (estimate_revenue_api is null or estimate_revenue_api='') then 0 else estimate_revenue_api end) as float),</span><br><span class="line">        cast(sum(case  when (estimate_currency_revenue_api is null or estimate_currency_revenue_api='') then 0 else estimate_currency_revenue_api end) as float),</span><br><span class="line">        cast(sum(case when (fake_impression_optimize is null or fake_impression_optimize='') then impression_optimize else fake_impression_optimize end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_load is null or fake_filled_load='') then filled_load else fake_filled_load end) as bigint),</span><br><span class="line">        cast(sum(case when (fake_filled_request is null or fake_filled_request='') then filled_request else fake_filled_request end) as bigint),</span><br><span class="line">        sum(ready_request),</span><br><span class="line">        sum(ready_success),</span><br><span class="line">        sum(show_failed)</span><br><span class="line">    from </span><br><span class="line">        $&#123;DB_BIGDATA&#125;.$&#123;zone_abtest_tk_table&#125;</span><br><span class="line">    where </span><br><span class="line">        dt='$&#123;zone_yyyy&#125;-$&#123;zone_mm&#125;-$&#123;zone_dd&#125;'</span><br><span class="line">        and dimen='$&#123;abtest_tk_tmp_dimen&#125;'</span><br><span class="line">    group by </span><br><span class="line">        date_time,</span><br><span class="line">        geo_short,</span><br><span class="line">        publisher_id,</span><br><span class="line">        app_id,</span><br><span class="line">        placement_id,</span><br><span class="line">        case when abtest_id &lt;&gt;'&amp;&amp;' then '00' else abtest_id end,</span><br><span class="line">        traffic_group_id</span><br><span class="line">    "</span><br><span class="line"></span><br><span class="line">spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \</span><br><span class="line">  --name "BigData_CommonSparkDateTimeJob_merge_strategy_app_dt$&#123;yyyy_mm_dd_hh&#125;" \</span><br><span class="line">  --master yarn \</span><br><span class="line">  --deploy-mode cluster \</span><br><span class="line">  --executor-memory 2g \</span><br><span class="line">  --driver-memory 2g \</span><br><span class="line">  --executor-cores 2 \</span><br><span class="line">  --num-executors 8 \</span><br><span class="line">  --conf spark.dynamicAllocation.enabled=false \</span><br><span class="line">  --conf spark.dynamicAllocation.minExecutors=32 \</span><br><span class="line">  --conf spark.dynamicAllocation.maxExecutors=64 \</span><br><span class="line">  --conf spark.core.connection.ack.wait.timeout=300 \</span><br><span class="line">  --files "$&#123;HIVE_SITE_PATH&#125;" \</span><br><span class="line"><span class="meta">  $</span><span class="bash">&#123;SPARK_SQL_JAR&#125; <span class="variable">$&#123;CLIENT_TMP_LOG_PATH&#125;</span> <span class="string">"<span class="variable">$&#123;yyyy_mm_dd_hh&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;merge_hql&#125;</span>"</span> <span class="string">"<span class="variable">$&#123;DB_BIGDATA&#125;</span>.<span class="variable">$&#123;zone_abtest_tk_table&#125;</span>"</span> <span class="string">"dt='<span class="variable">$&#123;zone_yyyy&#125;</span>-<span class="variable">$&#123;zone_mm&#125;</span>-<span class="variable">$&#123;zone_dd&#125;</span>', dimen='<span class="variable">$&#123;tk_dimen&#125;</span>'"</span> <span class="string">"overwrite"</span></span></span><br><span class="line"></span><br><span class="line">source ./export_tk_util.sh</span><br><span class="line"></span><br><span class="line">export_abtest_tk_func "$&#123;DB_BIGDATA&#125;.$&#123;zone_abtest_tk_table&#125;" " dt='$&#123;zone_yyyy&#125;-$&#123;zone_mm&#125;-$&#123;zone_dd&#125;' and dimen='$&#123;tk_dimen&#125;' and traffic_group_id&gt;0" "$&#123;zone_gp_abtest_tk_table&#125;" "date_time=$&#123;zone_yyyy&#125;$&#123;zone_mm&#125;$&#123;zone_dd&#125; and add_timestamp&lt;$&#123;gp_delete_timeStamp&#125; and source_type not in (2)"</span><br></pre></td></tr></table></figure><ol><li>把数据传递进到spark脚本中，在spark中把数据进行分裂，然后存放在对应的<code>dimen = &#39;100&#39;</code></li><li>从表中的<code>dimen = &#39;100&#39;</code>中提取数据，把数据的维度再次缩小</li></ol><p>spark代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line">object ParseAndSpiltAbtestTkJob &#123;</span><br><span class="line">  def main(args: Array[String]): Unit &#x3D; &#123;</span><br><span class="line">    val tmpPath &#x3D; parseArg(args(0))</span><br><span class="line">    &#x2F;&#x2F;format:yyyy-mm-dd-hh</span><br><span class="line">    val dt &#x3D; args(1)</span><br><span class="line">    val selectSql &#x3D; parseArg(args(2))</span><br><span class="line">    val abtestField &#x3D; args(3)</span><br><span class="line">    val trafficGroupField &#x3D; args(4)</span><br><span class="line">    val outputTable &#x3D; parseArg(args(5))</span><br><span class="line">    val partition &#x3D; args(6)</span><br><span class="line">    var trafficGroupFieldRaw &#x3D; &quot;&amp;&amp;&quot;</span><br><span class="line">    var trafficGroupFieldNew &#x3D; &quot;&quot;</span><br><span class="line">    if (args.length &gt;&#x3D; 8) &#123;</span><br><span class="line">      trafficGroupFieldRaw &#x3D; args(7)</span><br><span class="line">    &#125;</span><br><span class="line">    if (args.length &gt;&#x3D; 9) &#123;</span><br><span class="line">      trafficGroupFieldNew &#x3D; args(8)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    val sparkSession: SparkSession &#x3D; SparkSession.builder</span><br><span class="line">      &#x2F;&#x2F;      .master(&quot;local[3]&quot;)</span><br><span class="line">      .enableHiveSupport() &#x2F;&#x2F; self-explanatory, isn&#39;t it?</span><br><span class="line">      .config(&quot;spark.sql.warehouse.dir&quot;, tmpPath)</span><br><span class="line">      .getOrCreate</span><br><span class="line"></span><br><span class="line">    sparkSession.sqlContext.setConf(&quot;hive.merge.mapfiles&quot;, &quot;true&quot;)</span><br><span class="line">    sparkSession.sqlContext.setConf(&quot;mapred.max.split.size&quot;, &quot;256000000&quot;)</span><br><span class="line">    sparkSession.sqlContext.setConf(&quot;mapred.min.split.size.per.node&quot;, &quot;192000000&quot;)</span><br><span class="line">    sparkSession.sqlContext.setConf(&quot;mapred.min.split.size.per.rack&quot;, &quot;192000000&quot;)</span><br><span class="line">    sparkSession.sqlContext.setConf(&quot;hive.input.format&quot;, &quot;org.apache.hadoop.hive.ql.io.CombineHiveInputFormat&quot;)</span><br><span class="line"></span><br><span class="line">    val rawData &#x3D; sparkSession.sql(selectSql)</span><br><span class="line">    val newRdd: RDD[Row] &#x3D; rawData.rdd.map(row &#x3D;&gt; &#123;</span><br><span class="line">      &#x2F;&#x2F;        System.out.println(&quot;--------------------------------------&quot;, row.toString())</span><br><span class="line">      var resultList: ArrayBuffer[Row] &#x3D; new ArrayBuffer[Row]()</span><br><span class="line">      val tkRows &#x3D; mapSpiltFunc(row, abtestField, trafficGroupField, trafficGroupFieldRaw, trafficGroupFieldNew)</span><br><span class="line">      if (tkRows !&#x3D; null &amp;&amp; tkRows.nonEmpty) &#123;</span><br><span class="line">        resultList ++&#x3D; tkRows</span><br><span class="line">      &#125;</span><br><span class="line">      resultList</span><br><span class="line">    &#125;).flatMap(row &#x3D;&gt; row)</span><br><span class="line">    &#x2F;&#x2F;通过时间戳随机表名</span><br><span class="line">    val time &#x3D; System.currentTimeMillis() % 100000000;</span><br><span class="line">    val tmpTable &#x3D; &quot;spark_CommonSparkDateTimeJob_&quot; + time + &quot;_table&quot;</span><br><span class="line">    sparkSession.createDataFrame(newRdd, rawData.schema).registerTempTable(tmpTable)</span><br><span class="line">    val insertString &#x3D; &quot;insert overwrite table &quot; + outputTable + &quot; partition(&quot; + partition + &quot;) select * from &quot; + tmpTable</span><br><span class="line">    sparkSession.sql(insertString)</span><br><span class="line">    sparkSession.stop()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def parseArg(arg: String): String &#x3D; &#123;</span><br><span class="line">    var tmpArg &#x3D; arg</span><br><span class="line">    if (tmpArg.startsWith(&quot;&#39;&quot;)) &#123;</span><br><span class="line">      tmpArg &#x3D; tmpArg.substring(1);</span><br><span class="line">    &#125;</span><br><span class="line">    if (tmpArg.endsWith(&quot;&#39;&quot;)) &#123;</span><br><span class="line">      tmpArg &#x3D; tmpArg.substring(0, tmpArg.length() - 1);</span><br><span class="line">    &#125;</span><br><span class="line">    tmpArg;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def mapSpiltFunc(row: Row, abtestField: String, trafficGroupField: String, trafficGroupFieldRaw: String, trafficGroupFieldNew: String): ArrayBuffer[Row] &#x3D; &#123;</span><br><span class="line">    var resultList: ArrayBuffer[Row] &#x3D; new ArrayBuffer[Row]()</span><br><span class="line">    val abtest &#x3D; row.getAs[String](abtestField)</span><br><span class="line">    val rowRawArray &#x3D; row.toSeq.toArray</span><br><span class="line">    val trafficGroupIndex &#x3D; row.fieldIndex(trafficGroupField)</span><br><span class="line">    val abtestGroupIndex &#x3D; row.fieldIndex(abtestField)</span><br><span class="line">    val curtGroupId &#x3D; row.getAs[String](trafficGroupField)</span><br><span class="line"></span><br><span class="line">    if (!TextUtils.isEmpty(curtGroupId) &amp;&amp; curtGroupId &gt; &quot;0&quot;) &#123;</span><br><span class="line">      val newCurGroupRow &#x3D; rowRawArray.clone()</span><br><span class="line">      if (trafficGroupFieldRaw.isEmpty) &#123;</span><br><span class="line">        newCurGroupRow(abtestGroupIndex) &#x3D; &quot;&amp;&amp;&quot;</span><br><span class="line">      &#125; else &#123;</span><br><span class="line">        newCurGroupRow(abtestGroupIndex) &#x3D; trafficGroupFieldRaw;</span><br><span class="line">      &#125;</span><br><span class="line">      resultList +&#x3D; Row.fromSeq(newCurGroupRow)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (TextUtils.isEmpty(abtest) || abtest.equals(&quot;&#123;&#125;&quot;)) &#123;</span><br><span class="line">      return resultList</span><br><span class="line">    &#125;</span><br><span class="line">    val tGroupIDs &#x3D; AbtestTkParsing.getTrafficGroupIDs(abtest)</span><br><span class="line">    for (groupId &lt;- tGroupIDs) &#123;</span><br><span class="line">      if (!groupId.equals(curtGroupId)) &#123;</span><br><span class="line">        val newGroupRow &#x3D; rowRawArray.clone()</span><br><span class="line">        if (trafficGroupFieldNew.nonEmpty) &#123;</span><br><span class="line">          newGroupRow(abtestGroupIndex) &#x3D; trafficGroupFieldNew</span><br><span class="line">        &#125;</span><br><span class="line">        newGroupRow(trafficGroupIndex) &#x3D; groupId;</span><br><span class="line">        resultList +&#x3D; Row.fromSeq(newGroupRow)</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    resultList</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>至此，一个基本的<code>小时任务</code>的大数据ETL服务就做完了该作的事情了</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;总结一下公司大数据的任务ETL离线工作流 - 小时任务&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="公司" scheme="http://blog.crazylaw.cn/tags/%E5%85%AC%E5%8F%B8/"/>
    
  </entry>
  
  <entry>
    <title>【广告行业】知识点</title>
    <link href="http://blog.crazylaw.cn/2022/04/12/%E5%85%AC%E5%8F%B8/%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%9A%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    <id>http://blog.crazylaw.cn/2022/04/12/%E5%85%AC%E5%8F%B8/%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%9A%E7%9F%A5%E8%AF%86%E7%82%B9/</id>
    <published>2022-04-12T01:53:00.000Z</published>
    <updated>2022-04-12T12:20:15.427Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于广告行业有众多的知识点，所以记录一篇文章用以了解相关的专业名词和术语，并且加深了解的印象。</p><a id="more"></a><h2 id="头部竞价"><a href="#头部竞价" class="headerlink" title="头部竞价"></a>头部竞价</h2><p><code>Header Bidding</code>，顾名思义，就是<code>头部竞价</code>，跟其相对应的就是<code>Waterfall</code>，瀑布流。在<code>Header Bidding</code>风靡<code>之前</code>，<code>Waterfall</code>才是各家广告平台的主流竞价方式。想要了解<code>Header Bidding</code>，那我们就需要先弄清楚什么是<code>Waterfall</code>了。</p><p>这里涉及到的角色有<code>开发者（publisher）</code>，<code>广告调解平台（mediation platform）</code>，<code>需求方（demand partner）</code>。首先，<code>广告调解平台</code>扮演一个（中立）的第三方角色，<code>接入了多家广告平台的广告源</code>，比如<code>Facebook</code>，<code>Vungle</code>，<code>Fyber</code>，<code>Applovin</code>等，即将各家的广告放到一个SDK中，这时候开发者如果想要变现自家的流量，只需接入广告调解平台的SDK即可，再通过一个简单的配置即可自主决定接通哪几家的广告源了，而不需要每家的广告SDK都接一遍，省时省力，是不是很棒？</p><p>那么，问题来了。开发者通过调解平台的SDK介入了多家的广告源后，流量改怎么分配呢？同一个<code>广告请求（ad request）</code>到底是该发给Facebook，还是google还是vungle还是其他人呢？这时候就涉及到调解平台的算法逻辑了，通常，这个调解平台会对给新介入的广告平台分配一定的流量，测试下其表现，并得到一个大概的<code>eCPM</code>的值；然后，调解平台会根据不同的广告平台在<code>过去24小时内的eCPM的高低来排序</code>，广告请求<code>优先</code>发给<code>eCPM最高的第一位选手</code>，若没有<code>填充（fill）</code>，就<code>下一个</code>，<code>没有填充</code>就<code>再下一个</code>，如此<code>循环往复</code>。<code>Waterfall</code>刚出来的时候真的是一个超级棒的概念，很好地解决了开发者流量变现最大化的问题。</p><p>但是，问题又来了。<strong>昨天排在第一的广告平台，谁能保证它今天给的eCPM也是足够高而排在第一位呢？</strong>又或者，昨天排在第三位的广告平台，今天有个爆款的单子推广，可以给到很高的价格，但是由于调解平台的算法机制，它不具有优先选择广告位的权利，而导致它并不能买到多少量。</p><p>这时候，聪明的移动互联网人就想到了借鉴桌面端广告的做法，没错，就是<code>Header Bidding</code>。头部竞价技术源于网页端，开发者通过在网页头部嵌入代码，从而似的广告请求在公开竞价之前可以发给开发者优选的合作伙伴，拿到优选合作伙伴的返回后将其价格与公开竞价价格做对比，价高者得。而这个模型也得以运用到移动端了。</p><p>调解平台一改往日的瀑布流的形式，将<strong>一个接一个地发广告请求的方式</strong> <code>改为</code> <strong>同时像所有的广告平台发请求</strong>，在一定的时间内将收到的返回最比较，<code>最高出价</code>即赢得广告的展示权。</p><h2 id="DSP（Demand-Side-Platform）需求方平台"><a href="#DSP（Demand-Side-Platform）需求方平台" class="headerlink" title="DSP（Demand-Side Platform）需求方平台"></a>DSP（Demand-Side Platform）需求方平台</h2><p>互联网广告DSP（Demand-Side Platform），就是需求方平台</p><p>DSP为需求方（即广告主或代理商）提供实时竞价投放平台。广告需求方可以在平台上管理广告活动及其投放策略，包括设置目标受众的定向条件、预算、出价、创意等。</p><h2 id="SSP（Supply-Side-Platform）供应方平台"><a href="#SSP（Supply-Side-Platform）供应方平台" class="headerlink" title="SSP（Supply-Side Platform）供应方平台"></a>SSP（Supply-Side Platform）供应方平台</h2><p>SSP服务于媒体方，可以作为分散的流量入口、大小媒体的聚合平台。</p><h2 id="ADN（Ad-Network）广告网盟"><a href="#ADN（Ad-Network）广告网盟" class="headerlink" title="ADN（Ad Network）广告网盟"></a>ADN（Ad Network）广告网盟</h2><p>ADN可以被理解为媒体代理公司，通过为广告主采购媒体方流量，赚取中间差价，其代表有百度网盟等。</p><h2 id="ADX（Ad-Exchange）广告交易平台"><a href="#ADX（Ad-Exchange）广告交易平台" class="headerlink" title="ADX（Ad Exchange）广告交易平台"></a>ADX（Ad Exchange）广告交易平台</h2><p>ADX提供的功能是交换，实现实时竞价、广告库存和广告需求的匹配。广告需求方可以随时改变自己的出价策略和所选择的资源。</p><h2 id="程序化广告-交易模式术语"><a href="#程序化广告-交易模式术语" class="headerlink" title="程序化广告-交易模式术语"></a>程序化广告-交易模式术语</h2><h3 id="RTB-real-time-bidding-实时竞价"><a href="#RTB-real-time-bidding-实时竞价" class="headerlink" title="RTB (real time bidding) 实时竞价"></a>RTB (real time bidding) 实时竞价</h3><p>Real Time Bidding(实时竞价)，也叫Open Auction（公开竞价），简称RTB</p><p>流量需求方在广告交易平台中，设定广告流量底价的情况下，当有流量过来时，与其他程序化广告买家一起对流量出价，广告交易平台收到各个程序化买家的出价后，进行比价，价高者获得流量并同步竞价成功的结果。整个过程都是通过程序化的方式在 100 毫秒内完成的。</p><p>品牌能够对单个展示广告位置进行竞价购买，而不是以预先固定的价格进行购买，从而使购买决策更加划算，避免广告主预算浪费</p><h3 id="PDB（Private-Direct-Buy）程序化直接购买"><a href="#PDB（Private-Direct-Buy）程序化直接购买" class="headerlink" title="PDB（Private Direct Buy）程序化直接购买"></a>PDB（Private Direct Buy）程序化直接购买</h3><blockquote><p>这个概念应该和直投是同一个概念</p></blockquote><p>是目前国内市场最为常见和主流应用的一种私有交易模式。</p><p>指流量需求方用确定的价格买断固定、优质的媒体资源，然后进行程序化广告的精准定向投放。常说的“保价保量”。</p><h3 id="PD（Preferred-Deals）优先交易"><a href="#PD（Preferred-Deals）优先交易" class="headerlink" title="PD（Preferred Deals）优先交易"></a>PD（Preferred Deals）优先交易</h3><p>与 PDB 区别在于，这种私有交易方式在广告资源上具有一定的不确定性。即流量需求方可以购买某一优质广告位，但其能获得多少曝光展示量却不能预先保证。常说的“保价不保量”。</p><h3 id="PA（Private-Auction）私有竞价"><a href="#PA（Private-Auction）私有竞价" class="headerlink" title="PA（Private Auction）私有竞价"></a>PA（Private Auction）私有竞价</h3><p>供应方平台将较优质的固定广告位资源专门拿出来，放在一个半公开市场中，仅由进入白名单的买方（VIP）进行竞价，价高者得。因此，广告位可以锁定，但采买价格和是否最终获得曝光都不能预先保证。常说的“不保价不保量”。</p><h2 id="程序化广告-效果术语"><a href="#程序化广告-效果术语" class="headerlink" title="程序化广告-效果术语"></a>程序化广告-效果术语</h2><p>广告传播影响受众的认知、心理、行为和态度，由此带来的直接和间接广告效益，对广告效果的评估的也有着多方面要素和维度。</p><h3 id="ROI"><a href="#ROI" class="headerlink" title="ROI"></a>ROI</h3><p><code>Return On Investment（投资回报率）</code>，简称<code>ROI</code>。即营销者通过广告投放得到的经济回报占广告投入（花费）的比例。</p><h3 id="Impression"><a href="#Impression" class="headerlink" title="Impression"></a>Impression</h3><p><code>Impression</code>，即<code>曝光量</code>，也被称为“展示量”、“展现量”。即投放期广告被展示的总次数。一般用户每浏览一次页面，同时页面中广告位的广告被展示一次，就是一个曝光。</p><h3 id="Click"><a href="#Click" class="headerlink" title="Click"></a>Click</h3><p>Click，即<code>点击量</code>，为投放期用户点击某个广告的总次数。</p><h3 id="CTR-Click-Through-Rate-点击率"><a href="#CTR-Click-Through-Rate-点击率" class="headerlink" title="CTR(Click-Through-Rate) 点击率"></a>CTR(Click-Through-Rate) 点击率</h3><p>广告被点击的次数与广告曝光次数的比例</p><p>计算公式：Click/Impression*100%</p><p>反映了广告的受关注程度，或用来衡量广告的吸引程度。</p><h3 id="RR（Reach-Rate）到达率"><a href="#RR（Reach-Rate）到达率" class="headerlink" title="RR（Reach Rate）到达率"></a>RR（Reach Rate）到达率</h3><p>到达量与点击量的比例（到达量/点击量*100%）</p><p>到达量：即有多少用户点击广告后进入落地页。</p><h3 id="CR（Conversion-Rate）转化率"><a href="#CR（Conversion-Rate）转化率" class="headerlink" title="CR（Conversion Rate）转化率"></a>CR（Conversion Rate）转化率</h3><p>转化量与点击量的比例（转化量/点击量*100%）</p><p>转化量：即有多少用户点击广告并进入落地页（活动页）后，继续发生咨询、注册、下载、加入购物车、下单等行为。</p><h3 id="留存率"><a href="#留存率" class="headerlink" title="留存率"></a>留存率</h3><p>特定周期内（如次日留存、七日留存等），留存用户数量（有多少用户留下来）占广告（当时）导入的新增用户数量的比例。留存率=留存用户数/新增用户数量*100%</p><h3 id="LT（Life-Time）生命周期"><a href="#LT（Life-Time）生命周期" class="headerlink" title="LT（Life Time）生命周期"></a>LT（Life Time）生命周期</h3><p>一个用户从第1次到最后1次参与游戏之间的时间段，一般按月计算平均值</p><h3 id="LTV-Life-Time-Value-用户终生价值"><a href="#LTV-Life-Time-Value-用户终生价值" class="headerlink" title="LTV(Life Time Value) 用户终生价值"></a>LTV(Life Time Value) 用户终生价值</h3><p>用户在生命周期内为该游戏创造的收入总计，可以看成是一个ARPU 值的长期累计。</p><p>计算公式：LTV = ARPUxLT。</p><h3 id="DAU-Daily-Active-Users-日活跃用户数量"><a href="#DAU-Daily-Active-Users-日活跃用户数量" class="headerlink" title="DAU(Daily Active Users) 日活跃用户数量"></a>DAU(Daily Active Users) 日活跃用户数量</h3><p>DAU 指的是某产品（网站、软件或游戏等）在一日之内登录或使用过的用户总数（不包括重复的用户）。</p><p>DAU 是一个比较基本的指标，能够相对片面地展现产品短时间内的热度。</p><p>一般来说只看产品的 DAU 其实意义不大，单纯通过 DAU 无法判断产品的真实质量，且 DAU 很容易伪造。</p><h3 id="MAU-Monthly-Active-Users-月活跃用户数量"><a href="#MAU-Monthly-Active-Users-月活跃用户数量" class="headerlink" title="MAU(Monthly Active Users) 月活跃用户数量"></a>MAU(Monthly Active Users) 月活跃用户数量</h3><p>MAU 指的是某产品（网站、软件或游戏等）在一个月（统计月）之内登录或使用过的用户总数（不包括重复的用户）。</p><p>MAU 同样也是一个比较基本的指标，能够相对片面的展现产品一段时间内的热度。</p><p>通过 DAU 和 MAU 虽然能够看出产品在一段时间内的热度，但是无法精确地判断产品的留存率，因为你无法得知用户的属性（是否为老用户）。此时 DNU 和 DOU 是时候出来救场了。</p><h3 id="DNU-amp-DOU"><a href="#DNU-amp-DOU" class="headerlink" title="DNU &amp; DOU"></a>DNU &amp; DOU</h3><p>「Daily New Users（日新增用户数量 ）&amp; Daily Old Users（日非新增用户数量）」</p><p>这两个词的意义非常明确，就是直接展现了产品短时间内的新老用户情况。</p><p>通过 DNU 和 DOU 加上 DAU 和 MAU 这几个指标能够比较直接地判断产品的留存率（即用户粘性）。</p><h3 id="ARPU-Average-Revenue-Per-User-每用户平均收益"><a href="#ARPU-Average-Revenue-Per-User-每用户平均收益" class="headerlink" title="ARPU(Average Revenue Per User) 每用户平均收益"></a>ARPU(Average Revenue Per User) 每用户平均收益</h3><p>目前 ARPU 这个概念在许多行业都有着广泛的应用，特别是在互联网游戏产业里面，随着免费游戏的兴起，ARPU 日渐成为游戏运营商着重关注的元素。</p><p>一般来说，不同的行业乃至不同的企业都有自己专属的 ARPU 计算方式。</p><p>常用计算公式：每用户平均收益 = 总收益 ÷ 总用户数</p><h2 id="广告相关"><a href="#广告相关" class="headerlink" title="广告相关"></a>广告相关</h2><h3 id="eCPM（Effective-Cost-Per-Mille）-每千次展示收益"><a href="#eCPM（Effective-Cost-Per-Mille）-每千次展示收益" class="headerlink" title="eCPM（Effective Cost Per Mille） 每千次展示收益"></a>eCPM（Effective Cost Per Mille） 每千次展示收益</h3><p>eCPM 是一个主要面向产品方的指标。</p><p>指的是在产品（网页、应用等等）中展示某广告 1000 次所带来的收益。</p><p>计算公式：每千次展示收益 = 总收益 ÷ 广告展示总次数 × 1000</p><blockquote><p>只要是有效展示就行，可以说是很简单粗暴的变现方式了…</p></blockquote><h3 id="CPM"><a href="#CPM" class="headerlink" title="CPM"></a>CPM</h3><p>「Cost Per Mille / Cost Per Thousand Impressions（每千次印象成本）」</p><p>CPM 是一种主要面向广告主的广告计费模式。</p><p>指的是广告投放过程中，平均每向 1000 人展示某广告 1 次需要的成本。一般同一 IP 在 24 小时内最多只有一次有效展示。</p><p>计算公式：每千次印象成本 = 总成本 ÷ 广告达到人数 × 1000</p><blockquote><p>你可以不看，但是我这个广告一定要播！</p></blockquote><h3 id="CPC（Cost-Per-Click）-每点击成本"><a href="#CPC（Cost-Per-Click）-每点击成本" class="headerlink" title="CPC（Cost Per Click） 每点击成本"></a>CPC（Cost Per Click） 每点击成本</h3><p>CPC 是一种主要面向广告主的广告计费模式。</p><p>指的是在广告投放中，广告主仅为用户的有效点击行为付费，而不再为广告的展示次数付费。</p><p>计算公式：每点击成本 = 总成本 ÷ 点击数</p><blockquote><p>不点不给钱！</p></blockquote><h3 id="CPA（Cost-Per-Action）-每行动成本"><a href="#CPA（Cost-Per-Action）-每行动成本" class="headerlink" title="CPA（Cost Per Action） 每行动成本"></a>CPA（Cost Per Action） 每行动成本</h3><p>CPA 是一种主要面向广告主的广告计费模式。</p><p>CPA 顾名思义是按照用户的行为（Action）作为指标来计费，这个行为可以是注册、咨询或加入购物车等等。</p><p>意思就是用户点击了广告还不算，需要用户有注册成功之类的行为才行，不过这种模式下广告费也相对较高。</p><blockquote><p>这是一个不受产品方待见的模式，条件太苛刻了…</p></blockquote><h3 id="CPS-Cost-Per-Sale-每销售成本"><a href="#CPS-Cost-Per-Sale-每销售成本" class="headerlink" title="CPS(Cost Per Sale) 每销售成本"></a>CPS(Cost Per Sale) 每销售成本</h3><p>CPS 是一种面向广告主的广告计费模式。</p><p>在该模式下，广告主的商品成功销售出去之后，产品方才可以获取到一定比例的佣金（提成）。</p><blockquote><p>这么说来似乎有点销售的意思（吃提成）</p></blockquote><h3 id="CPP（Cost-Per-Purchase）每购买成本"><a href="#CPP（Cost-Per-Purchase）每购买成本" class="headerlink" title="CPP（Cost Per Purchase）每购买成本"></a>CPP（Cost Per Purchase）每购买成本</h3><p>CPP 是一种面向广告主的广告计费模式。</p><p>在该模式下，用户点击广告并成功进行交易后，广告主按照销售笔数付给产品方广告费用。</p><blockquote><p>要注意了，CPP 是按照销售笔数来算钱的</p></blockquote><h3 id="CPR（Cost-Per-Response）每回应成本"><a href="#CPR（Cost-Per-Response）每回应成本" class="headerlink" title="CPR（Cost Per Response）每回应成本"></a>CPR（Cost Per Response）每回应成本</h3><p>CPR 是一种面向广告主的广告计费模式，这种模式的特点为：及时反应、直接互动、准确记录。</p><p>在 CPR 模式下，广告展示后，还需要用户给予广告主回应才算有效。所谓回应，一般是拨打电话之类的形式。例如电视购物广告，一般在固定时段播出，当用户拨打了广告中的电话之后才算作有效传播。</p><p>这种模式要求相对较高，也挺不受待见的，这广告费太难赚了…</p><blockquote><p>又想起了被电视购物广告支配的日子..</p></blockquote><h3 id="PPC（Pay-Per-Click）点击付费广告"><a href="#PPC（Pay-Per-Click）点击付费广告" class="headerlink" title="PPC（Pay Per Click）点击付费广告"></a>PPC（Pay Per Click）点击付费广告</h3><p>PPC 是大公司最常用的网络广告形式，这种方法费用很高，但效果也很好，比如百度竞价、搜狐和新浪首页上的 Banner 广告。</p><p>计价公式：起价 + (点击数 × 每次点击的价格)</p><p>越是著名的搜索引擎，起价越高，最高可达数万甚至数十万，而每次点击的价格在 0.30 元左右。</p><p>提供点击付费的网站非常多，主要有各大门户网站(如搜狐、新浪)和搜索引擎（Google 和百度），以及其他浏览量较大的网站，比如提供软件下载的华军等等。</p><blockquote><p>就是那种在搜索引擎搜素关键词，然后在展示在搜索结果前面的那种广告…</p></blockquote><h3 id="PPS（Pay-Per-Sale）-按销售付费"><a href="#PPS（Pay-Per-Sale）-按销售付费" class="headerlink" title="PPS（Pay Per Sale） 按销售付费"></a>PPS（Pay Per Sale） 按销售付费</h3><p>PPS 广告是根据网络广告所产生的直接销售数量而付费的一种定价模式。</p><p>PPS 和 CPS 基本一个意思，类似于淘宝客这类的服务。广义上不仅仅是指互联网广告范畴，应包括所有形式的基于成功销售而收取一定比例佣金的商业合作方式。</p><h2 id="网站相关"><a href="#网站相关" class="headerlink" title="网站相关"></a>网站相关</h2><h3 id="UV（Unique-Visitors）独立访客数"><a href="#UV（Unique-Visitors）独立访客数" class="headerlink" title="UV（Unique Visitors）独立访客数"></a>UV（Unique Visitors）独立访客数</h3><p>UV 表示某网站 1 天内（00:00 - 24:00）的独立访客总数。</p><p>所谓的“独立”访客，是以浏览器的 Cookie 为依据的，只要 Cookie 相同，那么就算更换了 IP 也都将被视为同一个访客，且当天无论访问多少次 UV 都只会加 1 个。</p><blockquote><p>通常是一部手机（电脑）一个坑~</p></blockquote><h3 id="PV（Page-Views）页面浏览量"><a href="#PV（Page-Views）页面浏览量" class="headerlink" title="PV（Page Views）页面浏览量"></a>PV（Page Views）页面浏览量</h3><p>PV 表示某页面在一定统计周期内的总浏览量。</p><p>在一定周期内，用户每次打开或刷新该页面都将被视为 1 次浏览。</p><blockquote><p>刷新一下多一个真好玩~</p></blockquote><h3 id="IP（Internet-Protocol）独立-IP-数"><a href="#IP（Internet-Protocol）独立-IP-数" class="headerlink" title="IP（Internet Protocol）独立 IP 数"></a>IP（Internet Protocol）独立 IP 数</h3><p>IP 表示 1 天内（00:00 - 24:00）访问某网站的 IP 总数。</p><p>该指标以广域网 IP 为依据，同一 IP 的设备无论访问多少次都只算一个计数，也就是说，连接同一路由器的不同设备在同一天内多次访问该网站，在正常情况下都只会增加一个 IP 计数。</p><blockquote><p>一条网线一个坑~</p></blockquote><h3 id="RV（Repeat-Visitors）重复访客数"><a href="#RV（Repeat-Visitors）重复访客数" class="headerlink" title="RV（Repeat Visitors）重复访客数"></a>RV（Repeat Visitors）重复访客数</h3><p>RV 指的是在一定统计周期内，访问某网站两次或两次以上的访客总数。</p><blockquote><p>俗称：回头客</p></blockquote><h3 id="TP（Time-On-Page）页面停留时间"><a href="#TP（Time-On-Page）页面停留时间" class="headerlink" title="TP（Time On Page）页面停留时间"></a>TP（Time On Page）页面停留时间</h3><p>TP 指的是（总的）用户在某个页面的平均停留时长。</p><p>TP 时长可以反映出某个页面对用户的吸引力，帮助判断用户的喜好。</p><blockquote><p>能看完这篇文章的话 TP 应该能有 5 分钟吧</p></blockquote><h3 id="TS（Time-On-Site）-网站停留时间"><a href="#TS（Time-On-Site）-网站停留时间" class="headerlink" title="TS（Time On Site） 网站停留时间"></a>TS（Time On Site） 网站停留时间</h3><p>TS 指的是（总的）用户在某网站（包括了该网站下的所有页面）的平均停留时长。</p><blockquote><p>反正视频网站的 TS 肯定都挺长的</p></blockquote><h3 id="SD（Session-Duration-）平均会话时长"><a href="#SD（Session-Duration-）平均会话时长" class="headerlink" title="SD（Session Duration ）平均会话时长"></a>SD（Session Duration ）平均会话时长</h3><p>SD 是在 Google Analytics 中使用的一个指标，用来统计网站的平均停留时长。</p><p>SD 的作用类似于 Time On Site，但是这两者的计算方式不一样。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;由于广告行业有众多的知识点，所以记录一篇文章用以了解相关的专业名词和术语，并且加深了解的印象。&lt;/p&gt;
    
    </summary>
    
    
      <category term="广告行业" scheme="http://blog.crazylaw.cn/categories/%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%9A/"/>
    
    
      <category term="广告行业" scheme="http://blog.crazylaw.cn/tags/%E5%B9%BF%E5%91%8A%E8%A1%8C%E4%B8%9A/"/>
    
  </entry>
  
  <entry>
    <title>【Topon】- Day 1</title>
    <link href="http://blog.crazylaw.cn/2022/04/11/%E5%85%AC%E5%8F%B8/Topon-day1/"/>
    <id>http://blog.crazylaw.cn/2022/04/11/%E5%85%AC%E5%8F%B8/Topon-day1/</id>
    <published>2022-04-11T07:27:40.000Z</published>
    <updated>2022-05-27T11:15:23.407Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于入职了新公司，所以记录一下每天学习到内容，包括但不局限于技术，运营，业务等相关的知识。</p><p>今天是入职新公司的第一天，记录一下今天处理了的事情。</p><a id="more"></a><h2 id="上午"><a href="#上午" class="headerlink" title="上午"></a>上午</h2><p>今天，<code>10:30</code>(提前了20分钟)来到公司，一面的面试官来到前台，到我来到了组里选择座位。</p><p>在座位上通过钉钉填写了入职表格，打开了自己带过来的笔记本电脑，加入钉钉的群组，加入微信群组，静坐了小一会儿之后。</p><p>时间来到了<code>11:00</code>，于是上午到第一场培训开始了，就是 <code>入职培训</code></p><p>主要讲解了公司业务，考勤制度，薪资构成，团建活动，报销，禁令等基础事项。</p><h2 id="中午"><a href="#中午" class="headerlink" title="中午"></a>中午</h2><p>和组内的同事们一起下去觅食了，吃完之后回到公司进行小憩一会儿。</p><h2 id="下午"><a href="#下午" class="headerlink" title="下午"></a>下午</h2><p><code>13:30</code> 午休结束，然后开始，自行浏览钉钉的历史聊天记录，和文件以及通知公告，HR协助申请了企业邮箱。</p><p>静坐了一小会之后，在<code>15:40</code>的时候见到了部门负责人（但是并非二面负责人，看来二面的面试官的技术团队负责人。）接下来就一面面试官就准备带我去认识一下周围的同事，社恐的我，多少有点紧张（慢慢熟悉吧，😢）</p><p><code>16:00</code> 开始介绍公司业务，部门业务，重点讲解了一下部门业务。</p><p>当下部门的业务主要包含几个模块，分别为:</p><ul><li><code>ADX</code>         核心广告B2B竞价服务</li><li><code>直投</code>         直投竞价服务</li><li><code>EMR</code>         阿里云数仓</li><li><code>GP（DGP）</code>    deep greenplum(ap+tp非主流分支)</li><li><code>BI</code>          BI服务，或者也可以叫为数据中台服务，类似data-service，用于防止业务层直连数仓</li><li><code>Job</code>         分布式（主-从）的拉取各平台的服务（穿山甲b/腾讯t/facebook）</li><li><code>Other</code>       其他</li></ul><p>并且解答了一些在介绍业务的时候我的疑惑，例如为何要有2个数仓？以及冷热计算分离为什么不考虑在其中之类的问题。</p><p>其实在我看来，GP的存在就是利用数仓直接处理一些实时计算的问题，所以没有引入一些类似flink的流计算，只有基于<code>EMR</code>的利用spark的这些离线计算服务。</p><p>这里所有的BI服务，其实并不是常规的BI系统，仅仅只是封多一层API提供外露服务，提供给<code>业务层</code>的同事调用。</p><p>在讲解的过程中，发现了有很多广告行业的的专业名词我都还不是很清楚，所以接下来，可能需要去了解一下广告行业的一些专业名词，例如<code>头部竞价</code>，<code>ad network</code>等等。</p><p>所以接下来，需要需要去了解一些专业的广告行业的文章，我也会记录下来我在广告行业摄取到的所有的知识点，分享给大家。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;由于入职了新公司，所以记录一下每天学习到内容，包括但不局限于技术，运营，业务等相关的知识。&lt;/p&gt;
&lt;p&gt;今天是入职新公司的第一天，记录一下今天处理了的事情。&lt;/p&gt;
    
    </summary>
    
    
      <category term="公司" scheme="http://blog.crazylaw.cn/categories/%E5%85%AC%E5%8F%B8/"/>
    
    
      <category term="公司" scheme="http://blog.crazylaw.cn/tags/%E5%85%AC%E5%8F%B8/"/>
    
  </entry>
  
  <entry>
    <title>【Mac】Mac安装软件流程</title>
    <link href="http://blog.crazylaw.cn/2022/03/29/Mac/Mac%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%B5%81%E7%A8%8B/"/>
    <id>http://blog.crazylaw.cn/2022/03/29/Mac/Mac%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E6%B5%81%E7%A8%8B/</id>
    <published>2022-03-29T08:35:30.000Z</published>
    <updated>2022-04-11T10:31:25.337Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近，准备重新打造我的mac电脑。</p><a id="more"></a><h2 id="iterm2"><a href="#iterm2" class="headerlink" title="iterm2"></a>iterm2</h2><p><img src="/images/%E6%9D%82/iterm2.png" alt="iterm2"></p><p><img src="/images/%E6%9D%82/iterm2-2.png" alt="iterm2"></p><p><img src="/images/%E6%9D%82/iterm2-fonts.png" alt="iterm2"></p><ul><li>安装zsh</li><li>安装 <a href="https://github.com/romkatv/powerlevel10k" target="_blank" rel="noopener">powerlevel10k</a> (安装方式参考官网文档)</li><li>替换 <code>.vimrc</code> 中的 <code>zsh主题</code>, <code>ZSH_THEME=&quot;powerlevel10k/powerlevel10k&quot;</code></li></ul><h2 id="vim相关"><a href="#vim相关" class="headerlink" title="vim相关"></a>vim相关</h2><p>我的个人vim配置 <a href="https://github.com/whiteCcinn/ccinn-vim" target="_blank" rel="noopener">ccinn-vim</a></p><p><img src="/images/%E6%9D%82/vim.png" alt="vim"></p><p>vim的插件管理选择有 <code>Vundle</code>, <code>vim-plug</code></p><h3 id="vim的目录插件"><a href="#vim的目录插件" class="headerlink" title="vim的目录插件"></a>vim的目录插件</h3><ul><li><a href="https://github.com/preservim/nerdtree" target="_blank" rel="noopener">scrooloose/nerdtree</a></li></ul><h3 id="vim的目录增强插件-字体和icon的下载和安装"><a href="#vim的目录增强插件-字体和icon的下载和安装" class="headerlink" title="vim的目录增强插件,字体和icon的下载和安装"></a>vim的目录增强插件,字体和icon的下载和安装</h3><p>可以在nerd目录下显示图标，其他字体等</p><ul><li><p><a href="https://github.com/ryanoasis/nerd-fonts" target="_blank" rel="noopener">ryanoasis/nerd-fonts</a></p></li><li><p><a href="https://github.com/ryanoasis/vim-devicons" target="_blank" rel="noopener">ryanoasis/vim-devicons</a></p></li></ul><blockquote><p>主体iterm2 的字体需要和nerd-fonts一致</p></blockquote><h3 id="vim-窗口状态栏"><a href="#vim-窗口状态栏" class="headerlink" title="vim 窗口状态栏"></a>vim 窗口状态栏</h3><ul><li><a href="https://github.com/vim-airline/vim-airline" target="_blank" rel="noopener">vim-airline/vim-airline</a></li><li><a href="https://github.com/vim-airline/vim-airline-themes" target="_blank" rel="noopener">vim-airline/vim-airline-themes</a></li></ul><h2 id="Clean-my-mac"><a href="#Clean-my-mac" class="headerlink" title="Clean my mac"></a>Clean my mac</h2><p>付费软件，清理电脑</p><h2 id="ntfs-for-mac"><a href="#ntfs-for-mac" class="headerlink" title="ntfs for mac"></a>ntfs for mac</h2><p>外置移动硬盘专用</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近，准备重新打造我的mac电脑。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Mac" scheme="http://blog.crazylaw.cn/categories/Mac/"/>
    
    
      <category term="Mac" scheme="http://blog.crazylaw.cn/tags/Mac/"/>
    
  </entry>
  
  <entry>
    <title>【DevOps】git命令场景用法</title>
    <link href="http://blog.crazylaw.cn/2022/03/19/DevOps/git%E5%91%BD%E4%BB%A4%E5%9C%BA%E6%99%AF%E7%94%A8%E6%B3%95/"/>
    <id>http://blog.crazylaw.cn/2022/03/19/DevOps/git%E5%91%BD%E4%BB%A4%E5%9C%BA%E6%99%AF%E7%94%A8%E6%B3%95/</id>
    <published>2022-03-19T06:35:30.000Z</published>
    <updated>2022-04-15T07:40:12.764Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>现在，git已经成为了大家的代码仓库管理的一个工具了。在日常工作，我们会遇到各种个样的git问题，因此，用一篇文章来累计记录，日常生活中，我们会遇到，但是不常用的命令。</p><a id="more"></a><h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><p>其实 <code>git</code> 的概念，我们开发者应该很多有会了，存在以下几个区域：</p><ul><li>工作区   <code>（你的任何改动）</code></li><li>暂存区   <code>（git add）</code></li><li>本地仓库 <code>（git commit）</code></li><li>远端代码仓库 <code>（git push）</code></li></ul><h2 id="合并"><a href="#合并" class="headerlink" title="合并"></a>合并</h2><p>我们一般说合并其实是有</p><h3 id=""><a href="#" class="headerlink" title=""></a></h3>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;现在，git已经成为了大家的代码仓库管理的一个工具了。在日常工作，我们会遇到各种个样的git问题，因此，用一篇文章来累计记录，日常生活中，我们会遇到，但是不常用的命令。&lt;/p&gt;
    
    </summary>
    
    
      <category term="DevOps" scheme="http://blog.crazylaw.cn/categories/DevOps/"/>
    
    
      <category term="DevOps" scheme="http://blog.crazylaw.cn/tags/DevOps/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- go map源码阅读</title>
    <link href="http://blog.crazylaw.cn/2022/03/10/Golang/go%20map%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>http://blog.crazylaw.cn/2022/03/10/Golang/go%20map%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</id>
    <published>2022-03-10T07:55:51.000Z</published>
    <updated>2022-03-22T08:54:11.241Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近发现同事去面试，发现很多时候会被问到<code>go map</code>的底层结构。今天我们来记录一下map的底层实现。</p><a id="more"></a><p>当下的源码阅读基于1.17</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A header for a Go map.</span></span><br><span class="line"><span class="keyword">type</span> hmap <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go.</span></span><br><span class="line"><span class="comment">// Make sure this stays in sync with the compiler's definition.</span></span><br><span class="line">count     <span class="keyword">int</span> <span class="comment">// # live cells == size of map.  Must be first (used by len() builtin)</span></span><br><span class="line">flags     <span class="keyword">uint8</span></span><br><span class="line">B         <span class="keyword">uint8</span>  <span class="comment">// log_2 of # of buckets (can hold up to loadFactor * 2^B items)</span></span><br><span class="line">noverflow <span class="keyword">uint16</span> <span class="comment">// approximate number of overflow buckets; see incrnoverflow for details</span></span><br><span class="line">hash0     <span class="keyword">uint32</span> <span class="comment">// hash seed</span></span><br><span class="line"></span><br><span class="line">buckets    unsafe.Pointer <span class="comment">// array of 2^B Buckets. may be nil if count==0.</span></span><br><span class="line">oldbuckets unsafe.Pointer <span class="comment">// previous bucket array of half the size, non-nil only when growing</span></span><br><span class="line">nevacuate  <span class="keyword">uintptr</span>        <span class="comment">// progress counter for evacuation (buckets less than this have been evacuated)</span></span><br><span class="line"></span><br><span class="line">extra *mapextra <span class="comment">// optional fields</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看到这是一个map的头部结构，其中有几个关键结构，分别是</p><ul><li><code>count</code> 当前map的元素个数</li><li><code>buckets</code> 桶的数量，一般是2^B个</li><li><code>oldbuckets</code> 扩容前的buckets</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// mapextra holds fields that are not present on all maps.</span></span><br><span class="line"><span class="keyword">type</span> mapextra <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// If both key and elem do not contain pointers and are inline, then we mark bucket</span></span><br><span class="line"><span class="comment">// type as containing no pointers. This avoids scanning such maps.</span></span><br><span class="line"><span class="comment">// However, bmap.overflow is a pointer. In order to keep overflow buckets</span></span><br><span class="line"><span class="comment">// alive, we store pointers to all overflow buckets in hmap.extra.overflow and hmap.extra.oldoverflow.</span></span><br><span class="line"><span class="comment">// overflow and oldoverflow are only used if key and elem do not contain pointers.</span></span><br><span class="line"><span class="comment">// overflow contains overflow buckets for hmap.buckets.</span></span><br><span class="line"><span class="comment">// oldoverflow contains overflow buckets for hmap.oldbuckets.</span></span><br><span class="line"><span class="comment">// The indirection allows to store a pointer to the slice in hiter.</span></span><br><span class="line">overflow    *[]*bmap</span><br><span class="line">oldoverflow *[]*bmap</span><br><span class="line"></span><br><span class="line"><span class="comment">// nextOverflow holds a pointer to a free overflow bucket.</span></span><br><span class="line">nextOverflow *bmap</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>简单来说，这个可以忽略。</p></blockquote><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A bucket for a Go map.</span></span><br><span class="line"><span class="keyword">type</span> bmap <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// tophash generally contains the top byte of the hash value</span></span><br><span class="line"><span class="comment">// for each key in this bucket. If tophash[0] &lt; minTopHash,</span></span><br><span class="line"><span class="comment">// tophash[0] is a bucket evacuation state instead.</span></span><br><span class="line">tophash [bucketCnt]<span class="keyword">uint8</span></span><br><span class="line"><span class="comment">// Followed by bucketCnt keys and then bucketCnt elems.</span></span><br><span class="line"><span class="comment">// <span class="doctag">NOTE:</span> packing all the keys together and then all the elems together makes the</span></span><br><span class="line"><span class="comment">// code a bit more complicated than alternating key/elem/key/elem/... but it allows</span></span><br><span class="line"><span class="comment">// us to eliminate padding which would be needed for, e.g., map[int64]int8.</span></span><br><span class="line"><span class="comment">// Followed by an overflow pointer.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>bmap有2个模块的属性是在编译注入的，在源码上没办法浏览。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line">                                                    ┌─────────────────────────────────────┐</span><br><span class="line">                                                    │bmap                                 │</span><br><span class="line">┌─────────────────────────────────────┐             │                                     │</span><br><span class="line">│bmap                                 │             │                                     │</span><br><span class="line">│                                     │             │                                     │</span><br><span class="line">│                                     │             │    ┌──────────────────────────────┐ │</span><br><span class="line">│                                     │             │    │tohash[bucketCnt]uint8        │ │</span><br><span class="line">│    ┌──────────────────────────────┐ │             │    │                              │ │</span><br><span class="line">│    │tohash[bucketCnt]uint8        │ │             │    │                              │ │</span><br><span class="line">│    │                              │ │             │    │                              │ │</span><br><span class="line">│    │                              │ │             │    └──────────────────────────────┘ │</span><br><span class="line">│    │                              │ │             │                                     │</span><br><span class="line">│    └──────────────────────────────┘ │             │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">│                                     │             │    +  byte-array                  + │</span><br><span class="line">│    ++++++++++++++++++++++++++++++++ │             │    +        (save key-value)      + │</span><br><span class="line">│    +  byte-array                  + │     ┌──────►│    +                              + │</span><br><span class="line">│    +        (save key-value)      + │     │       │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">│    +                              + │     │       │                                     │</span><br><span class="line">│    ++++++++++++++++++++++++++++++++ │     │       │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">│                                     │     │       │    +   point to growed bucket     + │</span><br><span class="line">│    ++++++++++++++++++++++++++++++++ │     │       │    +                              + │</span><br><span class="line">│    +   point to growed bucket     + │     │       │    +                              + │</span><br><span class="line">│    +                              + ├─────┘       │    +++++++++++++─┐+++++++++++++++++ │</span><br><span class="line">│    +                              + │             │                  │                  │</span><br><span class="line">│    ++++++++++++++++++++++++++++++++ │             │                  │                  │</span><br><span class="line">│                                     │             └──────────────────┼──────────────────┘</span><br><span class="line">│                                     │                                │</span><br><span class="line">└─────────────────────────────────────┘                                │</span><br><span class="line">                                                                       │</span><br><span class="line">                                                                       ▼</span><br><span class="line">                                                     ┌─────────────────────────────────────┐</span><br><span class="line">                                                     │bmap                                 │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │    ┌──────────────────────────────┐ │</span><br><span class="line">                                                     │    │tohash[bucketCnt]uint8        │ │</span><br><span class="line">                                                     │    │                              │ │</span><br><span class="line">                                                     │    │                              │ │</span><br><span class="line">                                                     │    │                              │ │</span><br><span class="line">                                                     │    └──────────────────────────────┘ │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">                                                     │    +  byte-array                  + │</span><br><span class="line">                                                     │    +        (save key-value)      + │</span><br><span class="line">                                                     │    +                              + │</span><br><span class="line">                                                     │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">                                                     │    +   point to growed bucket     + │</span><br><span class="line">                                                     │    +                              + │</span><br><span class="line">                                                     │    +                              + │</span><br><span class="line">                                                     │    ++++++++++++++++++++++++++++++++ │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     │                                     │</span><br><span class="line">                                                     └─────────────────────────────────────┘s</span><br></pre></td></tr></table></figure><p>相比于hmap，bucket的结构显得简单一些，<code>byte-array</code>是我们使用的map中的key和value就存储在这里。<code>高位哈希值</code>数组记录的是当前bucket中key相关的<code>索引</code></p><h2 id="mapassign-赋值过程"><a href="#mapassign-赋值过程" class="headerlink" title="mapassign 赋值过程"></a>mapassign 赋值过程</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 判断会否当前已经进行了写保护</span></span><br><span class="line"><span class="keyword">if</span> h.flags&amp;hashWriting != <span class="number">0</span> &#123;</span><br><span class="line">throw(<span class="string">"concurrent map writes"</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 2. 根据key计算哈希值</span></span><br><span class="line">hash := t.hasher(key, <span class="keyword">uintptr</span>(h.hash0))</span><br><span class="line"><span class="comment">// 3. 进行写保护</span></span><br><span class="line">h.flags ^= hashWriting</span><br><span class="line"><span class="comment">// 4. 计算hash的低位部分</span></span><br><span class="line">bucket := hash &amp; bucketMask(h.B)</span><br><span class="line"><span class="comment">// 5. 判断是否正在扩容，如果是，则数据迁移</span></span><br><span class="line"><span class="keyword">if</span> h.growing() &#123;</span><br><span class="line">growWork(t, h, bucket)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 6. 根据低位hash找到对应的bucket</span></span><br><span class="line">b := (*bmap)(add(h.buckets, bucket*<span class="keyword">uintptr</span>(t.bucketsize)))</span><br><span class="line"><span class="comment">// 7. 计算高位hash</span></span><br><span class="line">top := tophash(hash)</span><br><span class="line"><span class="comment">// 8. 从对应的bucket以及overflow buckets中找到对应的key的位置</span></span><br><span class="line"><span class="comment">// 9. 判断是否需要扩容，如果需要，则重新找到key的位置</span></span><br><span class="line"><span class="keyword">if</span> !h.growing() &amp;&amp; (overLoadFactor(h.count+<span class="number">1</span>, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) &#123;</span><br><span class="line">hashGrow(t, h)</span><br><span class="line"><span class="keyword">goto</span> again <span class="comment">// Growing the table invalidates everything, so try again</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 10. 拿着可以插入kv的内存地址进行赋值</span></span><br><span class="line"><span class="keyword">if</span> t.indirectkey() &#123;</span><br><span class="line">kmem := newobject(t.key)</span><br><span class="line">*(*unsafe.Pointer)(insertk) = kmem</span><br><span class="line">insertk = kmem</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> t.indirectelem() &#123;</span><br><span class="line">vmem := newobject(t.elem)</span><br><span class="line">*(*unsafe.Pointer)(elem) = vmem</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 11. 写保护检查，并且解除写保护</span></span><br><span class="line"><span class="keyword">if</span> h.flags&amp;hashWriting == <span class="number">0</span> &#123;</span><br><span class="line">throw(<span class="string">"concurrent map writes"</span>)</span><br><span class="line">&#125;</span><br><span class="line">h.flags &amp;^= hashWriting</span><br></pre></td></tr></table></figure><p>赋值过程就是：</p><ol><li>进行写保护</li><li>根据key计算哈希值</li><li>在低位哈希中找到bucket</li><li>计算高位hash</li><li>在bucket和overflow bucket桶中找到能插入key/value的位置</li><li>找到了就赋值</li><li>解除锁保护</li></ol><blockquote><p>其中有多次判断bucket是否需要扩容和是否正在扩容</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近发现同事去面试，发现很多时候会被问到&lt;code&gt;go map&lt;/code&gt;的底层结构。今天我们来记录一下map的底层实现。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Go源码剖析系列" scheme="http://blog.crazylaw.cn/categories/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
      <category term="Go源码剖析" scheme="http://blog.crazylaw.cn/tags/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- go time.Sleep源码阅读</title>
    <link href="http://blog.crazylaw.cn/2022/03/10/Golang/go%20time.Sleep%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>http://blog.crazylaw.cn/2022/03/10/Golang/go%20time.Sleep%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</id>
    <published>2022-03-10T07:55:51.000Z</published>
    <updated>2022-03-10T14:09:34.592Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于time.Sleep()会挂起我们的协程，我们来看一下它的底层原理。</p><a id="more"></a><h2 id="sleep-的实现"><a href="#sleep-的实现" class="headerlink" title="sleep 的实现"></a>sleep 的实现</h2><p>我们通常使用 <code>time.Sleep(1 * time.Second)</code> 来将 goroutine 暂时休眠一段时间。sleep 操作在底层实现也是基于 timer 实现的。</p><p>有一些比较有意思的地方，单独拿出来讲下。</p><p>我们固然也可以这么做来实现 goroutine 的休眠:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">timer := time.NewTimer(<span class="number">2</span> * time.Seconds)</span><br><span class="line">&lt;-timer.C</span><br></pre></td></tr></table></figure><p>这么做当然可以。但 golang 底层显然不是这么做的，因为这样有两个明显的额外性能损耗。</p><ul><li>每次调用 sleep 的时候，都要创建一个 timer 对象</li><li>需要一个 channel 来传递事件</li></ul><p>既然都可以放在 runtime 里面做。golang 里面做的更加干净：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// timeSleep puts the current goroutine to sleep for at least ns nanoseconds.</span></span><br><span class="line"><span class="comment">//go:linkname timeSleep time.Sleep</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">timeSleep</span><span class="params">(ns <span class="keyword">int64</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> ns &lt;= <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">gp := getg()</span><br><span class="line">t := gp.timer</span><br><span class="line"><span class="keyword">if</span> t == <span class="literal">nil</span> &#123;</span><br><span class="line">t = <span class="built_in">new</span>(timer)</span><br><span class="line">gp.timer = t</span><br><span class="line">&#125;</span><br><span class="line">t.f = goroutineReady</span><br><span class="line">t.arg = gp</span><br><span class="line">t.nextwhen = nanotime() + ns</span><br><span class="line"><span class="keyword">if</span> t.nextwhen &lt; <span class="number">0</span> &#123; <span class="comment">// check for overflow.</span></span><br><span class="line">t.nextwhen = maxWhen</span><br><span class="line">&#125;</span><br><span class="line">gopark(resetForSleep, unsafe.Pointer(t), waitReasonSleep, traceEvGoSleep, <span class="number">1</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>在G对象上存在一个timer属性，在G的生命周期里timer都是唯一存在，解决了重复新建对象的问题</li><li>如果不存在timer，则在第一次的时候创建timer</li></ul><p>并且把<code>t.f</code>设置成<code>goroutineReay</code>(这个意思是time到了时间之后设置一个触发函数，这个触发函数就是唤醒我们当前G任务)。</p><p>然后通过<code>gopark</code>来挂起当前的G任务</p><h2 id="定时器的触发机制"><a href="#定时器的触发机制" class="headerlink" title="定时器的触发机制"></a>定时器的触发机制</h2><p>共分两种方式，分别为 <code>调度器触发</code> 和 <code>监控线程sysmon</code> 触发，两者主要是通过调用函数 <code>checkTimers()</code> 来实现的。</p><p>主要有两个地方会检查计时器，一个是 <code>runtime.schedule</code>，另一个是 <code>findrunnable</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runtime/proc.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">schedule</span><span class="params">()</span></span> &#123; </span><br><span class="line"> _g_ := getg() </span><br><span class="line"> </span><br><span class="line">top: </span><br><span class="line"> pp := _g_.m.p.ptr() </span><br><span class="line"> pp.preempt = <span class="literal">false</span> </span><br><span class="line"> </span><br><span class="line"> <span class="comment">// 处理调度时的计时器触发 </span></span><br><span class="line"> checkTimers(pp, <span class="number">0</span>) </span><br><span class="line"> ... </span><br><span class="line"> </span><br><span class="line"> execute(gp, inheritTime) </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>另外一种是当前处理器 P 没有可执行的 Timer，且没有可执行的 G。那么按照调度模型，就会去<code>窃取其他计时器</code>和 <code>G</code>：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// runtime/proc.go</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">findrunnable</span><span class="params">()</span> <span class="params">(gp *g, inheritTime <span class="keyword">bool</span>)</span></span> &#123; </span><br><span class="line"> _g_ := getg() </span><br><span class="line"> </span><br><span class="line">top: </span><br><span class="line"> _p_ := _g_.m.p.ptr() </span><br><span class="line"> ... </span><br><span class="line"> now, pollUntil, _ := checkTimers(_p_, <span class="number">0</span>) </span><br><span class="line"> ... </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;由于time.Sleep()会挂起我们的协程，我们来看一下它的底层原理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Go源码剖析系列" scheme="http://blog.crazylaw.cn/categories/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
      <category term="Go源码剖析" scheme="http://blog.crazylaw.cn/tags/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- go channel源码阅读</title>
    <link href="http://blog.crazylaw.cn/2022/03/04/Golang/go%20channel%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/"/>
    <id>http://blog.crazylaw.cn/2022/03/04/Golang/go%20channel%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB/</id>
    <published>2022-03-03T16:43:51.000Z</published>
    <updated>2022-03-29T02:24:03.596Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>channel 是 Golang 中一个非常重要的特性，也是 <code>Golang CSP</code> 并发模型的一个重要体现。简单来说就是，goroutine 之间可以通过 channel 进行通信。</p><p>channel 在 Golang 如此重要，在代码中使用频率非常高，以至于不得不好奇其内部实现。本文将基于 <code>go 1.17</code> 的源码，分析 channel 的内部实现原理。</p><a id="more"></a><h2 id="channel-的基本使用"><a href="#channel-的基本使用" class="headerlink" title="channel 的基本使用"></a>channel 的基本使用</h2><p>在正式分析 channel 的实现之前，我们先看下 channel 的最基本用法，代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"><span class="keyword">import</span> <span class="string">"fmt"</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    c := <span class="built_in">make</span>(<span class="keyword">chan</span> <span class="keyword">int</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">        c &lt;- <span class="number">1</span> <span class="comment">// send to channel</span></span><br><span class="line">    &#125;()</span><br><span class="line"></span><br><span class="line">    x := &lt;-c <span class="comment">// recv from channel</span></span><br><span class="line"></span><br><span class="line">    fmt.Println(x)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在以上代码中，我们通过 <code>make(chan int)</code> 来创建了一个类型为 int 的 channel。<br>在一个 goroutine 中使用 <code>c &lt;- 1</code> 将数据发送到 channel 中。在主 goroutine 中通过 <code>x := &lt;- c</code> 从 channel 中读取数据并赋值给 x。</p><p>以上代码对应了 channel 的两种基本操作：</p><ul><li>send 操作 <code>c &lt;- 1</code> 表示发送数据到 channel</li><li>recv 操作 <code>x := &lt;- c</code> 表示从 channel 中接收数据。</li></ul><p>此外，channel 还分为<code>有缓存 channel</code> 和<code>无缓存 channel</code>。上述代码中，我们使用的是无缓冲的 channel。对于无缓冲的 channel，如果当前没有其他 goroutine 正在接收 channel 数据，则发送方会阻塞在发送语句处。</p><p>我们可以在 channel 初始化时指定缓冲区大小。例如，<code>make(chan int, 2)</code> 则指定缓冲区大小为 2。在缓冲区未满之前，发送方无阻塞地可以往 channel 发送数据，无需等待接收方准备好。而如果缓冲区已满，则发送方依然会阻塞。</p><h2 id="channel-对应的底层实现函数"><a href="#channel-对应的底层实现函数" class="headerlink" title="channel 对应的底层实现函数"></a>channel 对应的底层实现函数</h2><p>在探究 channel 源码之前，我们肯定首先需要先找到 channel 在 Golang 的具体实现在哪。因为我们在使用 channel 时，用的是 <code>&lt;- 符号</code>，并不能直接在 go 源码中找到其实现。但是 Golang 编译器必然会将 <code>&lt;-</code> 符号翻译成底层对应的实现。</p><p>我们可以使用 Go 自带的命令: <code>go tool compile -N -l -S hello.go</code>, 将代码翻译成对应的汇编指令。</p><p>或者，直接可以使用 <code>Compiler Explorer</code> 这个在线工具。对于上述示例代码可以直接在这个链接看其汇编结果: <a href="go.godbolt.org/z/3xw5Cj">go.godbolt.org/z/3xw5Cj</a>。如下图：</p><p><img src="/images/Go/%E6%BA%90%E7%A0%81/chansend1.png" alt="chansend1"></p><blockquote><p>chansend1</p></blockquote><p><img src="/images/Go/%E6%BA%90%E7%A0%81/chanrevc1.png" alt="chanrevc1"></p><blockquote><p>chanrevc1</p></blockquote><p>通过仔细查看以上示例代码对应的汇编指令，可以发现以下的对应关系：</p><p>channel 的构造语句 <code>make(chan int)</code>, 对应的是 <code>runtime.makechan</code> 函数<br>发送语句 <code>c &lt;- 1</code>, 对应的是 <code>runtime.chansend1</code> 函数<br>接收语句 <code>x := &lt;- c</code>, 对应的是 <code>runtime.chanrecv1</code> 函数<br>以上几个函数的实现都位于 go 源码中的 <code>runtime/chan.go</code> 代码文件中。我们接下来针对这几个函数，探究下 channel 的实现。</p><h2 id="channel-的构造"><a href="#channel-的构造" class="headerlink" title="channel 的构造"></a>channel 的构造</h2><p>channel 的构造语句 <code>make(chan int)</code>，将会被 golang 编译器翻译为 <code>runtime.makechan</code> 函数, 其函数签名如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">makechan</span><span class="params">(t *chantype, size <span class="keyword">int</span>)</span> *<span class="title">hchan</span></span></span><br></pre></td></tr></table></figure><p>其中，<code>t *chantype</code> 即构造 channel 时传入的元素类型。<code>size int</code> 即用户指定的 channel 缓冲区大小，不指定则为 0。该函数的返回值是 <code>*hchan</code>。hchan 则是 channel 在 golang 中的内部实现。其定义如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> hchan <span class="keyword">struct</span> &#123;</span><br><span class="line">qcount   <span class="keyword">uint</span>           <span class="comment">// buffer 中已放入的元素个数</span></span><br><span class="line">dataqsiz <span class="keyword">uint</span>           <span class="comment">// 用户构造 channel 时指定的 buf 大小</span></span><br><span class="line">buf      unsafe.Pointer <span class="comment">// buffer</span></span><br><span class="line">elemsize <span class="keyword">uint16</span>         <span class="comment">// buffer 中每个元素的大小</span></span><br><span class="line">closed   <span class="keyword">uint32</span>         <span class="comment">// channel 是否关闭，== 0 代表未 closed</span></span><br><span class="line">elemtype *_type         <span class="comment">// channel 元素的类型信息</span></span><br><span class="line">sendx    <span class="keyword">uint</span>           <span class="comment">// buffer 中已发送的索引位置 send index</span></span><br><span class="line">recvx    <span class="keyword">uint</span>           <span class="comment">// buffer 中已接收的索引位置 receive index</span></span><br><span class="line">recvq    waitq          <span class="comment">// 等待接收的 goroutine  list of recv waiters</span></span><br><span class="line">sendq    waitq          <span class="comment">// 等待发送的 goroutine list of send waiters</span></span><br><span class="line"></span><br><span class="line">lock mutex</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>hchan 中的所有属性大致可以分为三类：</p><ul><li>buffer 相关的属性。例如 <code>buf</code>、<code>dataqsiz</code>、<code>qcount</code> 等。 当 channel 的缓冲区大小不为 0 时，buffer 中存放了待接收的数据。使用 <code>ring buffer</code> 实现。</li><li>waitq 相关的属性，可以理解为是一个 FIFO 的标准队列。其中 <code>recvq</code> 中是正在等待接收数据的 goroutine，<code>sendq</code> 中是等待发送数据的 goroutine。waitq 使用<code>双向链表</code>实现。</li><li>其他属性，例如 lock、elemtype、closed。</li></ul><p>通过简单分析 hchan 的属性，我们可以知道其中有两个重要的组件，<code>buffer</code> 和 <code>waitq</code>。hchan 所有行为和实现都是围绕这两个组件进行的。</p><h2 id="向-channel-中发送数据"><a href="#向-channel-中发送数据" class="headerlink" title="向 channel 中发送数据"></a>向 channel 中发送数据</h2><p>channel 的发送和接收流程很相似，我们先分析下 channel 的发送过程 (如 <code>c &lt;- 1</code>), 对应于 <code>runtime.chansend</code> 函数的实现。</p><p>在尝试向 channel 中发送数据时，如果 <code>recvq</code> 队列不为空，则首先会从 <code>recvq</code> 中头部取出一个等待接收数据的 goroutine 出来。并将数据直接发送给该 goroutine。代码如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">lock(&amp;c.lock)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> c.closed != <span class="number">0</span> &#123;</span><br><span class="line">unlock(&amp;c.lock)</span><br><span class="line"><span class="built_in">panic</span>(plainError(<span class="string">"send on closed channel"</span>))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> sg := c.recvq.dequeue(); sg != <span class="literal">nil</span> &#123;</span><br><span class="line">send(c, sg, ep, <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123; unlock(&amp;c.lock) &#125;, <span class="number">3</span>)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>我们看到当我们整个send的过程是需要加锁处理的，并且也可以看到我们老生常谈的一个问题，当向cloesd的channel数据的时候，会导致panic产生</p></blockquote><p>recvq 中是正在等待接收数据的 goroutine。当某个 goroutine 使用 recv 操作 (例如，<code>x := &lt;- c</code>)，如果此时 channel 的缓存中没有数据，且没有其他 goroutine 正在等待发送数据 (即 <code>sendq</code> 为空)，会将该 goroutine 以及要接收的数据地址打包成 <code>sudog</code> 对象，并放入到 recvq 中。</p><p>继续接着讲上面的代码，如果此时 <code>recvq</code> 不为空，则调用 <code>send 函数</code>将数据拷贝到对应的 goroutine 的堆栈上。</p><p>这个时候<code>不经过</code>我们的<code>环形缓存！！！</code></p><p>send 函数的实现主要包含两点：</p><ol><li><code>memmove(dst, src, t.size)</code> 进行数据的转移，本质上就是一个内存拷贝。</li><li><code>goready(gp, skip+1)</code> goready 的作用是唤醒对应的 goroutine。</li></ol><p>而如果 <code>recvq</code> 队列为空，则说明此时<code>没有等待接收</code>数据的 goroutine，那么此时 channel 会尝试把数据放到缓存中。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> c.qcount &lt; c.dataqsiz &#123;</span><br><span class="line"><span class="comment">// Space is available in the channel buffer. Enqueue the element to send.</span></span><br><span class="line">qp := chanbuf(c, c.sendx)</span><br><span class="line"><span class="keyword">if</span> raceenabled &#123;</span><br><span class="line">racenotify(c, c.sendx, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br><span class="line">typedmemmove(c.elemtype, qp, ep)</span><br><span class="line">c.sendx++</span><br><span class="line"><span class="keyword">if</span> c.sendx == c.dataqsiz &#123;</span><br><span class="line">c.sendx = <span class="number">0</span></span><br><span class="line">&#125;</span><br><span class="line">c.qcount++</span><br><span class="line">unlock(&amp;c.lock)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码的作用其实非常简单，就是把数据放到 buffer 中而已。此过程涉及了 <code>ring buffer</code> 的操作，其中 <code>dataqsiz</code> 代表用户指定的 channel 的 buffer 大小，如果不指定则默认为 0。</p><p>如果用户使用的是无缓冲 channel 或者此时 buffer 已满，则 <code>c.qcount &lt; c.dataqsiz</code> 条件不会满足, 以上流程也并不会执行到。此时会将当前的 goroutine 以及要发送的数据放入到 <code>sendq</code> 队列中，同时会切出该 goroutine</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Block on the channel. Some receiver will complete our operation for us.</span></span><br><span class="line">gp := getg()</span><br><span class="line">mysg := acquireSudog()</span><br><span class="line">mysg.releasetime = <span class="number">0</span></span><br><span class="line"><span class="keyword">if</span> t0 != <span class="number">0</span> &#123;</span><br><span class="line">mysg.releasetime = <span class="number">-1</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// No stack splits between assigning elem and enqueuing mysg</span></span><br><span class="line"><span class="comment">// on gp.waiting where copystack can find it.</span></span><br><span class="line">mysg.elem = ep</span><br><span class="line">mysg.waitlink = <span class="literal">nil</span></span><br><span class="line">mysg.g = gp</span><br><span class="line">mysg.isSelect = <span class="literal">false</span></span><br><span class="line">mysg.c = c</span><br><span class="line">gp.waiting = mysg</span><br><span class="line">gp.param = <span class="literal">nil</span></span><br><span class="line">c.sendq.enqueue(mysg)</span><br><span class="line"><span class="comment">// Signal to anyone trying to shrink our stack that we're about</span></span><br><span class="line"><span class="comment">// to park on a channel. The window between when this G's status</span></span><br><span class="line"><span class="comment">// changes and when we set gp.activeStackChans is not safe for</span></span><br><span class="line"><span class="comment">// stack shrinking.</span></span><br><span class="line">atomic.Store8(&amp;gp.parkingOnChan, <span class="number">1</span>)</span><br><span class="line"><span class="comment">// 将 goroutine 转入 waiting 状态</span></span><br><span class="line">gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, <span class="number">2</span>)</span><br><span class="line"><span class="comment">// Ensure the value being sent is kept alive until the</span></span><br><span class="line"><span class="comment">// receiver copies it out. The sudog has a pointer to the</span></span><br><span class="line"><span class="comment">// stack object, but sudogs aren't considered as roots of the</span></span><br><span class="line"><span class="comment">// stack tracer.</span></span><br><span class="line">KeepAlive(ep)</span><br><span class="line"><span class="comment">// 确保正在发送的值保持活动状态，直到接收者将其复制出来。sudog有一个指向堆栈对象的指针，但是sudog不被认为是堆栈跟踪程序的根。</span></span><br><span class="line"><span class="comment">// 总而言之：防止被GC</span></span><br></pre></td></tr></table></figure><p>调用 gopark 后，对于用户侧来看，该向 channel 发送数据的代码语句会进行阻塞。</p><p>以上过程就是 channel 的发送语句 (如，<code>c &lt;- 1</code>) 的内部工作流程，同时整个发送过程都使用 <code>c.lock</code> 进行加锁，保证并发安全。</p><p>简单来说，整个流程如下：</p><ol><li>检查 recvq 是否为空，如果不为空，则从 recvq 头部<code>取一个 goroutine</code>，将数据发送过去，并<code>唤醒对应的 goroutine</code> 即可</li><li>如果 recvq 为空，则将数据放入到 buffer 中</li><li>如果 buffer 已满，则将要发送的数据和当前 goroutine 打包成 <code>sudog</code> 对象放入到 <code>sendq</code> 中。并将当前 goroutine 置为 waiting 状态。</li></ol><p>从 channel 中接收数据的过程基本与发送过程类似，此处不再赘述了。</p><p>这里需要注意的是，channel 的<code>整个发送过程</code>和<code>接收过程</code>都使用 <code>runtime.mutex</code> 进行加锁。<code>runtime.mutex</code> 是 runtime 相关源码中常用到的一个<code>轻量级锁</code>。整个过程并不是最高效的 <code>lockfree</code> 的做法。</p><p>golang 在这里有个 <a href="https://github.com/golang/go/issues/8899" target="_blank" rel="noopener">issue:go/issues#8899</a>，给出了 <code>lockfree</code> 的 <code>channel</code> 的方案。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;channel 是 Golang 中一个非常重要的特性，也是 &lt;code&gt;Golang CSP&lt;/code&gt; 并发模型的一个重要体现。简单来说就是，goroutine 之间可以通过 channel 进行通信。&lt;/p&gt;
&lt;p&gt;channel 在 Golang 如此重要，在代码中使用频率非常高，以至于不得不好奇其内部实现。本文将基于 &lt;code&gt;go 1.17&lt;/code&gt; 的源码，分析 channel 的内部实现原理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Go源码剖析系列" scheme="http://blog.crazylaw.cn/categories/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%E7%B3%BB%E5%88%97/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
      <category term="Go源码剖析" scheme="http://blog.crazylaw.cn/tags/Go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- Sync包详解</title>
    <link href="http://blog.crazylaw.cn/2022/03/04/Golang/sync%E5%8C%85%E8%AF%A6%E8%A7%A3/"/>
    <id>http://blog.crazylaw.cn/2022/03/04/Golang/sync%E5%8C%85%E8%AF%A6%E8%A7%A3/</id>
    <published>2022-03-03T16:43:51.000Z</published>
    <updated>2022-04-15T07:40:12.764Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们直到sync包给我们提供了一系列并发安全的数据结构。之前有见过一次sync-map，但是这一次刚好复习整理一下sync包的知识点。</p><a id="more"></a><h2 id="Sync"><a href="#Sync" class="headerlink" title="Sync"></a>Sync</h2><ul><li>Sync.Map</li><li>Sync.Once</li><li>Sync.Pool</li><li>Sync.Cond</li><li>Sync.WaitGroup</li></ul><h2 id="sync-Map"><a href="#sync-Map" class="headerlink" title="sync.Map"></a>sync.Map</h2><ul><li>sync.Map主要针对于Map对于并发读写不支持的场景下提出实现的，其原理是通过对map的写操作进行加锁：Sync.RWMutex</li><li>同时sync.Map实现了读写分离，当对map进行读操作时，通过读read Map, 当read Map中不存在是去dirty map中读取</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Map <span class="keyword">struct</span> &#123;</span><br><span class="line">me Mutex</span><br><span class="line">read atomic.Value  <span class="comment">// readOnly,读数据</span></span><br><span class="line">dirty <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]*entry <span class="comment">// 包含最新的写入数据，当missed达到一定的值时，将值赋给read</span></span><br><span class="line">misses <span class="keyword">int</span>  <span class="comment">// 计数作用，每次从read中读失败，则missed加一</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// readOnly的数据结构</span></span><br><span class="line"><span class="keyword">type</span> readOnly <span class="keyword">struct</span>&#123;</span><br><span class="line">m <span class="keyword">map</span>[<span class="keyword">interface</span>&#123;&#125;]*entry</span><br><span class="line">amended <span class="keyword">bool</span>  <span class="comment">// Map.dirty中的数据和这里的m中的数据不同时值为true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// entry的数据结构：</span></span><br><span class="line"><span class="keyword">type</span> entry <span class="keyword">struct</span> &#123;</span><br><span class="line">p unsafe.Pointer <span class="comment">// *interface&#123;&#125;</span></span><br><span class="line"><span class="comment">// 可见value是一个指针值，虽然read和dirty存在冗余情况，但由于是指针类型，存储空间不会太多</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>sync.Map相关问题</p><ul><li>sync.Map的核心实现：两个map,一个用于写，一个用于读，这样的设计思想可以类比于缓存与数据库</li><li>sync.Map的局限性：如果写远高于读，dirty -&gt; readOnly这个类似于刷新数据的频率较高，不如直接使用mutex + map的效率高</li><li>sync.Map的设计思想：保证高频率读的无锁结构，空间换时间的思想</li></ul><h2 id="sync-WaitGroup"><a href="#sync-WaitGroup" class="headerlink" title="sync.WaitGroup"></a>sync.WaitGroup</h2><ul><li>sync.WaitGroup常用于针对goroutine的并发执行，通过WaitGroup可以等待所有的go程序执行结束之后再执行之后的逻辑</li><li>WaitGroup对象内部有一个计数器，最初重0开始，提供了三个方法：Add(),Done(),Wait()用来控制计数器的数量。Add(n)把计数器设置为n,Done()每次把计数器减一，Wait()会阻塞代码的执行，直到计数器的值减到0为止。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;我们直到sync包给我们提供了一系列并发安全的数据结构。之前有见过一次sync-map，但是这一次刚好复习整理一下sync包的知识点。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/categories/Golang/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>【大数据】- 在公司从0到1落地flink流计算任务</title>
    <link href="http://blog.crazylaw.cn/2022/02/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9C%A8%E5%85%AC%E5%8F%B8%E4%BB%8E0%E5%88%B01%E8%90%BD%E5%9C%B0flink%E6%B5%81%E8%AE%A1%E7%AE%97%E4%BB%BB%E5%8A%A1/"/>
    <id>http://blog.crazylaw.cn/2022/02/15/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%9C%A8%E5%85%AC%E5%8F%B8%E4%BB%8E0%E5%88%B01%E8%90%BD%E5%9C%B0flink%E6%B5%81%E8%AE%A1%E7%AE%97%E4%BB%BB%E5%8A%A1/</id>
    <published>2022-02-15T03:10:40.000Z</published>
    <updated>2022-02-17T01:14:41.637Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在公司落地一套flink，总结到目前为止做了的事情。</p><a id="more"></a><h2 id="开发环境的部署"><a href="#开发环境的部署" class="headerlink" title="开发环境的部署"></a>开发环境的部署</h2><p>我们默认场景下，<code>flink</code>使用<code>hive-catalog</code>，所以<code>hive</code>安装在这里。</p><p>Hive使用<code>mysql</code>作为<code>外部数据存储</code>，所以这里使用<code>mysql</code></p><p>对于flink的开发，如果我想要一整套的本地的docker开发环境。</p><p>需要集成如下服务：</p><ul><li>hadoop</li><li>hive</li><li>flink</li><li>kafka</li><li>mysql</li></ul><p>所以做了一个<a href="https://github.com/whiteCcinn/flink-docker-compose" target="_blank" rel="noopener">flink-docker-compose</a></p><p>在该项目中，由于不是采用<code>CDH</code>来集成的，都是一个个源码包手动安装的。所以需要下载源码包。</p><p>目前的版本为：</p><ul><li>flink: 1.12.0_2.11</li><li>mysql: 5.6 （8.0-jdbc）</li><li>kafka: 2.12_2.11</li><li>maven: 3.6.3</li><li>jdk: 8/11 (默认jdk8)</li></ul><blockquote><p>本地环境的话，jdk需要自行处理好</p></blockquote><ul><li>hadoop: 3.1.1</li><li>hive: 3.1.0</li></ul><h3 id="一键下载源码包"><a href="#一键下载源码包" class="headerlink" title="一键下载源码包"></a>一键下载源码包</h3><p>为了方便方便大家下载，对应的镜像链接，也都集成在了<code>download.sh</code>中，如果需要利用<code>迅雷</code>等p2p加速下载软件，可以通过从中提取出来 <code>url</code> 进行下载。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./download.sh all</span><br></pre></td></tr></table></figure><h3 id="可设置的-env"><a href="#可设置的-env" class="headerlink" title="可设置的.env"></a>可设置的<code>.env</code></h3><p>利用<code>docker-compose</code>对 <code>.env</code>的支持，可以在当中设置<code>build image</code>的一些环境变量和参数</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Hadoop</span></span><br><span class="line">HADOOP_VERSION=3.1.1</span><br><span class="line"><span class="meta">#</span><span class="bash"> Hive</span></span><br><span class="line">HIVE_VERSION=3.1.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> Scala</span></span><br><span class="line">SCALA_VERSION=2.11</span><br><span class="line"><span class="meta">#</span><span class="bash"> Flink</span></span><br><span class="line">FLINK_VERSION=1.12.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> Kafka</span></span><br><span class="line">KAFKA_VERSION=2.4.0</span><br><span class="line"><span class="meta">#</span><span class="bash"> Zookeeper</span></span><br><span class="line">ZOOKEEPER_VERSION=3.5.6</span><br><span class="line"><span class="meta">#</span><span class="bash"> Mysql</span></span><br><span class="line">MYSQL_VERSION=5.6</span><br><span class="line">MYSQL_DATABASE=default</span><br><span class="line">MYSQL_PORT=3306</span><br><span class="line">MYSQL_ROOT_PASSWORD=lnhzjm/B4qrSc</span><br><span class="line">MYSQL_ENTRYPOINT_INITDB=./deploy/mysql/docker-entrypoint-initdb.d</span><br><span class="line">MYSQL_TIMEZONE=UTC</span><br></pre></td></tr></table></figure><h3 id="kafka的网络"><a href="#kafka的网络" class="headerlink" title="kafka的网络"></a>kafka的网络</h3><p>我们知道kafka的网络协议是<code>支持多端口</code>的，由于我们有时候flink是在本地，有时候是在容器中，所以我们希望我们的kafka集群，支持容器内的网络，也支持和我们物理机的网络。</p><p>这个时候，我们需要设置kafka的2套端口协议。所以你可以看到</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">kafka1:</span></span><br><span class="line">   <span class="attr">build:</span></span><br><span class="line">     <span class="attr">context:</span> <span class="string">./deploy/kafka</span></span><br><span class="line">     <span class="attr">args:</span></span><br><span class="line">       <span class="attr">scala_version:</span> <span class="string">$&#123;SCALA_VERSION&#125;</span></span><br><span class="line">       <span class="attr">kafka_version:</span> <span class="string">$&#123;KAFKA_VERSION&#125;</span></span><br><span class="line">   <span class="attr">container_name:</span> <span class="string">flink-kafka1</span></span><br><span class="line">   <span class="attr">ports:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'19092:19092'</span></span><br><span class="line">   <span class="attr">environment:</span></span><br><span class="line">     <span class="attr">KAFKA_PORT:</span> <span class="number">19092</span></span><br><span class="line">     <span class="attr">KAFKA_ADVERTISED_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://kafka1:19092</span></span><br><span class="line">     <span class="attr">KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:</span> <span class="string">PLAINTEXT:PLAINTEXT,EXTERNAL_PLAINTEXT:PLAINTEXT</span></span><br><span class="line">     <span class="attr">KAFKA_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://:19092</span></span><br><span class="line">     <span class="attr">KAFKA_ZOOKEEPER_CONNECT:</span> <span class="string">zookeeper:2181</span></span><br><span class="line">     <span class="attr">KAFKA_DEFAULT_REPLICATION_FACTOR:</span> <span class="number">3</span></span><br><span class="line">   <span class="attr">networks:</span></span><br><span class="line">     <span class="attr">flink-networks:</span></span><br><span class="line">       <span class="attr">ipv4_address:</span> <span class="number">192.168</span><span class="number">.6</span><span class="number">.211</span></span><br><span class="line">   <span class="attr">extra_hosts:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'zookeeper:192.168.6.215'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka1:192.168.6.211'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka2:192.168.6.212'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka3:192.168.6.213'</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">'kafka4:192.168.6.214'</span></span><br><span class="line">   <span class="attr">depends_on:</span></span><br><span class="line">     <span class="bullet">-</span> <span class="string">zookeeper</span></span><br></pre></td></tr></table></figure><p>看到这里的</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">KAFKA_ADVERTISED_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://kafka1:19092</span></span><br><span class="line"><span class="attr">KAFKA_LISTENER_SECURITY_PROTOCOL_MAP:</span> <span class="string">PLAINTEXT:PLAINTEXT,EXTERNAL_PLAINTEXT:PLAINTEXT</span></span><br><span class="line"><span class="attr">KAFKA_LISTENERS:</span> <span class="string">PLAINTEXT://:9092,EXTERNAL_PLAINTEXT://:19092</span></span><br></pre></td></tr></table></figure><p>这个就是决定我们的<code>2套协议</code>的关键所在，分别是对<code>9092（容器内）</code>和<code>19092(和物理机)</code>端口的支持。</p><p>但是设置完了这个，由于一般kafka-client会从可本机的可访问的<code>dns服务器</code>上寻找<code>host映射</code>，在连接的时候必备的流程。</p><p>在本地连接的时候，会通过<code>kafka1/kafka2</code>等hostname返回到client，client需要在本机找到所有的ip映射，所以我们需要设置一下<code>etc/hosts</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo "127.0.0.1 kafka1 kafka2 kafka3 kafka4" &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure><p>目前为止，我们所需要的环境变量已经处理完了。</p><h2 id="基于datastream-api的flink开发"><a href="#基于datastream-api的flink开发" class="headerlink" title="基于datastream-api的flink开发"></a>基于datastream-api的flink开发</h2><p>我们知道flink提供了3种API，分别是<code>datastream-api</code>,<code>table-api</code>,<code>sql-api</code></p><p><code>datastream</code>，也是flink的最原始的api，和flink集成一体，通过<code>datastream-api</code>，我们可以实现各种灵活的数据流处理。</p><p>按照我们以往对流计算数据的处理，在游戏公司中，一个游戏项目部署一个流计算的任务即为合理。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── README.md</span><br><span class="line">├── pom.xml</span><br><span class="line">└── src</span><br><span class="line">    └── main</span><br><span class="line">        ├── java</span><br><span class="line">        │   ├── deps</span><br><span class="line">        │   │   ├── oaYdSdk</span><br><span class="line">        │   │   │   ├── Youdu.java</span><br><span class="line">        │   │   │   └── test</span><br><span class="line">        │   │   │       └── YouduTest.java</span><br><span class="line">        │   │   └── util</span><br><span class="line">        │   │       ├── ParameterToolEnvironmentUtils.java</span><br><span class="line">        │   │       └── Util.java</span><br><span class="line">        │   └── org</span><br><span class="line">        │       └── cp</span><br><span class="line">        │           └── flink</span><br><span class="line">        │               ├── Bootstrap.java</span><br><span class="line">        │               ├── async</span><br><span class="line">        │               │   └── AsyncOaYdHttpClient.java</span><br><span class="line">        │               ├── events</span><br><span class="line">        │               │   ├── CommonEvent.java</span><br><span class="line">        │               │   ├── CommonEventHeader.java</span><br><span class="line">        │               │   ├── app_error</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_ban</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_client_loss</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_consume_gold</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_fcm_error</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_index_record</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_index_record_data</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   ├── log_role_create</span><br><span class="line">        │               │   │   ├── Event.java</span><br><span class="line">        │               │   │   ├── EventHeader.java</span><br><span class="line">        │               │   │   └── EventLog.java</span><br><span class="line">        │               │   └── t_log_market</span><br><span class="line">        │               │       ├── Event.java</span><br><span class="line">        │               │       ├── EventHeader.java</span><br><span class="line">        │               │       └── EventLog.java</span><br><span class="line">        │               ├── jobs</span><br><span class="line">        │               │   ├── alarm</span><br><span class="line">        │               │   │   ├── ErrorReport_10008.java</span><br><span class="line">        │               │   │   ├── Job_10002.java</span><br><span class="line">        │               │   │   ├── Job_10008.java</span><br><span class="line">        │               │   │   ├── Job_19.java</span><br><span class="line">        │               │   │   ├── README.md</span><br><span class="line">        │               │   │   └── handler</span><br><span class="line">        │               │   │       ├── AbstractHandler.java</span><br><span class="line">        │               │   │       ├── errorReport_10008</span><br><span class="line">        │               │   │       │   ├── Logic.java</span><br><span class="line">        │               │   │       │   ├── Logic_10012.java</span><br><span class="line">        │               │   │       │   ├── Logic_19.java</span><br><span class="line">        │               │   │       │   └── Logic_20.java</span><br><span class="line">        │               │   │       ├── job_10002</span><br><span class="line">        │               │   │       │   ├── LogIndexRecordDataHandler.java</span><br><span class="line">        │               │   │       │   ├── LogIndexRecordHandler.java</span><br><span class="line">        │               │   │       │   └── model</span><br><span class="line">        │               │   │       │       ├── log_index_record</span><br><span class="line">        │               │   │       │       │   └── StatisticsMcfx2Model.java</span><br><span class="line">        │               │   │       │       └── log_index_record_data</span><br><span class="line">        │               │   │       │           └── StatisticsMcfx1Model.java</span><br><span class="line">        │               │   │       ├── job_10008</span><br><span class="line">        │               │   │       │   ├── AppErrorHandler.java</span><br><span class="line">        │               │   │       │   ├── LogFcmErrorHandler.java</span><br><span class="line">        │               │   │       │   └── model</span><br><span class="line">        │               │   │       │       ├── app_error</span><br><span class="line">        │               │   │       │       │   └── StatisticsAppErrorModel.java</span><br><span class="line">        │               │   │       │       └── log_fcm_error</span><br><span class="line">        │               │   │       │           └── StatisticsFcmErrorModel.java</span><br><span class="line">        │               │   │       └── job_19</span><br><span class="line">        │               │   │           ├── LogBanHandler.java</span><br><span class="line">        │               │   │           ├── LogClientLossHandler.java</span><br><span class="line">        │               │   │           ├── LogConsumeGoldHandler.java</span><br><span class="line">        │               │   │           ├── LogRoleCreateHandler.java</span><br><span class="line">        │               │   │           ├── TLogMarketHandler.java</span><br><span class="line">        │               │   │           └── model</span><br><span class="line">        │               │   │               ├── log_ban</span><br><span class="line">        │               │   │               │   └── StatisticsModel.java</span><br><span class="line">        │               │   │               ├── log_client_loss</span><br><span class="line">        │               │   │               │   └── IpMonitorModel.java</span><br><span class="line">        │               │   │               ├── log_consume_gold</span><br><span class="line">        │               │   │               │   ├── StatisticsBindGoldModel.java</span><br><span class="line">        │               │   │               │   └── StatisticsUnBindGoldModel.java</span><br><span class="line">        │               │   │               ├── log_role_create</span><br><span class="line">        │               │   │               │   └── SingleServerRoleCreateModel.java</span><br><span class="line">        │               │   │               └── t_log_market</span><br><span class="line">        │               │   │                   ├── MarketTransactionLogByBuyerModel.java</span><br><span class="line">        │               │   │                   └── MarketTransactionLogBySellerModel.java</span><br><span class="line">        │               │   └── stream</span><br><span class="line">        │               │       └── README.md</span><br><span class="line">        │               ├── mock</span><br><span class="line">        │               │   ├── MockAppError.java</span><br><span class="line">        │               │   ├── MockLogFcmError.java</span><br><span class="line">        │               │   └── README.md</span><br><span class="line">        │               ├── serializer</span><br><span class="line">        │               │   ├── AbstractSerializer.java</span><br><span class="line">        │               │   └── log_role_create</span><br><span class="line">        │               │       └── LogRoleCreateDeSerializer.java</span><br><span class="line">        │               └── sinks</span><br><span class="line">        │                   ├── AsyncOaYdSdkHttpSink.java</span><br><span class="line">        │                   ├── MysqlItem.java</span><br><span class="line">        │                   └── MysqlSink.java</span><br><span class="line">        └── resources</span><br><span class="line">            ├── application-dev.properties</span><br><span class="line">            ├── application-local.properties</span><br><span class="line">            ├── application-pro.properties</span><br><span class="line">            ├── application.properties</span><br><span class="line">            ├── jobs</span><br><span class="line">            │   ├── org.cp.flink.jobs.alarm.ErrorReport_10008</span><br><span class="line">            │   │   ├── application-dev.properties</span><br><span class="line">            │   │   ├── application-local.properties</span><br><span class="line">            │   │   ├── application-pro.properties</span><br><span class="line">            │   │   └── application.properties</span><br><span class="line">            │   ├── org.cp.flink.jobs.alarm.Job_10002</span><br><span class="line">            │   │   ├── application-dev.properties</span><br><span class="line">            │   │   ├── application-local.properties</span><br><span class="line">            │   │   ├── application-pro.properties</span><br><span class="line">            │   │   └── application.properties</span><br><span class="line">            │   ├── org.cp.flink.jobs.alarm.Job_10008</span><br><span class="line">            │   │   ├── application-dev.properties</span><br><span class="line">            │   │   ├── application-local.properties</span><br><span class="line">            │   │   ├── application-pro.properties</span><br><span class="line">            │   │   └── application.properties</span><br><span class="line">            │   └── org.cp.flink.jobs.alarm.Job_19</span><br><span class="line">            │       ├── application-dev.properties</span><br><span class="line">            │       ├── application-local.properties</span><br><span class="line">            │       ├── application-pro.properties</span><br><span class="line">            │       └── application.properties</span><br><span class="line">            └── log4j2.properties</span><br></pre></td></tr></table></figure><p>这是我们早期的一个<code>代码层级结构</code>，所有的流计算任务基于一个flink项目下，<code>resources</code>下的配置根据当前需要提交的项目和环境来进行区分加载具体的配置，可以做到支持<code>多环境</code>,<code>多项目</code>下配置灵活配置。</p><p>我们看到 <code>org.cp.flink</code>目下，就是我们的所有flink代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">➜  flinkjob git:(master) ✗ tree -d src/main/java/org</span><br><span class="line">src/main/java/org</span><br><span class="line">└── cp</span><br><span class="line">    └── flink</span><br><span class="line">        ├── async</span><br><span class="line">        ├── events</span><br><span class="line">        │   ├── app_error</span><br><span class="line">        │   ├── log_ban</span><br><span class="line">        │   ├── log_client_loss</span><br><span class="line">        │   ├── log_consume_gold</span><br><span class="line">        │   ├── log_fcm_error</span><br><span class="line">        │   ├── log_index_record</span><br><span class="line">        │   ├── log_index_record_data</span><br><span class="line">        │   ├── log_role_create</span><br><span class="line">        │   └── t_log_market</span><br><span class="line">        ├── jobs</span><br><span class="line">        │   ├── alarm</span><br><span class="line">        │   │   └── handler</span><br><span class="line">        │   │       ├── job_10002</span><br><span class="line">        │   │       │   └── model</span><br><span class="line">        │   │       │       ├── log_index_record</span><br><span class="line">        │   │       │       └── log_index_record_data</span><br><span class="line">        │   │       ├── job_10008</span><br><span class="line">        │   │       │   └── model</span><br><span class="line">        │   │       │       ├── app_error</span><br><span class="line">        │   │       │       └── log_fcm_error</span><br><span class="line">        │   │       └── job_19</span><br><span class="line">        │   │           └── model</span><br><span class="line">        │   │               ├── log_ban</span><br><span class="line">        │   │               ├── log_client_loss</span><br><span class="line">        │   │               ├── log_consume_gold</span><br><span class="line">        │   │               ├── log_role_create</span><br><span class="line">        │   │               └── t_log_market</span><br><span class="line">        │   └── stream</span><br><span class="line">        ├── mock</span><br><span class="line">        ├── serializer</span><br><span class="line">        │   └── log_role_create</span><br><span class="line">        └── sinks</span><br></pre></td></tr></table></figure><p>我们先看到，<code>jobs</code>目录下的，分为了2种类型，我们平时用的流计算任务可以分为2种，一种是常规的<code>告警属性</code>，另一种是<code>产品属性(类似BI系统需要的实时数据)</code>。</p><p>我们看到<code>alarm/handler/job_xxx</code>就是我们具体的项目。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">src/main/java/org/cp/flink/jobs/alarm/</span></span><br><span class="line"><span class="string">├──</span> <span class="string">Job_10002.java</span></span><br><span class="line"><span class="string">├──</span> <span class="string">Job_10008.java</span></span><br><span class="line"><span class="string">├──</span> <span class="string">Job_19.java</span></span><br><span class="line"><span class="string">├──</span> <span class="string">README.md</span></span><br><span class="line"><span class="string">└──</span> <span class="string">handler</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">AbstractHandler.java</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">errorReport_10008</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">Logic.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">Logic_10012.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">Logic_19.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">└──</span> <span class="string">Logic_20.java</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">job_10002</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">LogIndexRecordDataHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">LogIndexRecordHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">└──</span> <span class="string">model</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">├──</span> <span class="string">log_index_record</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsMcfx2Model.java</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">└──</span> <span class="string">log_index_record_data</span></span><br><span class="line">    <span class="string">│</span>           <span class="string">└──</span> <span class="string">StatisticsMcfx1Model.java</span></span><br><span class="line">    <span class="string">├──</span> <span class="string">job_10008</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">AppErrorHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">├──</span> <span class="string">LogFcmErrorHandler.java</span></span><br><span class="line">    <span class="string">│</span>   <span class="string">└──</span> <span class="string">model</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">├──</span> <span class="string">app_error</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsAppErrorModel.java</span></span><br><span class="line">    <span class="string">│</span>       <span class="string">└──</span> <span class="string">log_fcm_error</span></span><br><span class="line">    <span class="string">│</span>           <span class="string">└──</span> <span class="string">StatisticsFcmErrorModel.java</span></span><br><span class="line">    <span class="string">└──</span> <span class="string">job_19</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogBanHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogClientLossHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogConsumeGoldHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">LogRoleCreateHandler.java</span></span><br><span class="line">        <span class="string">├──</span> <span class="string">TLogMarketHandler.java</span></span><br><span class="line">        <span class="string">└──</span> <span class="string">model</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_ban</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsModel.java</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_client_loss</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">IpMonitorModel.java</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_consume_gold</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">├──</span> <span class="string">StatisticsBindGoldModel.java</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">StatisticsUnBindGoldModel.java</span></span><br><span class="line">            <span class="string">├──</span> <span class="string">log_role_create</span></span><br><span class="line">            <span class="string">│</span>   <span class="string">└──</span> <span class="string">SingleServerRoleCreateModel.java</span></span><br><span class="line">            <span class="string">└──</span> <span class="string">t_log_market</span></span><br><span class="line">                <span class="string">├──</span> <span class="string">MarketTransactionLogByBuyerModel.java</span></span><br><span class="line">                <span class="string">└──</span> <span class="string">MarketTransactionLogBySellerModel.java</span></span><br></pre></td></tr></table></figure><p>对于各个项目的<code>错误告警监控</code>，这里分为了多个<code>job</code>。</p><ul><li>Job_10002.java</li><li>Job_10008.java</li><li>Job_19.java</li></ul><p>我们从入口开始看</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.jobs.alarm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> com.alibaba.fastjson.JSONObject;</span><br><span class="line"><span class="keyword">import</span> deps.util.Util;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.common.serialization.SimpleStringSchema;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.ProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumer;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.OutputTag;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.Bootstrap;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_10008.AppErrorHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_10008.LogFcmErrorHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.CommonEvent;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.app_error.Event;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"><span class="keyword">import</span> java.util.Properties;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Job_10008</span> <span class="keyword">extends</span> <span class="title">Bootstrap</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(Job_10008<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env = getStreamExecutionEnvironment(args, Job_10008<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">        env.enableCheckpointing(<span class="number">5000</span>); <span class="comment">// checkpoint every 5000 msecs</span></span><br><span class="line"></span><br><span class="line">        ParameterTool parameterTool = (ParameterTool) env.getConfig().getGlobalJobParameters();</span><br><span class="line">        Properties props = <span class="keyword">new</span> Properties();</span><br><span class="line">        props.setProperty(<span class="string">"bootstrap.servers"</span>, parameterTool.get(<span class="string">"kafka.source.bootstrap.servers"</span>));</span><br><span class="line">        props.setProperty(<span class="string">"group.id"</span>, parameterTool.get(<span class="string">"kafka.source.group"</span>));</span><br><span class="line">        props.put(<span class="string">"enable.auto.commit"</span>, parameterTool.get(<span class="string">"kafka.source.enable.auto.commit"</span>));</span><br><span class="line">        props.put(<span class="string">"auto.commit.interval.ms"</span>, parameterTool.get(<span class="string">"kafka.source.auto.commit.interval.ms"</span>));</span><br><span class="line">        props.put(<span class="string">"session.timeout.ms"</span>, parameterTool.get(<span class="string">"kafka.source.session.timeout.ms"</span>));</span><br><span class="line">        props.put(<span class="string">"key.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.deserializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 设置kafka并行度</span></span><br><span class="line">        env.setParallelism(parameterTool.getInt(<span class="string">"kafka.source.parallelism"</span>, <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        DataStream&lt;String&gt; stream = env</span><br><span class="line">                .addSource(<span class="keyword">new</span> FlinkKafkaConsumer&lt;&gt;(Arrays.asList(parameterTool.get(<span class="string">"kafka.source.topic"</span>).split(<span class="string">","</span>)), <span class="keyword">new</span> SimpleStringSchema(), props));</span><br><span class="line"></span><br><span class="line">        env.setParallelism(parameterTool.getInt(<span class="string">"app.parallelism"</span>, <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;CommonEvent&gt; s0 = stream.filter((String json) -&gt; &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                JSONObject.parseObject(json, CommonEvent<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">                logger.error(json);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;).map(</span><br><span class="line">                (String json) -&gt; JSONObject.parseObject(json, CommonEvent<span class="class">.<span class="keyword">class</span>).<span class="title">setOriginJson</span>(<span class="title">json</span>)</span></span><br><span class="line"><span class="class">        ).<span class="title">returns</span>(<span class="title">CommonEvent</span>.<span class="title">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">final</span> OutputTag&lt;CommonEvent&gt; outputTagAppError = <span class="keyword">new</span> OutputTag&lt;CommonEvent&gt;(AppErrorHandler<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()) </span>&#123;</span><br><span class="line">        &#125;;</span><br><span class="line">        <span class="keyword">final</span> OutputTag&lt;CommonEvent&gt; outputTagLogFcmError = <span class="keyword">new</span> OutputTag&lt;CommonEvent&gt;(LogFcmErrorHandler<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()) </span>&#123;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment">// 1. 主流不需要了, 所以不需要调用collector.collect()</span></span><br><span class="line">        <span class="comment">// 2. 只要旁路输出流，因为要区分数据进行处理</span></span><br><span class="line">        <span class="comment">// 利用low-level-api的process算子处理旁路输出采集数据</span></span><br><span class="line">        SingleOutputStreamOperator&lt;CommonEvent&gt; s1 = s0.process(<span class="keyword">new</span> ProcessFunction&lt;CommonEvent, CommonEvent&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(CommonEvent event, Context context, Collector&lt;CommonEvent&gt; collector)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">switch</span> (event.getHeaders().getLogName()) &#123;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">"app_error"</span>:</span><br><span class="line">                        context.output(outputTagAppError, event);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">case</span> <span class="string">"log_fcm_error"</span>:</span><br><span class="line">                        context.output(outputTagLogFcmError, event);</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;CommonEvent&gt; AppErrorSource = s1.getSideOutput(outputTagAppError);</span><br><span class="line">        DataStream&lt;CommonEvent&gt; LogFcmErrorSource = s1.getSideOutput(outputTagLogFcmError);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Event&gt; AppErrorSource_s0 = AppErrorSource.map((CommonEvent event) -&gt; JSONObject.parseObject(event.getOriginJson(), Event<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">        ).<span class="title">returns</span>(<span class="title">Event</span>.<span class="title">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        DataStream&lt;org.cp.flink.events.log_fcm_error.Event&gt; LogFcmErrorSource_s0 = LogFcmErrorSource.map((CommonEvent event) -&gt; JSONObject.parseObject(event.getOriginJson(), org.cp.flink.events.log_fcm_error.Event<span class="class">.<span class="keyword">class</span>)</span></span><br><span class="line"><span class="class">        ).<span class="title">returns</span>(<span class="title">org</span>.<span class="title">cp</span>.<span class="title">flink</span>.<span class="title">events</span>.<span class="title">log_fcm_error</span>.<span class="title">Event</span>.<span class="title">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        AppErrorHandler.build().handle(AppErrorSource_s0);</span><br><span class="line">        LogFcmErrorHandler.build().handle(LogFcmErrorSource_s0);</span><br><span class="line"></span><br><span class="line">        env.execute(Util.getCurrentJobName(((ParameterTool) env.getConfig().getGlobalJobParameters())));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于我们一个topic只能够可能存在多种数据，所以这里利用了<code>旁路由</code>进行了分流。把数据流分发到不同的<code>子流</code>中，我们再把<code>子流</code>传递不同的<code>Handler</code>进行处理。</p><p>这里例如: <code>AppErrorHandler</code>。我们以此为例子进行说明。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.jobs.alarm.handler.job_10008;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.ProcessFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.OutputTag;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.AbstractHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_10008.model.app_error.StatisticsAppErrorModel;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.app_error.Event;</span><br><span class="line"></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AppErrorHandler</span> <span class="keyword">extends</span> <span class="title">AbstractHandler</span>&lt;<span class="title">Event</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> AppErrorHandler instance;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> AppErrorHandler <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> AppErrorHandler();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(DataStream&lt;Event&gt; s0)</span> </span>&#123;</span><br><span class="line">        ParameterTool parameterTool = <span class="keyword">this</span>.getParameterTool(s0);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 利用旁路输出多流到对应到model</span></span><br><span class="line">        <span class="comment">// StatisticsAppErrorModel</span></span><br><span class="line">        <span class="keyword">final</span> OutputTag&lt;Event&gt; outputTagStatisticsAppError = <span class="keyword">new</span> OutputTag&lt;Event&gt;(StatisticsAppErrorModel<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>()) </span>&#123;</span><br><span class="line">        &#125;;</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;Event&gt; s1 = s0.process(<span class="keyword">new</span> ProcessFunction&lt;Event, Event&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(Event event, Context context, Collector&lt;Event&gt; collector)</span> </span>&#123;</span><br><span class="line">                context.output(outputTagStatisticsAppError, event);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        DataStream&lt;Event&gt; sideOutputStreamAppError = s1.getSideOutput(outputTagStatisticsAppError);</span><br><span class="line"></span><br><span class="line">        StatisticsAppErrorModel.build().handle(sideOutputStreamAppError);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (parameterTool.getBoolean(<span class="string">"app.handler.print.console"</span>, <span class="keyword">false</span>)) &#123;</span><br><span class="line">            s0.print(AppErrorHandler<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于，我们希望到一条数据从<code>kafka</code>被<code>pull</code>下来到时候，可以用于多个不同的<code>流计算模型model</code>，所以我们在这里需要<code>copy</code>到多个<code>旁路输出</code>，但是这里我们只有一个<code>stream-model</code>，所以我们就只用一个来处理即可，从旁路输出拿到<code>datastream</code>之后，在对应的模型中进行<code>核心逻辑</code>处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.jobs.alarm.handler.job_10008.model.app_error;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> deps.util.Util;</span><br><span class="line"><span class="keyword">import</span> lombok.NoArgsConstructor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.functions.KeySelector;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple3;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.tuple.Tuple5;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.DataStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.SingleOutputStreamOperator;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.datastream.WindowedStream;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.timestamps.BoundedOutOfOrdernessTimestampExtractor;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.windowing.WindowFunction;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.assigners.TumblingEventTimeWindows;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.time.Time;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.windowing.windows.TimeWindow;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.runtime.operators.util.AssignerWithPeriodicWatermarksAdapter;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.AbstractHandler;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.events.app_error.Event;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.jobs.alarm.handler.job_19.model.log_ban.StatisticsModel;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.sinks.MysqlItem;</span><br><span class="line"><span class="keyword">import</span> org.cp.flink.sinks.MysqlSink;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.time.Duration;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 错误日志统计</span></span><br><span class="line"><span class="comment"> * 窗口：滚动事件窗口，每1分钟统计一次</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="meta">@NoArgsConstructor</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StatisticsAppErrorModel</span> <span class="keyword">extends</span> <span class="title">AbstractHandler</span>&lt;<span class="title">Event</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_SINK_DATABASE = <span class="string">"db_app_log_alarm"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String DEFAULT_SINK_TABLE = <span class="string">"t_log_app_error_alarm_164"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(StatisticsAppErrorModel<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> StatisticsAppErrorModel instance;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> StatisticsAppErrorModel <span class="title">build</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="keyword">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> StatisticsAppErrorModel();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">handle</span><span class="params">(DataStream&lt;Event&gt; s0)</span> </span>&#123;</span><br><span class="line">        s0.getExecutionConfig().setAutoWatermarkInterval(<span class="number">5000L</span>);</span><br><span class="line"></span><br><span class="line">        logger.debug(<span class="string">"getAutoWatermarkInterval: &#123;&#125;"</span>, s0.getExecutionConfig().getAutoWatermarkInterval());</span><br><span class="line">        ParameterTool parameterTool = <span class="keyword">this</span>.getParameterTool(s0);</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;Event&gt; s1 = s0.assignTimestampsAndWatermarks(<span class="keyword">new</span> AssignerWithPeriodicWatermarksAdapter.Strategy&lt;&gt;(</span><br><span class="line">                        <span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;Event&gt;(Time.of(<span class="number">1</span>, TimeUnit.SECONDS)) &#123;</span><br><span class="line"></span><br><span class="line">                            <span class="meta">@Override</span></span><br><span class="line">                            <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                                Long ts = event.getLogs().getMtime() * <span class="number">1000L</span>;</span><br><span class="line">                                logger.debug(</span><br><span class="line">                                        <span class="string">"thread-id: &#123;&#125;, eventTime: [&#123;&#125;|&#123;&#125;], watermark: [&#123;&#125;|&#123;&#125;]"</span>,</span><br><span class="line">                                        Thread.currentThread().getId(),</span><br><span class="line">                                        ts,</span><br><span class="line">                                        sdf.format(ts),</span><br><span class="line">                                        <span class="keyword">this</span>.getCurrentWatermark().getTimestamp(),</span><br><span class="line">                                        sdf.format(<span class="keyword">this</span>.getCurrentWatermark().getTimestamp())</span><br><span class="line">                                );</span><br><span class="line"></span><br><span class="line">                                <span class="keyword">return</span> ts;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                )</span><br><span class="line">                        <span class="comment">// 尽可能和窗口大小保持一致，所以如果其中一个并行度出现问题的情况下</span></span><br><span class="line">                        <span class="comment">// 最大的延迟计算结果是一个窗口大小的时间</span></span><br><span class="line">                        .withIdleness(Duration.ofMinutes(<span class="number">1L</span>))</span><br><span class="line">        );</span><br><span class="line"></span><br><span class="line">        WindowedStream&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt; s2 = s1.keyBy(<span class="keyword">new</span> KeySelector&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> Tuple5&lt;Integer, String, String, Integer, String&gt; <span class="title">getKey</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">                <span class="keyword">return</span> Tuple5.of(</span><br><span class="line">                        event.getLogs().getRelatedAppId(),</span><br><span class="line">                        event.getLogs().getChildApp(),</span><br><span class="line">                        event.getLogs().getSummary(),</span><br><span class="line">                        event.getLogs().getLevel(),</span><br><span class="line">                        event.getLogs().getIp()</span><br><span class="line">                );</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;)</span><br><span class="line">                .window(TumblingEventTimeWindows.of(Time.minutes(<span class="number">1L</span>)));</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; s3 = s2.apply(<span class="keyword">new</span> WindowFunction&lt;Event, Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(Tuple5&lt;Integer, String, String, Integer, String&gt; key, TimeWindow timeWindow, Iterable&lt;Event&gt; iterable, Collector&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span> (Event event : iterable) &#123;</span><br><span class="line">                    sum++;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                logger.debug(<span class="string">"聚合窗口key: &#123;&#125;, 窗口中的数量:&#123;&#125;, 此时的窗口范围是[&#123;&#125;,&#123;&#125;)"</span>, key, sum, sdf.format(timeWindow.getStart()), sdf.format(timeWindow.getEnd()));</span><br><span class="line">                collector.collect(Tuple3.of(key, iterable.iterator().next(), sum));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line"></span><br><span class="line">        String sinkDatabase = parameterTool.get(StatisticsModel.class.getName() + ".sink_database", DEFAULT_SINK_DATABASE);</span><br><span class="line">        String sinkTable = parameterTool.get(StatisticsModel.class.getName() + ".sink_table", DEFAULT_SINK_TABLE);</span><br><span class="line"></span><br><span class="line">        SingleOutputStreamOperator&lt;MysqlItem&gt; s4 = s3.map(e -&gt; &#123;</span><br><span class="line">                    HashMap&lt;String, Object&gt; kv = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">                    kv.put(<span class="string">"related_app_id"</span>, e.f1.getLogs().getRelatedAppId());</span><br><span class="line">                    kv.put(<span class="string">"child_app"</span>, e.f1.getLogs().getChildApp());</span><br><span class="line">                    kv.put(<span class="string">"summary"</span>, e.f1.getLogs().getSummary());</span><br><span class="line">                    kv.put(<span class="string">"level"</span>, e.f1.getLogs().getLevel());</span><br><span class="line">                    kv.put(<span class="string">"ip"</span>, e.f1.getLogs().getIp());</span><br><span class="line"></span><br><span class="line">                    kv.put(<span class="string">"mtime"</span>, e.f1.getLogs().getMtime());</span><br><span class="line">                    kv.put(<span class="string">"mdate"</span>, Util.timeStamp2Date(Integer.toString(e.f1.getLogs().getMtime()), <span class="string">"yyyy-MM-dd"</span>));</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 来自聚合窗口统计的结果</span></span><br><span class="line">                    kv.put(<span class="string">"cnt"</span>, e.f2);</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">return</span> MysqlItem.builder()</span><br><span class="line">                            .database(sinkDatabase)</span><br><span class="line">                            .table(sinkTable)</span><br><span class="line">                            .kv(kv)</span><br><span class="line">                            .build();</span><br><span class="line">                &#125;</span><br><span class="line">        ).returns(MysqlItem<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">        s4.addSink(<span class="keyword">new</span> MysqlSink(parameterTool))</span><br><span class="line">                .setParallelism(parameterTool.getInt(<span class="string">"mysql.sink.parallelism"</span>, <span class="number">1</span>))</span><br><span class="line">                .name(<span class="string">"MysqlSink"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (parameterTool.getBoolean(<span class="string">"app.handler.print.console"</span>, <span class="keyword">false</span>)) &#123;</span><br><span class="line">            s0.print(StatisticsAppErrorModel<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从上面的整体中，我们这里先看到设置<code>watermark</code>的逻辑，这个<code>watermark</code>决定了我们的flink的数据的有序性，是一个比较重要的处理。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// 每5s-flink需要获取新的watermark</span></span><br><span class="line">s0.getExecutionConfig().setAutoWatermarkInterval(<span class="number">5000L</span>);</span><br><span class="line"></span><br><span class="line">logger.debug(<span class="string">"getAutoWatermarkInterval: &#123;&#125;"</span>, s0.getExecutionConfig().getAutoWatermarkInterval());</span><br><span class="line">ParameterTool parameterTool = <span class="keyword">this</span>.getParameterTool(s0);</span><br><span class="line"></span><br><span class="line">SingleOutputStreamOperator&lt;Event&gt; s1 = s0.assignTimestampsAndWatermarks(<span class="keyword">new</span> AssignerWithPeriodicWatermarksAdapter.Strategy&lt;&gt;(</span><br><span class="line"><span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;Event&gt;(Time.of(<span class="number">1</span>, TimeUnit.SECONDS)) &#123;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line">Long ts = event.getLogs().getMtime() * <span class="number">1000L</span>;</span><br><span class="line">logger.debug(</span><br><span class="line"><span class="string">"thread-id: &#123;&#125;, eventTime: [&#123;&#125;|&#123;&#125;], watermark: [&#123;&#125;|&#123;&#125;]"</span>,</span><br><span class="line">Thread.currentThread().getId(),</span><br><span class="line">ts,</span><br><span class="line">sdf.format(ts),</span><br><span class="line"><span class="keyword">this</span>.getCurrentWatermark().getTimestamp(),</span><br><span class="line">sdf.format(<span class="keyword">this</span>.getCurrentWatermark().getTimestamp())</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> ts;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">)</span><br><span class="line"><span class="comment">// 尽可能和窗口大小保持一致，所以如果其中一个并行度出现问题的情况下</span></span><br><span class="line"><span class="comment">// 最大的延迟计算结果是一个窗口大小的时间</span></span><br><span class="line">.withIdleness(Duration.ofMinutes(<span class="number">1L</span>))</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>我们这里通过<code>AssignerWithPeriodicWatermarksAdapter</code>设置一个<code>watermark</code>生成的策略。</p><p>当数据到来的时候，允许<code>1秒延迟</code>的情况下，解析数据的<code>事件时间(event-time)</code>作为我们的<code>watermark</code>，这里需要注意的是，这里从event-time提取的时间的单位需要是<code>毫秒</code>级别。</p><p>再通过<code>.withIdleness</code>，进行当某个窗口下<code>idle</code>了，那么也会刷新<code>watermark</code>。这个知识点，在kafka中是一个很重要的逻辑，由于flink在kafka的topic在多partition下，在partition的数据<code>watermark</code>对齐的情况，才会进行，所以为了防止，由于防止kafka的partition的数据倾斜对我们造成业务逻辑一直无法更新watermark的问题。这个十分必要。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">WindowedStream&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt; s2 = s1.keyBy(<span class="keyword">new</span> KeySelector&lt;Event, Tuple5&lt;Integer, String, String, Integer, String&gt;&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Tuple5&lt;Integer, String, String, Integer, String&gt; <span class="title">getKey</span><span class="params">(Event event)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> Tuple5.of(</span><br><span class="line">event.getLogs().getRelatedAppId(),</span><br><span class="line">event.getLogs().getChildApp(),</span><br><span class="line">event.getLogs().getSummary(),</span><br><span class="line">event.getLogs().getLevel(),</span><br><span class="line">event.getLogs().getIp()</span><br><span class="line">);</span><br><span class="line">&#125;</span><br><span class="line">&#125;)</span><br><span class="line">.window(TumblingEventTimeWindows.of(Time.minutes(<span class="number">1L</span>)));</span><br></pre></td></tr></table></figure><p>对于<code>windowstream</code>，主要是定义<code>窗口的时间大小</code>， <code>窗口数据的唯一主键</code>。</p><p>在这里，由于我的需求是每1分钟统计一次，所以这里可以看到我的窗口是基于<code>EventTime（事件时间）</code>的窗口，并且大小范围为<code>1分钟</code>。而数据的唯一主键则是通过<code>getKet(Event event)</code>方法来处理。通过flink内置的便捷的<code>Tuple5</code>这个类来处理的原因是因为我这里有5个元素组成的key。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; s3 = s2.apply(<span class="keyword">new</span> WindowFunction&lt;Event, Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;, Tuple5&lt;Integer, String, String, Integer, String&gt;, TimeWindow&gt;() &#123;</span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">apply</span><span class="params">(Tuple5&lt;Integer, String, String, Integer, String&gt; key, TimeWindow timeWindow, Iterable&lt;Event&gt; iterable, Collector&lt;Tuple3&lt;Tuple5&lt;Integer, String, String, Integer, String&gt;, Event, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">                <span class="keyword">for</span> (Event event : iterable) &#123;</span><br><span class="line">                    sum++;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                logger.debug(<span class="string">"聚合窗口key: &#123;&#125;, 窗口中的数量:&#123;&#125;, 此时的窗口范围是[&#123;&#125;,&#123;&#125;)"</span>, key, sum, sdf.format(timeWindow.getStart()), sdf.format(timeWindow.getEnd()));</span><br><span class="line">                collector.collect(Tuple3.of(key, iterable.iterator().next(), sum));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure><p>接下来就是<code>聚合(统计)</code>的逻辑了，当<code>window-trigger-condition</code>满足条件之后，就会把当前窗口内的所有数据推到下一个<code>算子</code>，在这个<code>算子</code>的<code>apply()</code>中，我们可以看到我们只是简单的做了一个数据统计，也就是<code>sum++</code>，经过这一操作之后，经过<code>collector</code>对进行进行<code>收集</code>，准备用于下一个<code>算子</code>中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">SingleOutputStreamOperator&lt;MysqlItem&gt; s4 = s3.map(e -&gt; &#123;</span><br><span class="line">                    HashMap&lt;String, Object&gt; kv = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">                    kv.put(<span class="string">"related_app_id"</span>, e.f1.getLogs().getRelatedAppId());</span><br><span class="line">                    kv.put(<span class="string">"child_app"</span>, e.f1.getLogs().getChildApp());</span><br><span class="line">                    kv.put(<span class="string">"summary"</span>, e.f1.getLogs().getSummary());</span><br><span class="line">                    kv.put(<span class="string">"level"</span>, e.f1.getLogs().getLevel());</span><br><span class="line">                    kv.put(<span class="string">"ip"</span>, e.f1.getLogs().getIp());</span><br><span class="line"></span><br><span class="line">                    kv.put(<span class="string">"mtime"</span>, e.f1.getLogs().getMtime());</span><br><span class="line">                    kv.put(<span class="string">"mdate"</span>, Util.timeStamp2Date(Integer.toString(e.f1.getLogs().getMtime()), <span class="string">"yyyy-MM-dd"</span>));</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// 来自聚合窗口统计的结果</span></span><br><span class="line">                    kv.put(<span class="string">"cnt"</span>, e.f2);</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">return</span> MysqlItem.builder()</span><br><span class="line">                            .database(sinkDatabase)</span><br><span class="line">                            .table(sinkTable)</span><br><span class="line">                            .kv(kv)</span><br><span class="line">                            .build();</span><br><span class="line">                &#125;</span><br><span class="line">        ).returns(MysqlItem<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line"></span><br><span class="line">s4.addSink(<span class="keyword">new</span> MysqlSink(parameterTool))</span><br><span class="line">.setParallelism(parameterTool.getInt(<span class="string">"mysql.sink.parallelism"</span>, <span class="number">1</span>))</span><br><span class="line">.name(<span class="string">"MysqlSink"</span>);</span><br></pre></td></tr></table></figure><p>在这个前面到算子中，我们拿到了一些我们所期待到数据了，接下来就是把数据转换成为我们需要入库的一个结构。通过<code>MysqlItem</code>对象，我们把所有的结构化的对象通过<code>MysqlSink</code>方法进行发送给mysql。<code>mysqlsink</code>是我们自己封的一个<code>sinker</code>，其中的代码实现如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.cp.flink.sinks;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> lombok.Setter;</span><br><span class="line"><span class="keyword">import</span> lombok.experimental.Accessors;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.utils.ParameterTool;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.configuration.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.streaming.api.functions.sink.RichSinkFunction;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.Logger;</span><br><span class="line"><span class="keyword">import</span> org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.nio.charset.StandardCharsets;</span><br><span class="line"><span class="keyword">import</span> java.sql.Connection;</span><br><span class="line"><span class="keyword">import</span> java.sql.DriverManager;</span><br><span class="line"><span class="keyword">import</span> java.sql.PreparedStatement;</span><br><span class="line"><span class="keyword">import</span> java.sql.SQLException;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Setter</span></span><br><span class="line"><span class="meta">@Accessors</span>(chain = <span class="keyword">true</span>)</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MysqlSink</span> <span class="keyword">extends</span> <span class="title">RichSinkFunction</span>&lt;<span class="title">MysqlItem</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Logger logger = LoggerFactory.getLogger(MysqlSink<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">    ParameterTool parameterTool;</span><br><span class="line">    <span class="keyword">private</span> Connection connection;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MysqlSink</span><span class="params">(ParameterTool parameterTool)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.parameterTool = parameterTool;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">open</span><span class="params">(Configuration parameters)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.open(parameters);</span><br><span class="line">        <span class="keyword">if</span> (connection == <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection = <span class="keyword">this</span>.getConnection();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>.close();</span><br><span class="line">        <span class="keyword">if</span> (connection != <span class="keyword">null</span>) &#123;</span><br><span class="line">            connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * todo: 再考虑一下如果插入失败的话是否需要重试之类的</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> item</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> context</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">invoke</span><span class="params">(MysqlItem item, Context context)</span> </span>&#123;</span><br><span class="line">        logger.debug(<span class="string">"mysql-item: &#123;&#125;"</span>, item);</span><br><span class="line">        MysqlItem.Sql sqlInfo = item.toInsertIgnoreSql();</span><br><span class="line">        String sql = sqlInfo.getPreSql();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            PreparedStatement ps = <span class="keyword">this</span>.connection.prepareStatement(sql);</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= sqlInfo.getValues().size(); i++) &#123;</span><br><span class="line">                ps.setObject(i, sqlInfo.getValues().get(i-<span class="number">1</span>));</span><br><span class="line">            &#125;</span><br><span class="line">            logger.debug(ps.toString());</span><br><span class="line">            ps.execute();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            logger.error(e.getMessage());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Connection <span class="title">getConnection</span><span class="params">()</span> <span class="keyword">throws</span> ClassNotFoundException, SQLException </span>&#123;</span><br><span class="line">        Class.forName(<span class="string">"com.mysql.cj.jdbc.Driver"</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> DriverManager.getConnection(</span><br><span class="line">                String.format(</span><br><span class="line">                        <span class="string">"jdbc:mysql://%s:%s/?useUnicode=true&amp;characterEncoding=%s&amp;useSSL=false&amp;autoReconnect=true"</span>,</span><br><span class="line">                        <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.host"</span>),</span><br><span class="line">                        <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.port"</span>),</span><br><span class="line">                        <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.characterEncoding"</span>, StandardCharsets.UTF_8.toString())</span><br><span class="line">                ),</span><br><span class="line">                <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.user"</span>),</span><br><span class="line">                <span class="keyword">this</span>.parameterTool.get(<span class="string">"mysql.sink.password"</span>)</span><br><span class="line">        );</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>到此，一个基于<code>datastream-api</code>的job，就完成了。</p><p>但是由于这是<code>java技术栈</code>，对于不是<code>java技术栈</code>的团队而言，这是一件比较麻烦的事情。就算是<code>java技术栈</code>，也需要去属于了解flink的原理，然后去编写对应的flink代码，这对于不熟悉<code>datastream-api</code>的小伙伴来说，也是一种头痛的事情。</p><p>所以对于这个问题，我们考虑使用上层一些的api，也就是<code>table-api</code>和<code>sql-api</code>。</p><p>但是由于此类api还是需要熟悉api的细节，所以我们看到了flink提供了一个叫<code>sql-client</code>的东西。但是由于<code>sql-client</code>的不稳定性（某些版本下存在比较严重的bug），且某些需求无法满足我们，为了灵活和可控性，我们最终解决了自行开发<code>flink-sql-client</code>。</p><h2 id="基于自研sql-client的flink开发"><a href="#基于自研sql-client的flink开发" class="headerlink" title="基于自研sql-client的flink开发"></a>基于自研<code>sql-client</code>的flink开发</h2><p>具体的实现方式在 <a href="https://github.com/whiteCcinn/flink-sql-submit" target="_blank" rel="noopener">flink-sql-submit</a></p><p>实现原理其实也不复杂，其实就是通过一个flink项目，封装成为一个类似cmd的命令，然后通过此方式来提交我们的<code>sql或者sql文件</code></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">src/main/java/</span><br><span class="line">├── deps</span><br><span class="line">│   └── util</span><br><span class="line">│       ├── ParameterToolEnvironmentUtils.java</span><br><span class="line">│       ├── SqlCommandParser.java</span><br><span class="line">│       └── Util.java</span><br><span class="line">└── org</span><br><span class="line">    └── client</span><br><span class="line">        └── flink</span><br><span class="line">            ├── Bootstrap.java</span><br><span class="line">            ├── SqlSubmit.java</span><br><span class="line">            ├── cmds</span><br><span class="line">            │   ├── AbstractCommand.java</span><br><span class="line">            │   ├── HelpCommand.java</span><br><span class="line">            │   ├── HiveCatalogCommand.java</span><br><span class="line">            │   ├── ICommand.java</span><br><span class="line">            │   ├── JobCommand.java</span><br><span class="line">            │   └── SqlParserCommand.java</span><br><span class="line">            ├── enums</span><br><span class="line">            │   └── PlanType.java</span><br><span class="line">            ├── internals</span><br><span class="line">            └── udfs</span><br></pre></td></tr></table></figure><p>我们可以看到，整个项目只有少量文件。提供了几个命令：</p><ul><li>help 帮助命令</li><li>hivecatalog 管理<ul><li>增</li><li>删</li><li>查</li></ul></li><li>job 提交任务<ul><li>sql</li><li>sql-file</li></ul></li><li>sql-parser 调试解析sql</li></ul><p>我们以一个<code>sql-file</code>为例子，其他大家可以在github上查看源码。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 以":"为分隔符，分别代表：catalog_type, hive_conf_path, catalog_name</span></span><br><span class="line"><span class="comment">-- "-" 代表使用默认值</span></span><br><span class="line">CATALOG_INFO = hive:/opt/hadoopclient/Hive/config/:-;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">DATABASE</span> mstream_alarm <span class="keyword">COMMENT</span> <span class="string">'告警系统流计算'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">USE</span> mstream_alarm;</span><br><span class="line"></span><br><span class="line"><span class="keyword">SET</span> <span class="string">'pipeline.name'</span> = <span class="string">'每1分钟基础服务告警'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'table.exec.emit.early-fire.enabled'</span> = <span class="string">'true'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'table.exec.emit.early-fire.delay'</span> = <span class="string">'10s'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'mc.local.time.zone'</span> = <span class="string">'Asia/Shanghai'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'table.exec.sink.not-null-enforcer'</span> = <span class="string">'drop'</span>;</span><br><span class="line"><span class="comment">-- checkpoint配置</span></span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.mode'</span> = <span class="string">'EXACTLY_ONCE'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.interval'</span> = <span class="string">'2min'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.timeout'</span> = <span class="string">'1min'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.prefer-checkpoint-for-recovery'</span> = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'execution.checkpointing.externalized-checkpoint-retention'</span> = <span class="string">'RETAIN_ON_CANCELLATION'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'mc.state.backend.fs.checkpointdir'</span> = <span class="string">'hdfs:///flink/checkpoints/&#123;db&#125;/&#123;pipeline.name&#125;'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'mc.execution.savepoint.dir'</span> = <span class="string">'hdfs:///flink/savepoints/&#123;db&#125;/&#123;pipeline.name&#125;'</span>;</span><br><span class="line"><span class="comment">-- 重启策略</span></span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy'</span> = <span class="string">'failure-rate'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy.failure-rate.delay'</span> = <span class="string">'10s'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy.failure-rate.failure-rate-interval'</span> = <span class="string">'5min'</span>;</span><br><span class="line"><span class="keyword">SET</span> <span class="string">'restart-strategy.failure-rate.max-failures-per-interval'</span> = <span class="string">'10'</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> app_error_To_t_log_app_error_alarm_164 (</span><br><span class="line">    headers <span class="keyword">ROW</span>&lt;<span class="string">`app_id`</span> <span class="built_in">int</span>,<span class="string">`log_name`</span> <span class="keyword">string</span>&gt;,</span><br><span class="line">    <span class="keyword">logs</span> <span class="keyword">ROW</span>&lt;<span class="string">`related_app_id`</span> <span class="built_in">int</span>, <span class="string">`child_app`</span> <span class="built_in">varchar</span>(<span class="number">200</span>), <span class="string">`summary`</span> <span class="keyword">string</span>,<span class="string">`level`</span> <span class="built_in">int</span>,<span class="string">`ip`</span> <span class="built_in">varchar</span>(<span class="number">200</span>),<span class="string">`detail`</span> <span class="built_in">varchar</span>(<span class="number">100</span>), <span class="string">`mtime`</span> <span class="built_in">int</span>&gt;,</span><br><span class="line">    etime <span class="keyword">as</span> TO_TIMESTAMP(FROM_UNIXTIME(logs.<span class="string">`mtime`</span>)),</span><br><span class="line">    WATERMARK <span class="keyword">for</span> etime <span class="keyword">AS</span> etime <span class="comment">-- defines watermark on ts column, marks ts as event-time attribute</span></span><br><span class="line">)</span><br><span class="line"><span class="keyword">WITH</span> (</span><br><span class="line">    <span class="string">'connector'</span> = <span class="string">'kafka'</span>,</span><br><span class="line">    <span class="string">'topic'</span> = <span class="string">'mfeilog_dsp_10008_app_error'</span>,</span><br><span class="line">    <span class="string">'properties.bootstrap.servers'</span> = <span class="string">'127.0.0.1:9092'</span>,</span><br><span class="line">    <span class="string">'properties.group.id'</span> = <span class="string">'app_error_to_t_log_app_error_alarm_164'</span>,</span><br><span class="line">    <span class="string">'format'</span> = <span class="string">'json'</span>,</span><br><span class="line">    <span class="string">'scan.startup.mode'</span> = <span class="string">'latest-offset'</span>,</span><br><span class="line">    <span class="string">'json.fail-on-missing-field'</span> = <span class="string">'false'</span>,</span><br><span class="line">    <span class="string">'json.ignore-parse-errors'</span> = <span class="string">'false'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="string">`t_log_app_error_alarm_164`</span> (</span><br><span class="line">  <span class="string">`related_app_id`</span> <span class="built_in">int</span>,</span><br><span class="line">  <span class="string">`child_app`</span> <span class="built_in">varchar</span>(<span class="number">200</span>),</span><br><span class="line">  <span class="string">`summary`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`level`</span> <span class="built_in">int</span>,</span><br><span class="line">  <span class="string">`ip`</span> <span class="built_in">varchar</span>(<span class="number">200</span>) ,</span><br><span class="line">  <span class="string">`cnt`</span> <span class="built_in">varchar</span>(<span class="number">200</span>) <span class="keyword">COMMENT</span> <span class="string">'calculate the detail of count()'</span>,</span><br><span class="line">  <span class="string">`mdate`</span> <span class="keyword">string</span>,</span><br><span class="line">  <span class="string">`mtime`</span> <span class="built_in">int</span>,</span><br><span class="line">  PRIMARY <span class="keyword">KEY</span> (<span class="string">`related_app_id`</span>,<span class="string">`child_app`</span>,<span class="string">`summary`</span>,<span class="string">`level`</span>,<span class="string">`ip`</span>) <span class="keyword">NOT</span> <span class="keyword">ENFORCED</span></span><br><span class="line">) <span class="keyword">WITH</span> (</span><br><span class="line">   <span class="string">'connector'</span> = <span class="string">'jdbc'</span>,</span><br><span class="line">   <span class="string">'url'</span> = <span class="string">'jdbc:mysql://127.0.0.1:60701/db_app_log_alarm?useUnicode=true&amp;characterEncoding=utf8&amp;autoReconnect=true'</span>,</span><br><span class="line">   <span class="string">'driver'</span> = <span class="string">'com.mysql.cj.jdbc.Driver'</span>,</span><br><span class="line">   <span class="string">'table-name'</span> = <span class="string">'t_log_app_error_alarm_164'</span>,</span><br><span class="line">   <span class="string">'username'</span> = <span class="string">'flink_mstream_alarm'</span>,</span><br><span class="line">   <span class="string">'password'</span> = <span class="string">'xxxx'</span></span><br><span class="line">);</span><br><span class="line"></span><br><span class="line"><span class="keyword">insert</span> <span class="keyword">into</span> t_log_app_error_alarm_164 (</span><br><span class="line">    <span class="keyword">select</span> t1.<span class="string">`related_app_id`</span>,t1.<span class="string">`child_app`</span>,t1.<span class="string">`summary`</span>,t1.<span class="string">`level`</span>,t1.<span class="string">`ip`</span>,<span class="keyword">cast</span>(t1.<span class="string">`cnt`</span> <span class="keyword">as</span> <span class="built_in">VARCHAR</span>(<span class="number">200</span>)) <span class="keyword">as</span> <span class="string">`cnt`</span>,t1.<span class="string">`mdate`</span>,<span class="keyword">cast</span> (t1.<span class="string">`mtime`</span> <span class="keyword">as</span> <span class="built_in">INT</span>)  <span class="keyword">from</span> (</span><br><span class="line">        <span class="keyword">select</span></span><br><span class="line">            logs.<span class="string">`related_app_id`</span> <span class="keyword">as</span> <span class="string">`related_app_id`</span>,</span><br><span class="line">            logs.<span class="string">`child_app`</span> <span class="keyword">as</span> <span class="string">`child_app`</span>,</span><br><span class="line">            logs.<span class="string">`summary`</span> <span class="keyword">as</span> <span class="string">`summary`</span>,</span><br><span class="line">            logs.<span class="string">`level`</span> <span class="keyword">as</span> <span class="string">`level`</span>,</span><br><span class="line">            logs.<span class="string">`ip`</span> <span class="keyword">as</span> <span class="string">`ip`</span>,</span><br><span class="line">            <span class="keyword">DATE_FORMAT</span>(TUMBLE_START(etime, <span class="built_in">INTERVAL</span> <span class="string">'1'</span> <span class="keyword">MINUTE</span>), <span class="string">'yyyy-MM-dd'</span>) <span class="keyword">as</span> <span class="string">`mdate`</span>,</span><br><span class="line">            <span class="keyword">UNIX_TIMESTAMP</span>(<span class="keyword">DATE_FORMAT</span>(TUMBLE_START(etime, <span class="built_in">INTERVAL</span> <span class="string">'1'</span> <span class="keyword">MINUTE</span>), <span class="string">'yyyy-MM-dd HH:mm:ss'</span>)) <span class="keyword">as</span> <span class="string">`mtime`</span>,</span><br><span class="line">            <span class="keyword">COUNT</span>(logs.<span class="string">`detail`</span>) <span class="keyword">as</span> <span class="string">`cnt`</span></span><br><span class="line">        <span class="keyword">FROM</span> app_error_To_t_log_app_error_alarm_164</span><br><span class="line">        <span class="keyword">GROUP</span> <span class="keyword">BY</span> logs.<span class="string">`related_app_id`</span>, logs.<span class="string">`child_app`</span>,logs.<span class="string">`summary`</span>,logs.<span class="string">`level`</span>,logs.<span class="string">`ip`</span>,TUMBLE(etime, <span class="built_in">INTERVAL</span> <span class="string">'1'</span> <span class="keyword">MINUTE</span>)</span><br><span class="line">    ) t1</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>我们可以看到这个<code>sql-file</code>，支持了一些<code>关键字</code>，这些关键字被开发在<code>client</code>当中了，所以可以被正常解析到。</p><p>通过解析到关键字，再调用对应的API，我们就可以设置对应的行为了。</p><p>我们可以看到我们从繁杂的<code>datastreamapi</code>中，已经把剥离了出来，通过sql这种DSL的方式，让不同语言技术栈的同事都可以定制自己的job。</p><p>并且支持了自定义重启策略，保证每一个算子在异常或者正常的情况下，都可以从正确的数据中进行恢复重启。</p><p>这一套sql编写下来，做的事情和我们上面的<code>datastream</code>做的事情是一样的，但是却无需了解太多其中的细节。</p><h4 id="UDF的运用"><a href="#UDF的运用" class="headerlink" title="UDF的运用"></a>UDF的运用</h4><p>例如我们需要ip转地址字符串，这个时候，我们就需要udf来协助我们完成这件事。</p><p>client项目可以内置一些我们所需要的UDF，然后连同job一起生效。</p><p>例如：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@127.0,0.1_A ~]# flink run -yid `cat /data/flink-stream/mstream/mstream_xx/yid` /data/flink-stream/flink-sql-submit-1.0-SNAPSHOT.jar job --sql "CATALOG_INFO = hive:/opt/hadoopclient/Hive/config/:-;USE mstream_alarm;SELECT ip2location('219.135.155.76');"</span><br><span class="line"> Interface ana-group-1byez.dad44e53-24e6-41be-bfd5-a4055f4c6604.com:32263 of application 'application_1641337362340_6699'.</span><br><span class="line">Job has been submitted with JobID 824af5a31aba88db6e0137f5e834f26b</span><br><span class="line">+----+--------------------------------+</span><br><span class="line">| op |                         EXPR$0 |</span><br><span class="line">+----+--------------------------------+</span><br><span class="line">| +I |                 中国,广东,广州 |</span><br><span class="line">+----+--------------------------------+</span><br></pre></td></tr></table></figure><p>我们可以看到，通过<code>ip2localtion()</code>，我们完成了一个udf，并且可以实现在sql的模式上。用过ip地址转为为了地址。</p><h2 id="落地实战"><a href="#落地实战" class="headerlink" title="落地实战"></a>落地实战</h2><p>由于资源的有限，我们在flink的架构上，采用的是每个项目对应一个<code>application</code>的方法，每个<code>application通过yarn来分配来分配资源容器</code>，然后再通过<code>yarn-session</code>(非<code>per on job</code>)的方式来管理我们的flink应用。</p><h3 id="申请资源应用"><a href="#申请资源应用" class="headerlink" title="申请资源应用"></a>申请资源应用</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yarn-session.sh -jm 1024 -tm 1024 -s 16 -nm '告警流计算应用' -yd</span><br></pre></td></tr></table></figure><p><img src="/images/FLINK/application.png" alt="application"></p><h3 id="client-例子"><a href="#client-例子" class="headerlink" title="client 例子"></a>client 例子</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> <span class="built_in">help</span></span></span><br><span class="line">root@41c5967b5948:/www# flink run target/mc-flink-sql-submit-1.0-SNAPSHOT.jar help</span><br><span class="line">帮助命令</span><br><span class="line"></span><br><span class="line">Usage of "flink run &lt;.jar&gt; help [options]"</span><br><span class="line"></span><br><span class="line">Available Commands</span><br><span class="line">   job          提交job作业</span><br><span class="line">   sql-parser   解析sql文件</span><br><span class="line">   help         帮助命令</span><br><span class="line">   hive-catalog hive-catalog的相关</span><br><span class="line"></span><br><span class="line">Global Options:</span><br><span class="line">   --app.force.remote bool</span><br><span class="line">       是否启动远端环境变量: false</span><br><span class="line">   --app.config.debug bool</span><br><span class="line">       是否打印用户参数: false</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> job</span></span><br><span class="line">root@41c5967b5948:/www# flink run target/mc-flink-sql-submit-1.0-SNAPSHOT.jar job help</span><br><span class="line">提交job</span><br><span class="line"></span><br><span class="line">Usage of "flink run &lt;.jar&gt; job [options]"</span><br><span class="line">   --sql string</span><br><span class="line">       执行的sql (*)</span><br><span class="line">   --plan string</span><br><span class="line">       选择执行计划器:</span><br><span class="line">           flink-streaming</span><br><span class="line">           flink-batch</span><br><span class="line">           blink-streaming</span><br><span class="line">           flink-batch</span><br><span class="line"></span><br><span class="line">Global Options:</span><br><span class="line">   --app.force.remote bool</span><br><span class="line">       是否启动远端环境变量: false</span><br><span class="line">   --app.config.debug bool</span><br><span class="line">       是否打印用户参数: false</span><br></pre></td></tr></table></figure><h3 id="flink-stream-sql-mctl-用法"><a href="#flink-stream-sql-mctl-用法" class="headerlink" title="flink-stream-sql-mctl 用法"></a>flink-stream-sql-mctl 用法</h3><p>这是一个集成脚本，所以存在约定的规则和部署的架构约束。</p><p>这便于我们管理所有的applition和flink种的所有flink-job。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">flink-sql-submit git:(master) ✗ ./flink-stream-sql-mctl.sh</span><br><span class="line"></span><br><span class="line">  flink-stream-sql-mctl.sh [OPTION] &lt;COMMAND&gt;</span><br><span class="line"></span><br><span class="line">  Flink流计算SQL-Client的执行脚本</span><br><span class="line"></span><br><span class="line">  Command:</span><br><span class="line">    run          [FILE]            运行</span><br><span class="line">    stop         [FILE]            停止</span><br><span class="line">    list         [FILE]            列出FILE所在yid下的所有job任务列表</span><br><span class="line">    drop_table   [FILE]            删除所有表</span><br><span class="line">    rebuild_run  [FILE]            删除所有表，然后重跑(继承savepoint）</span><br><span class="line"></span><br><span class="line">  Command-Common-Options:</span><br><span class="line">    -c, --clientpath  [LEVEL]    flink-sql-submit.jar路径  (Default is '/data/tmp/mc-flink-sql-submit-1.0-SNAPSHOT.jar')</span><br><span class="line">    -f   是否强制运行，忽略以往savepoint</span><br><span class="line"></span><br><span class="line">  Common-Options:</span><br><span class="line">    -h, --help              Display this help and exit</span><br><span class="line">    --loglevel [LEVEL]      One of: FATAL, ERROR, WARN, INFO, NOTICE, DEBUG, ALL, OFF</span><br><span class="line">                            (Default is 'ERROR')</span><br><span class="line">    --logfile [FILE]        Full PATH to logfile.  (Default is '/Users/caiwenhui/logs/flink-stream-sql-mctl.sh.log')</span><br><span class="line">    -n, --dryrun            Non-destructive. Makes no permanent changes.</span><br><span class="line">    -q, --quiet             Quiet (no output)</span><br><span class="line">    -v, --verbose           Output more information. (Items echoed to 'verbose')</span><br><span class="line">    --force                 Skip all user interaction.  Implied 'Yes' to all actions.</span><br></pre></td></tr></table></figure><p>约定规则：</p><ul><li>模型所在父目录的至少有一个yid文件（取最近的一个父节点的yid）对应所在的应用id</li><li>默认情况下，模型启动的时候会取最近一次savepoint的数据进行恢复，如果不存在，则直接启动</li></ul><h3 id="停止所有模型"><a href="#停止所有模型" class="headerlink" title="停止所有模型"></a>停止所有模型</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(find /data/flink-stream/mstream_alarm/ -type f -name "*.sql");do /data/flink-stream/flink-stream-sql-mctl stop $i;done</span><br></pre></td></tr></table></figure><h3 id="启动所有模型"><a href="#启动所有模型" class="headerlink" title="启动所有模型"></a>启动所有模型</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(find /data/flink-stream/mstream_alarm/ -type f -name "*.sql");do /data/flink-stream/flink-stream-sql-mctl run $i;done</span><br></pre></td></tr></table></figure><h3 id="删除所有表"><a href="#删除所有表" class="headerlink" title="删除所有表"></a>删除所有表</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">for i in $(find /data/flink-stream/mstream_alarm/ -type f -name "*.sql");do /data/flink-stream/flink-stream-sql-mctl drop_table $i;done</span><br></pre></td></tr></table></figure><h3 id="相关的一些落地后截图信息"><a href="#相关的一些落地后截图信息" class="headerlink" title="相关的一些落地后截图信息"></a>相关的一些落地后截图信息</h3><p><img src="/images/FLINK/server.png" alt="server"></p><p><img src="/images/FLINK/detail-0.png" alt="detail-0"></p><p><img src="/images/FLINK/detail-1.png" alt="detail-1"></p><p><img src="/images/FLINK/detail-2.png" alt="detail-2"></p><p><img src="/images/FLINK/detail-3.png" alt="detail-3"></p><p>到此为止，我们的flink相关的流计算应用，从0到1的过程暂时画上一个里程碑。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;在公司落地一套flink，总结到目前为止做了的事情。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://blog.crazylaw.cn/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- 基于gnet的端口复用支持多协议的客服聊天监控服务</title>
    <link href="http://blog.crazylaw.cn/2022/02/12/Golang/%E5%9F%BA%E4%BA%8Egnet%E7%9A%84%E5%AE%A2%E6%9C%8D%E8%81%8A%E5%A4%A9%E7%9B%91%E6%8E%A7%E6%9C%8D%E5%8A%A1/"/>
    <id>http://blog.crazylaw.cn/2022/02/12/Golang/%E5%9F%BA%E4%BA%8Egnet%E7%9A%84%E5%AE%A2%E6%9C%8D%E8%81%8A%E5%A4%A9%E7%9B%91%E6%8E%A7%E6%9C%8D%E5%8A%A1/</id>
    <published>2022-02-11T16:46:51.000Z</published>
    <updated>2022-02-12T03:45:01.017Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近，公司以前有一些旧的服务，由于各种原因，导致各种问题，并且架构设计行也不是那么友好和不利于维护。<br>所以准备重构设计一些服务。</p><p>在游戏公司中，GM客服的其中一个职能就是监督舆论，从玩家平日的聊天中进行监控。</p><p>我们从<code>业务需求</code>+<code>技术架构</code>层面进行整理。</p><a id="more"></a><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p>在过去中，由于当时php还是如日中天，旧的则是采集的<code>swoole1.x</code>的版本进行开发的服务。<br>受限于php一个语言特性，注定无法实现一些高性能的中间件，或者说大数据生态十分欠缺。当时用php除了<code>fastcgi</code>的<code>web系统</code>外，最多就只能做一些基本的<code>常驻</code>任务。</p><p>消息中间件最多也就是用到<code>rabbitmq</code>，<code>rocketmq</code>等等。</p><p>而常驻，一般无非就是直接<code>cli</code>，外加一个<code>循环+sleep</code>的组合套餐。而要实现<code>websocket-server</code>这种常驻服务，一般是借助<code>swoole</code>来处理。毕竟<code>reactor</code>的模式，怎么都比<code>单进程</code>的实现好。</p><p>分为了3个模块（每个模块=每个角色=一个进程=一个服务）：</p><ul><li>chat_record （聊天记录角色）（weboccket_client, tcp_clinet）</li><li>db_server （数据层角色) (tcp_server)</li><li>websocket_server (连接层角色) (webocket_server)</li></ul><p>由于当时php基本无法多线程编程(可用，但是不友好)，只能采用这种委婉的<code>伪多进程</code>的模拟进行<code>不同任务的处理</code>和<code>数据的交互</code>。</p><p><img src="/images/Go/chat_monitor.png" alt="旧服务的数据流图"></p><h2 id="新服务"><a href="#新服务" class="headerlink" title="新服务"></a>新服务</h2><p><img src="/images/Go/chat_monitor_new.png" alt="新服务的数据流图"></p><blockquote><p>但是由于种种原因，后面并未如此拆分架构，而是将<code>websocket-server网络连接层</code>的和<code>业务层</code>合并成为了一个<code>单体服务</code></p></blockquote><p>技术选型上</p><ul><li>go</li><li>gnet</li><li>kafka</li></ul><h3 id="为什么核心的网络层需要采用gnet呢？"><a href="#为什么核心的网络层需要采用gnet呢？" class="headerlink" title="为什么核心的网络层需要采用gnet呢？"></a>为什么核心的网络层需要采用<code>gnet</code>呢？</h3><p>一般Go语言的TCP(和HTTP)的处理都是<code>每一个连接</code>启动<code>一个goroutine</code>去处理，因为我们被教导<code>goroutine</code>的不像<code>thread</code>, 它是很便宜的，可以在服务器上启动成<code>千上万的goroutine</code>。</p><p>但是对于<code>一百万</code>的连接，这种<code>goroutine-per-connection</code>的模式就<code>至少</code>要启动<code>一百万个goroutine</code>，这对资源的消耗也是极大的。</p><p>针对不同的操作系统和不同的Go版本，一个goroutine锁使用的最小的栈大小是<code>2KB ~ 8 KB (go stack)</code>,如果在每个goroutine中在<code>分配byte buffer</code>用以从连接中读写数据，<code>几十G的内存</code>轻轻松松就分配出去了。</p><p><code>吞吐率</code>和<code>延迟</code>需要数据来支撑，但是显然这个<code>单goroutine</code>处理的模式<code>不适合耗时较长</code>的业务处理，<code>&quot;hello world&quot;</code>或者<code>直接的简单的memory操作</code>应该没有问题。</p><p>对于百万连接<code>但是并发量很小</code>的场景，比如消息推送、页游等场景，这种实现应该是没有问题的。</p><p>但是对于并发量很大，延迟要求比较低的场景，这种实现可能会存在问题。</p><p><code>gnet</code>采用了类似<code>netty</code>的<code>reactor</code>模式，基于<code>epoll</code>或者<code>kqueue</code>实现io多路复用。并且基于golang的语言特性，其实现原理为<code>带线程/go程池的主从 Reactors 多线程</code>模式，在网络层上性能上有极大的优化。</p><p>我们通过gnet提供的tcp网络层，在应用层，实现了http和webocket的端口复用的形式。</p><p>http用于提供<code>prometheus</code>的<code>metrics</code>指标，例如<code>连接数/各种类型引发的error数/每条数据被多少个GM客服监视着</code>等等</p><p>websocket则是用于在我们的<code>GM客服</code>中，提一个实时的聊天数据获取</p><h3 id="为什么采用kafka"><a href="#为什么采用kafka" class="headerlink" title="为什么采用kafka"></a>为什么采用kafka</h3><p>由于我们整套日志服务都是基于kafka作为核心组件的，所以在数据的实时上，可以保证到数据的实效性。</p><p>从而取消了以往从mysql中分库分表去查询数据。也不需要通过其他<code>OLAP</code>的服务进行处理。</p><h3 id="端口复用实现支持多协议"><a href="#端口复用实现支持多协议" class="headerlink" title="端口复用实现支持多协议"></a>端口复用实现支持多协议</h3><p>这个是网络连接层，也是链接的核心业务逻辑，在gnet中当有数据到来的时候，由<code>IO多路复用</code>的<code>epoll</code>模型，会触发<code>OnTraffic(c gnet.Conn)</code>的回调函数，在这个过程中，我们就可以通过网络层中获取的数据进行加工处理，形成自己想要的<code>应用协议</code>。</p><p>由于刚才介绍到了，我们需要实现核心需求：<code>端口多协议复用</code></p><p>在这里，先列出核心的逻辑：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">type</span> ApplicationLayerProto <span class="keyword">int</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(alp ApplicationLayerProto)</span> <span class="title">String</span><span class="params">()</span> <span class="params">(s <span class="keyword">string</span>)</span></span> &#123;</span><br><span class="line"><span class="keyword">switch</span> alp &#123;</span><br><span class="line"><span class="keyword">case</span> HttpApplicationLayerProto:</span><br><span class="line">s = <span class="string">"http"</span></span><br><span class="line"><span class="keyword">case</span> WebsocketApplicationLayerProto:</span><br><span class="line">s = <span class="string">"websocket"</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">s = <span class="string">"unknown"</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> (</span><br><span class="line">HttpApplicationLayerProto ApplicationLayerProto = <span class="literal">iota</span></span><br><span class="line">WebsocketApplicationLayerProto</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> codec <span class="keyword">struct</span> &#123;</span><br><span class="line">proto ApplicationLayerProto</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *codec)</span> <span class="title">isHttp</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> c.proto == HttpApplicationLayerProto &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *codec)</span> <span class="title">isWebsocket</span><span class="params">()</span> <span class="title">bool</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> c.proto == WebsocketApplicationLayerProto &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> httpCodec <span class="keyword">struct</span> &#123;</span><br><span class="line">*codec</span><br><span class="line">parser *wildcat.HTTPParser</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> wsCodec <span class="keyword">struct</span> &#123;</span><br><span class="line">*codec</span><br><span class="line">connected <span class="keyword">bool</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(serv *server)</span> <span class="title">OnOpen</span><span class="params">(c gnet.Conn)</span> <span class="params">([]<span class="keyword">byte</span>, gnet.Action)</span></span> &#123;</span><br><span class="line">c.SetContext(<span class="built_in">new</span>(codec))</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, gnet.None</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(serv *server)</span> <span class="title">OnTraffic</span><span class="params">(c gnet.Conn)</span> <span class="title">gnet</span>.<span class="title">Action</span></span> &#123;</span><br><span class="line"><span class="keyword">var</span> buffer *bytes.Buffer</span><br><span class="line"><span class="keyword">var</span> buff []<span class="keyword">byte</span></span><br><span class="line">pipeline:</span><br><span class="line"><span class="keyword">switch</span> cdc := c.Context().(<span class="keyword">type</span>) &#123;</span><br><span class="line"><span class="keyword">case</span> *codec:</span><br><span class="line">buf, err := c.Next(<span class="number">-1</span>)</span><br><span class="line">buff = <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="built_in">len</span>(buf))</span><br><span class="line"><span class="built_in">copy</span>(buff, buf)</span><br><span class="line">buffer = bytes.NewBuffer(buff)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line">hc := &amp;httpCodec&#123;parser: wildcat.NewHTTPParser(), codec: cdc&#125;</span><br><span class="line">_, err = hc.parser.Parse(buf)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"http parser error: %v"</span>, err)&#125;)</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> upgrade := hc.parser.FindHeader([]<span class="keyword">byte</span>(<span class="string">"Upgrade"</span>)); upgrade != <span class="literal">nil</span> &amp;&amp; bytes.Equal(upgrade, []<span class="keyword">byte</span>(<span class="string">"websocket"</span>)) &#123;</span><br><span class="line">cdc.proto = WebsocketApplicationLayerProto</span><br><span class="line">wc := &amp;wsCodec&#123;</span><br><span class="line">codec: cdc,</span><br><span class="line">&#125;</span><br><span class="line">c.SetContext(wc)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">cdc.proto = HttpApplicationLayerProto</span><br><span class="line">c.SetContext(hc)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">goto</span> pipeline</span><br><span class="line"><span class="keyword">case</span> *httpCodec:</span><br><span class="line">buf := bufio.NewReader(buffer)</span><br><span class="line">req, err := http.ReadRequest(buf)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"request from http error: %v"</span>, err)&#125;)</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line">metrics.TotalConnectedCounter.WithLabelValues(HttpApplicationLayerProto.String()).Inc()</span><br><span class="line">resp := route.NewResponse(c)</span><br><span class="line">h, _ := serv.serverMux.Handler(req)</span><br><span class="line">h.ServeHTTP(resp, req)</span><br><span class="line"><span class="keyword">if</span> _, err = resp.Close(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"write to http error: %v"</span>, err)&#125;)</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line"><span class="keyword">case</span> *wsCodec:</span><br><span class="line"><span class="keyword">if</span> !cdc.connected &#123;</span><br><span class="line">wcb := &amp;wsConnBridge&#123;</span><br><span class="line">buff: buffer,</span><br><span class="line">c:    c,</span><br><span class="line">&#125;</span><br><span class="line">_, err := ws.Upgrade(wcb)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"upgrade[%s] to websocket error: %v"</span>, c.RemoteAddr().String(), err)&#125;)</span><br><span class="line">&#125;</span><br><span class="line">log.Debugf(log.NetServerDebugCategory&#123;&#125;, <span class="string">"conn[%v] upgrade websocket protocol"</span>, c.RemoteAddr().String())</span><br><span class="line">cdc.connected = <span class="literal">true</span></span><br><span class="line">metrics.ConnectedGauge.Inc()</span><br><span class="line">metrics.TotalConnectedCounter.WithLabelValues(WebsocketApplicationLayerProto.String()).Inc()</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">msg, op, err := wsutil.ReadClientData(c)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> _, ok := err.(wsutil.ClosedError); !ok &#123;</span><br><span class="line">log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"[%s] receive ws message error: %v"</span>, c.RemoteAddr().String(), err)&#125;)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line">log.Debugf(log.NetServerDebugCategory&#123;&#125;, <span class="string">"conn[%v] receive [op=%v] [msg=%v]"</span>, c.RemoteAddr().String(), op, <span class="keyword">string</span>(msg))</span><br><span class="line"><span class="keyword">if</span> op == ws.OpText &#123;</span><br><span class="line"><span class="keyword">if</span> rs := route.MatchRequestSpec(msg); rs == <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> route.GlobalWsRouter.DefaultHandler().ServeWebsocket(<span class="string">"/"</span>, msg, c, op)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line"><span class="keyword">return</span> route.GlobalWsRouter.MatchHandler(rs.Path).ServeWebsocket(rs.Path, rs.Params, c, op)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> gnet.None</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里，我们可以看到，当存在新链接进来的啥时候，首先经过<code>OnOpen(c gnet.Conn)</code>方法，这个时候，我们会在<code>gnet.Conn</code>中设置一个我们用户的一个<code>上下文环境Context</code>，在这个Context下，我们为每个连接都初始化了<code>codec</code>的结构体对象，当开始接收数据的时候，触发到了<code>OnTraffic(c gnet.Conn)</code>方法，这个以后，我们需要把网络层接收到的数据拿出来，由于<code>流</code>的存在，使得我们无法重复在同一个连接中，多次重复获取流，所以如果后面需要用到的话，利用取出来的<code>byte-buffer</code>生成一个新的<code>流</code>，以供后续使用。</p><p>所以你会发现有一段代码为:</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">buf, err := c.Next(<span class="number">-1</span>)</span><br><span class="line">buff = <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="built_in">len</span>(buf))</span><br><span class="line"><span class="built_in">copy</span>(buff, buf)</span><br><span class="line">buffer = bytes.NewBuffer(buff)</span><br></pre></td></tr></table></figure><p>接下来，需要做的事情就是解析数据为http协议对象，由于我这里的<code>端口复用</code>的逻辑是<code>http+webocket</code>复用，所以都是基于<code>http协议</code>的，所以这里可以简单粗暴的处理，然后通过判断<code>http协议</code>中是否包含了需要升级为<code>webocket协议</code>的关键字段<code>Upgrade:webocket</code>，如果包含，则表示本次请求是一个websocket连接，否则就是一个单纯http连接。以此来达到复用的需求。</p><p>在这个基础之上，我们也更新了当前连接的<code>上下文环境Context</code>，升级为了<code>httpCodec</code>和<code>wsCodec</code>，通过<code>goto+断言</code>语法，我们可以进入到，我们所需要进入的逻辑阶段。不要觉得这就完事了，麻烦的事情才刚开始，现在你只是知道了开头。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">buf := bufio.NewReader(buffer)</span><br><span class="line">req, err := http.ReadRequest(buf)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"request from http error: %v"</span>, err)&#125;)</span><br><span class="line">    <span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line">metrics.TotalConnectedCounter.WithLabelValues(HttpApplicationLayerProto.String()).Inc()</span><br><span class="line">resp := route.NewResponse(c)</span><br><span class="line">h, _ := serv.serverMux.Handler(req)</span><br><span class="line">h.ServeHTTP(resp, req)</span><br><span class="line"><span class="keyword">if</span> _, err = resp.Close(); err != <span class="literal">nil</span> &#123;</span><br><span class="line">    log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"write to http error: %v"</span>, err)&#125;)</span><br><span class="line">    <span class="keyword">return</span> gnet.Close</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> gnet.Close</span><br></pre></td></tr></table></figure><p>如果是<code>http协议</code>，那么我们就不需要升级协议了。但是有一个问题就是，在golang的<code>http/server.go</code>中，我们所熟悉的接口</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A Handler responds to an HTTP request.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// ServeHTTP should write reply headers and data to the ResponseWriter</span></span><br><span class="line"><span class="comment">// and then return. Returning signals that the request is finished; it</span></span><br><span class="line"><span class="comment">// is not valid to use the ResponseWriter or read from the</span></span><br><span class="line"><span class="comment">// Request.Body after or concurrently with the completion of the</span></span><br><span class="line"><span class="comment">// ServeHTTP call.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Depending on the HTTP client software, HTTP protocol version, and</span></span><br><span class="line"><span class="comment">// any intermediaries between the client and the Go server, it may not</span></span><br><span class="line"><span class="comment">// be possible to read from the Request.Body after writing to the</span></span><br><span class="line"><span class="comment">// ResponseWriter. Cautious handlers should read the Request.Body</span></span><br><span class="line"><span class="comment">// first, and then reply.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Except for reading the body, handlers should not modify the</span></span><br><span class="line"><span class="comment">// provided Request.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If ServeHTTP panics, the server (the caller of ServeHTTP) assumes</span></span><br><span class="line"><span class="comment">// that the effect of the panic was isolated to the active request.</span></span><br><span class="line"><span class="comment">// It recovers the panic, logs a stack trace to the server error log,</span></span><br><span class="line"><span class="comment">// and either closes the network connection or sends an HTTP/2</span></span><br><span class="line"><span class="comment">// RST_STREAM, depending on the HTTP protocol. To abort a handler so</span></span><br><span class="line"><span class="comment">// the client sees an interrupted response but the server doesn't log</span></span><br><span class="line"><span class="comment">// an error, panic with the value ErrAbortHandler.</span></span><br><span class="line"><span class="keyword">type</span> Handler <span class="keyword">interface</span> &#123;</span><br><span class="line">ServeHTTP(ResponseWriter, *Request)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们看到这个<code>Handler</code>interface，需要实现<code>ServeHTTP(ResponseWriter, *Request)</code>，而这个<code>Request</code>，对于我们目前来是，是不存在的，所以我们需要想办法构造一个<code>Request</code>对象出来。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ReadRequest reads and parses an incoming request from b.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// ReadRequest is a low-level function and should only be used for</span></span><br><span class="line"><span class="comment">// specialized applications; most code should use the Server to read</span></span><br><span class="line"><span class="comment">// requests and handle them via the Handler interface. ReadRequest</span></span><br><span class="line"><span class="comment">// only supports HTTP/1.x requests. For HTTP/2, use golang.org/x/net/http2.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">ReadRequest</span><span class="params">(b *bufio.Reader)</span> <span class="params">(*Request, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> readRequest(b, deleteHostHeader)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好在标准包中提供一个<code>ReadRequest(b *bufio.Reader) (*Request, error)</code>的方法，可以通过<code>bufio.Reader</code>去读取<code>http协议</code>，然后构造出我们所需要的<code>Request</code>对象，所以你会看到，我们在一开始<code>copy(buff, buf)</code>的意义就体现在此了。<br>还会那句话，因为这是一个<code>流</code>，无法重复读取，所以我们利用<code>[]byte</code>构造一个全新的可度的字节流。</p><p>解决了<code>Request</code>的问题之后，另外一个问题也来了，<code>ResponseWriter</code>是一个和Response相关可写的字节流。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// A ResponseWriter interface is used by an HTTP handler to</span></span><br><span class="line"><span class="comment">// construct an HTTP response.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// A ResponseWriter may not be used after the Handler.ServeHTTP method</span></span><br><span class="line"><span class="comment">// has returned.</span></span><br><span class="line"><span class="keyword">type</span> ResponseWriter <span class="keyword">interface</span> &#123;</span><br><span class="line"><span class="comment">// Header returns the header map that will be sent by</span></span><br><span class="line"><span class="comment">// WriteHeader. The Header map also is the mechanism with which</span></span><br><span class="line"><span class="comment">// Handlers can set HTTP trailers.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Changing the header map after a call to WriteHeader (or</span></span><br><span class="line"><span class="comment">// Write) has no effect unless the modified headers are</span></span><br><span class="line"><span class="comment">// trailers.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// There are two ways to set Trailers. The preferred way is to</span></span><br><span class="line"><span class="comment">// predeclare in the headers which trailers you will later</span></span><br><span class="line"><span class="comment">// send by setting the "Trailer" header to the names of the</span></span><br><span class="line"><span class="comment">// trailer keys which will come later. In this case, those</span></span><br><span class="line"><span class="comment">// keys of the Header map are treated as if they were</span></span><br><span class="line"><span class="comment">// trailers. See the example. The second way, for trailer</span></span><br><span class="line"><span class="comment">// keys not known to the Handler until after the first Write,</span></span><br><span class="line"><span class="comment">// is to prefix the Header map keys with the TrailerPrefix</span></span><br><span class="line"><span class="comment">// constant value. See TrailerPrefix.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// To suppress automatic response headers (such as "Date"), set</span></span><br><span class="line"><span class="comment">// their value to nil.</span></span><br><span class="line">Header() Header</span><br><span class="line"></span><br><span class="line"><span class="comment">// Write writes the data to the connection as part of an HTTP reply.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If WriteHeader has not yet been called, Write calls</span></span><br><span class="line"><span class="comment">// WriteHeader(http.StatusOK) before writing the data. If the Header</span></span><br><span class="line"><span class="comment">// does not contain a Content-Type line, Write adds a Content-Type set</span></span><br><span class="line"><span class="comment">// to the result of passing the initial 512 bytes of written data to</span></span><br><span class="line"><span class="comment">// DetectContentType. Additionally, if the total size of all written</span></span><br><span class="line"><span class="comment">// data is under a few KB and there are no Flush calls, the</span></span><br><span class="line"><span class="comment">// Content-Length header is added automatically.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Depending on the HTTP protocol version and the client, calling</span></span><br><span class="line"><span class="comment">// Write or WriteHeader may prevent future reads on the</span></span><br><span class="line"><span class="comment">// Request.Body. For HTTP/1.x requests, handlers should read any</span></span><br><span class="line"><span class="comment">// needed request body data before writing the response. Once the</span></span><br><span class="line"><span class="comment">// headers have been flushed (due to either an explicit Flusher.Flush</span></span><br><span class="line"><span class="comment">// call or writing enough data to trigger a flush), the request body</span></span><br><span class="line"><span class="comment">// may be unavailable. For HTTP/2 requests, the Go HTTP server permits</span></span><br><span class="line"><span class="comment">// handlers to continue to read the request body while concurrently</span></span><br><span class="line"><span class="comment">// writing the response. However, such behavior may not be supported</span></span><br><span class="line"><span class="comment">// by all HTTP/2 clients. Handlers should read before writing if</span></span><br><span class="line"><span class="comment">// possible to maximize compatibility.</span></span><br><span class="line">Write([]<span class="keyword">byte</span>) (<span class="keyword">int</span>, error)</span><br><span class="line"></span><br><span class="line"><span class="comment">// WriteHeader sends an HTTP response header with the provided</span></span><br><span class="line"><span class="comment">// status code.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// If WriteHeader is not called explicitly, the first call to Write</span></span><br><span class="line"><span class="comment">// will trigger an implicit WriteHeader(http.StatusOK).</span></span><br><span class="line"><span class="comment">// Thus explicit calls to WriteHeader are mainly used to</span></span><br><span class="line"><span class="comment">// send error codes.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The provided code must be a valid HTTP 1xx-5xx status code.</span></span><br><span class="line"><span class="comment">// Only one header may be written. Go does not currently</span></span><br><span class="line"><span class="comment">// support sending user-defined 1xx informational headers,</span></span><br><span class="line"><span class="comment">// with the exception of 100-continue response header that the</span></span><br><span class="line"><span class="comment">// Server sends automatically when the Request.Body is read.</span></span><br><span class="line">WriteHeader(statusCode <span class="keyword">int</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>秉着面向接口开发的原则，并且为了更好的兼容第三方的API，所以我们需要实现一个自己的<code>ResponseWriter</code>对象，于是就有了<code>route.NewResponse(c)</code>，这个<code>resp</code>实现了上述的接口.</p><p>兼容了<code>promhttp</code>提供的<code>Handler</code>，也兼容了自己的<code>helloworld</code>接口。</p><p>接着我们通过<code>cmux</code>进行一个路由匹配，然后调用到对应的<code>ServeHTTP</code>,处理完逻辑之后，在<code>resp</code>的<code>Close()</code>阶段，把缓存区的所有<code>[]byte</code>，推送到连接层，然后通过返回<code>gnet.Close</code>进行网络层的断开，至此，一个简单而完整的<code>http交互流程</code>完毕。</p><p>对于<code>Websocket</code>协议来说，要做的事情也是十分繁琐（由于用了开源协议库，相对简化了很多），请先看下面的应用层协议处理逻辑。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> !cdc.connected &#123;</span><br><span class="line">        wcb := &amp;wsConnBridge&#123;</span><br><span class="line">            buff: buffer,</span><br><span class="line">            c:    c,</span><br><span class="line">        &#125;</span><br><span class="line">        _, err := ws.Upgrade(wcb)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"upgrade[%s] to websocket error: %v"</span>, c.RemoteAddr().String(), err)&#125;)</span><br><span class="line">        &#125;</span><br><span class="line">        log.Debugf(log.NetServerDebugCategory&#123;&#125;, <span class="string">"conn[%v] upgrade websocket protocol"</span>, c.RemoteAddr().String())</span><br><span class="line">        cdc.connected = <span class="literal">true</span></span><br><span class="line">        metrics.ConnectedGauge.Inc()</span><br><span class="line">        metrics.TotalConnectedCounter.WithLabelValues(WebsocketApplicationLayerProto.String()).Inc()</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        msg, op, err := wsutil.ReadClientData(c)</span><br><span class="line">        <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> _, ok := err.(wsutil.ClosedError); !ok &#123;</span><br><span class="line">                log.Errorlog(log.NetServerErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"[%s] receive ws message error: %v"</span>, c.RemoteAddr().String(), err)&#125;)</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> gnet.Close</span><br><span class="line">        &#125;</span><br><span class="line">        log.Debugf(log.NetServerDebugCategory&#123;&#125;, <span class="string">"conn[%v] receive [op=%v] [msg=%v]"</span>, c.RemoteAddr().String(), op, <span class="keyword">string</span>(msg))</span><br><span class="line">        <span class="keyword">if</span> op == ws.OpText &#123;</span><br><span class="line">            <span class="keyword">if</span> rs := route.MatchRequestSpec(msg); rs == <span class="literal">nil</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> route.GlobalWsRouter.DefaultHandler().ServeWebsocket(<span class="string">"/"</span>, msg, c, op)</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> route.GlobalWsRouter.MatchHandler(rs.Path).ServeWebsocket(rs.Path, rs.Params, c, op)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>升级协议的过程中，我们用到了<code>github.com/gobwas/ws</code>这个协议库。</p><p>我们在接受到<code>websocket</code>前的时候需要先升级为websocket协议，但是这里遇到了一个问题，还是同理，我们的<code>gnet.Conn</code>的数据已经被我们取出来了，而升级的API显然就是需要提供一个可读可写的IO。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Upgrade is like Upgrader&#123;&#125;.Upgrade().</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">Upgrade</span><span class="params">(conn io.ReadWriter)</span> <span class="params">(Handshake, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> DefaultUpgrader.Upgrade(conn)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ReadWriter is the interface that groups the basic Read and Write methods.</span></span><br><span class="line"><span class="keyword">type</span> ReadWriter <span class="keyword">interface</span> &#123;</span><br><span class="line">Reader</span><br><span class="line">Writer</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Reader <span class="keyword">interface</span> &#123;</span><br><span class="line">Read(p []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Writer <span class="keyword">interface</span> &#123;</span><br><span class="line">Write(p []<span class="keyword">byte</span>) (n <span class="keyword">int</span>, err error)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>因此，我们又需要实现一个自己的<code>wsConnBridge</code>对象，主要是实现上述的接口，但是这个结构体相对来说就比较简单了，分别保存之前提出来的<code>[]byte</code>的buffer用于读行为，再保存一个<code>gnet.Conn</code>用于写行为即可。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> wsConnBridge <span class="keyword">struct</span> &#123;</span><br><span class="line">buff *bytes.Buffer</span><br><span class="line">c    gnet.Conn</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *wsConnBridge)</span> <span class="title">Read</span><span class="params">(p []<span class="keyword">byte</span>)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> w.buff.Read(p)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(w *wsConnBridge)</span> <span class="title">Write</span><span class="params">(p []<span class="keyword">byte</span>)</span> <span class="params">(n <span class="keyword">int</span>, err error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> w.c.Write(p)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>升级完了，我们需要给当前的<code>上下文环境的Context</code>标记为已经升级连接完毕。</p><p>然后就是进入到数据的收发环节了。</p><p><code>github.com/gobwas/ws</code>提供了<code>api</code>来进行数据的收发，分别有<code>high-level</code>和<code>low-level</code>，这里，我们可优先选择<code>high-level-api</code>，然后读取数据。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> WebsocketHandler <span class="keyword">interface</span> &#123;</span><br><span class="line">ServeWebsocket(path <span class="keyword">string</span>, data []<span class="keyword">byte</span>, w io.Writer, op ws.OpCode) gnet.Action</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>读取到数据之后，又因为我需要和http的route能有一个高度匹配的代码写法，所以在路由匹配上，也是做了一个类似的<code>Match</code>的行为，然后选择到对应的<code>Handler</code>，触发统一的<code>ServeWebsocket()</code>接口（为了和http的<code>ServeHttp()</code>对应）。</p><p>到此，从<code>网络层到应用层</code>的<code>端口复用实现多协议</code>原理就到此为止了。</p><p>接着就是处理自己的业务逻辑数据了。</p><h2 id="业务逻辑概述"><a href="#业务逻辑概述" class="headerlink" title="业务逻辑概述"></a>业务逻辑概述</h2><ol><li>记录客服需要监控的数据规则和连接关联</li><li>kafka-client从监控规则中匹配合适的数据，推送到对应的fd中 </li></ol><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ...</span></span><br><span class="line"><span class="keyword">var</span> i <span class="keyword">int64</span> = <span class="number">0</span></span><br><span class="line"><span class="keyword">var</span> wg sync.WaitGroup</span><br><span class="line">ListenChatRuleMap.Range(<span class="function"><span class="keyword">func</span><span class="params">(key, value <span class="keyword">interface</span>&#123;&#125;)</span> <span class="title">bool</span></span> &#123;</span><br><span class="line">    <span class="keyword">if</span> Match(key.(<span class="keyword">string</span>), kmsKey) &#123;</span><br><span class="line">        wg.Add(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">(c gnet.Conn, wsp *WsSendPayload)</span></span> &#123;</span><br><span class="line">            <span class="keyword">defer</span> wg.Done()</span><br><span class="line">            err := wsutil.WriteServerMessage(c, ws.OpText, wsp.Json())</span><br><span class="line">            <span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">                log.Errorf(log.AppErrorCategory&#123;Summary: fmt.Sprintf(<span class="string">"[wsWriteServerMessage failed] [err=%v]"</span>, err)&#125;, <span class="string">"[key=%s],[data=%s]"</span>, key.(<span class="keyword">string</span>), <span class="keyword">string</span>(wsp.Json()))</span><br><span class="line">                <span class="keyword">return</span></span><br><span class="line">            &#125;</span><br><span class="line">            atomic.AddInt64(&amp;i, <span class="number">1</span>)</span><br><span class="line">        &#125;(value.(gnet.Conn), wsp)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span></span><br><span class="line">&#125;)</span><br><span class="line">wg.Wait()</span><br><span class="line">metrics.ChatLogCounterClientHistogram.WithLabelValues(strconv.FormatUint(<span class="keyword">uint64</span>(lrc.Pid), <span class="number">10</span>), strconv.Itoa(wsp.ServerId), strconv.Itoa(wsp.AgentId)).Observe(<span class="keyword">float64</span>(atomic.LoadInt64(&amp;i)))</span><br><span class="line"><span class="comment">// ...</span></span><br></pre></td></tr></table></figure><p>至此，网络层和业务层的所有需求大体已经完毕了。</p><h2 id="prometheus-指标"><a href="#prometheus-指标" class="headerlink" title="prometheus 指标"></a>prometheus 指标</h2><p>部分的指标如下，后续可以通过一些指标对服务的稳定和可靠性进行优化升级处理。</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"># HELP chat_monitor_app_handle_chat_total Counter of handle.</span><br><span class="line"># TYPE chat_monitor_app_handle_chat_total counter</span><br><span class="line">chat_monitor_app_handle_chat_total&#123;agent_id="29",app_id="19",server_id="6558"&#125; 3</span><br><span class="line"># HELP chat_monitor_net_client_recv_counter number of chat log for client</span><br><span class="line"># TYPE chat_monitor_net_client_recv_counter histogram</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="1"&#125; 0</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="2"&#125; 0</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="4"&#125; 2</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="8"&#125; 3</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="16"&#125; 3</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="32"&#125; 3</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="64"&#125; 3</span><br><span class="line">chat_monitor_net_client_recv_counter_bucket&#123;agent_id="29",pid="1643890670000002",server_id="6558",le="+Inf"&#125; 3</span><br><span class="line">chat_monitor_net_client_recv_counter_sum&#123;agent_id="29",pid="1643890670000002",server_id="6558"&#125; 12</span><br><span class="line">chat_monitor_net_client_recv_counter_count&#123;agent_id="29",pid="1643890670000002",server_id="6558"&#125; 3</span><br><span class="line"># HELP chat_monitor_net_current_connected Current Counter Gauge of ws-connected.</span><br><span class="line"># TYPE chat_monitor_net_current_connected gauge</span><br><span class="line">chat_monitor_net_current_connected 4</span><br><span class="line"># HELP chat_monitor_net_total_connected The Total Counter of connected.</span><br><span class="line"># TYPE chat_monitor_net_total_connected counter</span><br><span class="line">chat_monitor_net_total_connected&#123;type="http"&#125; 15</span><br><span class="line">chat_monitor_net_total_connected&#123;type="websocket"&#125; 5</span><br><span class="line"># HELP chat_monitor_server_error_total Counter of error.</span><br><span class="line"># TYPE chat_monitor_server_error_total counter</span><br><span class="line">chat_monitor_server_error_total&#123;type="network_server_error"&#125; 1</span><br><span class="line"># HELP chat_monitor_server_gogc The value of GOGC</span><br><span class="line"># TYPE chat_monitor_server_gogc gauge</span><br><span class="line">chat_monitor_server_gogc 100</span><br><span class="line"># HELP chat_monitor_server_info Indicate the chat_monitor server info, and the value is the start timestamp (s).</span><br><span class="line"># TYPE chat_monitor_server_info gauge</span><br><span class="line">chat_monitor_server_info 1.644568978e+09</span><br><span class="line"># HELP chat_monitor_server_maxprocs The value of GOMAXPROCS.</span><br><span class="line"># TYPE chat_monitor_server_maxprocs gauge</span><br><span class="line">chat_monitor_server_maxprocs 6</span><br></pre></td></tr></table></figure><p>到这里，一些基础而核心的逻辑也介绍完了。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近，公司以前有一些旧的服务，由于各种原因，导致各种问题，并且架构设计行也不是那么友好和不利于维护。&lt;br&gt;所以准备重构设计一些服务。&lt;/p&gt;
&lt;p&gt;在游戏公司中，GM客服的其中一个职能就是监督舆论，从玩家平日的聊天中进行监控。&lt;/p&gt;
&lt;p&gt;我们从&lt;code&gt;业务需求&lt;/code&gt;+&lt;code&gt;技术架构&lt;/code&gt;层面进行整理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/categories/Golang/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>TIDB源码剖析（一）</title>
    <link href="http://blog.crazylaw.cn/2022/01/24/TIDB/TIDB%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://blog.crazylaw.cn/2022/01/24/TIDB/TIDB%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%EF%BC%88%E4%B8%80%EF%BC%89/</id>
    <published>2022-01-24T02:28:33.000Z</published>
    <updated>2022-01-25T03:01:50.165Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>这一章，作为我们的起始章节，跟着源码，我们一步步来熟悉TIDB的整体代码结构</p><hr><a id="more"></a><h2 id="Select"><a href="#Select" class="headerlink" title="Select"></a>Select</h2><p>当我们有一条基本的sql如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> mysql.user;</span><br></pre></td></tr></table></figure><p>我们从接收到客户端连接开始，<code>执行</code>，<code>解析</code>，<code>逻辑优化器</code>，<code>物理优化器</code>，到<code>最终结果</code>开始分析。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;planner.optimize at optimize.go:335</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;planner.Optimize at optimize.go:211</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;executor.(*Compiler).Compile at compiler.go:77</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;session.(*session).ExecuteStmt at session.go:1696</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*TiDBContext).ExecuteStmt at driver_tidb.go:220</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*clientConn).handleStmt at conn.go:1977</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*clientConn).handleQuery at conn.go:1846</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*clientConn).dispatch at conn.go:1341</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*clientConn).Run at conn.go:1091</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*Server).onConn at server.go:556</span><br><span class="line">runtime.goexit at asm_amd64.s:1371</span><br><span class="line"> - Async stack trace</span><br><span class="line">github.com&#x2F;pingcap&#x2F;tidb&#x2F;server.(*Server).startNetworkListener at server.go:453</span><br></pre></td></tr></table></figure><p>上面这是一个基本的执行流程，我们跟着这一段堆栈来进行分析。</p><h2 id="github-com-pingcap-tidb-server-Server-onConn-at-server-go-连接处理逻辑"><a href="#github-com-pingcap-tidb-server-Server-onConn-at-server-go-连接处理逻辑" class="headerlink" title="github.com/pingcap/tidb/server.(*Server).onConn at server.go (连接处理逻辑)"></a>github.com/pingcap/tidb/server.(*Server).onConn at server.go (连接处理逻辑)</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conn.Run(ctx)</span><br></pre></td></tr></table></figure><p>这里，我们看到了这是进入到了一个<code>clientConn</code>的 <code>Run</code> 方法。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Run reads client query and writes query result to client in for loop, if there is a panic during query handling,</span></span><br><span class="line"><span class="comment">// it will be recovered and log the panic error.</span></span><br><span class="line"><span class="comment">// This function returns and the connection is closed if there is an IO error or there is a panic.</span></span><br><span class="line"><span class="comment">// 在for循环中，执行读取客户端查询，并将查询结果写入客户端，如果在处理查询时出现panic，</span></span><br><span class="line"><span class="comment">// 它将被恢复并记录panic错误。</span></span><br><span class="line"><span class="comment">// 如果出现IO错误或panic，该函数返回并关闭连接。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *clientConn)</span> <span class="title">Run</span><span class="params">(ctx context.Context)</span></span></span><br></pre></td></tr></table></figure><p>这里我们看到了有一段文字帮助我们理解注意事项。</p><p>我们按照过程式的顺序来从上往下看源码</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">   <span class="keyword">const</span> size = <span class="number">4096</span></span><br><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line">r := <span class="built_in">recover</span>()</span><br><span class="line"><span class="keyword">if</span> r != <span class="literal">nil</span> &#123;</span><br><span class="line">buf := <span class="built_in">make</span>([]<span class="keyword">byte</span>, size)</span><br><span class="line">stackSize := runtime.Stack(buf, <span class="literal">false</span>)</span><br><span class="line">buf = buf[:stackSize]</span><br><span class="line">logutil.Logger(ctx).Error(<span class="string">"connection running loop panic"</span>,</span><br><span class="line">zap.Stringer(<span class="string">"lastSQL"</span>, getLastStmtInConn&#123;cc&#125;),</span><br><span class="line">zap.String(<span class="string">"err"</span>, fmt.Sprintf(<span class="string">"%v"</span>, r)),</span><br><span class="line">zap.String(<span class="string">"stack"</span>, <span class="keyword">string</span>(buf)),</span><br><span class="line">)</span><br><span class="line">err := cc.writeError(ctx, errors.New(fmt.Sprintf(<span class="string">"%v"</span>, r)))</span><br><span class="line">terror.Log(err)</span><br><span class="line">metrics.PanicCounter.WithLabelValues(metrics.LabelSession).Inc()</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> atomic.LoadInt32(&amp;cc.status) != connStatusShutdown &#123;</span><br><span class="line">err := cc.Close()</span><br><span class="line">terror.Log(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br></pre></td></tr></table></figure><p>这段代码，我们看到了几点。</p><ul><li>通过 <code>recover()</code> 方法来阻止<code>panic</code>引起的程序异常崩溃，如果是panic的话，那么将会有一段特殊的逻辑处理<br>  1.1 通过 <code>runtime.Stack(buf,false)</code> 的第二个参数来控制只获取当前协程下的堆栈信息，并且写入到<code>buf</code>变量中<br>  1.2 由于 <code>const size = 4096</code> 的原因，我们拿到的buf未必是那么多，因此，通过 <code>buf[:stackSize]</code> 来进行切片处理，把变量的指针重新指向新的数据区域<br>  1.3 通过日志组件来记录详细信息， 有意思的是，这里通过了<code>getLastStmtInConn结构体</code>里面的<code>String()</code>方法来进行序列化自己想要的内容信息，其他的就是基本的<code>err</code>, <code>stack</code>的信息了<br>  1.4 我们不单单需要在服务器上记录信息，还要把对应的用户错误信息也记录下来并且发送给客户端。所以通过了 <code>err := cc.writeError(ctx, errors.New(fmt.Sprintf(&quot;%v&quot;, r)))</code> 来实现这一点。<br>  1.5 然后就是记录相关的<code>metrics</code>，因为发生了一次 <code>panic</code>，所以需要通过<code>PanicCounter</code>记录下来，用于统计由于<code>session</code>引起的<code>panic</code>总共有多少次</li><li>如果是非panic引起的函数析构，那么还要通过原子性草走来判断状态是否为关闭状态，如果是关闭状态，那么在这里就需要把连接断开，并且记录下错误信息</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Usually, client connection status changes between [dispatching] &lt;=&gt; [reading].</span></span><br><span class="line"><span class="comment">// When some event happens, server may notify this client connection by setting</span></span><br><span class="line"><span class="comment">// the status to special values, for example: kill or graceful shutdown.</span></span><br><span class="line"><span class="comment">// The client connection would detect the events when it fails to change status</span></span><br><span class="line"><span class="comment">// by CAS operation, it would then take some actions accordingly.</span></span><br><span class="line"><span class="comment">// 通常情况下，客户端连接状态在[dispatching] &lt;=&gt; [reading]之间变化。</span></span><br><span class="line"><span class="comment">// 当某个事件发生时，服务器可以通过设置来通知这个客户端连接</span></span><br><span class="line"><span class="comment">// 将状态设置为特殊值，例如:kill或graceful shutdown。</span></span><br><span class="line"><span class="comment">// 当CAS操作改变状态失败时，客户端连接将检测到事件，然后采取相应的动作。</span></span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line"><span class="keyword">if</span> !atomic.CompareAndSwapInt32(&amp;cc.status, connStatusDispatching, connStatusReading) ||</span><br><span class="line"><span class="comment">// The judge below will not be hit by all means,</span></span><br><span class="line"><span class="comment">// But keep it stayed as a reminder and for the code reference for connStatusWaitShutdown.</span></span><br><span class="line">atomic.LoadInt32(&amp;cc.status) == connStatusWaitShutdown &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>我们看到这是一个循环操作，并且通过原子性操作<code>atomic.CompareAndSwapInt32</code>（比较然后再交换，所以符合CAS原则，乐观锁）来判断session连接是否能是否能切换到<code>connStatusDispatching</code> =&gt; <code>connStatusReading</code> 状态</li><li>如果不可以切换，那么则结束该方法</li><li>如果连接状态为等待关闭状态，那么也结束该方法</li></ul><p>对于其中的 <code>...</code>，现在会在下面进一步说明。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">cc.alloc.Reset()</span><br><span class="line"><span class="comment">// close connection when idle time is more than wait_timeout</span></span><br><span class="line">waitTimeout := cc.getSessionVarsWaitTimeout(ctx)</span><br><span class="line">cc.pkt.setReadTimeout(time.Duration(waitTimeout) * time.Second)</span><br><span class="line">start := time.Now()</span><br><span class="line">data, err := cc.readPacket()</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> terror.ErrorNotEqual(err, io.EOF) &#123;</span><br><span class="line"><span class="keyword">if</span> netErr, isNetErr := errors.Cause(err).(net.Error); isNetErr &amp;&amp; netErr.Timeout() &#123;</span><br><span class="line">idleTime := time.Since(start)</span><br><span class="line">logutil.Logger(ctx).Info(<span class="string">"read packet timeout, close this connection"</span>,</span><br><span class="line">zap.Duration(<span class="string">"idle"</span>, idleTime),</span><br><span class="line">zap.Uint64(<span class="string">"waitTimeout"</span>, waitTimeout),</span><br><span class="line">zap.Error(err),</span><br><span class="line">)</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">errStack := errors.ErrorStack(err)</span><br><span class="line"><span class="keyword">if</span> !strings.Contains(errStack, <span class="string">"use of closed network connection"</span>) &#123;</span><br><span class="line">logutil.Logger(ctx).Warn(<span class="string">"read packet failed, close this connection"</span>,</span><br><span class="line">zap.Error(errors.SuspendStack(err)))</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">disconnectByClientWithError.Inc()</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><code>cc.alloc.Reset()</code>重置内存池大小</li><li>当空闲时间大于等待超时时间的话那么将会关闭丽连接。<code>cc.pkt.setReadTimeout(time.Duration(waitTimeout) * time.Second)</code></li><li>从客户端读取数据，如果存在错误，那么将会记录下来相关信息，例如从读取数据到最后的时间，来统计idletime，通过<code>metrics.DisconnectionCounter.WithLabelValues(metrics.LblError)</code>来记录因为err导致连接断开的次数</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> !atomic.CompareAndSwapInt32(&amp;cc.status, connStatusReading, connStatusDispatching) &#123;</span><br><span class="line"><span class="keyword">return</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>同理，经过cas乐观锁，把状态从 <code>connStatusReading</code> =&gt; <code>connStatusDispatching</code>如果，交换设置失败，那么就结束函数。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">startTime := time.Now()</span><br><span class="line">err = cc.dispatch(ctx, data)</span><br></pre></td></tr></table></figure><h2 id="github-com-pingcap-tidb-server-clientConn-dispatch-（分发逻辑）"><a href="#github-com-pingcap-tidb-server-clientConn-dispatch-（分发逻辑）" class="headerlink" title="github.com/pingcap/tidb/server.(*clientConn).dispatch （分发逻辑）"></a>github.com/pingcap/tidb/server.(*clientConn).dispatch （分发逻辑）</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// dispatch handles client request based on command which is the first byte of the data.</span></span><br><span class="line"><span class="comment">// It also gets a token from server which is used to limit the concurrently handling clients.</span></span><br><span class="line"><span class="comment">// The most frequently used command is ComQuery.</span></span><br><span class="line"><span class="comment">// dispatch根据命令处理客户端请求，命令是数据的第一个字节。</span></span><br><span class="line"><span class="comment">// 它也从服务器获取一个令牌，用于限制并发处理客户端。</span></span><br><span class="line"><span class="comment">// 最常用的命令是ComQuery。</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *clientConn)</span> <span class="title">dispatch</span><span class="params">(ctx context.Context, data []<span class="keyword">byte</span>)</span> <span class="title">error</span></span></span><br></pre></td></tr></table></figure><p>下面的方法都是dispatch的过程顺序逻辑</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// reset killed for each request</span></span><br><span class="line">atomic.StoreUint32(&amp;cc.ctx.GetSessionVars().Killed, <span class="number">0</span>)</span><br><span class="line">&#125;()</span><br><span class="line">t := time.Now()</span><br><span class="line"><span class="keyword">if</span> (cc.ctx.Status() &amp; mysql.ServerStatusInTrans) &gt; <span class="number">0</span> &#123;</span><br><span class="line">connIdleDurationHistogramInTxn.Observe(t.Sub(cc.lastActive).Seconds())</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">connIdleDurationHistogramNotInTxn.Observe(t.Sub(cc.lastActive).Seconds())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>这里可以看到这里有一个defer，当函数结束的时候，会重置session的Killed次数</li><li><code>cc.ctx.Status() &amp; mysql.ServerStatusInTrans</code> 这里因为兼容了mysql的无状态协议，所以通过第一个<code>位运算</code>来判断当前状态<ol><li>如果当前链接处于一个<code>事务</code>状态下的话，那么通过<code>connIdleDurationHistogramInTxn.Observe(t.Sub(cc.lastActive).Seconds())</code> 用直方图监控从最后一次活跃时间到当前分发时间</li><li>否则则用另一个<code>metrics</code>来记录</li></ol></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">span := opentracing.StartSpan(<span class="string">"server.dispatch"</span>)</span><br><span class="line">cfg := config.GetGlobalConfig()</span><br><span class="line"><span class="keyword">if</span> cfg.OpenTracing.Enable &#123;</span><br><span class="line">ctx = opentracing.ContextWithSpan(ctx, span)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> cancelFunc context.CancelFunc</span><br><span class="line">ctx, cancelFunc = context.WithCancel(ctx)</span><br><span class="line">cc.mu.Lock()</span><br><span class="line">cc.mu.cancelFunc = cancelFunc</span><br><span class="line">cc.mu.Unlock()</span><br></pre></td></tr></table></figure><ul><li>通过<code>opentracing</code>来开始进行<code>分布式追踪</code>，<code>cc.mu</code> 主要是用来在<code>事务</code>中取消事务用的。</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cc.lastPacket = data</span><br><span class="line">cmd := data[<span class="number">0</span>]</span><br><span class="line">data = data[<span class="number">1</span>:]</span><br><span class="line"><span class="keyword">if</span> topsqlstate.TopSQLEnabled() &#123;</span><br><span class="line"><span class="keyword">defer</span> pprof.SetGoroutineLabels(ctx)</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> variable.EnablePProfSQLCPU.Load() &#123;</span><br><span class="line">label := getLastStmtInConn&#123;cc&#125;.PProfLabel()</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(label) &gt; <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">defer</span> pprof.SetGoroutineLabels(ctx)</span><br><span class="line">ctx = pprof.WithLabels(ctx, pprof.Labels(<span class="string">"sql"</span>, label))</span><br><span class="line">pprof.SetGoroutineLabels(ctx)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>把当前session接收到的数据记录在<code>lastPakcet</code>中</li><li><code>第一个字节</code>代表<code>命令</code></li><li><code>后面的字节</code>代表<code>数据</code></li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">token := cc.server.getToken()</span><br><span class="line"><span class="keyword">defer</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">// if handleChangeUser failed, cc.ctx may be nil</span></span><br><span class="line"><span class="keyword">if</span> cc.ctx != <span class="literal">nil</span> &#123;</span><br><span class="line">cc.ctx.SetProcessInfo(<span class="string">""</span>, t, mysql.ComSleep, <span class="number">0</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">cc.server.releaseToken(token)</span><br><span class="line">span.Finish()</span><br><span class="line">cc.lastActive = time.Now()</span><br><span class="line">&#125;()</span><br></pre></td></tr></table></figure><p>这里需要关注一下<code>defer</code>里面的内容</p><ul><li>根据mysql协议，当命令为<code>mysql.ComSleep</code>的时候，代表execute已经完成了。所以当结束的时候，需要设置一下这个<code>ProcessInfo</code></li><li>然后释放本次token，并且span也需要标记为完成</li><li>更新最后一次活跃时间</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vars := cc.ctx.GetSessionVars()</span><br><span class="line"><span class="comment">// reset killed for each request</span></span><br><span class="line">atomic.StoreUint32(&amp;vars.Killed, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">if</span> cmd &lt; mysql.ComEnd &#123;</span><br><span class="line">cc.ctx.SetCommandValue(cmd)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>获取当前session的变量</li><li>重置其中的killed属性</li><li>如果<code>cmd</code>在范围内的，更新当前命令的值</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dataStr := <span class="keyword">string</span>(hack.String(data))</span><br><span class="line"><span class="keyword">switch</span> cmd &#123;</span><br><span class="line"><span class="keyword">case</span> mysql.ComPing, mysql.ComStmtClose, mysql.ComStmtSendLongData, mysql.ComStmtReset,</span><br><span class="line">mysql.ComSetOption, mysql.ComChangeUser:</span><br><span class="line">cc.ctx.SetProcessInfo(<span class="string">""</span>, t, cmd, <span class="number">0</span>)</span><br><span class="line"><span class="keyword">case</span> mysql.ComInitDB:</span><br><span class="line">cc.ctx.SetProcessInfo(<span class="string">"use "</span>+dataStr, t, cmd, <span class="number">0</span>)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>这里利用了golang种的<code>hack（黑科技）</code>的方式来把<code>byte</code>转换成<code>string</code>，其实主要就是因为底层用的都有一样的结构体，所以可以直接通过<code>unsafe.pointer</code>来直接操作内容指针，进行<code>zero-copy</code></li><li>对cmd进行<code>processinfo</code>的处理，如果是<code>use db</code>的命令的话，则需要传递数据库</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span> cmd &#123;</span><br><span class="line"><span class="keyword">case</span> mysql.ComSleep:</span><br><span class="line"><span class="comment">// <span class="doctag">TODO:</span> According to mysql document, this command is supposed to be used only internally.</span></span><br><span class="line"><span class="comment">// So it's just a temp fix, not sure if it's done right.</span></span><br><span class="line"><span class="comment">// Investigate this command and write test case later.</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line"><span class="keyword">case</span> mysql.ComQuit:</span><br><span class="line"><span class="keyword">return</span> io.EOF</span><br><span class="line"><span class="keyword">case</span> mysql.ComInitDB:</span><br><span class="line"><span class="keyword">if</span> err := cc.useDB(ctx, dataStr); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> cc.writeOK(ctx)</span><br><span class="line"><span class="keyword">case</span> mysql.ComQuery: <span class="comment">// Most frequently used command.</span></span><br><span class="line"><span class="comment">// For issue 1989</span></span><br><span class="line"><span class="comment">// Input payload may end with byte '\0', we didn't find related mysql document about it, but mysql</span></span><br><span class="line"><span class="comment">// implementation accept that case. So trim the last '\0' here as if the payload an EOF string.</span></span><br><span class="line"><span class="comment">// See http://dev.mysql.com/doc/internals/en/com-query.html</span></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(data) &gt; <span class="number">0</span> &amp;&amp; data[<span class="built_in">len</span>(data)<span class="number">-1</span>] == <span class="number">0</span> &#123;</span><br><span class="line">data = data[:<span class="built_in">len</span>(data)<span class="number">-1</span>]</span><br><span class="line">dataStr = <span class="keyword">string</span>(hack.String(data))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> cc.handleQuery(ctx, dataStr)</span><br><span class="line">...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我复制了一部分，因为我们重点关注<code>mysql.ComQuery</code>命令。</p><ul><li>根据提示，我们发现因为mysql协议说明了输入载体可能以<code>\0</code>作为最后字节，所以这里一定要减去client发送的多余的最后一个字节。所以长度进行了-1操作</li><li>然后进入到<code>cc.handleQuery(ctx, dataStr)</code></li></ul><h2 id="github-com-pingcap-tidb-server-clientConn-handleQuery"><a href="#github-com-pingcap-tidb-server-clientConn-handleQuery" class="headerlink" title="github.com/pingcap/tidb/server.(*clientConn).handleQuery"></a>github.com/pingcap/tidb/server.(*clientConn).handleQuery</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// handleQuery executes the sql query string and writes result set or result ok to the client.</span></span><br><span class="line"><span class="comment">// As the execution time of this function represents the performance of TiDB, we do time log and metrics here.</span></span><br><span class="line"><span class="comment">// There is a special query `load data` that does not return result, which is handled differently.</span></span><br><span class="line"><span class="comment">// Query `load stats` does not return result either.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *clientConn)</span> <span class="title">handleQuery</span><span class="params">(ctx context.Context, sql <span class="keyword">string</span>)</span> <span class="params">(err error)</span></span></span><br></pre></td></tr></table></figure><p>这个方法，终于开始正式进入我们的主题了</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">defer</span> trace.StartRegion(ctx, <span class="string">"handleQuery"</span>).End()</span><br><span class="line">sc := cc.ctx.GetSessionVars().StmtCtx</span><br><span class="line">prevWarns := sc.GetWarnings()</span><br><span class="line">stmts, err := cc.ctx.Parse(ctx, sql)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(stmts) == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> cc.writeOK(ctx)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>defer进行了当函数结束的时候，标记<code>handleQuery</code>结束</li><li>拿到<code>statement</code>的上下文环境</li><li>从上下文中拿到所有的<code>warinning</code>警告</li><li>通过<code>cc.ctx.Parse(ctx, sql)</code>来进行解析sql，这里属于一个大的篇章，暂时不张开讲，主要涉及到的内容有<code>编译原理</code>,<code>AST-Tree</code>，<code>Yacc</code>。我们通过这里可以拿到一棵抽象语法树，实质是<code>SelectStmt</code>，内部包含了如下内容：<ol><li>dmlNode（因为select语句属于dml语句）</li><li>其他的都是常规的例如<code>FROM</code>, <code>WHERE</code>, <code>FIELDS</code>, <code>DISTINCT</code> 等等</li></ol></li><li>如果没有一个完成的抽象语法书，则直接返回响应协议和对应的内容</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> pointPlans []plannercore.Plan</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(stmts) &gt; <span class="number">1</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="comment">// The client gets to choose if it allows multi-statements, and</span></span><br><span class="line"><span class="comment">// probably defaults OFF. This helps prevent against SQL injection attacks</span></span><br><span class="line"><span class="comment">// by early terminating the first statement, and then running an entirely</span></span><br><span class="line"><span class="comment">// new statement.</span></span><br><span class="line"></span><br><span class="line">capabilities := cc.ctx.GetSessionVars().ClientCapability</span><br><span class="line"><span class="keyword">if</span> capabilities&amp;mysql.ClientMultiStatements &lt; <span class="number">1</span> &#123;</span><br><span class="line"><span class="comment">// The client does not have multi-statement enabled. We now need to determine</span></span><br><span class="line"><span class="comment">// how to handle an unsafe situation based on the multiStmt sysvar.</span></span><br><span class="line"><span class="keyword">switch</span> cc.ctx.GetSessionVars().MultiStatementMode &#123;</span><br><span class="line"><span class="keyword">case</span> variable.OffInt:</span><br><span class="line">err = errMultiStatementDisabled</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line"><span class="keyword">case</span> variable.OnInt:</span><br><span class="line"><span class="comment">// multi statement is fully permitted, do nothing</span></span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line">warn := stmtctx.SQLWarn&#123;Level: stmtctx.WarnLevelWarning, Err: errMultiStatementDisabled&#125;</span><br><span class="line">parserWarns = <span class="built_in">append</span>(parserWarns, warn)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Only pre-build point plans for multi-statement query</span></span><br><span class="line">pointPlans, err = cc.prefetchPointPlanKeys(ctx, stmts)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>通过Session中的var中的<code>ClientCapability</code>的<code>位运算</code>来判断是否支持<code>mysql.ClientMultiStatements</code>（多sql语句）</li><li>如果<code>sysvar</code>也不支持<code>MultiStatementMode</code>,也就是<code>variable.OffInt</code>，那么就直接返回err</li><li>如果没有能力支持client多statement的话，但是var又开启了的话，目前啥事也没做</li><li>默认就是不支持，但是会通过warn来展示给客户端</li><li>只有在多statement的场景下预取目标计划关键字</li></ul><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, stmt := <span class="keyword">range</span> stmts &#123;</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(pointPlans) &gt; <span class="number">0</span> &#123;</span><br><span class="line"><span class="comment">// Save the point plan in Session, so we don't need to build the point plan again.</span></span><br><span class="line">cc.ctx.SetValue(plannercore.PointPlanKey, plannercore.PointPlanVal&#123;Plan: pointPlans[i]&#125;)</span><br><span class="line">&#125;</span><br><span class="line">retryable, err = cc.handleStmt(ctx, stmt, parserWarns, i == <span class="built_in">len</span>(stmts)<span class="number">-1</span>)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">if</span> !retryable || !errors.ErrorEqual(err, storeerr.ErrTiFlashServerTimeout) &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">_, allowTiFlashFallback := cc.ctx.GetSessionVars().AllowFallbackToTiKV[kv.TiFlash]</span><br><span class="line"><span class="keyword">if</span> !allowTiFlashFallback &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// When the TiFlash server seems down, we append a warning to remind the user to check the status of the TiFlash</span></span><br><span class="line"><span class="comment">// server and fallback to TiKV.</span></span><br><span class="line">warns := <span class="built_in">append</span>(parserWarns, stmtctx.SQLWarn&#123;Level: stmtctx.WarnLevelError, Err: err&#125;)</span><br><span class="line"><span class="built_in">delete</span>(cc.ctx.GetSessionVars().IsolationReadEngines, kv.TiFlash)</span><br><span class="line">_, err = cc.handleStmt(ctx, stmt, warns, i == <span class="built_in">len</span>(stmts)<span class="number">-1</span>)</span><br><span class="line">cc.ctx.GetSessionVars().IsolationReadEngines[kv.TiFlash] = <span class="keyword">struct</span>&#123;&#125;&#123;&#125;</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">break</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>如果有目标计划的话，那么只需要在上下文中设置value即可，不需要再次构建目标计划</li><li><code>cc.handleStmt(ctx, stmt, parserWarns, i == len(stmts)-1)</code> 这是我们的核心中的核心，这里面就是处理<code>抽象语法树</code>的逻辑，包含了<code>逻辑优化</code>, <code>物理优化</code>, <code>执行器</code>，<code>tikv</code>交互等等</li><li>todo：留着回来分析</li></ul><h2 id="github-com-pingcap-tidb-server-clientConn-handleStmt"><a href="#github-com-pingcap-tidb-server-clientConn-handleStmt" class="headerlink" title="github.com/pingcap/tidb/server.(*clientConn).handleStmt"></a>github.com/pingcap/tidb/server.(*clientConn).handleStmt</h2><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The first return value indicates whether the call of handleStmt has no side effect and can be retried.</span></span><br><span class="line"><span class="comment">// Currently, the first return value is used to fall back to TiKV when TiFlash is down.</span></span><br><span class="line"><span class="comment">// 第一个返回值表示调用handleStmt是否没有副作用，是否可以重试</span></span><br><span class="line"><span class="comment">// 当前，第一个返回值用于在TiFlash down时回落到TiKV</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(cc *clientConn)</span> <span class="title">handleStmt</span><span class="params">(ctx context.Context, stmt ast.StmtNode, warns []stmtctx.SQLWarn, lastStmt <span class="keyword">bool</span>)</span> <span class="params">(<span class="keyword">bool</span>, error)</span></span></span><br></pre></td></tr></table></figure><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ctx = context.WithValue(ctx, execdetails.StmtExecDetailKey, &amp;execdetails.StmtExecDetails&#123;&#125;)</span><br><span class="line">ctx = context.WithValue(ctx, util.ExecDetailsKey, &amp;util.ExecDetails&#123;&#125;)</span><br><span class="line">reg := trace.StartRegion(ctx, <span class="string">"ExecuteStmt"</span>)</span><br><span class="line">cc.audit(plugin.Starting)</span><br><span class="line">rs, err := cc.ctx.ExecuteStmt(ctx, stmt)</span><br></pre></td></tr></table></figure><ul><li>上下文带上value，设置主要是<code>StmtExecDetails</code>，里面记录了写入sql到响应的时间</li><li>上下文带上value，设置主要是<code>ExecDetails</code>，里面记录了<code>execution</code>的详情信息，分别有</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;这一章，作为我们的起始章节，跟着源码，我们一步步来熟悉TIDB的整体代码结构&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
    
      <category term="TIDB" scheme="http://blog.crazylaw.cn/categories/TIDB/"/>
    
    
      <category term="TIDB" scheme="http://blog.crazylaw.cn/tags/TIDB/"/>
    
  </entry>
  
  <entry>
    <title>2022杂乱知识点总结</title>
    <link href="http://blog.crazylaw.cn/2022/01/19/2022%E6%9D%82%E4%B9%B1%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"/>
    <id>http://blog.crazylaw.cn/2022/01/19/2022%E6%9D%82%E4%B9%B1%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</id>
    <published>2022-01-19T06:38:06.000Z</published>
    <updated>2022-02-05T06:14:45.964Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>记录一下常规下的一些知识点。</p><hr><a id="more"></a><h2 id="Go"><a href="#Go" class="headerlink" title="Go"></a>Go</h2><h3 id="go-channel-close后读的问题"><a href="#go-channel-close后读的问题" class="headerlink" title="go channel close后读的问题"></a>go channel close后读的问题</h3>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;记录一下常规下的一些知识点。&lt;/p&gt;
&lt;hr&gt;
    
    </summary>
    
    
      <category term="知识点" scheme="http://blog.crazylaw.cn/categories/%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    
    
      <category term="2022杂乱知识点总结" scheme="http://blog.crazylaw.cn/tags/2022%E6%9D%82%E4%B9%B1%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>【2021】 2021年终总结</title>
    <link href="http://blog.crazylaw.cn/2022/01/02/2021%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    <id>http://blog.crazylaw.cn/2022/01/02/2021%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/</id>
    <published>2022-01-02T15:54:00.000Z</published>
    <updated>2022-01-25T03:01:32.272Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>2021已经过去了，在这里回忆一下，我的2021的年终总结。</p><a id="more"></a><h2 id="困难与挑战"><a href="#困难与挑战" class="headerlink" title="困难与挑战"></a>困难与挑战</h2><p>工作中，在过去的一年里，迎接了不少的挑战，在公司中落地大数据相关的服务了从<code>erlang</code>到<code>golang</code>的转换。我们整套新的体系称为：<code>mfeilog</code></p><ol><li><p>在公司中，积累了许多go语言的组件，并且不断的完善修复相关的bug，例如，mfeilog的核心数据源：<code>msource</code>，mfeilog的基础组件：<code>daemon组件</code>/<code>no-named-pipe组件</code>，<code>logbdev组件</code>，<code>sink_mysql</code>/<code>sink_kafka</code>等组件。</p></li><li><p>说到这个<code>msource</code>服务，这是一个基于<code>rocksdb</code>实现的支持<code>sql</code>语法的轻量级小型定制<code>数据库服务</code>，可以说是经过了不断优化，升级，修复内部各种内置功能，才得以现在的稳定和高效。给应用层提供了一个高可靠，稳定，的数据源功能。其中有一个bug，印象特别深刻，也是我始料未及的一个bug，因为<code>发号器</code>是附属在<code>Table</code>当中的，我需要<code>自定义序列化</code>后存储在底层的<code>rocksdb</code>中，所以在我<code>反序列化</code>出来的时候，启动了多个发号器，导致每个<code>field-colunm</code>都实例化了一个新的对象，而非同一个对象，引发了发号器错乱，从而导致数据丢失的问题(内存被覆盖，错误ack掉了数据)。这个问题排查也是十分不易！！！所以可以说是血的教训。</p></li><li><p>并且也为公司推广 “服务器日志查询方案” 中，确定了以<code>GPL（grafna+protomal+loki）</code>的日志查询架构，统一了日志查询的入口，大大提高了日志查询的效率。</p></li><li><p>在 <code>go服务流量录制和回放方案和实现</code> 中，为了实现流量闭环，特意去调研查看了 滴滴的 <code>《写轮眼》</code>项目，并且知道了通过类似注入的方式，可以在用户层编解码上替换到原来的函数指针，从而实现在用户层替换go底层源码的方式，但是由于性价比问题，在公司中最后并未推广，也没有进行研发。该需求后面被搁置了。</p></li><li><p>在 <code>配置服务方案</code> 中，这个需求在以往其实已经试过才用<code>consule</code>来做配置服务中心，原因是早期我们想要对服务做一个<code>服务注册和发现</code>，在 <code>php</code> 这种<code>fastcgi</code>的方式来说，consule的主动发现服务，就比很多类似<code>etcd</code>被动发现注册服务好用。但是由于最终因为我们的服务目前来说比较零散，并且需求的任务不是着急，这件事后面也被搁置了，后面今天再次提了一个这样子的类似的需求，实现了通过 go语言写的的工具，类似于<code>k8s</code>的<code>kubectl</code>的工具，进行配置的同步和管理，分别分为了2个模式，一个是C端的工具，一个是S端的同步服务，中间的枢纽，最终选择了以<code>etcd</code>为配置分布式存储服务。我们服务的部署特点，利用<code>jenkins</code>的<code>多阶段自定义编译</code>的<code>jenkins-shared-library</code>实现了灵活编译，根据现有的服务灵活部署，从而达到非嵌入式的配置同步方式。</p></li><li><p>因为公司成立得比较早，代码仓库一直从未进行变更，所以其中一个需求就是 <code>gitbucket</code> 到 <code>gitlab</code> 的代码仓库迁移，写了一个小工具，从而实现了从 gitbucket到 gitlab一键自动化无缝迁移代码，包括项目组，项目的历史<code>commit</code>，<code>tag</code>，<code>branch</code>等等都自动化完成，大大减轻了项目迁移的负担。</p></li><li><p>对 <code>jenkins</code> 的<code>shard-library</code> 模块进行优化升级，编写了一个<code>python的支持多凭据认证的脚本</code>，并且支持自定义编译代码。</p></li><li><p>集成了一套，<code>本地的大数据docker环境</code>，我们都知道大数据环境十分的繁杂，并且还需要多台机器才能处理，这对我们本地开发来说十分的不友好，但是网上又没有那些很好的开箱即用的<code>docker-compose</code>环境，因此整理了一套本地的大数据docker环境(非CDH版本)</p></li><li><p>优化升级部分 <code>mproxy</code> 的代码，从而让测试人员更友好的在该项目中完成<code>自动化测试</code>的脚本功能。</p></li><li><p>推动<code>flink</code>的落地，由于我们早期的流计算，是单机的，并且存在严重的外部依赖属性，所以，我们推动了flink的落地，探究了几种开发方式，分别是用纯<code>java</code> 写的<code>datastream-api</code>方式，这个方式有一个好处就是，所有的上层的api都是基于<code>datastream</code>的，一些上层的api无法满足我们的需求，我们通过datastream可以很轻松的实现各类需求。在这个过程中，我踩了不少的坑，主要是来自于<code>watermark</code>和<code>window</code>的概念，咋一看其实都是一些比较好理解的概念，但是其实在配合大数据专用的<code>kafka</code>消息队列中间件，一切就变得复杂起来，由于<code>kafka</code>的<code>partition</code>只能有一个client去消费的原因，加上flink自身的概念<code>并行度</code>，这一切结合在一起，就会出现一些让你疑惑的点。经过了大量反复的摸索和钻研，最终才掌握了在多partition下flink的watermark和window-trigger机制方式，但是由于该方式不够直观，也不管灵活，所以我们最终推广了<code>sql-api</code>。好家伙，你以为这就完了吗，并没有，由于flink自身带有<code>sql-client</code>的原因，我一开始尝试了用<code>sql-client</code>来编写流计算的模型，但是发现这个工具有太多问题了，不同的版本有不用的调用方式，不同版本下，对于<code>SET</code>支持的粒度也是不一致的，这让我很头疼。所以最终选择了，基于flink编写了一个自研的<code>flink-sql-client</code>，通过<code>flink run flink-sql-client.jar</code>的方式，我们就可以轻松的提交sql任务或者做其他的需求（例如查看hive的cataglog等等）。然而到了这里还没有结束，由于<code>sql</code>的部分，我们没办法控制，是由<code>flink-core</code>自身标准化了流程，所以有一些bug我们没办法解决，例如在 <code>flink-1.12.0</code> 种，就会因为<code>watermark</code>在<code>idle</code>的情况下，无法推进watermark，从而导致窗口在少量数据情况下，根本不能及时的统计和计算（这和号称实时分析的流计算违背），所以我们只能想了一些版本做了一些迂回的操作。从而最终解决类似这种由于底层bug所带来的问题。</p></li></ol><h2 id="自己的学习上"><a href="#自己的学习上" class="headerlink" title="自己的学习上"></a>自己的学习上</h2><ol><li><p>对<code>golang</code>的<code>protobuf</code>服务有一些的了解，并且学会了<code>protobuf</code>的插件开发。了解了protobuf的协议。</p></li><li><p>对<code>rust</code>上的生态更为清晰了，利用了其中的一些<code>actor</code>模型，<code>async-io</code>等分别实现了一些基础的工具。</p></li><li><p>对<code>flutter</code>也有了一定的了解，利用<code>dart</code>编写了一个可以用于自定义通信的库。s</p></li><li><p>对<code>linux</code> 种的一些磁盘io，网络io，已经shell命令的灵活运用更加深刻。</p></li></ol><blockquote><p>未完待续！！</p></blockquote><p>(悄咪咪的告诉大家，我买房了。嘿嘿)</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;2021已经过去了，在这里回忆一下，我的2021的年终总结。&lt;/p&gt;
    
    </summary>
    
    
      <category term="年终总结" scheme="http://blog.crazylaw.cn/categories/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="年终总结" scheme="http://blog.crazylaw.cn/tags/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/"/>
    
  </entry>
  
  <entry>
    <title>【大数据】- flink开发环境搭建</title>
    <link href="http://blog.crazylaw.cn/2021/09/28/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    <id>http://blog.crazylaw.cn/2021/09/28/%E5%A4%A7%E6%95%B0%E6%8D%AE/flink%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</id>
    <published>2021-09-28T01:56:40.000Z</published>
    <updated>2021-09-28T09:10:18.184Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>由于最近要推动flink的流计算代替我们的内部的自行研发的mstream流计算服务，所以需要对flink进行开发。</p><a id="more"></a><h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p>我们的flink的版本上1.12.0</p><p>理论上只是jdk8和jdk11.所以我们需要安装jdk8和jdk8</p><p>因为我的是macOS，所以这里我说一下mac安装的过程。</p><p>首先，我们需要安装jdk。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">brew tap adoptopenjdk/openjdk</span><br><span class="line">brew install adoptopenjdk8</span><br><span class="line">brew install adoptopenjdk11</span><br></pre></td></tr></table></figure><blockquote><p>置于要用jdk8还是jdk11，自行抉择，我这里2个都安装了。</p></blockquote><p>但是这个时候你可能会找不到安装路径</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ /usr/libexec/java_home -V</span><br><span class="line">Matching Java Virtual Machines (3):</span><br><span class="line">    11.0.12 (x86_64) "Oracle Corporation" - "Java SE 11.0.12" /Library/Java/JavaVirtualMachines/jdk-11.0.12.jdk/Contents/Home</span><br><span class="line">    11.0.11 (x86_64) "AdoptOpenJDK" - "AdoptOpenJDK 11" /Library/Java/JavaVirtualMachines/adoptopenjdk-11.jdk/Contents/Home</span><br><span class="line">    1.8.0_292 (x86_64) "AdoptOpenJDK" - "AdoptOpenJDK 8" /Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home</span><br></pre></td></tr></table></figure><p>通过<code>/usr/libexec/java_home -V</code>内置的一个程序，就可以找到所有相关的<code>java_home</code>，这里我们就可以看到对应的<code>java_home</code>，然后找到对应的java解析器。</p><h2 id="IDE初始化项目"><a href="#IDE初始化项目" class="headerlink" title="IDE初始化项目"></a>IDE初始化项目</h2><p>我这里用的是<code>IDEA</code>，所以我这里列一下我的操作步骤。</p><h3 id="New-Project"><a href="#New-Project" class="headerlink" title="New Project"></a>New Project</h3><p>先把<code>Maven</code>包的路径确定下来。后面利用docker-maven工具的时候，指定挂载仓库有用。</p><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject13.png" alt="newproject13"></p><p>开始创建项目</p><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject1.png" alt="newproject1"></p><p>选择使用Maven来创建项目，并且选择刚才安装好的<code>JDK8</code>或者<code>JDK11</code>。</p><p>默认情况下，这是不带<code>archetype</code>的，这个是<code>Maven</code>模板的类型。我们需要勾选这个<code>archetype</code>，</p><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject2.png" alt="newproject2"></p><p>接下来添加<code>flink-quickstart-java</code>的<code>archetype</code>。</p><ul><li>GroupId = org.apache.flink</li><li>AryofactId = flink-quickstart-java</li><li>Version = 1.12.0</li></ul><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject3.png" alt="newproject3"></p><p>利用模版创建项目</p><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject4.png" alt="newproject4"></p><p>可以根据自行的需要，填写项目的路径以及对应的<code>GroupId</code>, <code>AryofactId</code>, <code>Version</code></p><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject5.png" alt="newproject5"></p><p>然后就是Maven的相关配置，这里使用的默认的就行，直接点击<code>Finish</code>完成项目初始化，然后项目会自动根据Maven的配置加载对应的Jar包。</p><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject6.png" alt="newproject6"></p><p>等待一切初始化完毕后，会看到如下图的模板</p><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject7.png" alt="newproject7"></p><p>其中包含了2个Job，分别是<code>BatchJob</code>和<code>StreamingJob</code>。</p><ul><li>BatchJob 代表批处理任务</li><li>StreamingJob 代表流处理任务</li></ul><h2 id="编写批处理代码并测试执行"><a href="#编写批处理代码并测试执行" class="headerlink" title="编写批处理代码并测试执行"></a>编写批处理代码并测试执行</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one</span></span><br><span class="line"><span class="comment"> * or more contributor license agreements.  See the NOTICE file</span></span><br><span class="line"><span class="comment"> * distributed with this work for additional information</span></span><br><span class="line"><span class="comment"> * regarding copyright ownership.  The ASF licenses this file</span></span><br><span class="line"><span class="comment"> * to you under the Apache License, Version 2.0 (the</span></span><br><span class="line"><span class="comment"> * "License"); you may not use this file except in compliance</span></span><br><span class="line"><span class="comment"> * with the License.  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *     http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment"> * distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment"> * See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment"> * limitations under the License.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> my.flink;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.ExecutionEnvironment;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.api.java.operators.DataSource;</span><br><span class="line"><span class="keyword">import</span> org.apache.flink.util.Collector;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Skeleton for a Flink Batch Job.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;For a tutorial how to write a Flink batch application, check the</span></span><br><span class="line"><span class="comment"> * tutorials and examples on the &lt;a href="https://flink.apache.org/docs/stable/"&gt;Flink Website&lt;/a&gt;.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * &lt;p&gt;To package your application into a JAR file for execution,</span></span><br><span class="line"><span class="comment"> * change the main class in the POM.xml file to this class (simply search for 'mainClass')</span></span><br><span class="line"><span class="comment"> * and run 'mvn clean package' on the command line.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BatchJob</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="comment">// set up the batch execution environment</span></span><br><span class="line">        <span class="keyword">final</span> ExecutionEnvironment env = ExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        DataSource&lt;String&gt; el = env.fromElements(<span class="string">"good good study"</span>, <span class="string">"day day up"</span>);</span><br><span class="line"></span><br><span class="line">        el.flatMap(</span><br><span class="line">                (String a, Collector&lt;String&gt; out) -&gt; Arrays.stream(a.split(<span class="string">" "</span>)).forEach(x -&gt; out.collect(x))</span><br><span class="line">        ).returns(String<span class="class">.<span class="keyword">class</span>).<span class="title">print</span>()</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 由于print()是调试模式，所以不能指定Jobname，print()内部会自动调用Execute()</span></span><br><span class="line">        <span class="comment">// 所以 env.execute() 将无法调用，需要注释掉，否则会有报错抛出，当然你也可以选择忽略这个异常</span></span><br><span class="line">        <span class="comment">// execute program</span></span><br><span class="line">        <span class="comment">// env.execute("Flink Batch Java API Skeleton");</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们把<code>BatchJob</code>加入了<code>具体</code>的任务。我这里的写法是Java8的lamba的写法，使用lamba的写法记得需要在后面加上<code>returns</code>的函数，这是因为使用<code>lamba</code>的情况下，会导致部分信息无法自动推导，需要手动显式指定，从而导致我们需要调用多这个函数。</p><p>我们初始化了一个数据源集合，这个集合类型为<code>String</code>类型，我们指定这个集合的元素有2个，分别是<code>good good study</code>, <code>day day up</code>。</p><p>然后我们通过<code>flatMap</code>的方法进行一个归并的操作，把每个元素通过<code>一个空格</code>进行切分，切分之后，我们通过<code>Collector</code>的<code>collect()</code>进行收集起来。最终输出在终端。</p><p>并且这个Job的名字，我们定义为<code>Flink Batch Java API Skeleton</code>。</p><p>我们运行这个Job.默认情况下，会遇到如下报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org&#x2F;apache&#x2F;flink&#x2F;api&#x2F;java&#x2F;ExecutionEnvironment</span><br><span class="line">at my.flink.BatchJob.main(BatchJob.java:41)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: org.apache.flink.api.java.ExecutionEnvironment</span><br><span class="line">at java.base&#x2F;jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581)</span><br><span class="line">at java.base&#x2F;jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178)</span><br><span class="line">at java.base&#x2F;java.lang.ClassLoader.loadClass(ClassLoader.java:522)</span><br><span class="line">... 1 more</span><br></pre></td></tr></table></figure><p>你可能会觉得很奇怪，明明<code>IDEA</code>已经把<code>Flink</code>的包加载进来，也能正常跳转，为什么在运行的时候却出现了这个，这是因为这是编译的行为，和IDEA加载包没有直接的关系。</p><p>打开你的<code>pom.xml</code>，找到<code>dependencies</code>下的<code>&lt;groupId&gt;org.apache.flink&lt;/groupId&gt;</code>的所有依赖包，你会发现每个依赖包下面都有一个<code>&lt;scope /&gt;</code>的定义，里面的value写的是<code>provided</code>，我们只需要把这一整行注释掉就好了。</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">scope</span>&gt;</span>provided<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>注释后</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- &lt;scope&gt;provided&lt;/scope&gt; --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-streaming-java_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- &lt;scope&gt;provided&lt;/scope&gt; --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.flink<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>flink-clients_$&#123;scala.binary.version&#125;<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;flink.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- &lt;scope&gt;provided&lt;/scope&gt; --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>这样子，就等同于定义依赖包，使用默认的<code>scope</code>范围。</p><p>我们这里需要了解一下scope的一些细节。</p><p>对于<code>scope=compile</code>的情况（<code>默认scope</code>),也就是说这个项目在<code>编译</code>，<code>测试</code>，<code>运行阶段``都需要</code>这个artifact(模块)对应的jar包<code>在classpath中</code>。</p><p>而对于<code>scope=provided</code>的情况，则可以认为这个provided是<code>目标容器已经provide这个artifact</code>。换句话说，<code>它只影响到编译，测试阶段</code>。在编译测试阶段，我们需要这个artifact对应的jar包在classpath中，而在运行阶段，假定目标的容器（比如我们这里的liferay容器）已经提供了这个jar包，所以无需我们这个artifact对应的jar包了。</p><p>maven中三种classpath<br>编译，测试，运行</p><ul><li>compile：默认范围，编译测试运行都有效</li><li>provided：在编译和测试时有效</li><li>runtime：在测试和运行时有效</li><li>test：只在测试时有效</li><li>system：在编译和测试时有效，与本机系统关联，可移植性差</li></ul><p>所以我们需要改变的就是这个<code>scope</code>的范围，让某情况下可以运行。例如，我们需要在本机上运行，那么我们就可以注释掉，然后就会使用默认的<code>compile</code>。</p><p>但是需要注意的是，当你改动了这个<code>pom.xml</code>之后，idea我不知道是不是bug，反正我的当前版本不会自动刷新，怎么理解这句话？</p><p>通过<code>File -&gt; Project Structure</code>打开页面（因为我是mac），所以可以通过快捷键<code>Command + [:;]</code>打开。界面如下</p><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject8.png" alt="newproject8"></p><p>我们可以看到，<code>Flink</code>相关的依赖包其实已经存在了，这里显示了我们的Maven包下的scope是<code>Provided</code>，那就代表<code>IDEA</code>并未自动识别我刚才的注释。因为如果成功识别出来了，应该是会变成<code>Compile</code>。当然我可以直接在这里进行修改，但是为了统一维护的问题，不建议在此处修改，虽然直接修改很方便，但是下次加载还是从<code>pom.xml</code>加载的，并且间接依赖包也特别多，你无法掌握那么多依赖包的关系。</p><p>所以注释后，我们需要利用<code>pom.xml</code>进行<code>maven</code>的<code>reload project</code>。</p><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject10.png" alt="newproject10"></p><p>这个时候，我们就发现不管是直接还是间接的依赖包都变成了<code>Compile</code>。</p><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject11.png" alt="newproject11"></p><p>接下来，我们在运行一次我们的任务。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br></pre></td><td class="code"><pre><span class="line">15:33:55,353 INFO  org.apache.flink.api.java.utils.PlanGenerator                [] - The job has 0 registered types and 0 default Kryo serializers</span><br><span class="line">15:33:55,523 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.</span><br><span class="line">15:33:55,523 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.</span><br><span class="line">15:33:55,523 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.</span><br><span class="line">15:33:55,523 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.memory.network.min required for local execution is not set, setting it to its default value 64 mb.</span><br><span class="line">15:33:55,524 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.memory.network.max required for local execution is not set, setting it to its default value 64 mb.</span><br><span class="line">15:33:55,524 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutorResourceUtils [] - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.</span><br><span class="line">15:33:55,548 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Starting Flink Mini Cluster</span><br><span class="line">15:33:55,551 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Starting Metrics Registry</span><br><span class="line">15:33:55,627 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed&#x2F;reported.</span><br><span class="line">15:33:55,627 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Starting RPC Service(s)</span><br><span class="line">15:33:55,780 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start local actor system</span><br><span class="line">15:33:56,203 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started</span><br><span class="line">15:33:56,313 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka:&#x2F;&#x2F;flink</span><br><span class="line">15:33:56,328 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start local actor system</span><br><span class="line">15:33:56,341 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started</span><br><span class="line">15:33:56,356 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka:&#x2F;&#x2F;flink-metrics</span><br><span class="line">15:33:56,373 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka:&#x2F;&#x2F;flink-metrics&#x2F;user&#x2F;rpc&#x2F;MetricQueryService .</span><br><span class="line">15:33:56,399 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Starting high-availability services</span><br><span class="line">15:33:56,418 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Created BLOB server storage directory &#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#x2F;blobStore-4ec8c72e-36f6-4b8d-aba8-70bb3d443f93</span><br><span class="line">15:33:56,430 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Started BLOB server at 0.0.0.0:58212 - max concurrent requests: 50 - max backlog: 1000</span><br><span class="line">15:33:56,434 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory &#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#x2F;blobStore-3433044e-b47e-445c-9df2-ceb5d1e8da6f</span><br><span class="line">15:33:56,436 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory &#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#x2F;blobStore-4d06675d-1b13-4fa2-87e9-0a1609934f09</span><br><span class="line">15:33:56,436 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Starting 1 TaskManger(s)</span><br><span class="line">15:33:56,441 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: a7c681c7-48a2-4491-803a-535036a51fcb</span><br><span class="line">15:33:56,477 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory &#39;&#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#39;: total 233 GB, usable 25 GB (10.73% usable)</span><br><span class="line">15:33:56,482 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory &#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#x2F;flink-io-dc01cff1-6b52-43ed-9d16-9085f49c732e for spill files.</span><br><span class="line">15:33:56,492 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager uses directory &#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#x2F;flink-netty-shuffle-41571afb-b13e-494b-b937-0696d2c77ca1 for spill files.</span><br><span class="line">15:33:56,580 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).</span><br><span class="line">15:33:56,594 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.</span><br><span class="line">15:33:56,596 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.</span><br><span class="line">15:33:56,631 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;taskmanager_0 .</span><br><span class="line">15:33:56,650 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.</span><br><span class="line">15:33:56,653 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory &#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#x2F;flink-dist-cache-fc4fd5a1-79fa-4a19-8d7d-f3072006c91e</span><br><span class="line">15:33:56,714 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Starting rest endpoint.</span><br><span class="line">15:33:56,717 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.</span><br><span class="line">15:33:57,089 WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Log file environment variable &#39;log.file&#39; is not set.</span><br><span class="line">15:33:57,089 WARN  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable &#39;log.file&#39; or configuration key &#39;web.log.path&#39;.</span><br><span class="line">15:33:57,300 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Rest endpoint listening at localhost:58223</span><br><span class="line">15:33:57,302 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Proposing leadership to contender http:&#x2F;&#x2F;localhost:58223</span><br><span class="line">15:33:57,305 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - http:&#x2F;&#x2F;localhost:58223 was granted leadership with leaderSessionID&#x3D;22a043f5-f263-4e6c-87e9-6e61beef3075</span><br><span class="line">15:33:57,306 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Received confirmation of leadership for leader http:&#x2F;&#x2F;localhost:58223 , session&#x3D;22a043f5-f263-4e6c-87e9-6e61beef3075</span><br><span class="line">15:33:57,327 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;resourcemanager_1 .</span><br><span class="line">15:33:57,344 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Proposing leadership to contender LeaderContender: DefaultDispatcherRunner</span><br><span class="line">15:33:57,345 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Proposing leadership to contender LeaderContender: StandaloneResourceManager</span><br><span class="line">15:33:57,347 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - ResourceManager akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;resourcemanager_1 was granted leadership with fencing token 99793e5c3d8a81ced62f8a03bd21494c</span><br><span class="line">15:33:57,350 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Flink Mini Cluster started successfully</span><br><span class="line">15:33:57,350 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl [] - Starting the SlotManager.</span><br><span class="line">15:33:57,351 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Start SessionDispatcherLeaderProcess.</span><br><span class="line">15:33:57,353 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Recover all persisted job graphs.</span><br><span class="line">15:33:57,354 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Successfully recovered 0 persisted job graphs.</span><br><span class="line">15:33:57,355 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Received confirmation of leadership for leader akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;resourcemanager_1 , session&#x3D;d62f8a03-bd21-494c-9979-3e5c3d8a81ce</span><br><span class="line">15:33:57,357 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;resourcemanager_1(99793e5c3d8a81ced62f8a03bd21494c).</span><br><span class="line">15:33:57,365 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;dispatcher_2 .</span><br><span class="line">15:33:57,378 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Received confirmation of leadership for leader akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;dispatcher_2 , session&#x3D;0a8eb324-f6f9-44d7-a452-87c855415b0e</span><br><span class="line">15:33:57,387 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration</span><br><span class="line">15:33:57,393 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering TaskManager with ResourceID a7c681c7-48a2-4491-803a-535036a51fcb (akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;taskmanager_0) at ResourceManager</span><br><span class="line">15:33:57,395 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;resourcemanager_1 under registration id 3e9b649958365e1a080d0b1102807505.</span><br><span class="line">15:33:57,396 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission c9c27c95a1e3b4a8bfd7250101fa1126 (Flink Java Job at Tue Sep 28 15:33:55 CST 2021).</span><br><span class="line">15:33:57,396 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job c9c27c95a1e3b4a8bfd7250101fa1126 (Flink Java Job at Tue Sep 28 15:33:55 CST 2021).</span><br><span class="line">15:33:57,423 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;jobmanager_3 .</span><br><span class="line">15:33:57,433 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job Flink Java Job at Tue Sep 28 15:33:55 CST 2021 (c9c27c95a1e3b4a8bfd7250101fa1126).</span><br><span class="line">15:33:57,452 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for Flink Java Job at Tue Sep 28 15:33:55 CST 2021 (c9c27c95a1e3b4a8bfd7250101fa1126).</span><br><span class="line">15:33:57,487 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job Flink Java Job at Tue Sep 28 15:33:55 CST 2021 (c9c27c95a1e3b4a8bfd7250101fa1126).</span><br><span class="line">15:33:57,490 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 3 ms.</span><br><span class="line">15:33:57,512 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 pipelined regions in 3 ms</span><br><span class="line">15:33:57,518 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@4fe83a40 for Flink Java Job at Tue Sep 28 15:33:55 CST 2021 (c9c27c95a1e3b4a8bfd7250101fa1126).</span><br><span class="line">15:33:57,527 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Proposing leadership to contender akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;jobmanager_3</span><br><span class="line">15:33:57,528 INFO  org.apache.flink.runtime.jobmaster.JobManagerRunnerImpl      [] - JobManager runner for job Flink Java Job at Tue Sep 28 15:33:55 CST 2021 (c9c27c95a1e3b4a8bfd7250101fa1126) was granted leadership with session id 00c173d1-6a96-47ad-a2d9-da1ebc4d6a41 at akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;jobmanager_3.</span><br><span class="line">15:33:57,532 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job Flink Java Job at Tue Sep 28 15:33:55 CST 2021 (c9c27c95a1e3b4a8bfd7250101fa1126) under job master id a2d9da1ebc4d6a4100c173d16a9647ad.</span><br><span class="line">15:33:57,533 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]</span><br><span class="line">15:33:57,533 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Flink Java Job at Tue Sep 28 15:33:55 CST 2021 (c9c27c95a1e3b4a8bfd7250101fa1126) switched from state CREATED to RUNNING.</span><br><span class="line">15:33:57,537 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1) (2d0c18f32aaefecbd6f3d76a781d54b9) switched from CREATED to SCHEDULED.</span><br><span class="line">15:33:57,537 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - DataSink (collect()) (1&#x2F;1) (1feb48784b233306f550eda82cf1b5e9) switched from CREATED to SCHEDULED.</span><br><span class="line">15:33:57,546 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId&#123;1e28fd68790f78b4b48f557e8ba4d92f&#125;]</span><br><span class="line">15:33:57,552 INFO  org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService [] - Received confirmation of leadership for leader akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;jobmanager_3 , session&#x3D;00c173d1-6a96-47ad-a2d9-da1ebc4d6a41</span><br><span class="line">15:33:57,552 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;resourcemanager_1(99793e5c3d8a81ced62f8a03bd21494c)</span><br><span class="line">15:33:57,554 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration</span><br><span class="line">15:33:57,555 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager a2d9da1ebc4d6a4100c173d16a9647ad@akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;jobmanager_3 for job c9c27c95a1e3b4a8bfd7250101fa1126.</span><br><span class="line">15:33:57,559 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager a2d9da1ebc4d6a4100c173d16a9647ad@akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;jobmanager_3 for job c9c27c95a1e3b4a8bfd7250101fa1126.</span><br><span class="line">15:33:57,561 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 99793e5c3d8a81ced62f8a03bd21494c.</span><br><span class="line">15:33:57,562 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Requesting new slot [SlotRequestId&#123;1e28fd68790f78b4b48f557e8ba4d92f&#125;] and profile ResourceProfile&#123;UNKNOWN&#125; with allocation id d73fe42189235dfaf22a937eb4556ee1 from resource manager.</span><br><span class="line">15:33:57,562 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Request slot with profile ResourceProfile&#123;UNKNOWN&#125; for job c9c27c95a1e3b4a8bfd7250101fa1126 with allocation id d73fe42189235dfaf22a937eb4556ee1.</span><br><span class="line">15:33:57,565 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request d73fe42189235dfaf22a937eb4556ee1 for job c9c27c95a1e3b4a8bfd7250101fa1126 from resource manager with leader id 99793e5c3d8a81ced62f8a03bd21494c.</span><br><span class="line">15:33:57,570 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for d73fe42189235dfaf22a937eb4556ee1.</span><br><span class="line">15:33:57,571 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job c9c27c95a1e3b4a8bfd7250101fa1126 for job leader monitoring.</span><br><span class="line">15:33:57,573 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;jobmanager_3 with leader id 00c173d1-6a96-47ad-a2d9-da1ebc4d6a41.</span><br><span class="line">15:33:57,574 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration</span><br><span class="line">15:33:57,577 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;jobmanager_3 for job c9c27c95a1e3b4a8bfd7250101fa1126.</span><br><span class="line">15:33:57,578 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job c9c27c95a1e3b4a8bfd7250101fa1126.</span><br><span class="line">15:33:57,580 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job c9c27c95a1e3b4a8bfd7250101fa1126.</span><br><span class="line">15:33:57,588 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1) (2d0c18f32aaefecbd6f3d76a781d54b9) switched from SCHEDULED to DEPLOYING.</span><br><span class="line">15:33:57,590 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1) (attempt #0) with attempt id 2d0c18f32aaefecbd6f3d76a781d54b9 to a7c681c7-48a2-4491-803a-535036a51fcb @ localhost (dataPort&#x3D;-1) with allocation id d73fe42189235dfaf22a937eb4556ee1</span><br><span class="line">15:33:57,595 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - DataSink (collect()) (1&#x2F;1) (1feb48784b233306f550eda82cf1b5e9) switched from SCHEDULED to DEPLOYING.</span><br><span class="line">15:33:57,595 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying DataSink (collect()) (1&#x2F;1) (attempt #0) with attempt id 1feb48784b233306f550eda82cf1b5e9 to a7c681c7-48a2-4491-803a-535036a51fcb @ localhost (dataPort&#x3D;-1) with allocation id d73fe42189235dfaf22a937eb4556ee1</span><br><span class="line">15:33:57,595 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot d73fe42189235dfaf22a937eb4556ee1.</span><br><span class="line">15:33:57,627 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1)#0 (2d0c18f32aaefecbd6f3d76a781d54b9), deploy into slot with allocation id d73fe42189235dfaf22a937eb4556ee1.</span><br><span class="line">15:33:57,628 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1)#0 (2d0c18f32aaefecbd6f3d76a781d54b9) switched from CREATED to DEPLOYING.</span><br><span class="line">15:33:57,630 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot d73fe42189235dfaf22a937eb4556ee1.</span><br><span class="line">15:33:57,630 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot d73fe42189235dfaf22a937eb4556ee1.</span><br><span class="line">15:33:57,633 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1)#0 (2d0c18f32aaefecbd6f3d76a781d54b9) [DEPLOYING].</span><br><span class="line">15:33:57,634 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1)#0 (2d0c18f32aaefecbd6f3d76a781d54b9) [DEPLOYING].</span><br><span class="line">15:33:57,642 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task DataSink (collect()) (1&#x2F;1)#0 (1feb48784b233306f550eda82cf1b5e9), deploy into slot with allocation id d73fe42189235dfaf22a937eb4556ee1.</span><br><span class="line">15:33:57,642 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - DataSink (collect()) (1&#x2F;1)#0 (1feb48784b233306f550eda82cf1b5e9) switched from CREATED to DEPLOYING.</span><br><span class="line">15:33:57,643 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task DataSink (collect()) (1&#x2F;1)#0 (1feb48784b233306f550eda82cf1b5e9) [DEPLOYING].</span><br><span class="line">15:33:57,644 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Registering task at network: DataSink (collect()) (1&#x2F;1)#0 (1feb48784b233306f550eda82cf1b5e9) [DEPLOYING].</span><br><span class="line">15:33:57,647 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1)#0 (2d0c18f32aaefecbd6f3d76a781d54b9) switched from DEPLOYING to RUNNING.</span><br><span class="line">15:33:57,648 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - DataSink (collect()) (1&#x2F;1)#0 (1feb48784b233306f550eda82cf1b5e9) switched from DEPLOYING to RUNNING.</span><br><span class="line">15:33:57,648 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1) (2d0c18f32aaefecbd6f3d76a781d54b9) switched from DEPLOYING to RUNNING.</span><br><span class="line">15:33:57,649 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - DataSink (collect()) (1&#x2F;1) (1feb48784b233306f550eda82cf1b5e9) switched from DEPLOYING to RUNNING.</span><br><span class="line">15:33:57,659 WARN  org.apache.flink.metrics.MetricGroup                         [] - The operator name DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) exceeded the 80 characters length limit and was truncated.</span><br><span class="line">15:33:57,667 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1)#0 (2d0c18f32aaefecbd6f3d76a781d54b9) switched from RUNNING to FINISHED.</span><br><span class="line">15:33:57,667 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1)#0 (2d0c18f32aaefecbd6f3d76a781d54b9).</span><br><span class="line">15:33:57,670 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1)#0 2d0c18f32aaefecbd6f3d76a781d54b9.</span><br><span class="line">15:33:57,677 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - CHAIN DataSource (at main(BatchJob.java:43) (org.apache.flink.api.java.io.CollectionInputFormat)) -&gt; FlatMap (FlatMap at main(BatchJob.java:45)) (1&#x2F;1) (2d0c18f32aaefecbd6f3d76a781d54b9) switched from RUNNING to FINISHED.</span><br><span class="line">15:33:57,678 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - DataSink (collect()) (1&#x2F;1)#0 (1feb48784b233306f550eda82cf1b5e9) switched from RUNNING to FINISHED.</span><br><span class="line">15:33:57,678 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for DataSink (collect()) (1&#x2F;1)#0 (1feb48784b233306f550eda82cf1b5e9).</span><br><span class="line">15:33:57,679 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FINISHED to JobManager for task DataSink (collect()) (1&#x2F;1)#0 1feb48784b233306f550eda82cf1b5e9.</span><br><span class="line">15:33:57,682 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - DataSink (collect()) (1&#x2F;1) (1feb48784b233306f550eda82cf1b5e9) switched from RUNNING to FINISHED.</span><br><span class="line">15:33:57,685 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Flink Java Job at Tue Sep 28 15:33:55 CST 2021 (c9c27c95a1e3b4a8bfd7250101fa1126) switched from state RUNNING to FINISHED.</span><br><span class="line">15:33:57,691 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job c9c27c95a1e3b4a8bfd7250101fa1126 reached globally terminal state FINISHED.</span><br><span class="line">15:33:57,691 INFO  org.apache.flink.runtime.minicluster.MiniCluster             [] - Shutting down Flink Mini Cluster</span><br><span class="line">15:33:57,691 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Shutting down rest endpoint.</span><br><span class="line">15:33:57,691 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Stopping TaskExecutor akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;taskmanager_0.</span><br><span class="line">15:33:57,692 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close ResourceManager connection 01714233597d70de71bbfbda09ac665e.</span><br><span class="line">15:33:57,692 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Closing TaskExecutor connection a7c681c7-48a2-4491-803a-535036a51fcb because: The TaskExecutor is shutting down.</span><br><span class="line">15:33:57,693 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job c9c27c95a1e3b4a8bfd7250101fa1126.</span><br><span class="line">15:33:57,694 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job Flink Java Job at Tue Sep 28 15:33:55 CST 2021(c9c27c95a1e3b4a8bfd7250101fa1126).</span><br><span class="line">15:33:57,695 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:0, state:ALLOCATED, resource profile: ResourceProfile&#123;managedMemory&#x3D;128.000mb (134217728 bytes), networkMemory&#x3D;64.000mb (67108864 bytes)&#125;, allocationId: d73fe42189235dfaf22a937eb4556ee1, jobId: c9c27c95a1e3b4a8bfd7250101fa1126).</span><br><span class="line">15:33:57,697 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Suspending SlotPool.</span><br><span class="line">15:33:57,697 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 01714233597d70de71bbfbda09ac665e: Stopping JobMaster for job Flink Java Job at Tue Sep 28 15:33:55 CST 2021(c9c27c95a1e3b4a8bfd7250101fa1126)..</span><br><span class="line">15:33:57,697 INFO  org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl     [] - Stopping SlotPool.</span><br><span class="line">15:33:57,697 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager a2d9da1ebc4d6a4100c173d16a9647ad@akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;jobmanager_3 for job c9c27c95a1e3b4a8bfd7250101fa1126 from the resource manager.</span><br><span class="line">15:33:57,699 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Stop job leader service.</span><br><span class="line">15:33:57,699 INFO  org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager [] - Shutting down TaskExecutorLocalStateStoresManager.</span><br><span class="line">good</span><br><span class="line">good</span><br><span class="line">study</span><br><span class="line">day</span><br><span class="line">day</span><br><span class="line">up</span><br><span class="line">15:33:57,725 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Removing cache directory &#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#x2F;flink-web-ui</span><br><span class="line">15:33:57,727 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Shut down complete.</span><br><span class="line">15:33:57,729 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..</span><br><span class="line">15:33:57,729 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory &#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#x2F;flink-io-dc01cff1-6b52-43ed-9d16-9085f49c732e</span><br><span class="line">15:33:57,730 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Shutting down the network environment and its components.</span><br><span class="line">15:33:57,730 INFO  org.apache.flink.runtime.entrypoint.component.DispatcherResourceManagerComponent [] - Closing components.</span><br><span class="line">15:33:57,730 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Stopping SessionDispatcherLeaderProcess.</span><br><span class="line">15:33:57,730 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Stopping dispatcher akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;dispatcher_2.</span><br><span class="line">15:33:57,731 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Stopping all currently running jobs of dispatcher akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;dispatcher_2.</span><br><span class="line">15:33:57,731 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl [] - Closing the SlotManager.</span><br><span class="line">15:33:57,731 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl [] - Suspending the SlotManager.</span><br><span class="line">15:33:57,731 INFO  org.apache.flink.runtime.rest.handler.legacy.backpressure.BackPressureRequestCoordinator [] - Shutting down back pressure request coordinator.</span><br><span class="line">15:33:57,731 INFO  org.apache.flink.runtime.io.disk.FileChannelManagerImpl      [] - FileChannelManager removed spill file directory &#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#x2F;flink-netty-shuffle-41571afb-b13e-494b-b937-0696d2c77ca1</span><br><span class="line">15:33:57,732 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Shutting down the kvState service and its components.</span><br><span class="line">15:33:57,732 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Stopped dispatcher akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;dispatcher_2.</span><br><span class="line">15:33:57,732 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Stop job leader service.</span><br><span class="line">15:33:57,734 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - removed file cache directory &#x2F;var&#x2F;folders&#x2F;zq&#x2F;2b48w4_x5vq89_jrz3yns13h0000gn&#x2F;T&#x2F;flink-dist-cache-fc4fd5a1-79fa-4a19-8d7d-f3072006c91e</span><br><span class="line">15:33:57,735 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Stopped TaskExecutor akka:&#x2F;&#x2F;flink&#x2F;user&#x2F;rpc&#x2F;taskmanager_0.</span><br><span class="line">15:33:57,735 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopping Akka RPC service.</span><br><span class="line">15:33:57,760 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopping Akka RPC service.</span><br><span class="line">15:33:57,760 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopped Akka RPC service.</span><br><span class="line">15:33:57,766 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Shutting down BLOB cache</span><br><span class="line">15:33:57,768 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Shutting down BLOB cache</span><br><span class="line">15:33:57,772 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Stopped BLOB server at 0.0.0.0:58212</span><br><span class="line">15:33:57,772 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Stopped Akka RPC service.</span><br></pre></td></tr></table></figure><p><img src="/images/%E5%A4%A7%E6%95%B0%E6%8D%AE/newproject12.png" alt="newproject12"></p><p>可以看到，我们的代码已经执行，并且生效。这样子我们的开发环境就搭建完毕了。其他的基本大同小异，如需记录，后面会额外的篇章进行记录。</p><h2 id="项目打包并提交Flink集群执行"><a href="#项目打包并提交Flink集群执行" class="headerlink" title="项目打包并提交Flink集群执行"></a>项目打包并提交Flink集群执行</h2><p>直到刚才为止，我们都是本地开发的模式，但是如果要在生产环境运行，那么我们需要打包成jar，然后借助flink-client提交job图对象给flink-job-manager，然后再分发给各个的taskManager进行执行。</p><p>所以这里我们需要打包出<code>jar</code>包。</p><p>我们使用Maven的<code>mvn clean package</code>命令可以很方便地进行打包。</p><p>如果需要额外指定一些内容的话，可以使用<code>mvn clean package -Dfile.encoding=UTF-8 -DskipTests=true</code>，这样子可以忽略测试阶段。</p><p>利用docker</p><ul><li>构架一个flink1.12的集群</li><li>构建一个maven工具，版本3.6.3（由于idea采用的是内置的maven，这是是一个独立的jar包，所以外部无法直接引用mvn命令）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull flink:1.12-scala_2.11-java8</span><br><span class="line">docker pull maven:3.6.3</span><br></pre></td></tr></table></figure><p>在代码目录下打包出jar包</p><blockquote><p>记得打包成<code>生成环境的jar包</code>的时候，把<code>&lt;scope /&gt;</code>改回 <code>provided</code>, 也就是把注释取消掉。</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">➜  my-flink-jdk11 docker run --rm -it -v  ~/.m2:/root/.m2 -v $(PWD):/www -w /www maven:3.6.3 mvn clean package</span><br><span class="line">[INFO] Scanning for projects...</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] ----------------------&lt; my-flink:my-flink-jdk11 &gt;-----------------------</span><br><span class="line">[INFO] Building Flink Quickstart Job 1.0-SNAPSHOT</span><br><span class="line">[INFO] --------------------------------[ jar ]---------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ my-flink-jdk11 ---</span><br><span class="line">[INFO] Deleting /www/target</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ my-flink-jdk11 ---</span><br><span class="line">[INFO] Using 'UTF-8' encoding to copy filtered resources.</span><br><span class="line">[INFO] Copying 1 resource</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ my-flink-jdk11 ---</span><br><span class="line">[INFO] Changes detected - recompiling the module!</span><br><span class="line">[INFO] Compiling 2 source files to /www/target/classes</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ my-flink-jdk11 ---</span><br><span class="line">[INFO] Using 'UTF-8' encoding to copy filtered resources.</span><br><span class="line">[INFO] skip non existing resourceDirectory /www/src/test/resources</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ my-flink-jdk11 ---</span><br><span class="line">[INFO] No sources to compile</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ my-flink-jdk11 ---</span><br><span class="line">[INFO] No tests to run.</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ my-flink-jdk11 ---</span><br><span class="line">[INFO] Building jar: /www/target/my-flink-jdk11-1.0-SNAPSHOT.jar</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-shade-plugin:3.1.1:shade (default) @ my-flink-jdk11 ---</span><br><span class="line">[INFO] Excluding org.slf4j:slf4j-api:jar:1.7.15 from the shaded jar.</span><br><span class="line">[INFO] Excluding org.apache.logging.log4j:log4j-slf4j-impl:jar:2.12.1 from the shaded jar.</span><br><span class="line">[INFO] Excluding org.apache.logging.log4j:log4j-api:jar:2.12.1 from the shaded jar.</span><br><span class="line">[INFO] Excluding org.apache.logging.log4j:log4j-core:jar:2.12.1 from the shaded jar.</span><br><span class="line">[INFO] Replacing original artifact with shaded artifact.</span><br><span class="line">[INFO] Replacing /www/target/my-flink-jdk11-1.0-SNAPSHOT.jar with /www/target/my-flink-jdk11-1.0-SNAPSHOT-shaded.jar</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time:  8.988 s</span><br><span class="line">[INFO] Finished at: 2021-09-28T08:30:35Z</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p>转移就构建成功了。</p><p>在<code>target</code>目录下查看<code>jar包</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  my-flink-jdk11 ll target/my-flink-jdk11-1.0-SNAPSHOT.jar </span><br><span class="line">-rw-r--r--  1 caiwenhui  staff   6.6K Sep 28 16:30 target/my-flink-jdk11-1.0-SNAPSHOT.jar</span><br></pre></td></tr></table></figure><p>同样把代码目录挂载进flink容器，然后构建flink容器（此步骤只要是拿到target目录下的jar包，如果你指定了其他路径换个挂载目录也可以）</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -it --name flinkc --privileged  -w /www -v$(PWD):/www -p 8081:8081 flink:1.12-scala_2.11-java8 bash</span><br></pre></td></tr></table></figure><blockquote><p>8081是flink webui的服务，具体的内容后面再说</p></blockquote><p>进到容器后，启动单机版flink集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">flink@ed5e7ea28514:/www$ start-cluster.sh</span><br><span class="line">Starting cluster.</span><br><span class="line">Starting standalonesession daemon on host ed5e7ea28514.</span><br><span class="line">Starting taskexecutor daemon on host ed5e7ea28514</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">flink@ed5e7ea28514:&#x2F;www$ flink run --class my.flink.BatchJob .&#x2F;target&#x2F;my-flink-jdk11-1.0-SNAPSHOT.jar</span><br><span class="line">Job has been submitted with JobID ca99d6d7ef6f913ac334d7123d63658b</span><br><span class="line">Program execution finished</span><br><span class="line">Job with JobID ca99d6d7ef6f913ac334d7123d63658b has finished.</span><br><span class="line">Job Runtime: 187 ms</span><br><span class="line">Accumulator Results:</span><br><span class="line">- 40a6a5d6af948dba01cbb7bee71f2d4e (java.util.ArrayList) [6 elements]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">good</span><br><span class="line">good</span><br><span class="line">study</span><br><span class="line">day</span><br><span class="line">day</span><br><span class="line">up</span><br></pre></td></tr></table></figure><p>可以看到，可以这个结果和我们再IDEA执行的结果一致，所以开发环境搭建完毕。后面的篇章将会是具体的流计算内容。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;由于最近要推动flink的流计算代替我们的内部的自行研发的mstream流计算服务，所以需要对flink进行开发。&lt;/p&gt;
    
    </summary>
    
    
      <category term="大数据" scheme="http://blog.crazylaw.cn/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="flink" scheme="http://blog.crazylaw.cn/tags/flink/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- protobuf插件扩展开发2</title>
    <link href="http://blog.crazylaw.cn/2021/09/06/Golang/protobuf%E6%8F%92%E4%BB%B6%E6%89%A9%E5%B1%95%E5%BC%80%E5%8F%912/"/>
    <id>http://blog.crazylaw.cn/2021/09/06/Golang/protobuf%E6%8F%92%E4%BB%B6%E6%89%A9%E5%B1%95%E5%BC%80%E5%8F%912/</id>
    <published>2021-09-06T01:16:51.000Z</published>
    <updated>2021-09-06T01:57:29.825Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上一片，我们讲到了<code>protobuf扩展开发</code>的大体流程和思路，这一篇，我们来继续总结一下相关的API细节。</p><a id="more"></a><h2 id="API"><a href="#API" class="headerlink" title="API"></a>API</h2><h3 id="第一点"><a href="#第一点" class="headerlink" title="第一点"></a>第一点</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">option go_package &#x3D; &quot;github.com&#x2F;xxxx&#x2F;pb&#x2F;go-pb&#x2F;api;pb&quot;;</span><br></pre></td></tr></table></figure><p>我们经常可以看到这种定义，分好前面的<code>github.com/xxxx/pb/go-pb/api</code>，我们在写代码的时候会被加载到：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 源码</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(gen *Plugin)</span> <span class="title">NewGeneratedFile</span><span class="params">(filename <span class="keyword">string</span>, goImportPath GoImportPath)</span> *<span class="title">GeneratedFile</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 我们自己的代码</span></span><br><span class="line">filename := f.GeneratedFilenamePrefix + <span class="string">".api.go"</span></span><br><span class="line">g := plugin.NewGeneratedFile(strings.TrimPrefix(filename, strings.Trim(pbPkg.String(), <span class="string">"\""</span>)), f.GoImportPath)</span><br></pre></td></tr></table></figure><p>这里，我们可以看到<code>Plugin.NewGeneratedFile</code>有2个参数，第一个是<code>filename</code>,另外一个是<code>goImportPath</code>，分别的含义是：</p><p>生成的文件名和这个文件被import的时候，应该要怎么import。</p><ul><li>这个文件名需要注意的是，这是一个全路径文件名，如果你的文件名种存在<code>/</code>，那么前面的都是<code>目录</code>，直到最后一个，才是文件名。</li><li>例如我这里的是<code>github.com/xxxx/pb/go-pb/api</code>，那么生成的文件被引用的时候，就会<code>import &quot;github.com/xxxx/pb/go-pb/api&quot;</code>。</li></ul><p>看到这里，我们再来看看分号后面的<code>pb</code>，这个在外面写代码的时候到体现是：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 我们自己的代码</span></span><br><span class="line">g.P(<span class="string">"package "</span> + f.GoPackageName)</span><br></pre></td></tr></table></figure><p>看到其实这个<code>pb</code>会被加载进文件的<code>GoPackageName</code>种，所以分号前面的意义是不同的，前面的对应<code>filename</code>和<code>GoImportPath</code>,后面对应的就是<code>GoPackageName</code></p><h3 id="第二点"><a href="#第二点" class="headerlink" title="第二点"></a>第二点</h3><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">var</span> (</span><br><span class="line">pbPkg = protogen.GoImportPath(<span class="string">"github.com/xxx/pb/go-pb"</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>在代码中，我们会定义一些这样子的xxxPkg的变量，他们由<code>protogen.GoImportPath</code>来包装起来，在使用上就是：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">g.P(<span class="string">"     "</span>, method.GoName, <span class="string">"Api = "</span>, pbPkg.Ident(<span class="string">"NewApi"</span>), <span class="string">"(\""</span>, method.GoName, <span class="string">"\", \""</span>, m, <span class="string">"\", \""</span>, url, <span class="string">"\")"</span>)</span><br></pre></td></tr></table></figure><p>看到这里的<code>pbPkg.Ident(&quot;NewApi&quot;)</code>，意思就是这个要调用<code>pbPkg</code>包下的<code>NewApi</code>的方法。</p><p>值得注意的是，这里用到的<code>Ident()</code>API，顾名思义就是<code>.</code>的意思。</p><h3 id="第三点"><a href="#第三点" class="headerlink" title="第三点"></a>第三点</h3><p>有时候，我们调用<code>Plugin.NewGeneratedFile</code>，创建了生成文件实例并且已经预写入了一些内容，但是实际代码中，并<code>没有任何有意义</code>有价值的代码，那么这个时候我希望这个文件<code>不要生成</code>，我就可以调用<code>Skip()</code>的API。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 我们自己的代码</span></span><br><span class="line">g := plugin.NewGeneratedFile(strings.TrimPrefix(filename, strings.Trim(pbPkg.String(), <span class="string">"\""</span>)), f.GoImportPath)</span><br><span class="line">g.Skip()</span><br></pre></td></tr></table></figure><p>那么这个文件在最终将不会被生成。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;上一片，我们讲到了&lt;code&gt;protobuf扩展开发&lt;/code&gt;的大体流程和思路，这一篇，我们来继续总结一下相关的API细节。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/categories/Golang/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- protobuf插件扩展开发</title>
    <link href="http://blog.crazylaw.cn/2021/09/04/Golang/protobuf%E6%8F%92%E4%BB%B6%E6%89%A9%E5%B1%95%E5%BC%80%E5%8F%91/"/>
    <id>http://blog.crazylaw.cn/2021/09/04/Golang/protobuf%E6%8F%92%E4%BB%B6%E6%89%A9%E5%B1%95%E5%BC%80%E5%8F%91/</id>
    <published>2021-09-04T06:16:51.000Z</published>
    <updated>2021-09-04T06:28:36.840Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>最近，项目需要用到protobuf来定义消息，但是我们需要一个更灵活的代码片段，如何通过<code>proto</code>文件来创建自定义的代码呢？<br>可以通过proto的<code>plugin</code>对方式来自己是一个<code>proto-gen</code>。</p><p>在网上看了一些教程，发现有一些教程已经过时了，而且过于片面，没有把整套思想很好的说明。并且也有一些功能点并没有完全实现。<br>这里总结一下相关的内容，并且说一下最近实现的一个插件。</p><blockquote><p>对于已经了解大概<code>proto</code>的人来说，相对简单，但是如果是<code>自定义option</code>呢？你又了解吗？</p></blockquote><a id="more"></a><h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; test.proto</span><br><span class="line"></span><br><span class="line">syntax &#x3D; &quot;proto3&quot;;</span><br><span class="line">package pb;</span><br><span class="line">option go_package &#x3D; &quot;&#x2F;;pb&quot;;</span><br><span class="line"></span><br><span class="line">import &quot;unknow.proto&quot;;</span><br><span class="line"></span><br><span class="line">service ApiIMService &#123;</span><br><span class="line">    rpc RegisterDevice (ApiIMRegisterDeviceReq) returns (ApiIMRegisterDeviceResp) &#123;</span><br><span class="line">        option (unknow.api.http) &#x3D; &#123;</span><br><span class="line">            method: &quot;post&quot;</span><br><span class="line">            url: &quot;&#x2F;v1&#x2F;im&#x2F;register_device&quot;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 设备类型</span><br><span class="line">enum ApiIMDeviceType &#123;</span><br><span class="line">    API_IM_UNKNOWN &#x3D; 0;</span><br><span class="line">    API_IM_Android &#x3D; 1;</span><br><span class="line">    API_IM_IOS &#x3D; 2;</span><br><span class="line">    API_IM_Window &#x3D; 3;</span><br><span class="line">    API_IM_MacOS &#x3D; 4;</span><br><span class="line">    API_IM_Web &#x3D; 5;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message ApiIMRegisterDeviceReq &#123;</span><br><span class="line">    ApiIMDeviceType type &#x3D; 1; &#x2F;&#x2F; 设备类型</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message ApiIMRegisterDeviceResp &#123;</span><br><span class="line">    int64 device_id &#x3D; 1; &#x2F;&#x2F; 设备id</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们看到这一个<code>proto</code>文件，常规的我就不说了。主要是看到<code>import &quot;unknow.proto&quot;</code>, <code>option (unknow.api.http)</code></p><p>可以看到，我这里引入一个<code>unknow.proto</code>的文件。</p><p>我希望最终生成一个<code>api.unknow.go</code>的文件。里面的内容期待如下：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Copyright (c) 2021, whiteCcinn Inc.</span></span><br><span class="line"><span class="comment">// Code generated by protoc-gen-unknow. DO NOT EDIT.</span></span><br><span class="line"><span class="comment">// source: test.proto</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> pb</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Api <span class="keyword">struct</span> &#123;</span><br><span class="line">Name   <span class="keyword">string</span></span><br><span class="line">Method <span class="keyword">string</span></span><br><span class="line">Url    <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newApi</span><span class="params">(name, method, url <span class="keyword">string</span>)</span> *<span class="title">Api</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;Api&#123;</span><br><span class="line">name, method, url,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">RegisterDeviceApi = newApi(<span class="string">"RegisterDevice"</span>, <span class="string">"post"</span>, <span class="string">"/v1/im/register_device"</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>生成的文件，我可以在项目通过<code>pb.RegisterDeviceApi</code>拿到在<code>proto</code>定义好的API内容。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; unknow.proto</span><br><span class="line"></span><br><span class="line">syntax &#x3D; &quot;proto3&quot;;</span><br><span class="line"></span><br><span class="line">package unknow.api;</span><br><span class="line"></span><br><span class="line">option go_package &#x3D; &quot;&#x2F;;pb&quot;;</span><br><span class="line"></span><br><span class="line">import &quot;google&#x2F;protobuf&#x2F;descriptor.proto&quot;;</span><br><span class="line"></span><br><span class="line">extend google.protobuf.MethodOptions &#123;</span><br><span class="line">    &#x2F;&#x2F; See &#96;HttpRule&#96;.</span><br><span class="line">    HttpRule http &#x3D; 72295728;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message HttpRule &#123;</span><br><span class="line">    string url &#x3D; 1;</span><br><span class="line">    string method &#x3D; 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><a href="https://github.com/googleapis/googleapis/blob/master/google/api/annotations.proto" target="_blank" rel="noopener">google/api/annotations.proto</a></li><li><a href="https://github.com/googleapis/googleapis/blob/master/google/api/http.proto" target="_blank" rel="noopener">google/api/http.proto</a></li><li><a href="https://github.com/protocolbuffers/protobuf/blob/master/src/google/protobuf/descriptor.proto" target="_blank" rel="noopener">google/protobuf/descriptor.proto</a></li></ul><p>如果有了解过<code>google/api/annotations.proto</code> 和 <code>google/api/http.proto</code>的人应该不会陌生，当你需要用到<code>grpc-gateway</code>或者<code>proto-gen-swaager</code>的时候，都会有介绍到<code>option(goggle.api.http)</code>的用法。</p><p>这里我们看到<code>unknow.proto</code>的结构体，这就是一个简化版本。用于实现<code>自定义的option</code>用的。</p><h3 id="unknow-proto"><a href="#unknow-proto" class="headerlink" title="unknow.proto"></a>unknow.proto</h3><p>对于基础的语法规则来说，我们来看剖析一下<code>unknow.proto</code>，常规的就不说了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">package unknow.api;</span><br><span class="line"></span><br><span class="line">extend google.protobuf.MethodOptions &#123;</span><br><span class="line">    &#x2F;&#x2F; See &#96;HttpRule&#96;.</span><br><span class="line">    HttpRule http &#x3D; 72295728;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">message HttpRule &#123;</span><br><span class="line">    string url &#x3D; 1;</span><br><span class="line">    string method &#x3D; 2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>对于<code>extend</code>的用法，我这里列一下官方的链接。</p><ul><li><a href="https://developers.google.com/protocol-buffers/docs/overview#customoptions" target="_blank" rel="noopener">Custom Options</a></li></ul><p>我们看到这里，<code>extend google.protobuf.MethodOptions</code>。</p><p>代表着，我这里自定义个作用于<code>Method</code>的<code>option</code>。所以在真正的<code>proto</code>文件中，我就可以使用<code>unknow.api.option</code>的标签。也就是<code>option (unknow.api.http)</code>。</p><p>接着我们看到，这个option我们定义了一个元素，类型是<code>Message HttpRule</code>，命名为<code>http</code>，并且给它定义一个唯一的<code>Number</code>。</p><p>接着我们看到<code>HttpRule</code>，内部存在2个元素，一个是<code>string url</code> 和 <code>string method</code>，这意味着我们可以使用<code>独立行写法</code>：<code>option (unknow.api.http).url = &quot;/v1/im/register_device&quot;</code>，然后再下一行使用 <code>option (unknow.api.http).method = &quot;post&quot;</code>，一个完整的例如如下：</p><p>刚才说到，这是一个<code>method</code>的<code>option</code>，也就是我们这里定义的<code>rpc</code>下的 <code>option</code>。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">service ApiIMService &#123;</span><br><span class="line">    rpc RegisterDevice (ApiIMRegisterDeviceReq) returns (ApiIMRegisterDeviceResp) &#123;</span><br><span class="line">        option (unknow.api.http).method &#x3D; &quot;post&quot;</span><br><span class="line">        option (unknow.api.http).url &#x3D; &quot;&#x2F;v1&#x2F;im&#x2F;register_device&quot;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>除了这个写法，我更推荐如下更简洁的写法，用<code>map</code>的写法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">service ApiIMService &#123;</span><br><span class="line">    rpc RegisterDevice (ApiIMRegisterDeviceReq) returns (ApiIMRegisterDeviceResp) &#123;</span><br><span class="line">        option (unknow.api.http) &#x3D; &#123;</span><br><span class="line">            method: &quot;post&quot;</span><br><span class="line">            url: &quot;&#x2F;v1&#x2F;im&#x2F;register_device&quot;</span><br><span class="line">        &#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这样子，我们就看懂了<code>test.proto</code>的内容了对吧。连贯起来，那么我们的这个<code>unknow.proto</code>就是用于实现<code>option(unknow.api.http)</code>。而<code>option(unknow.api.http)</code>的使用则在<code>test.proto</code>进行采用。</p><p>好了，有了定义的文件，那么接下来就是我们的重点了，如何编写一个实现<code>自定义代码的protobuf插件扩展</code></p><h3 id="扩展实现"><a href="#扩展实现" class="headerlink" title="扩展实现"></a>扩展实现</h3><p><img src="/images/Go/protobuf.png" alt="protobuf解析流程图"></p><blockquote><p>protobuf解析旧版的流程图，便于我们理解。新版的后续我抽空再画画</p></blockquote><h3 id="不科学的例子"><a href="#不科学的例子" class="headerlink" title="不科学的例子"></a>不科学的例子</h3><p>第一个例子，以golang旧版<code>proto-gen-go</code>为例。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">package main</span><br><span class="line"></span><br><span class="line">import (</span><br><span class="line">&quot;io&#x2F;ioutil&quot;</span><br><span class="line">&quot;os&quot;</span><br><span class="line"></span><br><span class="line">&quot;github.com&#x2F;golang&#x2F;protobuf&#x2F;proto&quot;</span><br><span class="line">&quot;github.com&#x2F;golang&#x2F;protobuf&#x2F;protoc-gen-go&#x2F;generator&quot;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">func main() &#123;</span><br><span class="line">&#x2F;&#x2F; Begin by allocating a generator. The request and response structures are stored there</span><br><span class="line">&#x2F;&#x2F; so we can do error handling easily - the response structure contains the field to</span><br><span class="line">&#x2F;&#x2F; report failure.</span><br><span class="line">g :&#x3D; generator.New()</span><br><span class="line"></span><br><span class="line">data, err :&#x3D; ioutil.ReadAll(os.Stdin)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">g.Error(err, &quot;reading input&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if err :&#x3D; proto.Unmarshal(data, g.Request); err !&#x3D; nil &#123;</span><br><span class="line">g.Error(err, &quot;parsing input proto&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if len(g.Request.FileToGenerate) &#x3D;&#x3D; 0 &#123;</span><br><span class="line">g.Fail(&quot;no files to generate&quot;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">g.CommandLineParameters(g.Request.GetParameter())</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Create a wrapped version of the Descriptors and EnumDescriptors that</span><br><span class="line">&#x2F;&#x2F; point to the file that defines them.</span><br><span class="line">g.WrapTypes()</span><br><span class="line"></span><br><span class="line">g.SetPackageNames()</span><br><span class="line">g.BuildTypeNameMap()</span><br><span class="line"></span><br><span class="line">g.GenerateAllFiles()</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; Send back the results.</span><br><span class="line">data, err &#x3D; proto.Marshal(g.Response)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">g.Error(err, &quot;failed to marshal output proto&quot;)</span><br><span class="line">&#125;</span><br><span class="line">_, err &#x3D; os.Stdout.Write(data)</span><br><span class="line">if err !&#x3D; nil &#123;</span><br><span class="line">g.Error(err, &quot;failed to write output proto&quot;)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我发现现在网上很多教程都会以旧版的为主，并且都是沿用参考了<code>proto-gen-go</code>的这个旧版的写法，所以导致，我们在学习写的时候，会出现一些问题。并且其实你用了旧版的这个写法，当你在用<code>protoc</code>去编译的情况下，<code>protoc</code>也会友好的提示你，该API已经被废弃，将在未来的版本下移除，请使用新的写法。虽然你还是能编译通过，但是你不敢保证未来哪一个版本就直接不向后兼容了。</p><p>第二个例子。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">input, _ := ioutil.ReadAll(os.Stdin)</span><br><span class="line"><span class="keyword">var</span> req pluginpb.CodeGeneratorRequest</span><br><span class="line">proto.Unmarshal(input, &amp;req)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用默认选项初始化我们的插件</span></span><br><span class="line">opts := protogen.Options&#123;&#125;</span><br><span class="line">plugin, err := opts.New(&amp;req)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">   <span class="built_in">panic</span>(err)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这种方式就是从头到尾都自己写，把整个<code>pipeline</code>的流程都自己处理。但是大可不必，因为其实有很多流程化的东西，在新版的<code>genpro</code>下已经封装成了一个<code>Run</code>传递回调函数即可。</p><h3 id="正确的例子"><a href="#正确的例子" class="headerlink" title="正确的例子"></a>正确的例子</h3><p>如果真的要参考的话，推荐参考最新版本的<a href="https://github.com/golang/protobuf/blob/master/protoc-gen-go/main.go" target="_blank" rel="noopener">proto-gen-go</a></p><p>首先，我们需要知道一点，我们在采用<code>protoc</code>对<code>proto</code>文件进行编译的时候，经常是执行类似如下代码：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">protoc -I.:$&#123;GOGO_PROTOBUF&#125; \</span><br><span class="line">--gofast_out=plugins=grpc:./go-pb</span><br></pre></td></tr></table></figure><p><br>由于这里我用的是<code>gogoprotobuf</code>，所以你会看到我这里的是<code>--gofast_out=plugins=grpc:./go-pb</code>，如果你是<code>protobuf</code>的官方的<code>proto-gen</code>的话，那么你这里应该是<code>--go_out=plugins=grpc:./go-pb</code></p><p>这里我们需要注意的是什么呢，就是<code>插件二进制文件名</code>，这是有一定规则的，这是我之前在<code>自定义git凭据</code>文章中说明的一样，这二进制文件需要在你的环境变量中，否则你就需要通过<code>-I</code>来指定文件路径。然后命名规则为<code>proto-gen-xxx</code>，而这个<code>xxx</code>就是你的自定义的名字。在本例子中，我的扩展名字就是<code>proto-gen-unknow</code>。</p><p>因此，最终如果我要执行的话，那么就是执行如下命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">protoc -I.:$&#123;GOGO_PROTOBUF&#125; \</span><br><span class="line">--unknow_out=./go-pb</span><br></pre></td></tr></table></figure><p>其实如果有接触过<code>thrift</code> 或者 <code>Rust</code>的<code>元编程</code> 甚至是 <code>Python</code>的 <code>lark-parser</code>自定义抽象语法树，或者其他经由<code>AST</code>抽象语法树写代码的同学应该都知道，这其实抽象出来就是一个<code>AST</code>的解析处理而已。所以我首先需要了解他的部署。</p><p>一个简陋的<code>AST</code>定义如下（哈哈，略显简陋，但是了解AST是啥的应该多少能看懂一些）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">FileDescriptor -&gt; ServiceDescriptor</span><br><span class="line">-&gt; ServiceOptionDescriptor</span><br><span class="line">-&gt; MethodDescriptor</span><br><span class="line">-&gt; MethodOptionDescriptor</span><br><span class="line">    -&gt; [MessageDescriptor]</span><br><span class="line">               -&gt; MessageDescriptor</span><br><span class="line">-&gt; MessageOptionDescriptor</span><br><span class="line">-&gt; FieldDescriptor</span><br><span class="line">-&gt; FieldOptionDescriptor</span><br><span class="line">   -&gt; FieldOptionDescriptor</span><br></pre></td></tr></table></figure><p>知道怎么执行了，和<code>AST</code>, 我们就来看看怎么编写代码。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">➜  protoc-gen-unknow git:(main) tree</span><br><span class="line">.</span><br><span class="line">├── README.md</span><br><span class="line">├── go.mod</span><br><span class="line">├── go.sum</span><br><span class="line">├── internal</span><br><span class="line">│   └── unknow.go</span><br><span class="line">├── main.go</span><br><span class="line">├── out</span><br><span class="line">│   └── unknow.pb.go</span><br><span class="line">└── proto</span><br><span class="line">    ├── descriptor.proto</span><br><span class="line">    └── unknow.proto</span><br></pre></td></tr></table></figure><p>可以看到，这是我的一个代码结构目录</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"internal"</span></span><br><span class="line"><span class="string">"google.golang.org/protobuf/compiler/protogen"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">u := internal.Unknow&#123;&#125;</span><br><span class="line">protogen.Options&#123;&#125;.Run(u.Generate)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里，我们借助<code>protobuf</code> 编译包下的 <code>protogen</code> 工具来解析 <code>proto</code> 文件。我们接下来看一下 <code>internal</code> 包下具体的写法。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> internal</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line">pb <span class="string">"out"</span></span><br><span class="line"><span class="string">"google.golang.org/protobuf/compiler/protogen"</span></span><br><span class="line"><span class="string">"google.golang.org/protobuf/proto"</span></span><br><span class="line"><span class="string">"google.golang.org/protobuf/types/descriptorpb"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Unknow <span class="keyword">struct</span> &#123;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(u Unknow)</span> <span class="title">Generate</span><span class="params">(plugin *protogen.Plugin)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(plugin.Files) &lt; <span class="number">1</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 指定生成文件的文件名</span></span><br><span class="line">filename := <span class="string">"/api.unknow.go"</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建一个文件生成器对象</span></span><br><span class="line">g := plugin.NewGeneratedFile(filename, plugin.Files[<span class="built_in">len</span>(plugin.Files)<span class="number">-1</span>].GoImportPath)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 调用g.P就是往文件开始写入自己期待的代码</span></span><br><span class="line">g.P(<span class="string">`// Copyright (c) 2021, whiteCcinn Inc.`</span>)</span><br><span class="line">g.P(<span class="string">"// Code generated by protoc-gen-unknow. DO NOT EDIT."</span>)</span><br><span class="line">g.P(<span class="string">"// source: all MethodOptions(unknow.api.http) in proto file"</span>)</span><br><span class="line">g.P()</span><br><span class="line">g.P(<span class="string">"package "</span>, plugin.Files[<span class="built_in">len</span>(plugin.Files)<span class="number">-1</span>].GoPackageName)</span><br><span class="line"></span><br><span class="line">g.P(<span class="string">`</span></span><br><span class="line"><span class="string">type Api struct &#123;</span></span><br><span class="line"><span class="string">Name   string</span></span><br><span class="line"><span class="string">Method string</span></span><br><span class="line"><span class="string">Url    string</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">func newApi(name, method, url string) *Api &#123;</span></span><br><span class="line"><span class="string">return &amp;Api&#123;</span></span><br><span class="line"><span class="string">name, method, url,</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">`</span>)</span><br><span class="line"></span><br><span class="line">g.P(<span class="string">"var ("</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过plugin.Fiels，我们可以拿到所有的输入的proto文件</span></span><br><span class="line"><span class="comment">// 如果我们需要对这个文件生成代码的话，那么就进入到generateFile()逻辑</span></span><br><span class="line"><span class="comment">// 并且把g和f一起传递过去</span></span><br><span class="line"><span class="keyword">for</span> _, f := <span class="keyword">range</span> plugin.Files &#123;</span><br><span class="line"><span class="keyword">if</span> f.Generate &#123;</span><br><span class="line"><span class="keyword">if</span> _, err := u.generateFile(g, f); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">g.P(<span class="string">")"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(u Unknow)</span> <span class="title">generateFile</span><span class="params">(g *protogen.GeneratedFile, file *protogen.File)</span> <span class="params">(*protogen.GeneratedFile, error)</span></span> &#123;</span><br><span class="line"><span class="comment">// 这一段代码仅仅只是为了忽略包含proto文件中包含了streamClient和streamServer的代码</span></span><br><span class="line">isGenerated := <span class="literal">false</span></span><br><span class="line"><span class="keyword">for</span> _, srv := <span class="keyword">range</span> file.Services &#123;</span><br><span class="line"><span class="keyword">for</span> _, method := <span class="keyword">range</span> srv.Methods &#123;</span><br><span class="line"><span class="keyword">if</span> method.Desc.IsStreamingClient() || method.Desc.IsStreamingServer() &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line">isGenerated = <span class="literal">true</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> !isGenerated &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// file 的下一层级就是 services 层级</span></span><br><span class="line"><span class="keyword">for</span> _, srv := <span class="keyword">range</span> file.Services &#123;</span><br><span class="line"><span class="keyword">if</span> err := u.genService(g, srv); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, err</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> g, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(u Unknow)</span> <span class="title">genService</span><span class="params">(g *protogen.GeneratedFile, srv *protogen.Service)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="comment">// service 内部有很多 rpc 关键字的方法</span></span><br><span class="line"><span class="keyword">for</span> _, method := <span class="keyword">range</span> srv.Methods &#123;</span><br><span class="line"><span class="keyword">if</span> method.Desc.IsStreamingClient() || method.Desc.IsStreamingServer() &#123;</span><br><span class="line"><span class="keyword">continue</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 由于我们自定义的是就是MethodOptions，所以就来到了这里来进行判断</span></span><br><span class="line"><span class="keyword">if</span> err := u.genMethodHTTPRule(g, method); err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(u Unknow)</span> <span class="title">genMethodHTTPRule</span><span class="params">(g *protogen.GeneratedFile, method *protogen.Method)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="comment">// 因为我们通过method.Desc.Options() 拿到的数据类型是`interface&#123;&#125;` 类型</span></span><br><span class="line"><span class="comment">// 所以这里我们需要对Options，明确指定转换为 *descriptorpb.MethodOptions 类型</span></span><br><span class="line"><span class="comment">// 这样子就能拿到我们的MethodOption对象</span></span><br><span class="line">options, ok := method.Desc.Options().(*descriptorpb.MethodOptions)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// PS：重点</span></span><br><span class="line"><span class="comment">// 这里我们看到我们借助了一个非protogen下的包的内容</span></span><br><span class="line"><span class="comment">// 原因就是，protobuf编译器会把自定义的Option全部指定为Extension，由于并非内置的属性和值</span></span><br><span class="line"><span class="comment">// protobuf官方是没办法拿到和你对应的可读的内容的，只能通过拿到经过序列化之后的数据。</span></span><br><span class="line"><span class="comment">// 因此，我们这里通过 proto.GetExtension的方法，把刚才unknow.proto单独编译好的 unknow.pb.proto 文件下的 pb. E_HTTP 加载进来，指定了我需要在自定义扩展的MethodOptions中，拿到该Http下里面的value</span></span><br><span class="line"><span class="comment">// 也因此，我们可以再经过一次类型转换，就可以拿到了具体的httpRule</span></span><br><span class="line">httpRule, ok := proto.GetExtension(options, pb.E_Http).(*pb.HttpRule)</span><br><span class="line"><span class="keyword">if</span> !ok &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 接下来，我们就可以通过GetXxx的方式，来获取我们设置在其Message内部filed</span></span><br><span class="line">m := httpRule.GetMethod()</span><br><span class="line">url := httpRule.GetUrl()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> <span class="built_in">len</span>(m) == <span class="number">0</span> &amp;&amp; <span class="built_in">len</span>(url) == <span class="number">0</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">g.P(<span class="string">"     "</span>, method.GoName, <span class="string">"Api = "</span>, <span class="string">"newApi(\""</span>, method.GoName, <span class="string">"\", \""</span>, m, <span class="string">"\", \""</span>, url, <span class="string">"\")"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>请跟着说明中注释一步步查看详解</p></blockquote><p>查看这段代码逻辑，也是非常简单，因为没有特别复杂的逻辑，尽量不要跳过，因为里面涉及到如何读取自定义的Option的问题。代码大致定位在 <code>proto.GetExtension</code>方法附近。</p><p>因为这里的demo生成的代码比较简单。最终，我们生成的代码就是：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Copyright (c) 2021, whiteCcinn Inc.</span></span><br><span class="line"><span class="comment">// Code generated by protoc-gen-unknow. DO NOT EDIT.</span></span><br><span class="line"><span class="comment">// source: source: all MethodOptions(unknow.api.http) in proto file</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">package</span> pb</span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Api <span class="keyword">struct</span> &#123;</span><br><span class="line">Name   <span class="keyword">string</span></span><br><span class="line">Method <span class="keyword">string</span></span><br><span class="line">Url    <span class="keyword">string</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newApi</span><span class="params">(name, method, url <span class="keyword">string</span>)</span> *<span class="title">Api</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> &amp;Api&#123;</span><br><span class="line">name, method, url,</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">RegisterDeviceApi = newApi(<span class="string">"RegisterDevice"</span>, <span class="string">"post"</span>, <span class="string">"/v1/im/register_device"</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>放一下完整的测试命令:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">go install . &amp;&amp; protoc --proto_path proto/ -I=. test.proto  test2.proto --unknow_out=./out --go_out=./out</span><br></pre></td></tr></table></figure><p>最后生成的文件目录结构如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">➜  protoc-gen-unknow git:(main) tree</span><br><span class="line">.</span><br><span class="line">├── README.md</span><br><span class="line">├── go.mod</span><br><span class="line">├── go.sum</span><br><span class="line">├── internal</span><br><span class="line">│   └── unknow.go</span><br><span class="line">├── main.go</span><br><span class="line">├── out</span><br><span class="line">│   ├── api.unknow.go</span><br><span class="line">│   ├── test.pb.go</span><br><span class="line">│   ├── test2.pb.go</span><br><span class="line">│   └── unknow.pb.go</span><br><span class="line">└── proto</span><br><span class="line">    ├── descriptor.proto</span><br><span class="line">    ├── test.proto</span><br><span class="line">    ├── test2.proto</span><br><span class="line">    └── unknow.protos</span><br></pre></td></tr></table></figure><p>最后推荐几个扩展库写得不错的扩展插件: </p><ul><li><a href="https://github.com/grpc-ecosystem/grpc-gateway/tree/master/protoc-gen-grpc-gateway" target="_blank" rel="noopener">protoc-gen-grpc-gateway</a></li><li><a href="https://github.com/grpc-ecosystem/grpc-gateway/tree/master/protoc-gen-openapiv2" target="_blank" rel="noopener">protoc-gen-grpc-openapiv2</a></li><li><a href="https://github.com/nametake/protoc-gen-gohttp" target="_blank" rel="noopener">protoc-gen-grpc-gohttp</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;最近，项目需要用到protobuf来定义消息，但是我们需要一个更灵活的代码片段，如何通过&lt;code&gt;proto&lt;/code&gt;文件来创建自定义的代码呢？&lt;br&gt;可以通过proto的&lt;code&gt;plugin&lt;/code&gt;对方式来自己是一个&lt;code&gt;proto-gen&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;在网上看了一些教程，发现有一些教程已经过时了，而且过于片面，没有把整套思想很好的说明。并且也有一些功能点并没有完全实现。&lt;br&gt;这里总结一下相关的内容，并且说一下最近实现的一个插件。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对于已经了解大概&lt;code&gt;proto&lt;/code&gt;的人来说，相对简单，但是如果是&lt;code&gt;自定义option&lt;/code&gt;呢？你又了解吗？&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/categories/Golang/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>【Golang】- []byte在结构体的友好可读性处理</title>
    <link href="http://blog.crazylaw.cn/2021/09/03/Golang/[]byte%E5%9C%A8%E7%BB%93%E6%9E%84%E4%BD%93%E7%9A%84%E5%8F%8B%E5%A5%BD%E5%8F%AF%E8%AF%BB%E6%80%A7%E5%A4%84%E7%90%86/"/>
    <id>http://blog.crazylaw.cn/2021/09/03/Golang/[]byte%E5%9C%A8%E7%BB%93%E6%9E%84%E4%BD%93%E7%9A%84%E5%8F%8B%E5%A5%BD%E5%8F%AF%E8%AF%BB%E6%80%A7%E5%A4%84%E7%90%86/</id>
    <published>2021-09-03T03:16:51.000Z</published>
    <updated>2021-09-03T05:55:43.831Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>有些时候，我们会发现，<code>[]byte</code> 类型在 <code>struct</code> 中，是必不可少的结构体，因为用了<code>[]byte</code>代表可以存储字节数据，也可以叫做二进制安全的存储。代表可以存储任何数据。</p><p>如何才能做到在序列化json的情况下，可以<code>Println</code>出一个可读性的在<code>struct</code>的<code>[]byte</code>呢？</p><a id="more"></a><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><p>最近我在开发我们的部门的配置服务，需要提供一个配置工具。里面设计的一个struct，有一个<code>[]byte</code>类型，就是用来存储实际数据的。但是我们在这里的时候，我们有一个查看原始数据的需求，因为我们的数据经过了<code>加密</code>，和<code>压缩</code>，最终才会放到该结构体。</p><p>简化结构体，这里列举一下例子：</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> V []<span class="keyword">byte</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> Value <span class="keyword">struct</span> &#123;</span><br><span class="line">PublishTime     <span class="keyword">int64</span></span><br><span class="line">PublishDateTime <span class="keyword">string</span></span><br><span class="line">Value           V</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们看到，我们这里的<code>Value</code>实际就是一个<code>[]byte</code>，我们把这个结构体经过<code>json.Marshal</code>之后推送到远端<code>kv</code>服务中，一切都正常。</p><p>但是当我们需要查看的时候，就需要从远端的<code>kv</code>拉回来，经过<code>json.Unmarsha</code>处理，这个时候，我们会发现：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"PublishTime"</span>:<span class="number">1630636657</span>,<span class="attr">"PublishDateTime"</span>:<span class="string">"2021-09-03 02:37:37.8693941 +0000 UTC m=+0.015759101"</span>,<span class="attr">"Value"</span>:<span class="string">"MTIzCg=="</span>&#125;</span><br></pre></td></tr></table></figure><p>这里，我们看到<code>Value</code>是一个经过<code>base64</code>加密过的数据，这是因为默认情况下<code>[]byte</code>将会把数据经过<code>base64</code>变成<code>字符串</code>来符合<code>json数据类型</code>。那么我们有什么版本让他显示出原来真是的数据呢？</p><p>这里我使用了一个方案，借助多一个数据结构，对<code>T V</code>进行一个<code>重组</code>。</p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> VO []<span class="keyword">byte</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">type</span> ValueReadable <span class="keyword">struct</span> &#123;</span><br><span class="line">PublishTime     <span class="keyword">int64</span></span><br><span class="line">PublishDateTime <span class="keyword">string</span></span><br><span class="line">Value           VO</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *VO)</span> <span class="title">MarshalJSON</span><span class="params">()</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> *b, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(b *VO)</span> <span class="title">UnmarshalJSON</span><span class="params">(input []<span class="keyword">byte</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">*b = input</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义多一个<code>大体上一致</code>的结构体，注意此时的<code>Value</code>不再是<code>V</code>，而是<code>VO</code>，我们对<code>VO</code>自定义json序列化的行为，那就是把<code>base64</code>的行为给去掉。</p><p>这样子，我们得到的数据就会是</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"PublishTime"</span>:<span class="number">1630636657</span>,<span class="attr">"PublishDateTime"</span>:<span class="string">"2021-09-03 02:37:37.8693941 +0000 UTC m=+0.015759101"</span>,<span class="attr">"Value"</span>:<span class="number">123</span>&#125;</span><br></pre></td></tr></table></figure><p>细心的朋友一定发现了问题所在，那就是<code>Value</code>和<code>ValueReadable</code>怎么进行转换。</p><p>因为你存的时候是通过<code>Value</code>进行<code>marshal</code>的，那么你的<code>unmarsha</code>行为一定要对应才能解到正确的数据。</p><p>所以这里，就是我们的一个重点，我们需要借助<code>unsafe.Pointer</code></p><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">      <span class="comment">// because []byte in struct will be base64encode</span></span><br><span class="line"><span class="comment">// so you will see such as "Ik1USXpDZz09Ig=="</span></span><br><span class="line"><span class="comment">// we should base64decode, so we custom a struct do not base64encode</span></span><br><span class="line"><span class="comment">// struct type transform use unsafe.Pointer</span></span><br><span class="line">p := unsafe.Pointer(&amp;persistenceValue)</span><br><span class="line">vr := (*config_sync.ValueReadable)(p)</span><br><span class="line">tv, err := json.Marshal(vr)</span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line">log.Fatal(err)</span><br><span class="line">&#125;</span><br><span class="line">fmt.Println(<span class="keyword">string</span>(tv))</span><br></pre></td></tr></table></figure><p>我们利用<code>unsafe</code>的<code>指针</code>数据类型，进行一个强制转换，为什么会成功呢，因为在内存对齐的结构上，这2个对象的内存是一致的，所以我们就可以进行强制转换，而不用担心有<code>panic</code>的产生。这只是<code>unsafe</code>指针的一个灵活运用。但是可以达到我们的目的，十分的有效果。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="attr">"PublishTime"</span>:<span class="number">1630636657</span>,<span class="attr">"PublishDateTime"</span>:<span class="string">"2021-09-03 02:37:37.8693941 +0000 UTC m=+0.015759101"</span>,<span class="attr">"Value"</span>:<span class="number">123</span>&#125;</span><br></pre></td></tr></table></figure><p>转换后，就可以看到我原本的数据了 <code>123</code>.</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;有些时候，我们会发现，&lt;code&gt;[]byte&lt;/code&gt; 类型在 &lt;code&gt;struct&lt;/code&gt; 中，是必不可少的结构体，因为用了&lt;code&gt;[]byte&lt;/code&gt;代表可以存储字节数据，也可以叫做二进制安全的存储。代表可以存储任何数据。&lt;/p&gt;
&lt;p&gt;如何才能做到在序列化json的情况下，可以&lt;code&gt;Println&lt;/code&gt;出一个可读性的在&lt;code&gt;struct&lt;/code&gt;的&lt;code&gt;[]byte&lt;/code&gt;呢？&lt;/p&gt;
    
    </summary>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/categories/Golang/"/>
    
    
      <category term="Golang" scheme="http://blog.crazylaw.cn/tags/Golang/"/>
    
  </entry>
  
  <entry>
    <title>【kubernetes】k8s-docker-for-mac-磁盘挂载</title>
    <link href="http://blog.crazylaw.cn/2021/08/18/k8s/k8s-docker-for-mac-%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD/"/>
    <id>http://blog.crazylaw.cn/2021/08/18/k8s/k8s-docker-for-mac-%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD/</id>
    <published>2021-08-18T09:47:30.000Z</published>
    <updated>2021-08-18T14:45:43.337Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>上一次，我们说到了<code>docker-for-mac</code> 已经内置了最小化的k8s。我们在本地开发的时候，或多或少希望<code>yaml配置</code>是最接近线上环境的配置。</p><p>因此，上一次，教会了大家，如何在mac上开启nfs,把我们的pv和本地mac的nfs进行一个通信。</p><p>这一次，我们来聊聊<code>docker-for-mac</code>磁盘挂在的相关内容。</p><a id="more"></a><h2 id="虚拟机"><a href="#虚拟机" class="headerlink" title="虚拟机"></a>虚拟机</h2><p><code>Docker for Mac</code>是一个原生的苹果应用程序，被安装到 <code>/Application 目录</code>，安装时会创建 <code>/usr/local/bin</code> 目录下的 <code>docker、docker-compose</code> 符号链接。</p><p><code>Docker for Mac</code> 使用通过 Hypervisor.framework 提供的轻量级的 xhyve 虚拟化技术<br><code>Docker for Mac</code> <code>不使用</code> <code>docker-machine</code> 管理虚拟机<br><code>Docker for Mac</code> <code>不通过 TCP 端口通信</code>，反而使用 <code>docker.sock</code> 套接字文件通信（实际上是将 /var/tmp 目录挂载到了虚拟机中，虚拟机在其中生成套接字文件）</p><p>但是尽管如此，你可以理解为还是存在虚拟机的。这个虚拟机的作用就是允许在macos上运行docker。</p><h2 id="docker-for-mac"><a href="#docker-for-mac" class="headerlink" title="docker for mac"></a>docker for mac</h2><p><img src="/images/k8s/docker-for-mac-1.png" alt="docker for mac 1"></p><p>这个就是我们的<code>docker-for-mac</code>的桌面版客户端。</p><p><img src="/images/k8s/docker-for-mac-2.png" alt="docker for mac 2"></p><p>根据上面这个图，我们可以发现，所有的镜像都存储在。</p><ul><li><code>/Users/caiwenhui/Library/Containers/com.docker.docker/Data/vms/0/data</code> (记得修改为自己的路径，就是我这里的<code>caiwenhui</code>)</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ ll /Users/caiwenhui/Library/Containers/com.docker.docker/Data/vms/0/data</span><br><span class="line">total 103652496</span><br><span class="line">-rw-r--r--  1 caiwenhui  staff    96G  8 18 20:21 Docker.raw</span><br><span class="line"></span><br><span class="line">➜  ~ head -n 10 /Users/caiwenhui/Library/Containers/com.docker.docker/Data/vms/0/data/Docker.raw</span><br><span class="line">�D��?���</span><br><span class="line">        U�`�&amp;3�Ѻ`1O�� �ha�ha��S�J�#`</span><br><span class="line">                                     &lt;�kD*�&lt;O5K�VS�~~�/var/lib��B�uK����J�1�@</span><br><span class="line">                                                                             ]�#`</span><br><span class="line">���p��q  Z�]J,)NL������w</span><br><span class="line">)��%�</span><br><span class="line">z?fw</span><br><span class="line">    G/�%|gCԬ?f�u</span><br><span class="line">                )</span><br><span class="line">)�% �.?f</span><br><span class="line">  �% |?f) �% ��?f)� (L � X %X i;�F!)D0 M %@�")� �� ֑@#)� � �f�H$)" - :,�%)�</span><br><span class="line"> �e LE��()"h �a ��SnU&amp;43�%�C4k�?f �% &#123; �% �D WA T қ                            �� ��v&amp;)�" t� FW�D') &#125;</span><br><span class="line">�1 &amp;� � �</span><br><span class="line">       (A �� =�97 �; �&amp;N � _Z˭� � ��</span><br><span class="line"> �% F?f</span><br><span class="line">      �0 �V��</span><br><span class="line">           s</span><br><span class="line"> �% ԇ �% X� �% s�?f �RiDX0�m�&#125;�u �</span><br><span class="line">                                  �@$���w?�  �% ��?f  �% ��?f. � Շ�</span><br><span class="line"> �% MS?f</span><br><span class="line">         W s �w� � ! �o�</span><br><span class="line">  �% E�?f  �% n�?f</span><br></pre></td></tr></table></figure><p>我们这里可以看到，这个文件，占用了<code>96G</code>，就是我所分配的磁盘大小。并且这是一个经过了字节压缩的二进制文件。</p><p><img src="/images/k8s/docker-for-mac-3.png" alt="docker for mac 3"></p><p><img src="/images/k8s/docker-for-mac-4.png" alt="docker for mac 4"></p><p>这张图，算得上是我们今天的重点。</p><p>使用文件共享允许 Mac 上的本地目录与 Linux 容器共享。默认情况下<code>/Users</code>，<code>/Volume</code>、<code>/private</code>、<code>/tmp</code>和<code>/var/folders</code>目录是共享的。如果您的项目在此目录之外，则必须将其添加到列表中。否则，您可能会在运行时得到<code>Mounts denied</code>或<code>cannot start service</code>出错。</p><p>因此，我们可以看到在默认情况下，有几个目录是已经被共享的了。我们重点需要关注的是<code>/Users</code>目录，因为我们常常把我们的所有个人用户相关的东西，都会放在对应用户下，就我而言，我会把所有的代码都在 <code>/Users/caiwenhui/www</code> 下，这也意味着，我的所有代码，都将会被<code>虚拟机</code>同步到<code>linux系统</code>中，也正是因此，当你在MAC系统下，执行<code>docker run -v $(PWD):/www xxx</code>之类的命令的时候，你可以成功的挂载到容器中。<strong>如果你把挂载的目录放在上述的几个目录之外</strong>，docker命令将会<code>挂载失败</code>。</p><p>也是因为这个原因，你会发现，当你的代码，在下载大量依赖，或者在构建一堆索引的时候，或者你的<code>/Users</code>目录下有很多文件在变动的时候，你会发现你的<code>CPU</code>变成异常的高，而且会特别卡，可能你会觉得怎么那么卡。如果你不去查看哪个进程占用那么多cpu的话，你永远不会知道，其实大多数，显示出来都是docker的<code>虚拟机</code>占用的cpu为大头就是因为这个原因。</p><h2 id="获取虚拟机shell"><a href="#获取虚拟机shell" class="headerlink" title="获取虚拟机shell"></a>获取虚拟机shell</h2><p>既然，我们知道了上述的共享文件了，那么我们就会想知道，我要怎么去看，怎么去调试，或者我有什么更深的理解呢？</p><p>其实是有的，例如，我想看看，整个虚拟化技术，都挂载了什么数据卷构成我们的文件系统。</p><p>我们知道<code>MacOS</code>上的<code>Docker Desktop for mac</code>实际上是在Linux虚拟机中运行的Docker容器，这对于macOS主机上使用Docker<code>多了一层虚拟化</code>。有些情况下，我们需要能够访问这个Linux虚拟机，以便实现一些<code>hack</code>操作。</p><h3 id="netcat"><a href="#netcat" class="headerlink" title="netcat"></a>netcat</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ ll ~/Library/Containers/com.docker.docker/Data/debug-shell.sock</span><br><span class="line">srwxr-xr-x  1 caiwenhui  staff     0B  8 16 21:31 /Users/caiwenhui/Library/Containers/com.docker.docker/Data/debug-shell.sock</span><br></pre></td></tr></table></figure><p>我们可以看到，这里有一个名字叫<code>debug-shell.sock</code>的文件，这是一个可执行的sock文件。</p><p>使用 <code>nc</code> 命令连接Docker的<code>debug-shell socket</code>文件:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ nc -U ~/Library/Containers/com.docker.docker/Data/debug-shell.sock</span><br><span class="line">/ # ^[[49;5R</span><br></pre></td></tr></table></figure><blockquote><p>显示的提示符比较奇怪，不过不影响使用</p></blockquote><p>我们使用 <code>df -h</code> 命令可以看到Docker虚拟机的存储挂载:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">/ # ^[[49;5Rdf -h</span><br><span class="line">df -h</span><br><span class="line">Filesystem                Size      Used Available Use% Mounted on</span><br><span class="line">overlay                   3.9G      4.0K      3.9G   0% /</span><br><span class="line">tmpfs                     3.9G      8.0K      3.9G   0% /containers/onboot/000-dhcpcd/tmp</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/001-sysfs/tmp</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/002-sysctl/tmp</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/003-format/tmp</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/004-extend/tmp</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/005-mount/tmp</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/006-metadata/tmp</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/007-services0/tmp</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/008-services1/tmp</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/009-swap/tmp</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/010-mount-docker/tmp</span><br><span class="line">/dev/vda1                94.2G     48.2G     41.2G  54% /containers/services</span><br><span class="line">/dev/vda1                94.2G     48.2G     41.2G  54% /containers/services/docker</span><br><span class="line">tmpfs                     3.9G      4.0K      3.9G   0% /containers/services/acpid/tmp</span><br><span class="line">overlay                   3.9G      4.0K      3.9G   0% /containers/services/acpid/rootfs</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/services/binfmt/tmp</span><br><span class="line">overlay                   3.9G         0      3.9G   0% /containers/services/binfmt/rootfs</span><br><span class="line">tmpfs                     3.9G      8.0K      3.9G   0% /containers/services/dhcpcd/tmp</span><br><span class="line">overlay                   3.9G      8.0K      3.9G   0% /containers/services/dhcpcd/rootfs</span><br><span class="line">tmpfs                     3.9G      4.0K      3.9G   0% /containers/services/diagnose/tmp</span><br><span class="line">overlay                   3.9G      4.0K      3.9G   0% /containers/services/diagnose/rootfs</span><br><span class="line">overlay                   3.9G      4.0K      3.9G   0% /containers/services/diagnose/rootfs</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /containers/onboot/011-bridge/tmp</span><br><span class="line">tmpfs                    64.0M         0     64.0M   0% /dev</span><br><span class="line">tmpfs                   796.2M    528.0K    795.7M   0% /run/resolvconf/resolv.conf</span><br><span class="line">tmpfs                   796.2M    528.0K    795.7M   0% /run/config</span><br><span class="line">tmpfs                   796.2M    528.0K    795.7M   0% /run/containerd</span><br><span class="line">tmpfs                   796.2M    528.0K    795.7M   0% /run/guest-services</span><br><span class="line">tmpfs                   796.2M    528.0K    795.7M   0% /run/host-services</span><br><span class="line">tmpfs                   796.2M    528.0K    795.7M   0% /run/resolvconf/resolv.conf</span><br><span class="line">tmpfs                     3.9G         0      3.9G   0% /sys/fs/cgroup</span><br><span class="line">/dev/vda1                94.2G     48.2G     41.2G  54% /var/lib/containerd</span><br><span class="line">/dev/vda1                94.2G     48.2G     41.2G  54% /var/lib/docker</span><br><span class="line">tmpfs                   796.2M    528.0K    795.7M   0% /var/run</span><br><span class="line">tmpfs                   796.2M    528.0K    795.7M   0% /var/run/linuxkit-containerd/containerd.sock</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>使用命令 <code>exit</code> 或者<code>^C</code> 可以退出这个shell</p><p>进入shell，可以执行 <code>. /etc/profile</code> 获得环境</p><h3 id="nsenter"><a href="#nsenter" class="headerlink" title="nsenter"></a>nsenter</h3><p>使用nsenter从容器内部进入host主机的<code>名字空间(namespace)</code>，但是对文件系统是只读</p><p>另外一种巧妙的方法是运行一个debian容器，然后在这个<code>debian</code>容器中执行 <code>nsenter</code> 通过 <code>pid=host</code> 来实现进入到运行 <code>Docker4Mac</code> 的<code>mini VM</code>的进程空间，这样就相当于进入了macOS的Docker虚拟机</p><p>在这个运行的debian容器中通过 nsenter 进入到host主机，也就是Docker VM名字空间以后，就可以看到虚拟机的提示符:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ docker run -it --rm --privileged --pid=host debian nsenter -t 1 -m -u -n -i bash</span><br><span class="line">bash-5.0#</span><br></pre></td></tr></table></figure><p>我们可以在这个Docker VM中执行网络检查</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">bash-5.0# ip addr</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 brd 127.255.255.255 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 02:50:00:00:00:01 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.65.3/24 brd 192.168.65.255 scope global dynamic noprefixroute eth0</span><br><span class="line">       valid_lft 1576sec preferred_lft 136sec</span><br><span class="line">    inet6 fe80::50:ff:fe00:1/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: tunl0@NONE: &lt;NOARP&gt; mtu 1480 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ipip 0.0.0.0 brd 0.0.0.0</span><br><span class="line">4: ip6tnl0@NONE: &lt;NOARP&gt; mtu 1452 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/tunnel6 :: brd ::</span><br><span class="line">5: services1@if6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 42:2f:8d:45:a3:03 brd ff:ff:ff:ff:ff:ff link-netns services</span><br><span class="line">    inet 192.168.65.4 peer 192.168.65.5/32 scope global services1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::402f:8dff:fe45:a303/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">7: br-3a4b2ff7a5cb: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default</span><br><span class="line">    link/ether 02:42:11:9a:3a:8f brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.7.1/24 brd 192.168.7.255 scope global br-3a4b2ff7a5cb</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">8: br-ef48d4809428: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default</span><br><span class="line">    link/ether 02:42:10:cb:22:b6 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.18.0.1/16 brd 172.18.255.255 scope global br-ef48d4809428</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">9: br-f6b05f844262: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default</span><br><span class="line">    link/ether 02:42:f4:ec:b5:c4 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.19.0.1/16 brd 172.19.255.255 scope global br-f6b05f844262</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">10: br-ff0c8e959ac0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default</span><br><span class="line">    link/ether 02:42:48:7f:f8:bb brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.110.1/24 brd 192.168.110.255 scope global br-ff0c8e959ac0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">11: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 02:42:b9:db:7e:59 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::42:b9ff:fedb:7e59/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>因为信息比较多，我们重点关注几个网卡信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 02:50:00:00:00:01 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 192.168.65.3/24 brd 192.168.65.255 scope global dynamic noprefixroute eth0</span><br><span class="line">       valid_lft 1576sec preferred_lft 136sec</span><br><span class="line">    inet6 fe80::50:ff:fe00:1/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">11: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default</span><br><span class="line">    link/ether 02:42:b9:db:7e:59 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::42:b9ff:fedb:7e59/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p><img src="/images/k8s/docker-for-mac-5.png" alt="docker for mac 5"></p><p>上面的信息，结合来看，我们在<code>docker-for-mac</code>客户端设置了我们的虚拟机的网段 <code>192.168.65.0/24</code>，结合<code>eth0</code>和<code>docker0</code>这2个网卡信息，我们会发现，<code>eth0</code> 的 <code>192.168.65.3</code>, 就是我们这是的网段的信息，所以，这个虚拟机和macOS物理主机上对应的IP地址 <code>192.168.65.1</code> 对应，也就是说，如果我们使用 <code>NFS 方式</code>挂载物理主机上的NFS卷，访问的NFS服务器端地址就是这样获得的。</p><p>这里还可以看到在<code>Docker VM</code>上运行的<code>Docker网络</code>是 <code>172.17.xx.xx/16</code> ，是一个<code>NAT网络</code>，我们可以看到在<code>Docker VM端</code>分配的IP地址是 <code>172.17.0.1</code> 。这也验证了我们的<code>Docker VM</code>上实际上有<code>2个网络</code>。</p><ul><li><code>192.168.65.x/24</code> =&gt; 和<code>物理主机macOS</code>连接的NAT网络，用于虚拟机</li><li><code>172.17.x.x/16</code> =&gt; 和<code>Docker0</code>连接的NAT网络，用于容器</li></ul><p>在Docker容器中，通过两层NAT，依然可以访问外界Internet。不过，反过来，外部需要访问Docker容器就比较麻烦了，需要做<code>端口映射</code>。</p><h2 id="挂载"><a href="#挂载" class="headerlink" title="挂载"></a>挂载</h2><p>我们前面说到了，当你通过 <code>docker run -v</code>的时候，你可以指定在<code>共享目录</code>下的所有文件下，进行挂载进去。那么我们反过来想一下，既然是共享目录的话，那么容器是如何做到查找这些目录的呢？</p><p>通过<code>mount -l</code>，我们可以看到挂载点。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">bash-5.0# mount -l</span><br><span class="line">rootfs on / type tmpfs (ro,relatime)</span><br><span class="line">proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">tmpfs on /run type tmpfs (rw,nosuid,nodev,noexec,relatime,size=815300k,mode=755)</span><br><span class="line">tmpfs on /tmp type tmpfs (rw,nosuid,nodev,noexec,relatime,size=815300k)</span><br><span class="line">tmpfs on /var type tmpfs (rw,nosuid,nodev,noexec,relatime,mode=755)</span><br><span class="line">dev on /dev type devtmpfs (rw,nosuid,noexec,relatime,size=4008488k,nr_inodes=1002122,mode=755)</span><br><span class="line">mqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">shm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=000)</span><br><span class="line">sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">securityfs on /sys/kernel/security type securityfs (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">debugfs on /sys/kernel/debug type debugfs (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">fusectl on /sys/fs/fuse/connections type fusectl (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">pstore on /sys/fs/pstore type pstore (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">none on /sys/fs/bpf type bpf (rw,nodev,relatime)</span><br><span class="line">binfmt_misc on /proc/sys/fs/binfmt_misc type binfmt_misc (rw,nosuid,nodev,noexec,relatime)</span><br><span class="line">cgroup_root on /sys/fs/cgroup type tmpfs (rw,nosuid,nodev,noexec,relatime,size=10240k,mode=755)</span><br><span class="line">cpuset on /sys/fs/cgroup/cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)</span><br><span class="line">cpu on /sys/fs/cgroup/cpu type cgroup (rw,nosuid,nodev,noexec,relatime,cpu)</span><br><span class="line">cpuacct on /sys/fs/cgroup/cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct)</span><br><span class="line">blkio on /sys/fs/cgroup/blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)</span><br><span class="line">memory on /sys/fs/cgroup/memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)</span><br><span class="line">devices on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)</span><br><span class="line">freezer on /sys/fs/cgroup/freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)</span><br><span class="line">net_cls on /sys/fs/cgroup/net_cls type cgroup (rw,nosuid,nodev,noexec,relatime,net_cls)</span><br><span class="line">perf_event on /sys/fs/cgroup/perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)</span><br><span class="line">net_prio on /sys/fs/cgroup/net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio)</span><br><span class="line">hugetlb on /sys/fs/cgroup/hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)</span><br><span class="line">pids on /sys/fs/cgroup/pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>可以看到，我们这里有大量的挂载点，这些挂载点，组合成了一个独立的文件系统，或者各种命名空间。</p><p>现在有一个需求。例如，我们知道在使用k8s的时候，当我们用<code>pv</code>的<code>type</code>为<code>hostPath</code>的时候，是可以做到持久化数据磁盘的，那么我能不能做到，数据存放在<code>Docker VM 非共享目录</code>中呢？</p><p>就是我的物理主机，并不希望同步这些数据。这些数据仅仅只需要存在<code>Docker VM</code>中就好了。</p><p>当然，这个场景就是我们经常说，我们想要看一些容器的配置或者目录的时候，会发现输出的路径，在我们的宿主机上找不到，为什么会这样子？难道是出错了吗？其实只是这些文件都在<code>Docker VM</code>中，其实就是因为这个原因导致的。只要我们进入到 <code>Docker VM</code>就可以看到这些文件。</p><p>例如，以我目前的例子为例子，我需要采集我本地所有<code>k8s-pods</code>的输出在终端的日志信息，我想通过<code>promtail</code>来进行日志采集，然后通过<code>loki</code>作为存储和查询服务器，再通过<code>grafna</code>来进行展示。我们的服务以前台的方式进行启动，所以我们那么首先我需要解决的第一个问题，就是pods的标准输出到哪里？后来发现<code>/var/log/pods/</code>。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">bash-5.0# ls -l /var/log/pods/</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 18 09:05 default_dev-grafana-7cd4c89fd4-wdkpb_cf869741-be0d-44d2-b776-3239dd276069</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 18 09:05 default_dev-loki-statefulset-0_1d34dcac-a763-478a-b17b-addb082462ef</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 18 09:05 default_dev-loki-statefulset-1_c82d61e9-c66f-4b6a-960a-a8f7a1d5a8e2</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 18 09:05 default_dev-promtail-n6jgs_51afda31-be9c-4377-8167-8e29e991d9b0</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 16 13:32 kube-system_coredns-558bd4d5db-g2m9h_67ec7c7f-2e48-4cd7-8298-86295073072b</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 16 13:32 kube-system_coredns-558bd4d5db-jk9bp_b9d8b64f-dda8-426a-8f55-029298828333</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 16 13:32 kube-system_etcd-docker-desktop_5d9d97b8d8daed31d6fd5c6d386c29c5</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 16 13:32 kube-system_kube-apiserver-docker-desktop_6fcd2fd42808f86960df2a06a72d6dc0</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 16 13:32 kube-system_kube-controller-manager-docker-desktop_bed77ee1871d9eabd1710836ad671f32</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 16 13:32 kube-system_kube-proxy-4wbs6_8bece9c8-e5fb-41f5-8869-2d408e71ba31</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 16 13:32 kube-system_kube-scheduler-docker-desktop_a52842863dff28cb2f7d4171a9f614a0</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 16 13:32 kube-system_storage-provisioner_79a3e8e5-6a93-43c1-abf3-c916384a4018</span><br><span class="line">drwxr-xr-x    3 root     root            60 Aug 16 13:32 kube-system_vpnkit-controller_3742d607-ea8f-43df-aecf-4f925accbc3e</span><br></pre></td></tr></table></figure><p>我们随便找一个pods，去查看日志。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">bash-5.0# tail -n 10 /var/log/pods/default_dev-grafana-7cd4c89fd4-wdkpb_cf869741-be0d-44d2-b776-3239dd276069/grafana/0.log</span><br><span class="line">&#123;"log":"&#123;\"@level\":\"debug\",\"@message\":\"datasource: registering query type handler\",\"@timestamp\":\"2021-08-18T09:05:05.385825Z\",\"queryType\":\"node_graph\"&#125;\n","stream":"stderr","time":"2021-08-18T09:05:05.3860495Z"&#125;</span><br><span class="line">&#123;"log":"&#123;\"@level\":\"debug\",\"@message\":\"datasource: registering query type fallback handler\",\"@timestamp\":\"2021-08-18T09:05:05.385855Z\"&#125;\n","stream":"stderr","time":"2021-08-18T09:05:05.3860803Z"&#125;</span><br><span class="line">&#123;"log":"t=2021-08-18T09:05:05+0000 lvl=info msg=\"HTTP Server Listen\" logger=http.server address=[::]:3000 protocol=http subUrl= socket=\n","stream":"stdout","time":"2021-08-18T09:05:05.3939314Z"&#125;</span><br><span class="line">&#123;"log":"t=2021-08-18T09:07:52+0000 lvl=eror msg=\"Failed to look up user based on cookie\" logger=context error=\"user token not found\"\n","stream":"stdout","time":"2021-08-18T09:07:52.5402974Z"&#125;</span><br><span class="line">&#123;"log":"t=2021-08-18T09:07:52+0000 lvl=info msg=\"Request Completed\" logger=context userId=0 orgId=0 uname= method=GET path=/dashboard/new status=302 remote_addr=192.168.65.3 time_ms=0 size=29 referer=\n","stream":"stdout","time":"2021-08-18T09:07:52.5403468Z"&#125;</span><br><span class="line">&#123;"log":"t=2021-08-18T09:07:56+0000 lvl=info msg=\"Successful Login\" logger=http.server User=admin@localhost\n","stream":"stdout","time":"2021-08-18T09:07:56.6167821Z"&#125;</span><br><span class="line">&#123;"log":"t=2021-08-18T09:08:00+0000 lvl=info msg=\"Request Completed\" logger=context userId=1 orgId=1 uname=admin method=GET path=/login status=302 remote_addr=192.168.65.3 time_ms=11 size=24 referer=\n","stream":"stdout","time":"2021-08-18T09:08:00.7292107Z"&#125;</span><br><span class="line">&#123;"log":"t=2021-08-18T09:09:50+0000 lvl=info msg=\"Request Completed\" logger=context userId=1 orgId=1 uname=admin method=GET path=/api/datasources/proxy/1/loki/api/v1/query_range status=400 remote_addr=192.168.65.3 time_ms=2 size=57 referer=\"http://localhost:3000/dashboard/new?editPanel=2\u0026orgId=1\"\n","stream":"stdout","time":"2021-08-18T09:09:50.7530735Z"&#125;</span><br><span class="line">&#123;"log":"t=2021-08-18T09:14:53+0000 lvl=eror msg=\"Data proxy error\" logger=data-proxy-log userId=1 orgId=1 uname=admin path=/api/datasources/proxy/1/loki/api/v1/label/filename/values remote_addr=192.168.65.3 referer=\"http://localhost:3000/d/UWO8RT7nk/new-dashboard-copy?editPanel=2\u0026viewPanel=2\u0026orgId=1\" error=\"http: proxy error: EOF\"\n","stream":"stdout","time":"2021-08-18T09:14:53.0497419Z"&#125;</span><br><span class="line">&#123;"log":"t=2021-08-18T09:14:53+0000 lvl=eror msg=\"Request Completed\" logger=context userId=1 orgId=1 uname=admin method=GET path=/api/datasources/proxy/1/loki/api/v1/label/filename/values status=502 remote_addr=192.168.65.3 time_ms=79695 size=0 referer=\"http://localhost:3000/d/UWO8RT7nk/new-dashboard-copy?editPanel=2\u0026viewPanel=2\u0026orgId=1\"\n","stream":"stdout","time":"2021-08-18T09:14:53.0502414Z"&#125;</span><br></pre></td></tr></table></figure><p>现在，我们知道了日志是存储在这里了，那么我们就可以知道，在<code>Docker VM</code>中，我们只需要挂载<code>/var/log/pods</code>到我们的容器<code>promtail</code>中，然后进行采集再推送到<code>loki</code>，就可以通过<code>grafna</code>查询了。</p><p>这个思路是没问题的，那么我们再往深程度的角度想，那么这个时候，我们的<code>k8s-pv-type</code>应该填什么呢？刚才不是说了<code>hostPath</code>是可以持久化到本地吗？但是那是针对物理主机<code>macos</code>来说的，况且这个目录，我们并非在<code>Docker VM</code>之下，这就回到了我们上面说的，在<code>Docker VM</code>存在，在<code>物理主机</code>不存在的需求。</p><p>那么我们这个时候，其实还是可以使用<code>hostPath</code>的，理由很简单，因为k8s会识别路径，如果是在共享目录下的话，那么他会从共享目录的数据卷中找到对应的磁盘路径，如果不在共享目录下的，则从<code>Docker VM</code>中查找，因此，这就是解开了我们这个疑惑了。可以大胆的放心使用<code>hostPath</code>来创建<code>pv</code>资源。</p><p>最后，附上一张最终的效果图：</p><p><img src="/images/k8s/docker-for-mac-6.png" alt="docker-for-mac-6"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;&lt;p&gt;上一次，我们说到了&lt;code&gt;docker-for-mac&lt;/code&gt; 已经内置了最小化的k8s。我们在本地开发的时候，或多或少希望&lt;code&gt;yaml配置&lt;/code&gt;是最接近线上环境的配置。&lt;/p&gt;
&lt;p&gt;因此，上一次，教会了大家，如何在mac上开启nfs,把我们的pv和本地mac的nfs进行一个通信。&lt;/p&gt;
&lt;p&gt;这一次，我们来聊聊&lt;code&gt;docker-for-mac&lt;/code&gt;磁盘挂在的相关内容。&lt;/p&gt;
    
    </summary>
    
    
      <category term="kubernetes" scheme="http://blog.crazylaw.cn/categories/kubernetes/"/>
    
    
      <category term="kubernetes" scheme="http://blog.crazylaw.cn/tags/kubernetes/"/>
    
  </entry>
  
</feed>
