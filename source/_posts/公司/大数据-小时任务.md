---
title: 大数据任务-小时任务
date: 2022-05-26 11:52:40
categories: [大数据]
tags: [大数据, 公司]
---

## 前言

总结一下公司大数据的任务ETL离线工作流 - 小时任务

<!-- more -->

公司的ETL服务，目前采用的是组件为：

- 数仓 (hadoop)
- 任务调度器 (azkaban)
- 出仓 (gp)
- 数仓查询 (hue)(hive)(spark)

## job_hour（小时任务）

- schedule: `30 * * * *`

> 每小时30分的时候进行启动任务

![小时任务](/images/公司/bigdata-hour.png)

### check_tk_batch_log_success

> 检测tk服务是否把原始日志已经上传到oss服务中

核心流程如下：

```shell
path=${LOG_TRACKING_BATCH_PATH}

path=${path}/${yyyy}/${mm}/${dd}/${hh}/_SUCCESS

hadoop fs -test -e ${path}
```

数据是根据每个小时为一个基本单位，通过`_SUCCESS`文件来标志当前小时的数据是否已经同步到OSS完毕。

### sync_mysql_config

> 同步mysql的当前配置信息


#### 同步广告位数据

核心流程如下：

```shell
stat_source='placement'

mysql -u${DB_USER} -P${DB_PORT} -p${DB_PWD} -h${DB_HOST} -e "
select id,uuid,format from ${DB_NAME}.${stat_source}
" > tmp/bigdata_mysql_placement_list.log

if [ -f "tmp/bigdata_mysql_placement_list.log" ]; then
    # hadoop fs -rm -r ${CLIENT_TMP_LOG_META_PATH}/tmp/placement/
    ${FILE_COMMAND_RM} ${CLIENT_TMP_LOG_META_PATH}/tmp/placement/ --recursive
    ${FILE_COMMAND_CP} tmp/bigdata_mysql_placement_list.log ${CLIENT_TMP_LOG_META_PATH}/tmp/placement/
fi
```

1. 从数据库导出广告信息：`id`, `uuid`, `format(广告样式)` 到`广告列表文件`
2. 把本地数据更新到oss中

```shell
tmpfilename="tmp/bigdata_mysql_placement.log"

mysql -u${DB_USER} -P${DB_PORT} -p${DB_PWD} -h${DB_HOST} -e "
    select 
        id,
        uuid,        
        publisher_id,
        app_id,      
        name,        
        format,      
        remark,      
        create_time, 
        update_time 
    from 
        ${DB_NAME}.${stat_source} 
    ;
" --skip-column-names | sed 's/\t/|/g' > ${tmpfilename}

if [ -f "${tmpfilename}" ]; then

    target="${HIVE_DB_PATH}/${T_BIGDATA_PLACEMENT}/yyyy=${yyyy}/mm=${mm}/dd=${dd}/"

    ${FILE_COMMAND_RM} ${target} --recursive

    ${FILE_COMMAND_CP} ${tmpfilename} ${target}

    echo "sync ${tmpfilename} to ${target}"

fi
```

1. 导出数据广告位数据，并且以`|`符号作为分隔符，写入到`广告位文件`
2. 如果 `广告位` 文件存在的话，那么就把 `广告位文件` 从 `file-oss` 同步到 `hive-oss`

#### 同步广告聚合收益数据

```shell
bigdata_unit_source='unit'
bigdata_network_source='network'
tmpAdsourcefilename="tmp/bigdata_mysql_unit.log"
tmpAdsourceFbFilename="tmp/bigdata_mysql_unit_fb.log"

mysql -u${DB_USER} -P${DB_PORT} -p${DB_PWD} -h${DB_HOST} -e "
    select 
        a.id,     
        a.publisher_id,
        a.placement_id,
        a.network_id,  
        a.network_id,
        0,  
        a.name,
        a.remote_unique,
        a.remote_unit,
        a.header_bidding_switch,
        a.ecpm,
        a.ecpm_currency,
        a.cap_hour,
        a.cap_hour_switch,
        a.cap_day,
        a.cap_day_switch,
        a.pacing,
        a.pacing_switch,
        a.create_time,
        a.update_time,
        a.status,
        b.nw_firm_id
    from 
        ${DB_NAME}.${bigdata_unit_source} a
    left outer join
         ${DB_NAME}.${bigdata_network_source} b
    on
        a.network_id=b.id
    where 
        b.nw_firm_id!=1
    ;
" --skip-column-names | sed 's/\t/|/g' > ${tmpAdsourcefilename}

mysql -u${DB_USER} -P${DB_PORT} -p${DB_PWD} -h${DB_HOST} -e "
    select 
        a.id,     
        a.publisher_id,
        a.placement_id,
        b.parent_id,  
        a.network_id,
        b.parent_id,  
        a.name,
        a.remote_unique,
        a.remote_unit,
        a.header_bidding_switch,
        a.ecpm,
        a.ecpm_currency,
        a.cap_hour,
        a.cap_hour_switch,
        a.cap_day,
        a.cap_day_switch,
        a.pacing,
        a.pacing_switch,
        a.create_time,
        a.update_time,
        a.status,
        b.nw_firm_id
    from 
        ${DB_NAME}.${bigdata_unit_source} a
    left outer join
         ${DB_NAME}.${bigdata_network_source} b
    on
        a.network_id=b.id
    where 
        b.nw_firm_id=1
    ;
" --skip-column-names | sed 's/\t/|/g' > ${tmpAdsourceFbFilename}


if [ -f "${tmpfilename}" ]; then

    target="${HIVE_DB_PATH}/${T_BIGDATA_UNIT}/yyyy=${yyyy}/mm=${mm}/dd=${dd}/"

    ${FILE_COMMAND_RM} ${target} --recursive

    ${FILE_COMMAND_CP} ${tmpAdsourcefilename} ${target}
    ${FILE_COMMAND_CP} ${tmpAdsourceFbFilename} ${target}

    echo "sync ${tmpfilename} to ${target}"

fi

```

1. 把 `国内广告` 和 `国外广告` 数据导出分别放在`不同的文件`中
2. 然后从 `file-oss` 同步到 `hive-oss`

> 备注：这里采用的是判断${tmpfilename}是广告位的文件，暂不确定是不是说明如果广告位文件没数据的话，那么这个逻辑也不做处理了。

#### 广告场景

```shell
bigdata_scenario_source='scenario'
tmpScenariofilename="tmp/bigdata_mysql_scenario.log"

mysql -u${DB_USER} -P${DB_PORT} -p${DB_PWD} -h${DB_HOST} -e "
    select 
        id,
        uuid,
        publisher_id,
        app_id,
        placement_id,
        name,
        remark,
        create_time,
        update_time,
        status
    from 
        ${DB_NAME}.${bigdata_scenario_source}
    ;
" --skip-column-names | sed 's/\t/|/g' > ${tmpScenariofilename}

if [ -f "${tmpScenariofilename}" ]; then

    target="${HIVE_DB_PATH}/${T_BIGDATA_SCENARIO}/"

    ${FILE_COMMAND_RM} ${target} --recursive

    ${FILE_COMMAND_CP} ${tmpScenariofilename} ${target}

    echo "sync ${tmpScenariofilename} to ${target}"

fi
```

1. 把广告场景数据导入到广告场景文件中
2. 然后从 `file-oss` 同步到 `hive-oss`

#### 等等...

### check_strategy_app_log_success

> 检测app日志策略是否写入完成

### check_strategy_placement_log_success

> 检测广告策略日志写入是否写入完成

### parse_tk_batch

```shell
dependencies=check_tk_batch_log_success,sync_mysql_config
command=sh -x parse_tk_batch.sh
```

> 开始解析tk数据

```shell
log_type=18
hadoop fs -rm -r ${CLIENT_TMP_LOG_META_PATH}/${T_BIGDATA_TK_BATCH}/
hadoop jar ${parse_jar} ${LOG_TRACKING_BATCH_PATH}/${yyyy}/${mm}/${dd}/${hh}/* ${CLIENT_TMP_LOG_META_PATH} ${yyyy_mm_dd_hh} ${log_type} ${T_BIGDATA_TK_BATCH} ${T_BIGDATA_DEVICE_ACTIVE_HOUR} ${CLIENT_TMP_LOG_META_PATH}/tmp/placement/bigdata_mysql_placement_list.log
```
通过hadoop的`map-reduce`进行处理分布式处理数据

其实目前脚本来说，这里只有前5个参数有用

1. 第一个参数是原始日志的目录（有用）
2. 第二个参数是输出日志的目录（没用）
3. 第三个参数是日期时间
4. 第四个参数是日志类型（这里=18）
5. 第五个参数是表名（也是完整hive路径的一级目录）
6. 第六个参数是输出结果表名（这里没用）
7. 第七个参数是这里是广告日志文件路径

TK原始日志的存储目录下，tk原始日志文件中里面有不同类型的数据，其中有一个`type`类型，可以叫做`tk_type`, 代表不同类型的数据(`TYPE_TRACKING_XXX`)

```java
public class TrackingLogConst {

    public static final int TYPE_TRACKING_REQUEST = 1; // 请求
    public static final int TYPE_TRACKING_FILLED_REQUEST = 2; // 有填充的请求
    public static final int TYPE_TRACKING_NO_FILLED_REQUEST = 3; // 没填充的请求
    public static final int TYPE_TRACKING_IMPRESSION = 4; // 展示
    public static final int TYPE_TRACKING_REFERSH_IMPRESSION = 5; //刷新展示
    public static final int TYPE_TRACKING_CLICK = 6; // 点击
    public static final int TYPE_TRACKING_VIDEO_PLAY = 7; // 视频播放
    public static final int TYPE_TRACKING_RV_PLAY_START = 8;// 激励视频播放开始
    public static final int TYPE_TRACKING_RV_PLAY_COMPLETE = 9;// 激励视频播放完成
    public static final int TYPE_TRACKING_LOAD = 10;// load调用数据
    public static final int TYPE_TRACKING_HEADER_BIDDING = 11;// header bidding
    public static final int TYPE_TRACKING_LOADFILLED = 12;// loadfilled数据
    public static final int TYPE_TRACKING_SHOW = 13;// show调用
    public static final int TYPE_TRACKING_RAND_WATERFALL = 15;// show调用
    public static final int TYPE_TRACKING_AD_SCENARIO = 16;// 到达广告场景


    // myoffer的tracking对应类型
    public static final String TYPE_MYOFFER_TRACKING_RV_0 = "1";
    public static final String TYPE_MYOFFER_TRACKING_RV_25 = "2";
    public static final String TYPE_MYOFFER_TRACKING_RV_50 = "3";
    public static final String TYPE_MYOFFER_TRACKING_RV_75 = "4";
    public static final String TYPE_MYOFFER_TRACKING_RV_100 = "5";
    public static final String TYPE_MYOFFER_TRACKING_RV_END_SHOW = "6";
    public static final String TYPE_MYOFFER_TRACKING_RV_END_CLOSE = "7";
    public static final String TYPE_MYOFFER_TRACKING_IMPRESSION = "8";
    public static final String TYPE_MYOFFER_TRACKING_CLICK = "9";
}

```

```java
        private org.apache.hadoop.mapreduce.lib.output.MultipleOutputs<Text, Text> mos;

        protected void setup(Mapper.Context context) throws IOException, InterruptedException {
            mos = new MultipleOutputs<Text, Text>(context);
            Configuration conf = context.getConfiguration();
            tableName = conf.get("table_name");
            deviceTable = conf.get("result_table");
            inputTime = conf.get("date");
            inputTimeSplit = inputTime.split("-");
            logType = Integer.parseInt(conf.get("log_type"));

            Path[] uriList = context.getLocalCacheFiles();

            placementMap = PlacementData.getPlacementListFromUri(uriList);

            super.setup(context);
        }

        private void writeMosString(StringBuilder stringBuilder, int trackingType) {
            String resultString = stringBuilder.toString();
            if (LogFactory.isDebug) {
                System.out.println("result:" + resultString + " tableName:" + tableName + "/yyyy=" + inputTimeSplit[0] + "/mm=" + inputTimeSplit[1] + "/dd=" + inputTimeSplit[2] + "/hh=" + inputTimeSplit[3] + "/");
            }
            // 写结果表
            if (resultString != null && resultString != "" && !LogFactory.isDebug) {
                // 写结果后，会使用logtype_作为前缀
                try {
                    mos.write(new Text(resultString), new Text(), tableName + "/" + trackingType + "/raw/" + logType + "_" + trackingType + "_");
                } catch (IOException e) {
                    e.printStackTrace();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                }
            }
        }

        ...

            String outputPathTmp = outputPath + "/" + tableName + logType + "/";
            FileSystem fs = null;
            try {

                fs = FileSystem.get(new URI(inputPath), conf);
                Path outPath = new Path(outputPathTmp);
                if (fs.exists(outPath)) {
                    fs.delete(outPath, true);
                }
            } catch (URISyntaxException e) {
                e.printStackTrace();
            }
```

父级路径位：`outputPathTmp`: `/{table}{logType}/`

看到数据被解析之后，会被写入到如下子级路径：

`{tableName} + "/" + {trackingType} + "/raw/" + {logType} + "_" + {trackingType} + "_"`

在当前的解析任务中，以 `TYPE_TRACKING_IMPRESSION=4` 为例子，具体的例子如下：

`{T_BIGDATA_TK_BATCH}/4/raw/18_4_xxx`

具体用法需要串联下一个节点来看。

### copy_xxx(copy_impression为例)

```shell
${FILE_COMMAND_RM} ${HIVE_DB_PATH}/${T_BIGDATA_IMPRESSION}/yyyy=${yyyy}/mm=${mm}/dd=${dd}/hh=${hh} --recursive
${FILE_COMMAND_RM} ${HIVE_DB_PATH}/${T_BIGDATA_IMPRESSION_V2}/yyyy=${yyyy}/mm=${mm}/dd=${dd}/hh=${hh} --recursive

${FILE_COMMAND_SYNC} ${CLIENT_TMP_LOG_META_PATH}/${T_BIGDATA_TK_BATCH}18/${T_BIGDATA_TK_BATCH}/4/raw/ ${HIVE_DB_PATH}/${T_BIGDATA_IMPRESSION}/yyyy=${yyyy}/mm=${mm}/dd=${dd}/hh=${hh}/
${FILE_COMMAND_SYNC} ${CLIENT_TMP_LOG_META_PATH}/${T_BIGDATA_TK_BATCH}18/${T_BIGDATA_TK_BATCH}/5/raw/ ${HIVE_DB_PATH}/${T_BIGDATA_IMPRESSION}/yyyy=${yyyy}/mm=${mm}/dd=${dd}/hh=${hh}/

hive -e "
        use ${DB_BIGDATA};
        alter table ${T_BIGDATA_IMPRESSION} drop IF EXISTS  partition (yyyy='${yyyy}',mm='${mm}',dd='${dd}',hh='${hh}');
        alter table ${T_BIGDATA_IMPRESSION} add partition (yyyy='${yyyy}',mm='${mm}',dd='${dd}',hh='${hh}') location 'yyyy=${yyyy}/mm=${mm}/dd=${dd}/hh=${hh}';
"

hql=" select
        cast(c_date as int) as c_date,
        c_time,
        cast(created as bigint) as created,
        ip,
        remote_ip,
        server_id,
        country_code,
        cast((case when os_platform is null or os_platform='' then 1 else os_platform end) as int) as os_platform,
        imei,
        mac,
        android_id,
        gaid,
        idfa,
        os_vn,
        os_vc,
        model,
        brand,
        screen_size,
        cast((case when orientation is null or orientation='' then 1 else orientation end) as int) as orientation,
        network_type,
        mcc,
        mnc,
        language,
        time_zone,
        user_agent,
        gpv,
        app_vn,
        app_vc,
        app_package,
        sdk_version,
        cast((case when publisher_id is null or publisher_id='' then 0 else publisher_id end) as int) as publisher_id,
        app_id,
        cast((case when app_raw_id is null or app_raw_id='' then 0 else app_raw_id end) as int) as app_raw_id,
        placement_id,
        cast((case when placement_raw_id is null or placement_raw_id='' then 0 else placement_raw_id end) as int) as placement_raw_id,
        request_id,
        psid,
        sessionid,
        cast((case when sdk_time is null or sdk_time='' then 0 else sdk_time end) as bigint) as sdk_time,
        ug_id,
        nw_version,
        cast((case when nw_firm_id is null or nw_firm_id='' then 0 else nw_firm_id end) as int) as nw_firm_id,
        cast((case when sc_type is null or sc_type='' then 0 else sc_type end) as int) as sc_type,
        cast((case when group_id is null or group_id='' then 0 else group_id end) as int) as group_id,
        cast((case when format is null or format='' then 0 else format end) as int) as format,
        extra,
        cast((case when is_refresh is null or is_refresh='' then 0 else is_refresh end) as int) as is_refresh,
        cast((case when unit_id is null or unit_id='' then 0 else unit_id end) as int) as unit_id,
        cast((case when system_type is null or system_type='' then 0 else system_type end) as int) as system_type,
        cast((case when load_type is null or load_type='' then 0 else load_type end) as int) as load_type,
        case when asid is null then '' else asid end as asid,
        case when channel is null then '' else channel end as channel,
        case when upid is null then '' else upid end as upid,
        cast((case when auto_refresh is null or auto_refresh='' then 0 else auto_refresh end) as int) as auto_refresh,
        cast((case when aprn_auto_req is null or aprn_auto_req='' then 0 else aprn_auto_req end) as int) as aprn_auto_req,
        cast((case when bidtype is null or bidtype='' then 0 else bidtype end) as int) as bidtype,
        cast((case when bidprice is null or bidprice='' then 0 else bidprice end) as float) as bidprice,
        case when offer_pkg is null then '' else offer_pkg end as offer_pkg,
        case when sub_channel is null then '' else sub_channel end as sub_channel,
        case when idfv is null then '' else idfv end as idfv,
        cast((case when traffic_group_id is null or traffic_group_id='' then 0 else traffic_group_id end) as int) as traffic_group_id,
        cast((case when myoffer_show_type is null or myoffer_show_type='' then 0 else myoffer_show_type end) as int) as myoffer_show_type,
        cast((case when ofl is null or ofl='' then 0 else ofl end) as int) as ofl,
        cast((case when gdpr_cs is null or gdpr_cs='' then 0 else gdpr_cs end) as int) as gdpr_cs,
        case when scenario is null then '1' else scenario end as scenario,
        cast((case when deduction_res is null or deduction_res='' then 0 else deduction_res end) as int) as deduction_res,
        cast((case when deduction_num is null or deduction_num='' then 1 else deduction_num end) as int) as deduction_num,
        case when oaid is null then '' else oaid end as oaid,
        cast((case when is_cn_sdk is null or is_cn_sdk='' then 0 else is_cn_sdk end) as int) as is_cn_sdk,
        cast((case when adtype_day_show_times is null or adtype_day_show_times='' then 0 else adtype_day_show_times end) as int) as adtype_day_show_times,
        cast((case when adtype_hour_show_times is null or adtype_hour_show_times='' then 0 else adtype_hour_show_times end) as int) as adtype_hour_show_times,
        cast((case when placement_day_show_times is null or placement_day_show_times='' then 0 else placement_day_show_times end) as int) as placement_day_show_times,
        cast((case when placement_hour_show_times is null or placement_hour_show_times='' then 0 else placement_hour_show_times end) as int) as placement_hour_show_times,
        case when install_source is null then '' else install_source end as install_source,
        protocol,
        origin_num,
        protocol_type,
        abtest_id,
        first_init_time,
        days_from_first_init,
        app_custom,
        user_id,
        age,
        gender,
        cl_imp,
        ex_ad
        from 
            ${DB_BIGDATA}.${T_BIGDATA_IMPRESSION}
        where 
            yyyy='${yyyy}'
            and mm='${mm}'
            and dd='${dd}'
            and hh='${hh}' "


spark-submit --class com.BigData.spark.jobs.common.CommonSparkSaveORCJob \
--name "BigData_CommonSparkDateTimeJob_copy_impression_dt${yyyy_mm_dd_hh}" \
--master yarn  \
--deploy-mode cluster \
--executor-memory 2g \
--driver-memory 2g \
--executor-cores 2 \
--num-executors 8 \
--conf spark.dynamicAllocation.enabled=false \
--conf spark.dynamicAllocation.minExecutors=8 \
--conf spark.dynamicAllocation.maxExecutors=64 \
--conf spark.core.connection.ack.wait.timeout=300 \
--files "${HIVE_SITE_PATH}" \
${SPARK_SQL_JAR} ${CLIENT_TMP_LOG_HIVE_PATH} "${hql}" "${HIVE_DB_PATH}/${T_BIGDATA_IMPRESSION_V2}/yyyy=${yyyy}/mm=${mm}/dd=${dd}/hh=${hh}/"\


 hive -e "
    use ${DB_BIGDATA};
    alter table ${T_BIGDATA_IMPRESSION_V2} drop IF EXISTS  partition (yyyy='${yyyy}',mm='${mm}',dd='${dd}',hh='${hh}');
    alter table ${T_BIGDATA_IMPRESSION_V2} add partition (yyyy='${yyyy}',mm='${mm}',dd='${dd}',hh='${hh}') location 'yyyy=${yyyy}/mm=${mm}/dd=${dd}/hh=${hh}';
 "
```


这里接着上一个节点的分析，这里的`${CLIENT_TMP_LOG_META_PATH}/${T_BIGDATA_TK_BATCH}18/${T_BIGDATA_TK_BATCH}/4/raw/` 就是经过hadoop解析后输出文件的目录

1. 如果有历史的数据，则删除历史的数据，然后重新导入数据到表中
2. 接着再把数据copy到 `impression` 对应的目录分区中
3. 重建（修复）分区，把数据加载到hive中的`impression`
4. 通过sql把数据进行 `第一次` 清洗，经过这一级的清洗，通过spark把数据转成 `ORC` 格式进行存储到 `impression_v2` 表
5. 重建（修复）分区，把数据加载到hive中`impression_v2`

### merge_xxx(merge_tk_impression为例)

> 清洗tk的impression数据到tk小时的orc表（此orc非物理上的orc表）

```shell
hql="select
        ${yyyy}${mm}${dd},
        ${hh},
        a.nw_firm_id,
        a.group_id,
        a.unit_id,
        a.system_type,
        a.sdk_version,
        a.app_vn,
        a.os_platform,
        a.country_code,
        a.publisher_id,
        a.app_raw_id,
        a.placement_raw_id,
        a.format,
        a.sc_type,
        0,
        0,
        cast(count(a.request_id) as bigint),
        0,
        0,
        0,
        0,
        0,
        a.channel,
        a.sub_channel,
        0,
        0,
        0,
        ${timeStamp},
        0,
        cast(b.network_id as int),
        a.traffic_group_id,
        a.bidtype,
        0,
        0,
        cast((sum(a.bidprice)/1000) as float),
        case when (a.scenario is null or a.scenario='' or c.uuid is null or c.status<>3) then '1' else a.scenario end,
        case when (a.scenario is not null and a.scenario<>'' and a.scenario<>'1' and c.uuid is null) then 1 when (a.scenario is not null and a.scenario<>'' and a.scenario<>'1' and c.status<>3) then 2 else 0 end,
        case when (a.scenario is not null and a.scenario<>'' and a.scenario<>'1' and c.uuid is null or a.scenario is not null and a.scenario<>'' and a.scenario<>'1' and c.status<>3) then a.scenario else '' end,
        cast(sum(case when a.deduction_num is null or a.deduction_num = '' then '1' else a.deduction_num end) as bigint),                
        0,
        0,
        case  when (a.is_cn_sdk is null or a.is_cn_sdk='null') then 0 else a.is_cn_sdk end,
        case when os_platform=2 and length(model)>=4 and upper(substr(model,1,4))='IPAD' then 2 else 1 end,
        0,
        0,
        case when (os_platform = '2' and ((length(idfa) > 0 and idfa <> '00000000-0000-0000-0000-000000000000') or (idfa = '' and gdpr_cs = '1'))) then 1 else 0 end as idfa_exist_tag,
        0,
        0,
        0,
        a.abtest_id
    from 
        ${DB_BIGDATA}.${T_BIGDATA_IMPRESSION_V2} as a
    left outer join
        ${DB_BIGDATA}.${T_BIGDATA_UNIT} as b
    on
        a.yyyy='${yyyy}'
        and a.mm='${mm}'
        and a.dd='${dd}'
        and a.hh='${hh}'
        and b.yyyy='${yyyy}'
        and b.mm='${mm}'
        and b.dd='${dd}'
        and a.unit_id=b.id
    left outer join
        ${DB_BIGDATA}.${T_BIGDATA_SCENARIO} as c
    on
        a.yyyy='${yyyy}'
        and a.mm='${mm}'
        and a.dd='${dd}'
        and a.hh='${hh}'
        and a.placement_raw_id=c.placement_id
        and a.scenario=c.uuid
    where 
        a.yyyy='${yyyy}'
        and a.mm='${mm}'
        and a.dd='${dd}'
        and a.hh='${hh}'
        and a.is_refresh=0
        and a.unit_id>0
        and a.publisher_id is not null
        and a.bidprice <> 'Infinity'
        and a.bidprice >= 0
        and a.bidprice <= 100000
    group by 
        a.nw_firm_id, 
        a.group_id, 
        a.unit_id, 
        a.system_type, 
        a.sdk_version, 
        a.app_vn, 
        a.os_platform, 
        a.country_code, 
        a.publisher_id, 
        a.app_raw_id, 
        a.placement_raw_id, 
        a.format, 
        a.sc_type,
        a.channel,
        a.sub_channel,
        b.network_id,
        a.traffic_group_id,
        a.bidtype,
        case when (a.scenario is null or a.scenario='' or c.uuid is null or c.status<>3) then '1' else a.scenario end,
        case when (a.scenario is not null and a.scenario<>'' and a.scenario<>'1' and c.uuid is null) then 1 when (a.scenario is not null and a.scenario<>'' and a.scenario<>'1' and c.status<>3) then 2 else 0 end,
        case when (a.scenario is not null and a.scenario<>'' and a.scenario<>'1' and c.uuid is null or a.scenario is not null and a.scenario<>'' and a.scenario<>'1' and c.status<>3) then a.scenario else '' end,
        case  when (a.is_cn_sdk is null or a.is_cn_sdk='null') then 0 else a.is_cn_sdk end,
        case when os_platform=2 and length(model)>=4 and upper(substr(model,1,4))='IPAD' then 2 else 1 end,
        case when (os_platform = '2' and ((length(idfa) > 0 and idfa <> '00000000-0000-0000-0000-000000000000') or (idfa = '' and gdpr_cs = '1'))) then 1 else 0 end,
        a.abtest_id
"

spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \
--name "BigData_CommonSparkDateTimeJob_merge_impression_dt${yyyy_mm_dd_hh}" \
--master yarn  \
--deploy-mode cluster \
--executor-memory 2g \
--driver-memory 2g \
--executor-cores 2 \
--num-executors 8 \
--conf spark.dynamicAllocation.enabled=false \
--conf spark.dynamicAllocation.minExecutors=8 \
--conf spark.dynamicAllocation.maxExecutors=64 \
--conf spark.core.connection.ack.wait.timeout=300 \
--files "${HIVE_SITE_PATH}" \
${SPARK_SQL_JAR} ${CLIENT_TMP_LOG_HIVE_PATH} "${yyyy_mm_dd_hh}" "${hql}" "${DB_BIGDATA}.${T_BIGDATA_REPORT_TK_HOUR_ORC}"  "dt='${yyyy}-${mm}-${dd}', hh='${hh}', dimen='3'" "overwrite"\
```

1. 这里是操作的主表为`v2`表，join的表一般只能是`v1`表，因为文本的解析是一起执行的，但是`各个任务的v2表`什么时候更新完毕暂时是不确定的。
2. 这里看到分区信息中有一个 `dimen = '3'`，是和接下来的 `${T_BIGDATA_REPORT_TK_HOUR_ORC}` 有关系。这是一个tk数据的汇总表，几乎所有维度的数据最后都会汇集在这里，加上我们有不同的任务的数据都写入到这个表，所以我们加一个dimen的分区，便于区分不同的`数据的来源`。

### merge_tracking_hour

> 清洗orc的表数据到非orc的表，数据基本可以认为是一份基本可以出仓的数据了

```shell
hql="select
        ${yyyy}${mm}${dd},
        ${hh},
        case nw_firm_id when '' then 0 else nw_firm_id end,
        case group_id when '' then 0 else group_id end,
        case nw_firm_id when '35' then 1 else unit_id end,
        case system_type when '' then 0 else system_type end,
        case sdk_version when 'null' then '0' else sdk_version end,
        case when app_vn = 'null' then '0' when length(app_vn) >= 50 then '0' else regexp_replace(app_vn,'\\\\\\\\0000','') end as app_vn,
        case os_platform when '' then 0 else os_platform end,
        case geo_short when 'null' then '00' else geo_short end,
        case publisher_id when '' then 0 else publisher_id end,
        case app_id when '' then 0 else app_id end,
        case placement_id when '' then 0 when 'null' then 0 else placement_id end,
        case format when '' then 0 else format end,
        case sc_type when '' then 0 else sc_type end,
        cast(sum(request) as bigint),
        cast(sum(filled_request) as bigint),
        cast(sum(impression) as bigint),
        cast(sum(click) as bigint),
        cast(sum(load) as bigint),
        cast(sum(filled_load) as bigint),
        cast(sum(rv_play_start) as bigint),
        cast(sum(rv_play_complete) as bigint),
        case channel when '' then '' else channel end,
        case sub_channel when '' then '' else sub_channel end,
        cast(sum(app_request) as bigint),
        cast(sum(placement_request) as bigint),
        cast(sum(show) as bigint),
        ${timeStamp},
        cast(sum(impression_optimize) as bigint),
        case network_id when '' then 0 else network_id end,
        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,
        case  when (bidtype is null or bidtype='') then 0 else bidtype end,
        cast(sum(bid_request) as bigint),
        cast(sum(bid_response) as bigint),
        cast(sum(case when dimen='12' then estimated_revenue else 0 end) as float),
        case when (scenario is null or scenario='') then '1' else scenario end,
        case when (error_type is null or error_type='') then 0 else error_type end,
        case when (error_msg is null or error_msg='') then '' else error_msg end,
        cast(sum(case when (fake_impression_optimize>0 and dimen='12') then fake_impression_optimize else 0 end) as bigint),
        cast(sum(case when (fake_filled_load is null) then 0 else fake_filled_load end) as bigint),
        cast(sum(case when (fake_filled_request is null) then 0 else fake_filled_request end) as bigint),
        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,
        case when device_type is null then 1 else device_type end,
        cast(sum(load_cost_time) as bigint),
        cast(sum(request_cost_time) as bigint),
        idfa_exist_tag,
        case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end,
        cast(sum(case when (scenario_entry is null or scenario_entry='') then 0 else scenario_entry end) as bigint),
        cast(sum(case when (scenario_entry_ready is null or scenario_entry_ready='') then 0 else scenario_entry_ready end) as bigint),
        abtest_id
    from 
        ${DB_BIGDATA}.${T_BIGDATA_REPORT_TK_HOUR_ORC}
    where 
        dt='${yyyy}-${mm}-${dd}'
        and hh='${hh}'
        and dimen in ('1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16')
        and unit_id is not null
        and publisher_id is not null
        and app_id is not null
        and placement_id is not null
        and format is not null
        and sc_type is not null
        and system_type is not null 
        and os_platform is not null 
        and sdk_version is not null 
        and app_vn is not null 
        and channel is not null 
        and sub_channel is not null 
        and group_id is not null
        and nw_firm_id is not null
        and network_id is not null
        and group_id>=0
        and group_id<=2147483647
        and format<=10
        and estimated_revenue <> 'Infinity'
        and is_cn_sdk<=1
        and length(geo_short)<=2
    group by
        case nw_firm_id when '' then 0 else nw_firm_id end,
        case group_id when '' then 0 else group_id end,
        case nw_firm_id when '35' then 1 else unit_id end,
        case system_type when '' then 0 else system_type end,
        case sdk_version when 'null' then '0' else sdk_version end,
        case when app_vn = 'null' then '0' when length(app_vn) >= 50 then '0' else regexp_replace(app_vn,'\\\\\\\\0000','') end,
        case os_platform when '' then 0 else os_platform end,
        case geo_short when 'null' then '00' else geo_short end,
        case publisher_id when '' then 0 else publisher_id end,
        case app_id when '' then 0 else app_id end,
        case placement_id when '' then 0 when 'null' then 0 else placement_id end,
        case format when '' then 0 else format end,
        case sc_type when '' then 0 else sc_type end,
        case channel when '' then '' else channel end,
        case sub_channel when '' then '' else sub_channel end,
        case network_id when '' then 0 else network_id end,
        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,
        case  when (bidtype is null or bidtype='') then 0 else bidtype end,
        case when (scenario is null or scenario='') then '1' else scenario end,
        case when (error_type is null or error_type='') then 0 else error_type end,
        case when (error_msg is null or error_msg='') then '' else error_msg end,
        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,
        case when device_type is null then 1 else device_type end,
        idfa_exist_tag,
        abtest_id
"

spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \
--name "BigData_CommonSparkDateTimeJob_merge_report_hour_dt${yyyy_mm_dd_hh}" \
--master yarn  \
--deploy-mode cluster \
--executor-memory 2g \
--driver-memory 2g \
--executor-cores 2 \
--num-executors 8 \
--conf spark.dynamicAllocation.enabled=false \
--conf spark.dynamicAllocation.minExecutors=8 \
--conf spark.dynamicAllocation.maxExecutors=64 \
--conf spark.core.connection.ack.wait.timeout=300 \
--files "${HIVE_SITE_PATH}" \
${SPARK_SQL_JAR} ${CLIENT_TMP_LOG_HIVE_PATH} "${yyyy_mm_dd_hh}" "${hql}" "${DB_BIGDATA}.${T_BIGDATA_REPORT_TK_HOUR}"  "dt='${yyyy}-${mm}-${dd}', hh='${hh}', dimen='0'" "overwrite"\
```

1. where条件加上了`dimen in ('1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16')`，代表要拿到所有父节点的任务数据
2. 其他的where条件代表在这个节点，不可能存在这些字段没有数据
3. 把数据写入到非orc的表中，并且 `dimen = '0'`

### to_db_tracking_hour

> 数据出仓到gp

```shell

dimension_tk_hour_field="date_time,hour,nw_firm_id,group_id,unit_id,system,sdk_version,app_version,platform,geo_short,publisher_id,app_id,placement_id,format,sc_type,channel,sub_channel,hour_timestamp,network_id,traffic_group_id,bid_type,scenario,error_type,error_msg,is_cn_sdk,device_type,idfa_exist_tag "
hive_dimension_tk_hour_field="date_time,hour,nw_firm_id,group_id,unit_id,system_type,sdk_version,app_vn,os_platform,geo_short,publisher_id,app_id,placement_id,format,sc_type,channel,sub_channel,hour_timestamp,network_id,traffic_group_id,bidtype,scenario,error_type,error_msg,is_cn_sdk,device_type,idfa_exist_tag"
select_tk_hour_field="${hive_dimension_tk_hour_field},cast(sum(request) as bigint),cast(sum(filled_request) as bigint),cast(sum(impression) as bigint),cast(sum(click) as bigint),cast(sum(load) as bigint),cast(sum(filled_load) as bigint),cast(sum(rv_play_start) as bigint),cast(sum(rv_play_complete) as bigint),cast(sum(app_request) as bigint),cast(sum(placement_request) as bigint),cast(sum(show) as bigint),cast(sum(impression_optimize) as bigint),cast(sum(bid_request) as bigint),cast(sum(bid_response) as bigint),cast(sum(estimated_revenue) as float),cast(sum(fake_impression_optimize) as bigint),cast(sum(fake_filled_load) as bigint),cast(sum(fake_filled_request) as bigint),cast(sum(load_cost_time) as bigint),cast(sum(request_cost_time) as bigint), case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end as bid_response_ecpm,cast(sum(scenario_entry) as bigint),cast(sum(scenario_entry_ready) as bigint) "
export_tk_hour_field="${dimension_tk_hour_field},request,filled_request,impression,click,loads,filled_loads,rv_start,rv_complete,strategy_app_request,strategy_placement_request,shows,impression_optimize,bid_request,bid_filled_request,estimated_revenue,fake_impression_optimize,fake_filled_load,fake_filled_request,load_cost_time,request_cost_time,bid_filled_request_ecpm,scenario_entry,scenario_entry_ready"

function export_tk_hour_func() {
  stat_source_hour='report_tk_hour'
  gp_delete_timeStamp=$(expr ${timeStamp} + 1 \* 3600)
  del_sql="delete from ${stat_source_hour} where date_time = ${yyyy}${mm}${dd} and hour=${hh} and add_timestamp<${gp_delete_timeStamp} and source_type not in (2);"
  select_sql="select ${select_tk_hour_field} from ${DB_BIGDATA}.${T_BIGDATA_REPORT_TK_HOUR} where dt='${yyyy}-${mm}-${dd}' and hh='${hh}' and dimen='0' group by ${hive_dimension_tk_hour_field}"
  # 针对两个库的删除和导入
  export_to_pgsql_by_select_data "${select_sql}" ${stat_source_hour} bigdata_job_base_data_report_hour_${RANDOM}_tmp.log "${del_sql}" '|' "(${export_tk_hour_field})"
}

export_to_pgsql_by_select_data() {
  el_sql=$1
  el_stat_source=$2
  el_tmp_file=$3
  el_delete_sql=$4
  el_terminated=$5
  el_rows=$6

  filepath=$(
    cd "$(dirname "$0")"
    pwd
  )
  fileTmpDir=tmp_${el_stat_source}/${el_stat_source}/

  if [ -f "${el_tmp_file}" ]; then
    rm ${el_tmp_file}
  fi
  hive -e "
              INSERT OVERWRITE  DIRECTORY '${fileTmpDir}'
              ROW format delimited fields terminated BY '${el_terminated}'
              ${el_sql}
            "
  hadoop fs -getmerge ${fileTmpDir}* ${el_tmp_file}
  head -n 20 ${el_tmp_file}

  #export to pgsql
  echo "copy ${el_stat_source}  ${el_rows} from STDIN delimiter as '${el_terminated}';"
  sql="copy ${el_stat_source}  ${el_rows} from STDIN delimiter as '${el_terminated}'"

  if [[ ${PG_BI_DB_ENABLE} = true ]]; then
    psql "host=${PG_BI_DB_HOST} port=${PG_BI_DB_PORT} user=${PG_BI_DB_USER} password=${PG_BI_DB_PWD} dbname=${PG_BI_DB_NAME}" -c "${el_delete_sql}"
    psql "host=${PG_BI_DB_HOST} port=${PG_BI_DB_PORT} user=${PG_BI_DB_USER} password=${PG_BI_DB_PWD} dbname=${PG_BI_DB_NAME}" -c "${sql}" <${el_tmp_file}
  fi

  if [[ ${PG_REL_BI_DB_ENABLE} = true ]]; then
    psql "host=${PG_REL_BI_DB_HOST} port=${PG_REL_BI_DB_PORT} user=${PG_REL_BI_DB_USER} password=${PG_REL_BI_DB_PWD} dbname=${PG_REL_BI_DB_NAME}" -c "${el_delete_sql}"
    psql "host=${PG_REL_BI_DB_HOST} port=${PG_REL_BI_DB_PORT} user=${PG_REL_BI_DB_USER} password=${PG_REL_BI_DB_PWD} dbname=${PG_REL_BI_DB_NAME}" -c "${sql}" <${el_tmp_file}
  fi

  rm ${el_tmp_file}
  hadoop fs -rmr ${fileTmpDir}
}

export_tk_hour_func
```

1. 把数据通过sql查出来，然后通过 `|` 符号进行分割，然后写入到一个临时文件中
2. 删除当前小时周期下的数据
3. 通过 `copy` 命令列出所有的字段，然后通过标准输入`STDIN` 作为分隔符，从`临时文件中`导入数据

### to_db_traking

> 把小时级表的数据合并到天级表

```shell
# 天表的数据都来自于小时表，从小时表导出后导入天表
# tk表及东八区的时间和小时表的时间一样，0时区和西八区需要特殊处理一下
currentUnixTime=$(date '+%s')
tmpTkHourFileName="/data/gp_tk_tmp/report_tk_utce8_${currentUnixTime}.log" # 此文件是在GP服务器上面的，需要有专门的任务去做清除

# 参照收益任务hour小时数据到天级数据的处理方式: export_report_unit_hour.sh
CurrentDay=${utce8_yyyy}${utce8_mm}${utce8_dd}

# 机器为零时区
startTimeStamp=`date -d "8 hour ago ${utce8_yyyy}-${utce8_mm}-${utce8_dd} 00:00:00" +%s`
endTimeStamp=`date -d "8 hour ago ${utce8_yyyy}-${utce8_mm}-${utce8_dd} 23:59:59" +%s`

# estimate_revenue_api,estimate_currency_revenue_api,ready_request,ready_success,show_failed 由ltv任务写入
pgSearchSql="
SELECT
  ${CurrentDay},
  nw_firm_id,
  group_id,
  geo_short,
  publisher_id,
  channel,
  sub_channel,
  system,
  platform,
  app_id,
  sdk_version,
  app_version,
  placement_id,
  unit_id,
  format,
  sc_type,
  SUM(request),
  SUM(filled_request),
  SUM(strategy_app_request),
  SUM(strategy_placement_request),
  SUM(impression),
  SUM(shows),
  SUM(click),
  SUM(loads),
  SUM(filled_loads),
  SUM(rv_start),
  SUM(rv_complete),
  SUM(impression_optimize),
  network_id,
  bid_type,
  SUM(estimated_revenue),
  traffic_group_id,
  SUM(bid_request),
  SUM(bid_filled_request),
  case when (scenario is null or scenario='') then '1' else scenario end,
  error_type,
  case when (error_msg is null or error_msg='') then '' else error_msg end,
  SUM(fake_impression_optimize),
  SUM(fake_filled_load),
  SUM(fake_filled_request),
  is_cn_sdk,
  device_type,
  source_type,
  SUM(load_cost_time),
  SUM(request_cost_time),
  idfa_exist_tag,
  case coalesce(sum(bid_filled_request),0) when 0  then 0.0 else cast(sum(bid_filled_request * bid_filled_request_ecpm) / sum(bid_filled_request) as float) end,
  SUM(scenario_entry),
  SUM(scenario_entry_ready)
FROM
  report_tk_hour
WHERE
  hour_timestamp >= ${startTimeStamp}
  AND hour_timestamp <= ${endTimeStamp}
  AND source_type NOT IN (2)
  AND add_timestamp < ${gp_delete_timeStamp}
GROUP BY
  nw_firm_id,
  group_id,
  geo_short,
  publisher_id,
  channel,
  sub_channel,
  system,
  platform,
  app_id,
  sdk_version,
  app_version,
  placement_id,
  unit_id,
  format,
  sc_type,
  network_id,
  bid_type,
  traffic_group_id,
  case when (scenario is null or scenario='') then '1' else scenario end,
  error_type,
  case when (error_msg is null or error_msg='') then '' else error_msg end,
  is_cn_sdk,
  device_type,
  source_type,
  idfa_exist_tag
  "

# 导出数据，report_tk 和 report_tk_utce8 表数据一致，只用导出一次便可
outputSql="COPY ( ${pgSearchSql} ) TO '${tmpTkHourFileName}' WITH CSV;"
export PGPASSWORD=${PG_BI_DB_PWD}
psql --host=${PG_BI_DB_HOST} --port=${PG_BI_DB_PORT} --user=${PG_BI_DB_USER} --dbname=${PG_BI_DB_NAME} -c "${outputSql}"

deleteSql="DELETE FROM report_tk_utce8 WHERE date_time = ${CurrentDay}  AND source_type NOT IN (2) AND add_timestamp < ${gp_delete_timeStamp};"
inputSql="COPY report_tk_utce8 ( ${rowNames} ) FROM '${tmpTkHourFileName}' WITH CSV;"

export PGPASSWORD=${PG_BI_DB_PWD}
respTag10=`psql --host=${PG_BI_DB_HOST} --port=${PG_BI_DB_PORT} --user=${PG_BI_DB_USER} --dbname=${PG_BI_DB_NAME} <<EOF
BEGIN;
${deleteSql}
${inputSql}
COMMIT;
EOF`

echo ${respTag10}
if [[ ${respTag10} =~ "ROLLBACK" ]] ; then
  exit 1
fi
```

1. 先把数据导出到一个临时文件`${tmpTkHourFileName}`
2. 再把数据从临时文件导入到另外一个天级表`report_tk_utce8`
3. utc0/utcw8时区的一样的操作

### merge_tracking_hour

```shell
#转换成utc8时间
utce8_day_start_timeStamp=`date -d "${utce8_yyyy}-${utce8_mm}-${utce8_dd} 00:00:00" +%s`
utce8_day_end_timeStamp=`date -d "${utce8_yyyy}-${utce8_mm}-${utce8_dd} 23:00:00" +%s`
while_run_stamp=${utce8_day_start_timeStamp}
utce8_utc0_hour_where='('

while [ "${while_run_stamp}" -le "${utce8_day_end_timeStamp}" ]
do
    tmp_run_stamp=`expr ${while_run_stamp} - 8 \* 3600`
    tmp_date_time=`date -d @${tmp_run_stamp} "+%Y-%m-%d-%H"`
    tmp_yyyy=`echo ${tmp_date_time}|awk -F- '{print $1}'`
    tmp_mm=`echo ${tmp_date_time}|awk -F- '{print $2}'`
    tmp_dd=`echo ${tmp_date_time}|awk -F- '{print $3}'`
    tmp_hh=`echo ${tmp_date_time}|awk -F- '{print $4}'`
    if [ "${while_run_stamp}" == "${utce8_day_start_timeStamp}" ]
        then
           utce8_utc0_hour_where="${utce8_utc0_hour_where}dt='${tmp_yyyy}-${tmp_mm}-${tmp_dd}' and hh='${tmp_hh}'"
        else
           utce8_utc0_hour_where="${utce8_utc0_hour_where} or dt='${tmp_yyyy}-${tmp_mm}-${tmp_dd}' and hh='${tmp_hh}'"
        fi
        while_run_stamp=`expr ${while_run_stamp} + 3600`
done
utce8_utc0_hour_where="${utce8_utc0_hour_where})"

hql="select
        ${utce8_yyyy}${utce8_mm}${utce8_dd},
        nw_firm_id,
        group_id,
        unit_id,
        system_type,
        sdk_version,
        app_vn,
        os_platform,
        geo_short,
        publisher_id,
        app_id,
        placement_id,
        format,
        sc_type,
        cast(sum(request) as bigint),
        cast(sum(filled_request) as bigint),
        cast(sum(impression) as bigint),
        cast(sum(click) as bigint),
        cast(sum(load) as bigint),
        cast(sum(filled_load) as bigint),
        cast(sum(rv_play_start) as bigint),
        cast(sum(rv_play_complete) as bigint),
        channel,
        sub_channel,
        cast(sum(app_request) as bigint),
        cast(sum(placement_request) as bigint),
        cast(sum(show) as bigint),
        cast(sum(impression_optimize) as bigint),
        case  when network_id is null then 0 else network_id end,
        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,
        case  when (bidtype is null or bidtype='') then 0 else bidtype end,
        cast(sum(case  when (bid_request is null or bid_request='') then 0 else bid_request end) as bigint),
        cast(sum(case  when (bid_response is null or bid_response='') then 0 else bid_response end) as bigint),
        cast(sum(case  when (estimated_revenue is null or estimated_revenue='') then 0 else estimated_revenue end) as float),
        0,
        0,
        case when (scenario is null or scenario='') then '1' else scenario end,
        case when (error_type is null or error_type='') then 0 else error_type end,
        case when (error_msg is null or error_msg='') then '' else error_msg end,
        cast(sum(case when (fake_impression_optimize is null or fake_impression_optimize='') then impression_optimize else fake_impression_optimize end) as bigint),
        cast(sum(case when (fake_filled_load is null or fake_filled_load='') then filled_load else fake_filled_load end) as bigint),
        cast(sum(case when (fake_filled_request is null or fake_filled_request='') then filled_request else fake_filled_request end) as bigint),
        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,
        0,
        0,
        0,
        case when device_type is null then 1 else device_type end,
        cast(sum(case when load_cost_time is null or load_cost_time<0 then 0 else load_cost_time end) as bigint),
        cast(sum(case when request_cost_time is null or request_cost_time<0 then 0 else request_cost_time end) as bigint),
        case when idfa_exist_tag is null then 0 else idfa_exist_tag end,
        case coalesce(sum(bid_response),0) when 0  then 0.0 else cast(sum(bid_response * coalesce(bid_response_ecpm,0)) / sum(bid_response) as float) end,
        cast(coalesce(sum(scenario_entry),0) as bigint),
        cast(coalesce(sum(scenario_entry_ready),0) as bigint),
        abtest_id
    from 
        ${DB_BIGDATA}.${T_BIGDATA_REPORT_TK_HOUR}
    where 
        ${utce8_utc0_hour_where}
        and dimen='0'
        and group_id>=0
        and group_id<=2147483647
    group by 
        nw_firm_id,
        group_id,
        unit_id,
        system_type,
        sdk_version,
        app_vn,
        os_platform,
        geo_short,
        publisher_id,
        app_id,
        placement_id,
        format,
        sc_type,
        channel,
        sub_channel,
        case
            when network_id is null then 0
        else network_id
        end,
        case  when (traffic_group_id is null or traffic_group_id='') then 0 else traffic_group_id end,
        case  when (bidtype is null or bidtype='') then 0 else bidtype end,
        case when (scenario is null or scenario='') then '1' else scenario end,
        case when (error_type is null or error_type='') then 0 else error_type end,
        case when (error_msg is null or error_msg='') then '' else error_msg end,
        case  when (is_cn_sdk is null or is_cn_sdk='null' or is_cn_sdk='') then 0 else is_cn_sdk end,
        case when device_type is null then 1 else device_type end,
        case when idfa_exist_tag is null then 0 else idfa_exist_tag end,
        abtest_id
"

spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \
--name "BigData_CommonSparkDateTimeJob_merge_report_utce8_dt${yyyy_mm_dd_hh}" \
--master yarn  \
--deploy-mode cluster \
--executor-memory 2g \
--driver-memory 2g \
--executor-cores 2 \
--num-executors 8 \
--conf spark.dynamicAllocation.enabled=false \
--conf spark.dynamicAllocation.minExecutors=8 \
--conf spark.dynamicAllocation.maxExecutors=64 \
--conf spark.core.connection.ack.wait.timeout=300 \
--files "${HIVE_SITE_PATH}" \
${SPARK_SQL_JAR} ${CLIENT_TMP_LOG_HIVE_PATH} "${yyyy_mm_dd_hh}" "${hql}" "${DB_BIGDATA}.${T_BIGDATA_REPORT_TK_UTCE8}"  "dt='${utce8_yyyy}-${utce8_mm}-${utce8_dd}', dimen='0'" "overwrite"\
```

1. 数据通过小时表转成`report_tk`表，并且 `dimen='0'`

### abtest_tk_xxx

> 业务需要，根据abtest_id，把数据分别成不同的traffi_group_id，原始的数据的abtest_id字段会变成&&，分别出来的会变成00

```shell
tk_dimen='0'
abtest_tk_tmp_dimen="10${tk_dimen}"
zone_type=$1

if [ -n "${run_type}" ]; then
  if [[ ${run_type} = 'utcw8' ]]; then
    zone_type="3"
  else
    if [[ ${run_type} = 'utc0' ]]; then
      zone_type="2"
    else
      zone_type="1"
    fi
  fi
fi

zone_yyyy="${yyyy}"
zone_mm="${mm}"
zone_dd="${dd}"
zone_tk_table="${T_BIGDATA_REPORT_TK_UTCE8}"
zone_abtest_tk_table="${T_BIGDATA_REPORT_ABTEST_TK_UTCE8}"
zone_gp_abtest_tk_table="report_abtest_tk_utce8"

if [ "${zone_type}" == "2" ]; then
  zone_yyyy="${utc0_yyyy}"
  zone_mm="${utc0_mm}"
  zone_dd="${utc0_dd}"
  zone_tk_table="${T_BIGDATA_REPORT_TK_UTC0}"
  zone_abtest_tk_table="${T_BIGDATA_REPORT_ABTEST_TK_UTC0}"
  zone_gp_abtest_tk_table="report_abtest_tk_utc0"
else
  if [ "${zone_type}" == "3" ]; then
    zone_yyyy="${utcw8_yyyy}"
    zone_mm="${utcw8_mm}"
    zone_dd="${utcw8_dd}"
    zone_tk_table="${T_BIGDATA_REPORT_TK_UTCW8}"
    zone_abtest_tk_table="${T_BIGDATA_REPORT_ABTEST_TK_UTCW8}"
    zone_gp_abtest_tk_table="report_abtest_tk_utcw8"
  fi
fi

hql="select
        date_time,
        nw_firm_id,
        group_id,
        unit_id,
        sdk_version,
        app_vn,
        os_platform,
        geo_short,
        publisher_id,
        app_id,
        placement_id,
        format,
        device_type,
        channel,
        network_id,
        case when abtest_id is null then '' else abtest_id end as abtest_id,
        traffic_group_id,
        bidtype,
        cast(sum(request) as bigint),
        cast(sum(filled_request) as bigint),
        cast(sum(impression) as bigint),
        cast(sum(click) as bigint),
        cast(sum(load) as bigint),
        cast(sum(filled_load) as bigint),
        cast(sum(rv_play_start) as bigint),
        cast(sum(rv_play_complete) as bigint),
        cast(sum(show) as bigint),
        cast(sum(impression_optimize) as bigint),
        cast(sum(case  when (bid_request is null or bid_request='') then 0 else bid_request end) as bigint),
        cast(sum(case  when (bid_response is null or bid_response='') then 0 else bid_response end) as bigint),
        cast(sum(case  when (estimated_revenue is null or estimated_revenue='') then 0 else estimated_revenue end) as float),
        cast(sum(case  when (estimate_revenue_api is null or estimate_revenue_api='') then 0 else estimate_revenue_api end) as float),
        cast(sum(case  when (estimate_currency_revenue_api is null or estimate_currency_revenue_api='') then 0 else estimate_currency_revenue_api end) as float),
        cast(sum(case when (fake_impression_optimize is null or fake_impression_optimize='') then impression_optimize else fake_impression_optimize end) as bigint),
        cast(sum(case when (fake_filled_load is null or fake_filled_load='') then filled_load else fake_filled_load end) as bigint),
        cast(sum(case when (fake_filled_request is null or fake_filled_request='') then filled_request else fake_filled_request end) as bigint),
        sum(ready_request),
        sum(ready_success),
        sum(show_failed)
    from 
        ${DB_BIGDATA}.${zone_tk_table}
    where 
        dt='${zone_yyyy}-${zone_mm}-${zone_dd}'
        and dimen='${tk_dimen}'
    group by 
        date_time,
        nw_firm_id,
        group_id,
        unit_id,
        sdk_version,
        app_vn,
        os_platform,
        geo_short,
        publisher_id,
        app_id,
        placement_id,
        format,
        device_type,
        channel,
        network_id,
        case when abtest_id is null then '' else abtest_id end,
        traffic_group_id,
        bidtype
        "

spark-submit --class com.BigData.spark.parse.jobs.ParseAndSpiltAbtestTkJob \
  --name "BigData_ParseAndSpiltAbtestTkJob_abtest_dt${yyyy_mm_dd_hh}_${zone_type}" \
  --master yarn \
  --deploy-mode cluster \
  --executor-memory 2g \
  --driver-memory 2g \
  --executor-cores 2 \
  --num-executors 8 \
  --conf spark.dynamicAllocation.enabled=false \
  --conf spark.dynamicAllocation.minExecutors=32 \
  --conf spark.dynamicAllocation.maxExecutors=64 \
  --conf spark.core.connection.ack.wait.timeout=300 \
  --files "${HIVE_SITE_PATH}" \
  ${SPARK_SQL_JAR} ${CLIENT_TMP_LOG_PATH} "${yyyy_mm_dd_hh}" "${hql}" "abtest_id" "traffic_group_id" "${DB_BIGDATA}.${zone_abtest_tk_table}" "dt='${zone_yyyy}-${zone_mm}-${zone_dd}', dimen='${abtest_tk_tmp_dimen}'"

# 合并分解后的数据
# 再次减少维度数据
merge_hql=" 
select
        date_time,
        0 as nw_firm_id,
        0 as group_id,
        0 as unit_id,
        '',
        '',
        0 as os_platform,
        geo_short,
        publisher_id,
        app_id,
        placement_id,
        -1 as format,
        -1 as device_type,
        '',
        0,
        case when abtest_id <>'&&' then '00' else abtest_id end as abtest_id,
        traffic_group_id,
        -1 as bidtype,
        cast(sum(request) as bigint),
        cast(sum(filled_request) as bigint),
        cast(sum(impression) as bigint),
        cast(sum(click) as bigint),
        cast(sum(load) as bigint),
        cast(sum(filled_load) as bigint),
        cast(sum(rv_play_start) as bigint),
        cast(sum(rv_play_complete) as bigint),
        cast(sum(show) as bigint),
        cast(sum(impression_optimize) as bigint),
        cast(sum(case  when (bid_request is null or bid_request='') then 0 else bid_request end) as bigint),
        cast(sum(case  when (bid_response is null or bid_response='') then 0 else bid_response end) as bigint),
        cast(sum(case  when (estimated_revenue is null or estimated_revenue='') then 0 else estimated_revenue end) as float),
        cast(sum(case  when (estimate_revenue_api is null or estimate_revenue_api='') then 0 else estimate_revenue_api end) as float),
        cast(sum(case  when (estimate_currency_revenue_api is null or estimate_currency_revenue_api='') then 0 else estimate_currency_revenue_api end) as float),
        cast(sum(case when (fake_impression_optimize is null or fake_impression_optimize='') then impression_optimize else fake_impression_optimize end) as bigint),
        cast(sum(case when (fake_filled_load is null or fake_filled_load='') then filled_load else fake_filled_load end) as bigint),
        cast(sum(case when (fake_filled_request is null or fake_filled_request='') then filled_request else fake_filled_request end) as bigint),
        sum(ready_request),
        sum(ready_success),
        sum(show_failed)
    from 
        ${DB_BIGDATA}.${zone_abtest_tk_table}
    where 
        dt='${zone_yyyy}-${zone_mm}-${zone_dd}'
        and dimen='${abtest_tk_tmp_dimen}'
    group by 
        date_time,
        geo_short,
        publisher_id,
        app_id,
        placement_id,
        case when abtest_id <>'&&' then '00' else abtest_id end,
        traffic_group_id
    "

spark-submit --class com.BigData.spark.jobs.common.CommonSparkDateTimeJob \
  --name "BigData_CommonSparkDateTimeJob_merge_strategy_app_dt${yyyy_mm_dd_hh}" \
  --master yarn \
  --deploy-mode cluster \
  --executor-memory 2g \
  --driver-memory 2g \
  --executor-cores 2 \
  --num-executors 8 \
  --conf spark.dynamicAllocation.enabled=false \
  --conf spark.dynamicAllocation.minExecutors=32 \
  --conf spark.dynamicAllocation.maxExecutors=64 \
  --conf spark.core.connection.ack.wait.timeout=300 \
  --files "${HIVE_SITE_PATH}" \
  ${SPARK_SQL_JAR} ${CLIENT_TMP_LOG_PATH} "${yyyy_mm_dd_hh}" "${merge_hql}" "${DB_BIGDATA}.${zone_abtest_tk_table}" "dt='${zone_yyyy}-${zone_mm}-${zone_dd}', dimen='${tk_dimen}'" "overwrite"

source ./export_tk_util.sh

export_abtest_tk_func "${DB_BIGDATA}.${zone_abtest_tk_table}" " dt='${zone_yyyy}-${zone_mm}-${zone_dd}' and dimen='${tk_dimen}' and traffic_group_id>0" "${zone_gp_abtest_tk_table}" "date_time=${zone_yyyy}${zone_mm}${zone_dd} and add_timestamp<${gp_delete_timeStamp} and source_type not in (2)"
```

1. 把数据传递进到spark脚本中，在spark中把数据进行分裂，然后存放在对应的`dimen = '100'`
2. 从表中的`dimen = '100'`中提取数据，把数据的维度再次缩小

spark代码如下：

```spark
object ParseAndSpiltAbtestTkJob {
  def main(args: Array[String]): Unit = {
    val tmpPath = parseArg(args(0))
    //format:yyyy-mm-dd-hh
    val dt = args(1)
    val selectSql = parseArg(args(2))
    val abtestField = args(3)
    val trafficGroupField = args(4)
    val outputTable = parseArg(args(5))
    val partition = args(6)
    var trafficGroupFieldRaw = "&&"
    var trafficGroupFieldNew = ""
    if (args.length >= 8) {
      trafficGroupFieldRaw = args(7)
    }
    if (args.length >= 9) {
      trafficGroupFieldNew = args(8)
    }

    val sparkSession: SparkSession = SparkSession.builder
      //      .master("local[3]")
      .enableHiveSupport() // self-explanatory, isn't it?
      .config("spark.sql.warehouse.dir", tmpPath)
      .getOrCreate

    sparkSession.sqlContext.setConf("hive.merge.mapfiles", "true")
    sparkSession.sqlContext.setConf("mapred.max.split.size", "256000000")
    sparkSession.sqlContext.setConf("mapred.min.split.size.per.node", "192000000")
    sparkSession.sqlContext.setConf("mapred.min.split.size.per.rack", "192000000")
    sparkSession.sqlContext.setConf("hive.input.format", "org.apache.hadoop.hive.ql.io.CombineHiveInputFormat")

    val rawData = sparkSession.sql(selectSql)
    val newRdd: RDD[Row] = rawData.rdd.map(row => {
      //        System.out.println("--------------------------------------", row.toString())
      var resultList: ArrayBuffer[Row] = new ArrayBuffer[Row]()
      val tkRows = mapSpiltFunc(row, abtestField, trafficGroupField, trafficGroupFieldRaw, trafficGroupFieldNew)
      if (tkRows != null && tkRows.nonEmpty) {
        resultList ++= tkRows
      }
      resultList
    }).flatMap(row => row)
    //通过时间戳随机表名
    val time = System.currentTimeMillis() % 100000000;
    val tmpTable = "spark_CommonSparkDateTimeJob_" + time + "_table"
    sparkSession.createDataFrame(newRdd, rawData.schema).registerTempTable(tmpTable)
    val insertString = "insert overwrite table " + outputTable + " partition(" + partition + ") select * from " + tmpTable
    sparkSession.sql(insertString)
    sparkSession.stop()
  }

  def parseArg(arg: String): String = {
    var tmpArg = arg
    if (tmpArg.startsWith("'")) {
      tmpArg = tmpArg.substring(1);
    }
    if (tmpArg.endsWith("'")) {
      tmpArg = tmpArg.substring(0, tmpArg.length() - 1);
    }
    tmpArg;
  }

  def mapSpiltFunc(row: Row, abtestField: String, trafficGroupField: String, trafficGroupFieldRaw: String, trafficGroupFieldNew: String): ArrayBuffer[Row] = {
    var resultList: ArrayBuffer[Row] = new ArrayBuffer[Row]()
    val abtest = row.getAs[String](abtestField)
    val rowRawArray = row.toSeq.toArray
    val trafficGroupIndex = row.fieldIndex(trafficGroupField)
    val abtestGroupIndex = row.fieldIndex(abtestField)
    val curtGroupId = row.getAs[String](trafficGroupField)

    if (!TextUtils.isEmpty(curtGroupId) && curtGroupId > "0") {
      val newCurGroupRow = rowRawArray.clone()
      if (trafficGroupFieldRaw.isEmpty) {
        newCurGroupRow(abtestGroupIndex) = "&&"
      } else {
        newCurGroupRow(abtestGroupIndex) = trafficGroupFieldRaw;
      }
      resultList += Row.fromSeq(newCurGroupRow)
    }

    if (TextUtils.isEmpty(abtest) || abtest.equals("{}")) {
      return resultList
    }
    val tGroupIDs = AbtestTkParsing.getTrafficGroupIDs(abtest)
    for (groupId <- tGroupIDs) {
      if (!groupId.equals(curtGroupId)) {
        val newGroupRow = rowRawArray.clone()
        if (trafficGroupFieldNew.nonEmpty) {
          newGroupRow(abtestGroupIndex) = trafficGroupFieldNew
        }
        newGroupRow(trafficGroupIndex) = groupId;
        resultList += Row.fromSeq(newGroupRow)
      }
    }
    resultList
  }
```


至此，一个基本的`小时任务`的大数据ETL服务就做完了该作的事情了